<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Github Pages + jekyll 全面介绍极简搭建个人网站和博客</title>
    <url>/posts/1991789c/</url>
    <content><![CDATA[利用 github pages 搭建个人博客。本文指导建立 github 工程，并配置 github pages 搭建博客的全过程。
注意：图床使用 github，图片显示问题自己解决
第一步，建立 Github 仓库
首先到这里 Github，创建一个仓库。

仓库名称有固定的格式： username.github.io，其中 username 必须是 Github 账户的用户名（我的是 scottcgi），github.io 是固定的，这个地址将会成为个人站点的网站地址。另外，我们可以勾选 Initialize this repository with a README，让仓库自动创建一个 README.md 文件，我们用它来做站点的首页（当然也可以不创建，后面自行创建，或是建立 index.html 也行）。
注意： username 如果不是 Github 账户名，这个仓库就会成为 username.github.io 的子站点，比如访问地址会是：username.github.io/aaa.github.io。可见，username.github.io 是 github 默认分配给你的域名，同名仓库即代表着默认网站内容。而 username.github.io/ 仓库名称，是用来访问你的其它仓库的地址。
第二步，设置仓库开启 Github Pages
进入仓库设置界面，如图。

这里能够重新修改仓库的名称，比如这个仓库内容是 fork 别人的，就可以在这里修改成自己的 username.github.io 名称。

在 Setting 页面下有 Github Pages 的设置选项。绿色表示部署成功，每次修改仓库内容，都会出发 Github jekyll 重新编译部署，需要 1-2 分钟的时间，更新才能体现。如果有编译错误，包括 js，css，html，markdown 语法问题，都会显示红色以及错误页面和行号，同时会发邮件通知。其中，Source 有以下几个选项：
gh-pages branch 是项目新建一个分支命名为这个，使用这个分支来做站点内容。
master branch 是使用主分支也是默认的，来作为站点内容。
master branch/docs folder 是使用主分支的 docs 文件夹来作为站点内容。
None 就是禁用 Github Pages。
如果是 username.github.io 只能使用主分支，其它仓库项目可以选择其它两个。接下来 Choose a theme 是 Github 提供的内置的网站主题，选择即可应用无需其它设置。Custom domain 是自定义域名，本文暂不讨论。
第三步，使用 Github 内置主题
选择好主题，过一会刷新网站地址就已经能看到效果了，而在 Code 页面仅有两个文件。

编辑 README.md 文件的内容，就会默认显示在网站首页，_config.yml 是 jekyll 的全局配置文件，现在里面只有一句话，theme: jekyll-theme-modernist。我们可以手动修改这个 theme 主题配置，网站就会应用不同的主题。
Github 内置支持的几个主题，官方的仓库在这里：https://pages.github.com/themes，每个 README.md 里都有介绍如何设置。
那么我们现在就有两种方法来使用这些主题：
第一种，就是直接 fork 一个主题仓库，然后修改仓库名称为我们自己的，然后修改我们需要的部分。

第二种，只是简单的 Choose (Change) theme（或在_config.yml 设置 theme），然后我们对照着官方仓库的主题目录，需要改什么文件就按照同样的路径拷贝单独一个文件到自己的仓库来修改（保持路径一致），这样就可以保持自己仓库的简洁。（如果使用了 github 内置的主题，github 就会把你仓库的内容和内置主题内容合并到一起编译成静态网页。）
另外，更多主题可以参看这两个地址（不要挑花眼了）： jekyll themes 和 jekyll wiki site。
第四步，jekyll 的目录结构
我们只需要关注几个核心的目录结构如下（可以自己创建）：
- _layouts （存放页面模板，md或html文件的内容会填充模板）
- _sass（存放样式表）
- _includes （可以复用在其它页面被include的html页面）
- _posts（博客文章页面）
- assets（原生的资源文件）
  - js
  - css
  - image
- _config.yml （全局配置文件）
- index.html, index.md, README.md （首页index.html优先级最高，如果没有index，默认启用README.md文件）
- 自定义文件和目录
  更多更详细的目录结构参看jekyll官网：https://jekyllrb.com/docs/structure
第五步，jekyll 的模板编程语言 Liquid 的使用


变量  被嵌入在页面中，会在静态页面生成的时候被替换成具体的数值。常用的全局变量对象有：site 和 page。这两个对象有很多默认自带的属性，比如：，。更多的默认值参看：https://jekyllrb.com/docs/variables。


site 对象对应的就是网站范围，自定义变量放在_config.yml 中，比如 title: 标题使用访问。


page 对象对应的是单个页面，自定义变量放在每个页面的最开头，比如：


myNum:100
 
myStr:我是字符串
使用 和  访问。
条件判断语句，更多详见：https://shopify.github.io/liquid/tags/control-flow

循环迭代，更多详见：https://shopify.github.io/liquid/tags/iteration

默认函数，可以对变量进行一些处理，比如大小写转化、数学运算、格式化、排序等等，在 Liquid 中叫做 Filters。比如 {{ "Hello World!" | downcase }} 转换字符串为小写。更多内置函数详见：https://jekyllrb.com/docs/liquid/filters
第六步，使用_config.yml 文件设置 jekyll
如果不是 fork 别人的仓库，就需要自己创建一个这个文件。然后，我们就可以配置一些默认的属性来控制 jekyll 的编译过程。更多详细的内置属性详见：https://jekyllrb.com/docs/configuration/default
同时我们可以自定变量，会自动绑定到 site 对象上，比如我们可以把导航配置到_config.yml 中：


当然，我们也可以把一些数据单独放入一个 yml 文件，然后放在固定的数据文件夹_data 下，比如_data/navigation.yml，这样访问这个文件的数据对象就是 site.data.navigation。
第七步，_layouts 模板配置
_layouts 文件夹存放的是页面模板，默认需要一个 default.html，什么意思？就是说，layout 提供一个页面的布局框架，这是固定的模式，包括样式、结构、布局、脚本控制等等。然后，我们在用其它 md 或 html 文件去动态填充这个框架，这样就形成了一个完整的页面。比如我的 default.html 页面如下：



{% seo %} 是 jekyll 的一个插件提供的 seo 优化，详情在这里：https://github.com/jekyll/jekyll-seo-tag
 核心在于 content 这个变量是内置的，会用我们的 md 或 html 页面填充这部分内容。
其它的，我们看到会大量使用变量和流程控制代码，来填充模板的方方面面。
于是，填充模板的内容，一方面是来自读取配置文件的变量，一方面是来自_includes 的页面，还有就是来自 content 对应的页面。
当然，我们也可以不使用 content 来填充模板，而是使用_includes 的页面来代替 content  ，但这样不够灵活，因为使用 content ，我们可以在每个页面单独设置对应的 layout 模板。

第八步，md 和 html 页面编写
站点内容页面，可以使用 markdown 或 html 来编写，但 markdown 编写的 md 文件，在浏览器地址访问的时候依然使用 html 文件后缀。推荐使用 markdown 来书写内容，语法参见：Github md 示例 和 Github md 教程。比如下面这个 About.md 页面：
---
layout: default
title: About
---
# About page
 
This page tells you a little bit about me.
 
layout: default 就是告诉 jekyll 这个页面使用哪个模板，即这个页面会放入哪个模板的 content。当然，我们可以在_layouts 文件夹下提供多个不同的模板，然后根据需要不同的页面使用不同的 layout。
页面可以放在任意位置和目录，访问的时候从站点域名开始，带上目录名称，再次注意需要使用 html 结尾。如果想要自定义浏览器的访问路径，可以参看详细设置：permalinks。
md 和 html 页面的区别：
md 有自己的语法，可以使用少量的 html 标签，最终会编译成 html，侧重于内容编写。
html 可以随意使用 html 标签，可以使用 liquid 模板语言，侧重于页面模板和功能控制。
至此，我们就可以在 github 上，新建 md 文件然后编辑提交，等待几分钟编译生成之后，就可以在浏览器里看到页面内容了。
第九步，博客文章编写和管理
我们自然可以新建目录，提交文章，然后添加一个文章列表页面。但我们也可以把这些交给 jekyll 的内置机制来完成，因为它提供了一些方便的内置文章管理功能。

_posts 文件夹是内置的放置文章的目录，我们可以将固定格式 year-moth-day-name.md 名称的 md 文件放到这里。比如新建一篇 md 的博客文章放到_posts 目录下：

---
layout: post
---
这是一篇博客文章。


接下来我们需要添加一个 post 的模板页面到_layouts 文件夹下面。


可见，模板页面本身也可以使用模板，这里 post 使用了 default 模板，而这里 content 就会填充_posts 下面编写的页面（如果页面使用了 layout: post 模板）。
最后，我们还需要编写一个博客文章列表的页面，用来展示所有的文章。比如在根目录新建 blog.html 页面：


site.posts jekyll 会自动生成_posts 目录的对象。
_post.url jekyll 会自动会设置在_posts 目录下的页面 url。
post.title 默认是 md 文件名称，但也可以在文章页面自定义 title: 我的文章自定义名称。
post.excerpt 默认是文章第一段的摘要文字。

第十步，Github Pages 的限制

Github Pages 并不是无限存储和无限流量的静态站点服务，一些限制如下：
内容存储不能超过 1GB。
每个月 100GB 流量带宽。
每小时编译构建次数不超过 10 次。（在线修改重新编译并未发现这个限制）
更多参看官方说明：usage-limits。

总结
在实际的使用过程中，我发现完全可以在 Github 网站上，编写 md 和 html 页面，修改 js 和 css 文件，来完成站点的设置和搭建。只不过每次修改都要触发 Github jekyll 的编译行为，有点慢（不知道是不是增量编译），没有在本地修改调试的速度快。
更多 jekyll 详细的设置和功能，参看官方网站的文档：https://jekyllrb.com/docs。
原文链接：https://blog.csdn.net/tom_221x/article/details/84630283
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Github</tag>
        <tag>Jekyll</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Gitlab 的安装及使用</title>
    <url>/posts/d08eb7b/</url>
    <content><![CDATA[Gitlab 概述
1.1 GitLab 介绍
GitLab 是利用 Ruby on Rails 一个开源的版本管理系统，实现一个自托管的 Git 项目仓库，可通过 Web 界面进行访问公开的或者私人项目。
GitLab 能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序 (Wall) 进行交流。
它还提供一个代码片段收集功能可以轻松实现代码复用，便于日后有需要的时候进行查找
1.2 Gitlab 服务构成


Nginx：静态 web 服务器。


gitlab-shell：用于处理 Git 命令和修改 authorized keys 列表。


gitlab-workhorse: 轻量级的反向代理服务器。


logrotate：日志文件管理工具。


postgresql：数据库。


redis：缓存数据库。


sidekiq：用于在后台执行队列任务（异步执行）。


unicorn：An HTTP server for Rack applications，GitLab Rails 应用是托管在这个服务器上面的。


1.3 Gitlab 工作流程

1.4 GitLab Shell
GitLab Shell 有两个作用：为 GitLab 处理 Git 命令、修改 authorized keys 列表
当通过 SSH 访问 GitLab Server 时，GitLab Shell 会：

限制执行预定义好的 Git 命令（git push，git pull，git annex）
调用 GitLab Rails API 检查权限
执行 pre-receive 钩子（在企业版中叫做 Git 钩子）
执行用户请求的动作，处理 GitLab 的 post-receive 动作
处理自定义的 post-receive 动作

当通过 http (s) 访问 GitLab Server 时，工作流程取决于你是从 Git 仓库拉取 (pull) 代码还是向 git 仓库推送 (push) 代码：
如果是从 Git 仓库拉取 (pull) 代码，GitLab Rails 应用会全权负责处理用户鉴权和执行 Git 命令的工作
如果是向 Git 仓库推送 (push) 代码，GitLab Rails 应用既不会进行用户鉴权也不会执行 Git 命令，它会把以下工作交由 GitLab Shell 进行处理：

调用 GitLab Rails API 检查权限
执行 pre-receive 钩子（在 GitLab 企业版中叫做 Git 钩子）
执行你请求的动作
处理 GitLab 的 post-receive 动作
处理自定义的 post-receive 动作

1.5 GitLab Workhorse
GitLab Workhorse 是一个敏捷的反向代理。它会处理一些大的 HTTP 请求，比如文件上传、文件下载、Git push/pull 和 Git 包下载。其它请求会反向代理到 GitLab Rails 应用，即反向代理给后端的 unicorn。
Gitlab 的安装部署


Gitlab 要求服务器内存 2G 以上

2.1 方式一：下载 gitlab-ce 的 rpm 包

gitlab 官方 rpm 包下载
清华的源

将对应版本的 gitlab-ce 下载到本地后，直接 yum 安装即可
要先将这个 rpm 包下载到本地
yum install -y gitlab-ce-13.6.1-ce.0.el7.x86_64.rpm
2.2 方式二：配置 yum 源
在 /etc/yum.repos.d/ 下新建 gitlab-ce.repo，写入如下内容：
[gitlab-ce]
name=gitlab-ce
baseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/ Repo_gpgcheck=0
Enabled=1 Gpgkey=https://packages.gitlab.com/gpg.key
然后创建 cache，再直接安装 gitlab-ce
yum makecache  # 这一步会创建大量的数据
直接安装最新版
yum install -y gitlab-ce # 如果要安装指定的版本，在后面填上版本号即可
yum install -y  gitlab-ce-13.6.1
如果安装时出现 gpgkey 验证错误，只需在安装时明确指明不进行 gpgkey 验证
yum install gitlab-ce -y --nogpgcheck
2.3 gitlab 的配置
配置文件位置  /etc/gitlab/gitlab.rb
[root@centos7 test]# vim /etc/gitlab/gitlab.rb
[root@centos7 test]# grep "^[a-Z]" /etc/gitlab/gitlab.rb
external_url 'http://10.0.0.51'  # 这里一定要加上http://
配置邮件服务
gitlab_rails['smtp_enable'] = true
gitlab_rails['smtp_address'] = "smtp.qq.com" gitlab_rails['smtp_port'] = 25 gitlab_rails['smtp_user_name'] = "hgzerowzh@qq.com"  # 自己的qq邮箱账号
gitlab_rails['smtp_password'] = "xxx"  # 开通smtp时返回的授权码
gitlab_rails['smtp_domain'] = "qq.com" gitlab_rails['smtp_authentication'] = "login" gitlab_rails['smtp_enable_starttls_auto'] = true
gitlab_rails['smtp_tls'] = false
gitlab_rails['gitlab_email_from'] = "hgzerowzh@qq.com"  # 指定发送邮件的邮箱地址
user["git_user_email"] = "shit@qq.com"   # 指定接收邮件的邮箱地址
修改好配置文件后，要使用 gitlab-ctl reconfigure 命令重载一下配置文件，否则不生效。
gitlab-ctl reconfigure # 重载配置文件
2.4 Gitlab 常用命令
gitlab-ctl start         # 启动所有 gitlab 组件
gitlab-ctl stop          # 停止所有 gitlab 组件
gitlab-ctl restart       # 重启所有 gitlab 组件
gitlab-ctl status        # 查看服务状态
gitlab-ctl reconfigure   # 启动服务
gitlab-ctl show-config   # 验证配置文件
gitlab-ctl tail          # 查看日志
gitlab-rake gitlab:check SANITIZE=true --trace    # 检查gitlab
vim /etc/gitlab/gitlab.rb # 修改默认的配置文件
Gitlab 的使用


Gitlab 安装好后，设置密码，管理账户为 root

3.1 创建 Group

填上组名即可，这里组名为 java



3.2 创建 User

创建四个 User：pm、dev1、dev2、dev3



3.3 添加 User 到 Group 中并授权

3.4 创建 Project 并配置 SSH




3.5 在项目中添加成员


3.6 将本地文件推送到 Gitlab
将 app01 项目克隆下来
git clone git@10.0.0.51:java/app01.git # 初始化配置
git config --global user.name "hgzero" git config --global user.email "hgzero@qq.com"
在 app01 目录下新建一些文件
推送到 gitlab
git add .
git commit -m "first edition" git push origin master


制定开发计划


4.1 创建开发计划

项目：app01
 版本：v1.0


4.2 创建里程碑 Milestones

用 pm 账号登录 gitlab 后操作（先要在 admin 中设置 pm 账号的密码）
要根据开发计划来创建 Milestones





4.3 根据开发计划创建 issue

创建 4 个 issue，分派给 dev1 和 dev2 这两个开发人员







**4.4 开发者登录账号查看分派的任务 **

然后开发 dev1 登录 gitlab，就能看到任务已经分配过来了


4.5 开发流程

公司里的开发开始任务

1. 先从仓库把项目拉下来
git clone git@10.0.0.51:java/app01.git
cd app01/
2. 先创建一个自己的分支，然后进行开发
git checkout -b index   # 创建一个叫index的分支，并切换到这个分支
git status # 3. 开始开发首页
echo "&lt;h1&gt;welcome to this app&lt;/h1&gt;" &gt; index.html  # 假设就开发了一个index页面
4. 开发完成后，把项目传到仓库
git add .
git commit -m "index"
如果写成 git commit -m "close #2" ，则表示 merge 请求允许且 merge 成功之后，自动删除编号为 #2 的 issue
传到 index 分支
git push origin index
4.6 合并分支
1）开发 dev1 发送合并分支请求给 pm



2）pm 收到开发的 Merge 请求后进行处理

使用 pm 登录，就可以看到 pm 已经收到了合并请求 merge request





3）开发 dev1 确认任务完成

退出 pm 账户，登入 dev1 账户：



或者点进去后，在侧边栏进行标识 Done，然后已经完成的 issue，可以将其 Close



 这个时候 Milestones 的进度已经往前进了一些了：


4.7 开发其他功能

然后其他开发者或者自己再次进行开发时，先要把刚刚更新后的内容（master 主干）拉回来，然后再进行开发 

git checkout master  # 切换到master
git pull             # 从远端仓库拉取数据
然后再进行其他操作
Gitlab 备份恢复

5.1 备份 gitlab
1）修改配置文件

/etc/gitlab/gitlab.rb

备份保存的位置，这里是默认位置，可修改成指定的位置
gitlab_rails['backup_path'] = "/var/opt/gitlab/backups"
设置备份保存的时间，超过此时间的日志将会被新覆盖
gitlab_rails['backup_keep_time'] = 604800  # 这里是默认设置，保存7天
特别注意： # 如果自定义了备份保存位置，则要修改备份目录的权限，比如： # chown -R git.git/data/backup/gitlab

配置完成后要重启以使配置生效

重读配置文件
gitlab-ctl reconfigure # 重启gitlab
gitlab-ctl restart
2）设置定时任务
每天凌晨 2 点定时创建备份 # 将一下内容写入到定时任务中 crontab -e
0 2 * * * /usr/bin/gitlab-rake gitlab:backup:create # 备份策略建议： # 本地保留3到7天，在异地备份永久保存
3）备份时间的识别
备份后的文件类似这样的形式：1494170842_gitlab_backup.tar，可以根据前面的时间戳确认备份生成的时间
data -d  @1494170842
5.2 恢复 gitlab
1）停止数据写入服务
停止数据写入服务
gitlab-ctl stop unicorn
gitlab-ctl stop sidekiq
2）进行数据恢复并重启
进行恢复
gitlab-rake gitlab:backup:restore BACKUP=1494170842  # 这个时间戳就是刚刚备份的文件前面的时间戳
重启
gitlab-ctl restart
gitlab 邮件通知配置


vim  /etc/gitlab/gitlab.rb

gitlab_rails['time_zone'] = 'Asia/Shanghai' gitlab_rails['gitlab_email_enabled'] = true
gitlab_rails['gitlab_email_from'] = 'example@163.com' # 填写发件人的邮箱地址
gitlab_rails['gitlab_email_display_name'] = 'gitlab' gitlab_rails['smtp_enable'] = true
gitlab_rails['smtp_address'] = "smtp.163.com"  # smtp服务器的地址,如网易的地址
gitlab_rails['smtp_port'] = 25                 # 要注意如果使用了SSL/TLS的话,端口可能不是25
gitlab_rails['smtp_user_name'] = "smtp用户名" gitlab_rails['smtp_password'] = "smtp用户密码" gitlab_rails['smtp_domain'] = "163.com" gitlab_rails['smtp_authentication'] = "login"


使用 SourceTree 进行项目开发



7.1 项目拉取

先把项目克隆下来




如果 ssh 的方式克隆失败，可能是因为 SSH Key 没找到，可以在这里添加



7.2 创建分支进行功能开发
1）新建立一个叫 “pay” 的分支


2）进行功能开发

7.3 提交项目
1）开发 pay 功能完成后进行提交

可以看到 SourceTree 中已经有 “未提交的更改”



2）添加 “用户信息”

** 3）进行提交 **


注释也可以写成  close #3    ，作用是提交完成后关闭 3 号 issue

7.4 推送到仓库



然后就可以在 gitlab 上进行发送 merge 请求了，后面就可以进行其他操作了

7.5 项目上线
1）当所有工作完成之后，就可以进行上线了

2）打标签

上线先打个标签




** 3）删除无用分支 **

然后删除已经合并到主干中的不必要的分支，如 index、pay 等
最后一定要注意时间一定要同步，不然会错乱

参考

Praywu

Gitlab 使用系列


Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab


系列教程
Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
        <tag>Git</tag>
        <tag>Crack</tag>
      </tags>
  </entry>
  <entry>
    <title>PT 工具集，Linux 硬链接助手</title>
    <url>/posts/bb600b4b/</url>
    <content><![CDATA[由于自我需求，写了两个脚本完成 PT 下载和保种两全其美的硬链接 Linux shell 脚本方案。
PTtool
Github: appotry/PTtool
Gitee: 镜像 bloodwolf/PTtool
PT 工具集合

硬链接工具
flexget-nexusphp, Flexget 插件，增强对 NexusPHP 的过滤 
IYUUAutoReseed 自动辅种助手。PT 三剑客 
PTPP 浏览器辅种助手。PT 三剑客 
pt_helper, 自动刷流与签到。PT 三剑客 
PT 站生成海报墙
一键转种脚本

硬链接工具
设计目的
方便 PT 用户硬链接文件，在最大可能情况下节约空间，并保持做种。
小于 1M 的文件直接复制，方便 emby，tmm 等工具刮削修改 nfo 等小文件。
大于 1M 的文件硬链接到目的目录，可以修改文件名，但是不能修改文件内容！
例如：
/share/Download/src #保存下载的 PT 文件
/share/Download/dst #保存你自己处理过的视频文件，把 emby，tmm 的目录设置到 dst 下面
下载脚本后 chmod +x mklink.sh 给与执行权限
使用 mklink 脚本修改如下，然后直接运行 mklink.sh。就可以把 src 下面的文件全部硬链接到 dst 目录。mklink 适合一次性把源文件夹链接到目的文件夹
SRC="/share/Download/src"
DST="/share/Download/dst"
注意：

源目录，目的目录需要在一个硬盘分区里面。硬链接不能跨分区。
硬链接过的文件可以使用 mv 来修改存储目录，不影响硬链接效果。但是 cp 会增加一份存储空间。所以对于已经硬链接过的文件，使用 mv，不要使用 cp。

解决的问题
tmm，emby 刮削的时候，必定修改 nfo 文件，下载的封面等图片不同刮削站点都不同，所以小文件复制，不怕修改。大文件硬链接，占有一份空间
被硬链接过的文件，同时存在多个地方，但是都指向一个存储空间，只有所有的硬链接都删除了，这个文件才会被系统删除。
同时，所有的硬链接文件，修改其中一个，其它所有指向这个位置的硬链接文件都被修改了。
使用说明
下载资源目录 /share/Download，qbittorrent 资源分类下载到 /share/Download/src/ 下面的各个子目录，例如 tv, anime, tv, movie, 4k, soft 等等
创建一个资源整理使用目录 /share/Download/dst/ 目录，然后就可以把 /share/Download/src 和 /share/Download/dst 目录作为下面 2 个脚本的输入目录，来使用了
小文件直接复制，方便 tmm 刮削修改 nfo 文件，大文件硬链接，只占有一份空间，但有 2 分文件，可以改名，移动目录，方便 tmm 整理刮削。 做种，emby 使用两不误！
建议目录结构
/share/Downlosd/src       # BT下载工具默认保存主目录
/share/Download/dst       # 硬链接目的目录，Emby，tmm，使用的目录，保存各种刮削信息。以及个人文件名修改，目录结构修改。
在src目录下面建立子目录movie,music,anime,tv,4k等等，在qbittorrent里面设置分类，
指向这里的movie,music,anime，tv等子目录。下载完后使用下面的硬链接脚本，
把文件硬链接到目的文件夹。tmm，emby使用目的文件夹刮削数据。
qbittorrent 使用设置

移动种子保存位置
在 qt 的 web 界面种子上面右键，选择菜单保存位置
设置分类目录
在 qt 的 web 界面种子上面右键，选择分类 -&gt; 新分类，先写分类名称和路径。对于多文件种子，种子添加时选择自动管理。对于单文件种子，请自行添加子文件夹，或强制创建子文件夹。

mklink.sh
修改脚本参数源目录，目的目录，替换为你自己的目录。
脚本将把源目录所有文件硬链接到目的目录，小于 1M 的文件直接复制到目的目录。方便 nfo 等小文件刮削修改，大于 1M 的文件
硬链接到目的目录，以节约空间，2 份文件只占有一份空间。
SRC="/share/Download/tmp/src"
DST="/share/Download/tmp/dst"
mklink 直接针对 2 个文件夹做硬链接，小于 1m 的复制，但是没有判断是否已经硬链接过。适合全新的没有硬链接过的目录。
dirlink.sh
设计原理：针对输入原路径下一级子目录判断是否有文件 islinked.lk，
有这个文件就跳过，没有就硬链接这个子目录到目的目录生成对应的子目录。
小于 1M 的文件复制，大于 1M 的文件硬链接。
可以直接修改脚本源目录，目的目录参数，也可以从参数 $!,$2 输入源目录，目的目录。
此脚本和 mklink.sh 区别在于，将检查每个目录是否已经被硬链接过，已经连接过的将跳过去不再硬链接。
原理是在源文件夹目录下添加文件 islinked.lk，通过检测这个文件来判断是否硬链接过
SRC="/share/Download/tmp/src/movie"
DST="/share/Download/tmp/dst/movie"
注意：src 目录下面的文件需要放到各个子目录下面去，例如 src/anime/amine1,src/tv/tv2，这样才能保证 islinked.lk 工作正常
目录设置可以直接修改脚本，也可以命令行参数输入
#dirlink.sh sourcedir dstdir
dirlink.sh /share/Download/tmp/src /share/Download/tmp/dst
重新建立连接，一次性删除所有 islinked.lk 文件
find /share/Download/tmp -name "islinked.lk" | xargs rm -f
替换前面的路径 /share/Download/tmp 为你自己的路径，操作和 rm 相关的命令一定注意不要输入错误，删错文件代价极大！
一次性硬链接多个目录
如下所示脚本 link.sh
#!/bin/sh
/share/Download/source/dirlink.sh /share/Download/source/anime /share/Download/dst/anime
/share/Download/source/dirlink.sh /share/Download/source/movie /share/Download/dst/movie
/share/Download/source/dirlink.sh /share/Download/source/tv /share/Download/dst/tv
修改限制 2M 大小以下的复制
修改脚本参数 FILEGIG，原脚本是 1M 大小，修改为下面这样就是 2M 大小
FILEGIG=2000000c
autolink.sh
qBittorrent 下载完成时自动硬链接下载完的种子，适用于新下载完成的种子文件。以前下载完成的文件建议使用 link.sh 脚本的方法。
注意：脚本会判断是否进行硬链接的分类，分类详情见脚本内容。

修改脚本目标目录
将你的目录填在 your_path 的等号后。
设置下载完成后自动运行
在 qt 的 web 界面 g，点击工具 -&gt; 选项 -&gt; 下载，勾选 “Torrent 完成时运行外部程序”，填入 /path/to/autolink.sh "%N" "%D" "%L"
注意：填入 autolink.sh 的绝对位置，同时 autolink 与 dirlink 须在同一目录

使用声明
数据无价，小心操作。
本脚本（除 autolink.sh 外）没有 rm 删除，只有 mkdir 和 cp， 最多搞乱文件系统。但要注意不要把目的地目录设置到系统目录去了。
一切后果自负
感觉对你有帮助，来个 star 吧
Contributing

Fork it ( https://github.com/[my-github-username]/PTtool/fork )
Create your feature branch (git checkout -b my-new-feature)
Commit your changes (git commit -am 'Add some feature')
Push to the branch (git push origin my-new-feature)
Create a new Pull Request

]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>hardlink</tag>
        <tag>bt</tag>
        <tag>pt</tag>
      </tags>
  </entry>
  <entry>
    <title>破解 Gitlab EE</title>
    <url>/posts/29a820b3/</url>
    <content><![CDATA[由于需要一些镜像等 gitlab 高级功能，所有破解 gitlab ee 版本。
安装 ruby
安装完 gitlab ee 之后
安装 ruby：yum install ruby
ruby 版本需要 2.3 或以上。
生成许可证
gem install gitlab-license
创建一个 rb 文件
license.rb

require "openssl"
require "gitlab/license"
 
key_pair = OpenSSL::PKey::RSA.generate(2048)
File.open("license_key", "w") { |f| f.write(key_pair.to_pem) }
 
public_key = key_pair.public_key
File.open("license_key.pub", "w") { |f| f.write(public_key.to_pem) }
 
private_key = OpenSSL::PKey::RSA.new File.read("license_key")
Gitlab::License.encryption_key = private_key
 
license = Gitlab::License.new
license.licensee = {
  "Name" =&gt; "none",
  "Company" =&gt; "none",
  "Email" =&gt; "example@test.com",
}
license.starts_at = Date.new(2020, 1, 1) # 开始时间
license.expires_at = Date.new(2050, 1, 1) # 结束时间
license.notify_admins_at = Date.new(2049, 12, 1)
license.notify_users_at = Date.new(2049, 12, 1)
license.block_changes_at = Date.new(2050, 1, 1)
license.restrictions = {
  active_user_count: 10000,
}
 
puts "License:"
puts license
 
data = license.export
puts "Exported license:"
puts data
File.open("GitLabBV.gitlab-license", "w") { |f| f.write(data) }
 
public_key = OpenSSL::PKey::RSA.new File.read("license_key.pub")
Gitlab::License.encryption_key = public_key
 
data = File.read("GitLabBV.gitlab-license")
$license = Gitlab::License.import(data)
 
puts "Imported license:"
puts $license
 
unless $license
  raise "The license is invalid."
end
 
if $license.restricted?(:active_user_count)
  active_user_count = 10000
  if active_user_count &gt; $license.restrictions[:active_user_count]
    raise "The active user count exceeds the allowed amount!"
  end
end
 
if $license.notify_admins?
  puts "The license is due to expire on #{$license.expires_at}."
end
 
if $license.notify_users?
  puts "The license is due to expire on #{$license.expires_at}."
end
 
module Gitlab
  class GitAccess
    def check(cmd, changes = nil)
      if $license.block_changes?
        return build_status_object(false, "License expired")
      end
    end
  end
end
 
puts "This instance of GitLab Enterprise Edition is licensed to:"
$license.licensee.each do |key, value|
  puts "#{key}: #{value}"
end
 
if $license.expired?
  puts "The license expired on #{$license.expires_at}"
elsif $license.will_expire?
  puts "The license will expire on #{$license.expires_at}"
else
  puts "The license will never expire."
end
 

ruby license.rb
生成 GitLabBV.gitlab-license license_key license_key.pub 这三个文件。
使用许可证
用 license_key.pub 文件替换 /opt/gitlab/embedded/service/gitlab-rails/.license_encryption_key.pub。
GitLabBV.gitlab-license 即是许可证，填入 ${address}/admin/license 地址并重启 gitlab-ctl restart 。
修改等级
--- /opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb
+++ /opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb
@@ -458,7 +458,7 @@
  end
 
  def plan
-    restricted_attr(:plan).presence || STARTER_PLAN
+    restricted_attr(:plan).presence || ULTIMATE_PLAN
  end
 
  def edition
 
修改完成后使用 gitlab-ctl restart 重新加载配置。
Gitlab 使用系列


Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab


参考

https://www.rubydoc.info/gems/gitlab-license/1.0.0/file/README.md

系列教程
Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
        <tag>Git</tag>
        <tag>Crack</tag>
      </tags>
  </entry>
  <entry>
    <title>完美笔记进化论</title>
    <url>/posts/a8535f26/</url>
    <content><![CDATA[前言：

受够了一些网络服务随意被关闭，如 google reader 等。经过 google doc, 有道笔记，为知笔记，手机备忘录，记事本，git，等等方式记录笔记，使用过 TXT，work，gitbook，markdown 等格式，找到一种接近完美的解决记录笔记的方式。主要采用 selfhost，自主搭建服务器，每个组件都可以被取代，大多数都是开源可定制的。
​
经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

笔记进化历史
浏览器书签
优点：使用方便，一些实时更新的内容可以直达。
缺点：需要联网，没办法搜索编辑，经常有链接失效。很多有实效的资源，或者可能只能存在一定时间的资源。
由于时效更新的缘故，一直和其它笔记记录方式一起使用。

word 笔记
优点：富文本支持
缺点：word 相对笨重，很多低端平台没有 word 可用

txt 笔记
优点：多平台，随时随地，格式简单
缺点：富文本支持不好，同步机制只能自己想办法，没有富文本

gitbook
优点：同步机制，修改版本机制
缺点：富文本相对缺乏
单独来说只解决了修改日志问题
markdown
优点：富文本
缺点：无修改日志，显示上传不友好
单独来说解决了富文本问题
google doc
优点：在线编辑，富文本支持，修改历史支持，搜索支持。
缺点：文件是 google 专有格式，数据保存在网上，国内访问需要代 / 理支持，google 还有关闭热度不高网络服务先例。

有道笔记
优点：对 markdown 支持非常好
缺点：收费，多平台不够友好，同步问题

手机 '' 备忘录 "app
优点： 方便，随时随地
缺点：一般只能同型号手机之间同步， 对于多平台同步没有支持，也没有富文本，没有修改历史。

最终选择方案
为知笔记 docker 版 + Typora+Picgo+github+snipaste

最近替换 wiznote 为 Joplin，完全开源免费。Joplin 插件异常强大，支持各种 Markdown 语法。

wiznote docker 版作为笔记管理搜索工具，typora 作为 markdown 编辑器，只使用 markdown 格式笔记，Picgo 作为图上上传工具，github 作为图像图床，Snippaste 作为截屏工具。一起组成笔记工具链。
怎么样？ 够复杂吧，作者也觉得很复杂，但整体免费，满足 selfhost， 富文本，多平台，版本管理，目录管理，可搜索，对图像友好的苛刻要求，超越市面所有产品，wiznote 还可以对外网提供服务。
优点：selfhost， 富文本，多平台，版本管理，目录管理，可搜索，对图像友好。只使用其中部分功能，每个功能都是有其它可替代方案
缺点：配置异常复杂，配置完整难度较高，一些组件还不够成熟，稳定性不够好，存在 bug
完整解决方案图示
wiznote docker 版
数据完整保存在自己搭建的服务器上面，备份转移方便。其实主要是使用 wiznote docker 版的目录管理，多文档搜索，修改记录功能。可以使用 gitlab docker 版来代替。

教程： 为知笔记私有化 Docker 部署
最近更新 Joplin docker +Typora+VIM + Picgo+github+snipaste

选用理由： 从服务器到客户端，到 APP 完全开源，支持 dropbox，webdav，本地文件系统，docker 镜像等同步方式。

Jopin 配合 Typora 才是最佳搭档，配置如下
Joplin
Joplin 教程：


替代 Evernote 免费开源笔记 Joplin - 网盘同步笔记历史版本 Markdown 可视化
Joplin 入门指南 &amp; 实践方案
Joplin 插件使用推荐
官方插件下载地址


中文界面
工具–&gt; 选项

点击下方图的按钮来触发 Joplin 设置的外部编辑器

把 Joplin 用在日常工作中
此处主要介绍 Joplin 在终端中的使用，主要参考了官方文档。
和 Vim 协作编辑文档
我喜欢 Joplin 终端的设计，它很符合 tmux 和 Vim 的逻辑。
终端 Joplin 由三个横向的 Panel 组成，切换的时候用 tab 和 Shift-Tab。为了使得它更符合 Vim 的风格（Control + 方向键），可以在 ~/.config/joplin/keymap.json 中加入以下的设置（完整版见此 gist keymap.json ）：
...
        { "keys": ["TAB","l"], "type": "function", "command": "focus_next" },
        { "keys": ["SHIFT_TAB","h"], "type": "function", "command": "focus_previous" },
        { "keys": ["UP","k"], "type": "function", "command": "move_up" },
        { "keys": ["DOWN","j"], "type": "function", "command": "move_down" },
        { "keys": ["PAGE_UP","K","{"], "type": "function", "command": "page_up" },
        { "keys": ["PAGE_DOWN","J","}"], "type": "function", "command": "page_down" },
...
这样就变成了 HJKL 风格了。
选择好要编辑的笔记之后，回车就会用默认的终端编辑器打开了。对我来说，必然是 Vim。要注意的是编辑中的语法高亮需要加入 vim-markdown.vim，预览则要 markdown-preview.nvim。
利用 CLI 快速记录
假设你正在工作环境中（例如 Shell 下、tmux 下或着 Vim 下），不想离开终端，更不想离开现在的窗口，这种情况下 Joplin 的命令行介面就很有帮助了。你可以快速记录、查询一些笔记内容。
我在这里写了一些例子供你参考。

创建一个笔记本 = 为项目建立日志存储：

$ joplin mkbook "My-Project"
$ joplin use "My-Project"

创建新笔记并以当前时间命名 = 记录当前进度：

$ joplin mknote `date +%Y/%m/%d`

查看已有的笔记：

$ joplin ls -l

完成当前进度：

$ joplin todo toggle "Feature1"
更多的命令行，你可以通过 joplin help all 查看。
Joplin 插件以及 Markdown 语法

教程： Joplin 插件以及其 Markdown 语法

Gitlab docker
和上面的 wiznote docker 基本一样的使用功能。
除了记录笔记，还可以保存自己的各种代码。

Typora
Typora 官方介绍及下载地址
编辑器演示

上传图片图示

后端图像上传工具 picgo

一次性上传本 MD 文件中所有图片

picgo
Picgo 官方下载地址
官方插件下载地址及其介绍

picgo 插件配置
要想 picgo 用的过得去，一般来说需要插件

picgo 使用 github 作为图床需要 github 配置，也可以使用 sm.ms， gitee。选择 github 相对来说被随意关闭可能性更低。
Snipaste 截图工具

Snipaste 官方下载地址
系列教程
笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

hexo 系列

hexo 独立博客搭建 [三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优化



 docker 环境
 hexo 使用入门
 hexo 基础配置
自定义修改
 hexo 部署
个性定义
性能优化
常见问题 



Hexo Markdown 以及各种插件功能测试



 markdown 各种其它语法插件
 latex 公式支持
 mermaid 图表
 plant uml 图表
 URL 卡片
 bilibili 卡片
 github 卡片
豆瓣卡片
插入音乐和视频
插入脑图


]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>note</tag>
        <tag>markdown</tag>
        <tag>picgo</tag>
        <tag>wiz</tag>
        <tag>Joplin</tag>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title>qnap 硬盘移动位置</title>
    <url>/posts/10fee780/</url>
    <content><![CDATA[qnap 硬盘移动位置，改变硬盘位
需求：硬盘位 4 的硬盘移动到硬盘位 3
步骤 1
造作步骤： 存储和快照总管 app-&gt; 存储 / 快照 -&gt; 管理 -&gt; 操作 -&gt; 安全卸载磁盘区
如此，硬盘 4 卸载下来了，如下图

步骤 2
再把硬盘 4 拔下来，插入硬盘位 3。等待硬盘被识别到，一般 1 分钟之内。
步骤 3
造作步骤： 存储和快照总管 app-&gt; 磁盘 / VJBOD-&gt; 点击磁盘 3-&gt; 还原 -&gt; 链接并回复存储池

]]></content>
      <categories>
        <category>qnap</category>
      </categories>
      <tags>
        <tag>QNAP</tag>
        <tag>硬盘</tag>
        <tag>nas</tag>
      </tags>
  </entry>
  <entry>
    <title>3G,4G,Wifi 选型需求分析及技术简介</title>
    <url>/posts/6b2ba137/</url>
    <content><![CDATA[3G,4G,Wifi 选型需求分析及技术简介


文章写了好多年了，只在一个网站发布过 PDF 版本。行业内应该很多人看过这个。


关于本 blog，图床一般使用 github，已经配置了 CDN，如果图片还是未显示请自行代理解决


原创声明警告，文章禁止转载，禁止发布到其它任何网站，可以接受约稿。


用户需求分析
减少布线，或有的地方很难布线。
​    例如：偏远森林，沙漠，海岛，土地所有制导致不能随便开挖等各种原因。
--3G，4G--
优点： 布线，距离远。
缺点：流量费高（可以和运营商合作 ）
--Wifi--
优点：费用低，
缺点：距离近
研发需求分析
WANTED!
3G，4G 选型标准需求
1：产品生命周期，时间空间的重叠。 初产时间较近，出货时间长，
2：客户那里运营商网络制式？？（例如 TD-LTE****，FDD-LTE，CDMA2000 等等），
​    运营商名称？？（一般不同国家不一样，一个国家很多个运营商）
3：3G，4G 具体型号选择： 1：厂家选择？？？ 2：网络制式选择（需要选择制式尽可能支持区域大的，亚洲，欧美，日韩）？？？ 3：USB 使用的技术代差（1：usb 猫，2：usb 光驱，3：html 拨号）
4：客户 3G，4G 使用场景？？。流量大小，费用
** 注意：** 可能客户那里支持的制式和国内不一样，我们这边验证的制式在客户那里不能用，客户那里支持的制式在国内又没法验证。选择制式的时候特别需要注意。
Wifi 选择需求
5：芯片厂家需要支持 Linux 驱动。 芯片出来年代？？？，价格？？？，协议标准（决定速度），网络信号质量？？？，传输速度（不同距离速度，是否要求穿墙）？？？
6：对应的无线路由器调试
7：客户 Wifi 使用场景？？。 主要是使用距离引起速度衰变， 现在有 2,4G，5G 路由，速度有 150Mbit/s 300Mbit/s，450Mbit/s。需要 ap 评估这种速度能否满足各种场景使用需求
3G，4G 部分
中国 2G，3G，4G 制式标准

UMTS (Universal Mobile Telecommunications System)，意即通用移动通信系统。UMTS 是国际标准化组织 3GPP 制定的全球 3G 标准之一。作为一个完整的 3G 移动通信技术标准，UMTS 并不仅限于定义空中接口。它的主体包括 CDMA 接入网络和分组化的核心网络等一系列技术规范和接口协议。除 WCDMA 作为首选空中接口技术获得不断完善外，UMTS 还相继引入了 TD-SCDMA 和 HSDPA 技术。
UMTS 网络优先选择的就是 WCDMA，国内就是中国联通
电信

2G CDMA
3G CDMA2000
4G TD-LTE**，**FDD-LTE

移动

2G GSM
3G TD-SCDMA
4G TD-LTE**，**FDD-LTE

联通


2G GSM


3G WCDMA


4G TD-LTE**，**FDD-LTE


中国移动 TD-LTE：支持频段 38、39、40


中国联通 TD-LTE：支持频段 40、41


中国电信 TD-LTE：支持频段 40、41


中国联通 FDD-LTE：支持频段 3


中国电信 FDD-LTE：支持频段 3


全球制式和区域
2G 有 GSM，还有 CDMA。
​    我们平时说的 G 网或者 C 网了。联通和移动都是 GSM，电信的 133 号段（之前是联通主营，后来转移给电信）是 C 网
3G 有 3 种：WCDMA，CDMA2000，TD_CDMA
WCDMA（日本、欧洲）、CDMA2000（北美）、TD-SCDMA（中国移动）
使用最广泛的是 WCDMA。美国、欧洲等国很多是 WCDMA 和 CDMA2000 都有的。
另外 WCDMA、CDMA2000 里面还有更细的划分，主要是技术、标准、速度的细微差别。
WCDMA（欧洲版）：这个是欧洲的主流，也是目前世界范围 3G 的使用模式最广的，在中国大陆，是中国联通 3G （沃）的模式。
CDMA2000（美国版）：这个数量相对少些，由美国为代表。在大陆，是中国电信 3G （天翼）的模式
TD-SCDMA（中国版）：这个是中国大陆自主知识产权的，可以说是中国特色的 3G ，虽然大部分的通讯厂商宣布对此技术可以支持，但世界范围内使用的范围有限。在大陆，是中国移动 3G 的网络模式。
4G 有 2 种: LTE FDD，LTE TDD
LTE FDD（世界绝大多数国家）、LTE TDD（中国移动和国外极少数地区的个别运营商）。
TD- LTE 是我国自主研发的 4G 标准，是由 TD-SCDMA（3G 网络）发展而来。
LTE FDD 是现在国际上主流的，使用最广泛的 4G 网络，由 WCDMA 演化而来。
现在全球有超过 200 个 LTE 的商用网络，其中超过 90% 是 FDD 的。
从技术上说，TD- LTE 采用的是时分双工，而 LTE FDD 采用的是频分双工
TD-LTE 和 FDD-LTE 是 4G 的两种国际标准，各有利弊。TD-LTE 占用频段少，节省资源，带宽长，适合区域热点覆盖；FDD 速度更快，覆盖更广，但占用资源多。适合广域覆盖。
国内三家运营商 4G 网络制式分别如下：
联通 4G：TD-LTE、FDD-LTE
电信 4G：TD-LTE、FDD-LTE
移动 4G：TD-LTE
虽然联通跟电信都是采用双 4G 网络制式，但目前 4G 网络仅在部分地区覆盖，3G 网络仍然是不可或缺的。而联通 3G 采用的是 WCDMA，为欧洲标准，是技术发展最成熟、国际通用和覆盖范围最广的制式，目前是国内 3G 网络最快的，最高可达 42Mbps，在国外已将其定义为 4G 标准。
综合以上，选型推荐。
3G 推荐选型：WCDMA 欧洲，CDMA2000 美国
4G 推荐选型：FDD-LTE
WIFI 部分
2.4G 和 5G 究竟是什么
   以往我们一直使用的 Wi-Fi 大多数是支持 IEEE 802.11n（第四代）无线标准的，而且工作在 2.4GHz 这个频段上的，所以称之为 2.4gWi-Fi，但是严格来说工作在 5GHz 频段上的不一定就是 5G Wi-Fi，因为 IEEE 802.11a（第一代）IEEE 802.11n（第四代）和 IEEE 802.11ac（第五代) 这三种标准都可以工作在 5GHz 这个频段上。
   严格来说只有支持 802.11ac 的才是真正 5G Wi-Fi（在这个视频里我们将它称作 ac 5G)，现来在说支持 2.4G 和 5G 双频的路由器其实很多都是指支持第四代无线标准，也就是 802.11n 的双频，而真正支持 ac 5G 的路由最便宜都要 400、500 甚至上千元
   我们的路由器一般会有标有一些类似 54Mbps，150Mbps，300Mbps 这样的参数，要说明一下，这个参数不是指路由器的无线覆盖范围，而是指它的最高传输速率。若要支持 ac 5G 的也要双方同时支持，单方面支持是不行的。
   这个速率就相当于车道上的限速标志，当然也不能完全等同与限速标志，因为如果网络中多个设备同时传输要分流的

最后不要忘记要考虑空间的大小，200 多平米的房子一般普通无线路由器的 2.4G 勉强可以覆盖，5G 的话 150 平米就开始有压力，如果房屋太大或者多楼层的话可能就要考虑一下多个无线路由桥接了。
5GWifi 速度快，穿墙弱
5G Wi-Fi 的最大缺点就是穿墙能力比较弱，墙体对 Wi-Fi 信号的强度影响是比较大的，每穿过一面墙，Wi-Fi 信号就要减弱不少。
路由器摆放小技巧。增强信号。
最根本一半是有线速度限制，但信号强度也很重要
另外分享一个摆放路由器的方法，如果受制与网线或者台式电脑的位置就没得说，但是如果可以移动的话，这个位置的原则是要经过尽量少的墙体
最好不要放在地上，更不要放在角落，
放在高处
而且应该经适当的放高一点，而不是放在地上，这和手机信号塔的原理是一样的，更加不应该因为他碍眼把它放进抽屉、柜子等里面。这些方法可以略微增强信号强度，不过想从根本上解决信号问题，还是要换一款更好的路由。
无线网卡选购简介
常见值得选购的 USB 无线网卡按技术规格和价位，大致可以分为如下 3 类：
单频 11n 网卡，标注速度 200-300M，20-30 元。
双频 11n 网卡，支持 5g 频段，标注速度 600M，40-50 元。
双频 11ac 网卡，支持 5g 频段，标注速度 900-1200M 或更高，80 元以上。
无线网卡要想达到标注的技术标准和速度，首先需要路由器支持该标准及速度，否则会降速运行。
USB 协议：速度，选择 2.0 还是 3.0
USB2.0 的速度传输，理论最大速率 480M bit/S。 60MB/S
USB3.0 的理论最大速率是 5G bit/S，要比 USB2.0 快 10 倍！ 640MB/S
看线路，工艺质量，实际速度可能不到理论速度一半
USB3.0 对 wifi 和 BlueTooth 干扰。
USB3.0 的传输频率确实是 5GHz 串行，但 USB3.0 使用 4 条数据线组成 2 组，每组负责一个传输方向，实现全双工双向 5GHz，而每条数据线的基准频率是 2.5GHz。
所以，总带宽是 5GHz 没错，但每条线上是 2.5GHz，这个频率距离 2.4G Wifi 的频率太近了，又因为高频设备大多数都使用了 SSC 技术（扩频时钟？）使得信号不完全分布在一个固定频率上，所以就波及了 2.5GHz 附近的其它频率，所以对 Wifi 和蓝牙产生了较大的干扰。
USB 3.0 干扰 Wifi 2.4G 通讯的问题和解决方法
USB3.0 WIFI 干扰解决方法
USB3.0 的确对 2.4G 有影响，不过一样可以解决，比如网件的解决方法就是，USB3.0 和网口，天线不在一面，USB3.0 接口弄到前面，而且是所有接口有金属屏蔽罩（包括 WAN 和 LAN 口），连 USB 接口与主板连线处都用屏蔽胶布包裹。可惜国内厂商哪怕是大如华为，网口也舍不得这点成本用金属屏蔽的。
带有 USB 3.0 接口的无线路由，如果出现外接 3.0 移动硬盘后网速下降，断网，或者 ping 延时变得很高，说明出现了 3.0 对无线的干扰。
USB3.0 与无线冲突解决办法：
第一种：给 USB 接口加金属膜做屏蔽可以适当降低干扰，但不能完全屏蔽
第二种：给主板的 USB 底座增加统一（并与使用设备）接地和增加金属屏蔽罩，基本可以排除
【推荐】第三种：用 1.2 米 双磁环带屏蔽层的 USB 延长线将移动硬盘放到一米外的地方使用，基本可以完全可以排除
其实不单是无线路由，像我们平常使用的无线鼠标键盘、蓝牙、wifi 电视、iPad、手机等各种使用民用 2.4G 的通信设备都会出现与 USB3.0 冲突的情况。
USB3.0 移动硬盘干扰解决方法
相信随着 USB3.0 使用的用户越来越多，不少人遇到了一插上 USB3.0 的硬盘，wifi 就出现降速或者中断的问题。其本质原因是 USB 3.0 干扰 2.4GHz 下的 Wifi 通讯。
解决方法如下，
1. 更换无线路由为 5GHz，因为 USB 3.0 对 5GHz 的 Wifi 干扰程度较低
2. 把硬盘盒从 USB3.0 接口换到 USB2.0 接口也可以将问题解决
3. 使用高质量带屏蔽的 USB3.0 设备 / 线缆 / 接口。或者在 USB3.0 接口处加屏蔽罩（金属箔即可）
4. 最简单的，使用 1m 以上的高质量 USB3.0 延长线。将 USB3.0 设备远离电脑主机。
Intel 官方对 USB3.0 对 WIFI 干扰的描述文档：
http://www.usb.org/developers/whitepapers/327216.pdf
目前在调试的两款型号：
TL-WN823N

​         Bus 002 Device 007: ID 0bda:818b
​         RTL8192EU
​         300M 迷你型无线 USB 网卡 TL-WN823N

TL-WN725N

​         Bus 002 Device 008: ID 0bda:8179
​         rtl8188eu
​         150M 无线 USB 网卡 TL-WN725N
​         网上的驱动版本数据结构和 3.10 差异较大，不能用

Wifi 芯片厂家
Realtek：
​         官方无 linux 驱动支持
Ralink
（已经被 MTK 收购）： 官方有 linux 驱动
Atheros
（已经被高通 qualcomm 收购）：AR9271
整理推荐芯片型号：
USB 2.0 Mbit/s
rt3070

http://www.mediatek.cn/products/broadbandWifi/rt3070
IEEE 802.11:b/g/n
Wi-Fi Frequency:2.4GHz
Antenna:1T1R
Data Throughput:150Mbit/s

rt5370

http://www.mediatek.cn/products/broadbandWifi/rt5370
IEEE 802.11:b/g/n
Wi-Fi Frequency:2.4GHz
Antenna:1T1R
Data Throughput:150Mbit/s

RT3573

http://www.mediatek.cn/products/broadbandWifi/rt3573
IEEE 802.11:b/g/n/ac
Wi-Fi Frequency:2.4GHz, 5GHz
Antenna:3T3R
Data Throughput:450Mbit/s

RT5572

http://www.mediatek.cn/products/broadbandWifi/rt5572
IEEE 802.11:b/g/n/ac
Wi-Fi Frequency:2.4GHz, 5GHz
Antenna:2T2R
Data Throughput:300Mbit/s

集成分析
3G，4G 集成分析
根据拨号技术流程，现在已经发现的 USB 上网有三种

1：默认识别为 USB Modem，使用 pppoe 拨号脚本拨号。
2：默认识别为 usb cdrom，使用 usb-modeswitch 转换 usb 设备工作状态，转换为 USB Modem 后再采用 pppoe 拨号脚本拨号。
3：使用 CGI 调用 Html 链接方式拨号。不需要我们配置用户名密码，网络制式，最方便。

1：Pppoe 拨号
pppd call wcdma 
2：usb_modeswitch 转换 usb 设备工作模式。
usb_modeswitch -W -c /etc/usb_modeswitch.d/19D2:0117
3：CGI 拨号示例
从集成实现来说，这种最方便。
./curl --header "Referer: http://192.168.0.1/index.html" http://192.168.0.1/goform/goform_set_cmd_process?goformId=SET_CONNECTION_MODE&amp;ConnectionMode=auto_dial

./curl --header "Referer: http://192.168.0.1/index.html" http://192.168.0.1/goform/goform_process?goformId=MODE_SWITCH&amp;switchCmd=FACTORY
Wifi 集成分析
步骤：

1：驱动移植识别
 2：wireless_tools 或者 wpa_supplicant 拨号

wpa_supplicant 依赖 openssl 和 libnl，支持 PSK 加密需要用到这个。wireless_tools 只支持普通 web 加密。
带宽性能测试
服务器运行 iperf -s
客户端运行 iperf -c 服务器 ip -t 60000 -i 2
iperf -c 192.168.1.100 -t 60000 -i 2
TP—Link 845
笔记本有线连接运行服务端，H3531a（2716TE_C）使用 TL-WN823N 连接
[root@Tvt iperf]# ./iperf.hisi3531A -c 192.168.1.100 -t 60000 -i 2
\------------------------------------------------------------
Client connecting to 192.168.1.100, TCP port 5001
TCP window size: 21.0 KByte (default)
\------------------------------------------------------------
[ 3] local 192.168.1.103 port 47671 connected with 192.168.1.100 port 5001
[ ID] Interval    Transfer   Bandwidth
[ 3] 0.0- 2.0 sec 2.25 MBytes 9.44 Mbits/sec
[ 3] 2.0- 4.0 sec  256 KBytes 1.05 Mbits/sec
[ 3] 4.0- 6.0 sec  128 KBytes  524 Kbits/sec
[ 3] 6.0- 8.0 sec  256 KBytes 1.05 Mbits/sec
[ 3] 8.0-10.0 sec 1.25 MBytes 5.24 Mbits/sec
[ 3] 10.0-12.0 sec 3.75 MBytes 15.7 Mbits/sec
[ 3] 12.0-14.0 sec 4.25 MBytes 17.8 Mbits/sec
[ 3] 14.0-16.0 sec 3.13 MBytes 13.1 Mbits/sec
[ 3] 16.0-18.0 sec 1.75 MBytes 7.34 Mbits/sec
[ 3] 18.0-20.0 sec 1.38 MBytes 5.77 Mbits/sec
[ 3] 20.0-22.0 sec 1.13 MBytes 4.72 Mbits/sec
[ 3] 22.0-24.0 sec  256 KBytes 1.05 Mbits/sec
[ 3] 24.0-26.0 sec  128 KBytes  524 Kbits/sec
[ 3] 26.0-28.0 sec  128 KBytes  524 Kbits/sec
[ 3] 28.0-30.0 sec  512 KBytes 2.10 Mbits/sec
[ 3] 30.0-32.0 sec 2.88 MBytes 12.1 Mbits/sec
[ 3] 32.0-34.0 sec 1.63 MBytes 6.82 Mbits/sec
[ 3] 34.0-36.0 sec 3.50 MBytes 14.7 Mbits/sec
[ 3] 36.0-38.0 sec  768 KBytes 3.15 Mbits/sec
[ 3] 38.0-40.0 sec 4.38 MBytes 18.4 Mbits/sec
[ 3] 40.0-42.0 sec 5.38 MBytes 22.5 Mbits/sec
[ 3] 42.0-44.0 sec 7.13 MBytes 29.9 Mbits/sec
[ 3] 44.0-46.0 sec 6.63 MBytes 27.8 Mbits/sec
[ 3] 46.0-48.0 sec 5.38 MBytes 22.5 Mbits/sec
[ 3] 48.0-50.0 sec 5.75 MBytes 24.1 Mbits/sec
[ 3] 50.0-52.0 sec 7.50 MBytes 31.5 Mbits/sec
[ 3] 52.0-54.0 sec 4.63 MBytes 19.4 Mbits/sec
[ 3] 54.0-56.0 sec 7.50 MBytes 31.5 Mbits/sec
[ 3] 56.0-58.0 sec 6.75 MBytes 28.3 Mbits/sec
[ 3] 58.0-60.0 sec 5.13 MBytes 21.5 Mbits/sec
[ 3] 60.0-62.0 sec 5.38 MBytes 22.5 Mbits/sec
[ 3] 62.0-64.0 sec 4.75 MBytes 19.9 Mbits/sec
[ 3] 64.0-66.0 sec 6.00 MBytes 25.2 Mbits/sec
[ 3] 66.0-68.0 sec 3.50 MBytes 14.7 Mbits/sec
[ 3] 68.0-70.0 sec 5.50 MBytes 23.1 Mbits/sec
[ 3] 70.0-72.0 sec 4.75 MBytes 19.9 Mbits/sec
[ 3] 72.0-74.0 sec 1.50 MBytes 6.29 Mbits/sec
[ 3] 74.0-76.0 sec 4.50 MBytes 18.9 Mbits/sec
[ 3] 76.0-78.0 sec 4.25 MBytes 17.8 Mbits/sec
[ 3] 78.0-80.0 sec 5.13 MBytes 21.5 Mbits/sec
[ 3] 80.0-82.0 sec 7.88 MBytes 33.0 Mbits/sec
[ 3] 82.0-84.0 sec 7.38 MBytes 30.9 Mbits/sec
[ 3] 84.0-86.0 sec 4.38 MBytes 18.4 Mbits/sec
[ 3] 86.0-88.0 sec 5.25 MBytes 22.0 Mbits/sec
[ 3] 88.0-90.0 sec 6.63 MBytes 27.8 Mbits/sec
[ 3] 90.0-92.0 sec 5.00 MBytes 21.0 Mbits/sec
[ 3] 92.0-94.0 sec 6.88 MBytes 28.8 Mbits/sec
[ 3] 94.0-96.0 sec 8.25 MBytes 34.6 Mbits/sec
[ 3] 96.0-98.0 sec 7.25 MBytes 30.4 Mbits/sec
附录
1：TD- LTE 和 LTE FDD 标准差异
TD- LTE 是我国自主研发的 4G 标准，是由 TD-SCDMA（3G 网络）发展而来。
LTE FDD 是现在国际上主流的，使用最广泛的 4G 网络。
现在全球有超过 200 个 LTE 的商用网络，其中超过 90% 是 FDD 的。
从技术上说，TD- LTE 采用的是时分双工，而 LTE FDD 采用的是频分双工
那什么是频分双工，什么又是时分双工呢？
先来解释 “双工”。
移动通信系统的工作方式分为：单工、半双工和全双工
1，单工就是信息只能向一个方向传播。例如寻呼机和收音机，只能接收信息，不能发出信息。
2，半双工就是信息可以双向传播，但是上传信息的时候只能上传，下载的时候只能下载。例如对讲机，你说话的时候听不见别人别人说，听别人说的时候自己不能说。
3， 全双工就是信息可以同时双向传播。例如手机，可以边听边说。
其中全双工又分为：时分双工 TDD，与频分双工 FDD。
​    所谓的频分双工就是将信息上传和信息下载放在两个不同的频段，称为上行频段和下行频段，且这两个频段必须对称。为了不防止上下行频段之间的信息串频，两个频段不能重叠，而且中间必须隔开一段，称为保护频。如下图：上行和下行频段相互分开

所谓的时分双工就是将上传和下载放在同一个频段，也就是上行频段和下行频段完全一样。那它是如何做到上下的信息不串频呢？其实很简单，顾名思义，频分双工分的是频段，那时分双工分的就是时间。将波传播的时间轴一分为二，
前半部分用于信息的上传，后一部分用于信息的下载。其实这从理论上更像是同步的半双工，但是由于上行和下行时间差距极短，我们无法感觉到，所以从效果上也是全双工。如下图：时间帧的第一帧为上行，第二帧而为下行，上下行共用一个频段，用时间的差将他们隔开。

​    接下来说一说移动 TD- LTE 和电信联通 LTE FDD 的优缺点，其实就是时分双工与频分双工的特点。
​     TD- LTE 由于采用上行和下行分时，所以上行和下行的时间差导致他信息传输的速度受到一定的限制。他的理论下载峰值为 100Mbps，相比 FDD 的 150Mbps 来说，慢了不少。当然 TD- LTE 的基站信号覆盖半径也比 LTE FDD 小一点。
​    LTE FDD 也并非都是优点。FDD 制式必须要找对称分开的上行、下行频段，也就是说它必须浪费更多的频段资源。那中国联通的 FDD 网为例，工信部给他发的频段牌照为，上行 17551765MHz 和下行 18501860MHz（2×10M），实际联通只得到了上下各 10M 的频段，但是加上当中的保护频段，一共占用了 1755~1860MHz 也就是 105MHz 的频段。这就导致了频段资源利用率低，是一种资源的浪费。目前，频率资源本身就紧张，能找到对称的上行和下行频段就尤其难。频率除了用在手机上网通讯上，像广播，军事，甚至无线路由器等民用领域也广泛使用。将来随着科技的进步，频率频段的稀缺会日益严重。
​    TD-LTE 和 FDD-LTE 是 4G 的两种国际标准，各有利弊。TD-LTE 占用频段少，节省资源，带宽长，适合区域热点覆盖；FDD 速度更快，覆盖更广，但占用资源多。适合广域覆盖。

]]></content>
      <categories>
        <category>embeded</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>embeded</tag>
        <tag>3G</tag>
        <tag>4G</tag>
        <tag>3531a</tag>
        <tag>移植</tag>
        <tag>嵌入式</tag>
      </tags>
  </entry>
  <entry>
    <title>海思 MPP&amp;UNF 构架源代码级分析</title>
    <url>/posts/13894dce/</url>
    <content><![CDATA[

文章写了好多年了，只在一个网站发布过 PDF 版本。行业内应该很多人看过这个。由于早期笔记使用 Word 格式，转换格式时有不少格式错误，笔者尽量修正。


关于本 blog，图床一般使用 github，已经配置了 CDN，如果图片还是未显示请自行代理解决


原创声明警告，文章禁止转载，禁止发布到其它任何网站，可以接受约稿。


前言：
​    本文通过分析海思文档和代码，把海思 SDK 的 MPI 和 UNF 构架大概实现思想和构架进行了简略的分析。着重分析了内存管理，底层功能如何实现。
​    前面章节简要分析了 NVR 芯片 MPI 构架及其内存管理机制，后面着重详细分析了 3798M 底层模块 api 和 drv 实现的细节过程及其方法流程。
​    本文前面简略分析了 DVR，MPI 构架的大体实现机制。后面就具体分析 3798M UNF 构架的实现。
本文不光分析了 UNF 构架，还使用了很多工具，辅助分析代码。这里从三个层面分析了 UNF 的实现。
1: 应用层，驱动层的实现框架，使用 source insight 查看代码并着重分析了 avplay 等几个模块。
2：静态分析函数调用。使用 cflow，dot 工具生成调用关系图
3：动态追踪运行过程。Ltrace, strace, valgrind 分析函数调用，perf 动态分析内核调用。
1:Hi35xx 系列芯片 MPP 构架
1.1 概述
海思提供的媒体处理软件平台 (Media Process Platform, 简称 MPP)，可支持应用软件快速开发。该平台对应用软件屏蔽了芯片相关的复杂的底层处理，并对应用软件直接提供 MPI（MPP Programe Interface）接口完成相应功能。该平台支持应用软件快速开发以下功能：输入视频捕获、H.264/MJPEG/JPEG/MPEG4 编码、H264/H.265/VC1/MPEG4/MPEG2/AVS 解码、视频输出显示、视频图像前处理（包括去噪、增强、锐化、Deinterlace） 、编码码流叠加 OSD、视频侦测分析、智能分析、音频捕获及输出、音频编解码等功能。
1.2 整体软硬件构架

MPP 平台支持的典型的系统层次如上图所示，主要分为以下层次：
硬件层
硬件层由 Hi35xx 芯片加上必要的外围器件构成。外围器件包括 Flash、DDR
（Double Data-Rate） 、视频 Sensor 或 AD、音频 AD 等。
操作系统层
基于 Linux 3.10.y 的 OS 系统。
媒体处理平台
基于操作系统层，控制芯片完成相应的媒体处理功能。它对应用层屏蔽了硬件处理细节，并为应用层提供 API 接口完成相应功能。
其他驱动
除媒体处理平台外，海思为 Hi35xx 芯片的其他相关硬件处理单元提供了相应的驱动，
包括 GMAC、SDIO、I2C、USB、SSP 等驱动。
应用层
基于海思媒体处理平台及其他驱动，由用户开发的应用软件系统。
1.3 海思媒体处理平台架构
海思媒体处理平台的主要内部处理流程如上图所示，主要分为视频输入（VI） 、视频处理（VPSS） 、视频编码（VENC） 、视频解码（VDEC） 、视频输出 (VO)、视频侦测分析 (VDA)、音频输入 (AI)、音频输出 (AO)、音频编码（AENC） 、音频解码（ADEC） 、区域管理（REGION）等模块。主要的处理流程介绍如下



VI 模块捕获视频图像，可对其做剪切、缩放、镜像等处理，并输出多路不同分辨
率的图像数据。


解码模块对编码后的视频码流进行解码，并将解析后的图像数据送 VPSS 进行图
像处理或直接送 VO 显示。可对 H.264/H.265/VC1/MPEG4/MPEG2/AVS 格式的视
频码流进行解码。


VPSS 模块接收 VI 和解码模块发送过来的图像，可对图像进行去噪、图像增强、
锐化等处理，并实现同源输出多路不同分辨率的图像数据用于编码、预览或抓
拍。


编码模块接收 VI 捕获并经 VPSS 处理后输出的图像数据，可叠加用户通过 Region
模块设置的 OSD 图像，然后按不同协议进行编码并输出相应码流。
VDA 模块接收 VI 的输出图像，并进行移动侦测和遮挡侦测，最后输出侦测分析
结果。


VO 模块接收 VPSS 处理后的输出图像，可进行播放控制等处理，最后按用户配置
的输出协议输出给外围视频设备。


AI 模块捕获音频数据，然后 AENC 模块支持按多种音频协议对其进行编码，最后
输出音频码流。


用户从网络或外围存储设备获取的音频码流可直接送给 ADEC 模块，ADEC 支持


1.4 MMZ 与模块绑定

MPP 提供系统绑定接口（HI_MPI_SYS_Bind） ，即通过数据接收者绑定数据源来建立
两者之间的关联关系（只允许数据接收者绑定数据源） 。绑定后，数据源生成的数据将
自动发送给接收者。
Uboot 环境变量中定义 linux 内核使用的内存大小
setenv 'mem=288M console=ttyAMA0,115200 root=/dev/mtdblock2 rootfstype=jffs2 mtdparts=hi_sfc:768K(boot),2304K(sdr021000),13M(rootfs)'
加载内核模块分配 MMZ 内存大小
insmod mmz.ko mmz=anonymous,0,0x8E000000,792M anony=1
例如 512M 的 DDR
DDR:
DDR:                                                          
-----------|----------|  0x80000000   # Memory managed by OS.             
   64M     |   OS     |                                                
           |          |                                                
-----------|----------|  0x84000000   # Memory managed by MMZ block anonymous.         
   448M    |    MMZ   |                                                
           |          |                                                
-----------|----------|  0xA0000000   # Memory managed by MMZ block jpeg.                      
1.5 HiMPP 支持的绑定关系



数据源
数据接收者




 VI
VO



VENC



VDA



VPSS



PCIV


VPSS
VO



VENC



VDA



VPSS



PCIV


VDEC
VPSS



VO（只能是标清设备或 single 模式分割）



VDA



PCIV


vo(WBC)
VO



VENC



VPSS



PCIV


AI
AENC



AO


ADEC
AO



1.6 函数约定说明


Open/Close
Open/Close 操作用来打开、关闭那些可枚举的设备。


Create/ Destroy
Create/ Destroy 操作用来创建、销毁那些不可枚举的设备。


Handle
Handle 用来标识一个 “不可枚举” 类型的设备。Handle 只在本进程内有效，也就是说 Handle 不可以跨进程传递 Handle 是一个 32bit 的数据，其低 8bit 表示设备的 ID，高 16bit 表示模块 ID。比如 0x00110000 表示模块 ID 为 0x11 的第 0 个设备。


Attach /Detach
Attach/Detach 用来绑定、解绑定两个设备直接的关联。


Attach 后，目的设备将自动处于 Start/Enable 状态； Detach 后，目的设备将自动处于 Stop/Disable 状态。
对于多级绑定，要求从最后一个设备逐级向前绑定，解绑定的顺序则相反，要求逐级向后。**
** 当绑定在一起的多个设备可以设置相同属性时，必须通过最后一个设备进行设置。


Get/Put
Get/Put 用来往某个模块输入数据。


Acquire/Release
Acquire/Release 用来从某个模块获取数据。


Get/Put 和 Acquire/Release 推荐成对使用

1.7 MPP 优缺点
1.7.1 MPP 优点
​    内存 VB 管理和模块绑定子系统，proc 运行时调试信息是 MPP 构架节约用户时间最大的设计。
​    大部分外围接口都封装好，用户调用接口直接使用，快速，方便。
1.7.2 MPP 缺点
​    没有相应子系统的源代码。出了问题，有 bug 必须需要海思查看，解决。
​    MPI 接口和标准 linux 接口差异非常大，构架也不一样。有问题需要找海思。中间时间成本。
不利于研发技术积累。
2:  MPP 和 UNF 对比
从函数命名，参数，使用方法来看。UNF 和 MPP 分开比较早，UNF 构架在上面函数约定说明基础上的 MPI 接口封装了一层，UNF-&gt;MPI 调用，UNF 开发支持更多的模块接口。MPP 的模块接口比较固定，比 UNF 少得多，增强了 MMZ 内存，VB 管理功能，模块绑定功能。
MPP 由 HI_MPI_SYS_Bind 来绑定两个模块，而 UNF 还是使用 Hi_XXX_Attach 来绑定两个模块。
MPP 内存管理 MMZ，VB 也比 UNF 更细致，强大。
UNF 支持更多的外设模块。如 TUNER（广播电视），CIPHER（芯片内部加密），Subtitle（字幕），PDM（低功耗），SCI（智能卡），GPU 等。
UNF 开源。在一些模块的实现中，也使用了一些开源项目，如 FFmpeg，Alsa，wpa_supplicant 等。
3:  3798 芯片 UNF 处理构架
3.1 应用架构
海思媒体处理平台（ MSP）实现了对海思高清机顶盒解决方案处理器中媒体、图形以
及外设的屏蔽和封装，对应用软件直接提供 API（ Application Program Interface）接口
完成相应功能。典型的应用架构如下图所示

3798 比 35xx 多了一个 UNF 层，它在 MPI 基础上进行了一层封装
软件架构主要包含以下 4 层：


UNF 层
媒体处理平台（ MSP）对外统一的应用开发接口。


MPI 层
处理器各模块硬件能力实现层的用户态部分。


DRV 层
处理器各模块硬件能力实现层的内核态部分。


HAL 层
处理器各模块的硬件抽象层。


3.2 3798SDK 概览（功能介绍）
媒体处理平台（ MSP）中所有模块按照功能可以分为媒体处理，图形处理，外设处理 3
类：


媒体处理
DEMUX、 AVPLAY、 SOUND、 DISPLAY、 VO、 HDMI、 PVR、 VDEC、 VENC、
ADEC、 AENC、 VI、 AI


图形处理
HIFB、 HIGO、 TDE、 JPEG、 JPGE、 GPU


外设处理
Cipher、 OTP、 PMOC、 Frontend、 I2C、 SCI、 KEYLED、 GPIO、 IR、 WDG、 C51


3.3 3798 内存管理
3.3.1 Mmz 内存
3798 的 mmz 内存在 uboot bootargs 环境变量中分配，在内核中大块连续内存使用 dma_alloc_from_contiguous（drv/mmz/drv_media_mem_v2.c）来分配内存， 小块内存使用 kmalloc 分配，并且使用内核链表标记管理。和应用层交互使用 mamp，umamp，并使用内核链表管理内存。这点和 35xx DVR 芯片有很大区别，DVR 芯片模块内存和 linux 内核使用内存不再一个地方，应该是通过物理地址往虚拟地址映射来使用的。
# cat /proc/cmdline
mem=1G console=ttyAMA0,115200 root=/dev/romblock3 rootfstype=squashfs mtdparts=hinand:5M(boot),1M(baseparam),7M(kernel),18M(rootfs),64M(appfs),16M(qte),4M(config),12M(log),1M(logo) mmz=ddr,0,0,500M
具体就是在 bootargs 中配置 mem=1G mmz=ddr,0,0,435M
查看内存使用情况跟监控相同，通过 cat /proc/media-mem

3.3.2 解码 vid 内存
关于码流解码过程中视频缓冲 buffer u32VidBufSize 配置：
创建 avplay 时，可以指定视频 es buf 大小，参考如下代码
Ret = HI_UNF_AVPLAY_GetDefaultConfig(&amp;AvplayAttr, HI_UNF_AVPLAY_STREAM_TYPE_ES);
AvplayAttr.stStreamAttr.u32VidBufSize = 2*1024*1024;
Ret |= HI_UNF_AVPLAY_Create(&amp;AvplayAttr, &amp;hAvplay[i]);
Es buf 的作用存储码流原始 es 流。
这个 buffer 的大小跟码流分辨率、码率都有关系，一般情况下，D1/720P/1080P/4K 码流的配置为 2M/3M/5M/16M 即可，特殊码流除外。
3.4 3798 模块
DEMUX：
​	数据输入模块。IF，TSI，RAM。
​	NVR 使用的是 RAM 接口输入 ES 码流。
VI:
虚拟 VI
VDEC
​	解码器模块提供一组函数指针，供解码使用。目前有 264，mpeg4 两个。
视频解码的简单流程是：
步骤 1 VDEC 从 Demux 或 ES buffer 获取 ES 数据送 Firmware 进行解码（ Firmware: StreamInput (VDEC-&gt;Firmware)）。
步骤 2 Firmware 将解码完的 1D 或者 2D 帧存放在帧 buffer 中。
步骤 3 VDEC 从帧 buffer 中获取（ Firmware: Frame Output (Firmware-&gt;VDEC)）视频帧放入其帧队列中。
步骤 4 VPSS 在线程中从 VDEC 的帧队列中取帧做解码后处理（ Frame Output (VDEC-&gt;VPSS)）。
步骤 5 AVPLAY 向 VDEC 获取视频帧， VDEC 从 VPSS 获取视频帧返回给 AVPLAY。
SYNC：
音视频同步工具
DISPLAY：显示设备
WINDOW：显示通道
msp 目录下的 “windowXXYY” 节点的中的 XX 为显示通道的编号， YY 为 window 序号。比如 window0100， bit [15:8] 的 01 表示该 window 基于 DISPLAY1 创建， bit [7:0] 的 00 表示 window 序号为 0。有支持 3D 显示
DISP（ Display）模块接收 WINDOW 提供的视频图像、 Frame Buffer 提供的图形画
面，进行图像叠加处理和图像色彩调节，并将叠加后图像通过多种视频输出端口输出
给显示设备；此外， DISP 支持获取视频输出端口上的包含视频和图形的完整图像。
窗口类型

Display：独立显示窗口
 Virtual：虚拟窗口
 Main：同源显示主窗口
 Slave：同源显示从窗口



SO（ Subtitle Output）
PDM

PDM (Product Data Manager) 模块用于管理与产品相关的数据，包括基本参数、开机画
面参数及数据、瞬播参数及数据的管理

用户通过镜像制作工具制作基本参数镜像与瞬播镜像，通过烧写工具烧写至 FLASH，PDM 模块在 BOOT 下将基本参数及瞬播数据读入内存，并传递至 KERNEL。 KERNEL 下瞬播从 PDM 模块获取参数及数据，调用 DEMUX、 VDEC、 VO 等模块驱动，完成瞬播播放
demux

DEMUX 模块接收 DEMOD 或内存中的 TS 流，按客户应用程序（下简称 APP）的设
置提取出其中的 SEC 数据、 PES 数据、 TS 数据、音频数据和视频数据。 APP 获取
SEC 数据、 PES 数据和 TS 数据进行处理。 AVPLAY 获取音频数据进行处理， VDEC 获
取视频数据进行处理。

AVPLAY 主要依赖 ADEC/VDEC/DEMUX 等模块，其向应用或中间件播放器提供基本
的播放业务相关接口。

3.5 3798 和 NVR 模块使用方面区别：
3798 模块中 vpss，sync 等模块是其它模块自动创建，自动绑定处理的。这点和 NVR 系列芯片差别很大，nvr 中 vi，vpss，vo 都需要用户自己绑定，设置属性，而 3798 中 vpss，vo 创建，属性设置是在上层模块中自动处理的（少量设置属性上层传递下去）。
​    简单来说，MPP 接口只实现了基本的功能接口，没有封装或很少封装。
UNF 应用层实现了很多业务接口，对底层驱动进行了多层封装，并且实现了一些常用的业务。
4: 3798 代码祥看
4.1 分析方法
4.1.1：查看代码，静态分析应用层，驱动层实现方法
​    使用 Source insight 分析 kernel，msp 代码。
4.1.2：图示静态分析函数调用关系
​    使用 cflow， tree2dotx，和 dot 生成函数静态调用图。
4.1.3：图示动态分析函数调用关系：库函数，系统调用，内核调用

​    使用 ltrace 分析系统库函数
​    strace 分析系统调用流程
​    使用 Ftrace，valgrind，gprof2dot 生成运行时调用图。
​    Perf 分析内核空间调用。发现一些依赖库在 ubuntu12.04 里面不可用。

这一步实现了 valgrind 动态分析，其它的几个工具需要交叉编译，TODO。使用 Perf 可能需要换更新的 linux 版本。
其它还有 time (大概运行时间)，gconv（覆盖率统计）等分析方式。
4.2 基础模块：hi_media hi_mmz hi_common

​    可以从 lsmod 中很清晰的看出来 hi_media hi_mmz hi_common 这几个模块的基础地位。hi_media 基础模块管理，hi_mmz 提供内存管理，hi_common 提供 proc，log 等基础功能，符号导出供其他海思模块使用。
Common

COMMON 模块是 SDK 的基础模块，提供的 API 主要供 SDK 的其他模块调用。
COMMON 模块现在主要有以下功能：

系统初始化和去初始化；
版本信息获取；
获取时间戳；
寄存器读写、映射功能；
MMZ 内存使用；
调试信息控制；
Flash 操作。



4.2.1 基本通用模块应用层接口 common/api
HiSTBLinuxFS/source/common/api
mpi_mem.c
MEM_POOL_Init 应用层的内存池，重复利用。
mpi_memmap.c
映射使用链表区分。管理mmap映射
 
 
mpi_module.c
HI_MODULE_Init中有打开内存操作，内存统一管理。
模块id，名称注册，相互查找。
 
mpi_stat.c
线程时间归零，等相关处理
 
hi_common.c
proc，sys一些路径目录增删提供了用户层接口，mmz内存管理用户层接口
 
mpi_userproc
用户层提供线程 通用proc接口，proc读写是在其它模块内部实现的，函数指针形式
 
 
注：himedia 相关模块是海思自己实现的内核子系统。有自己实现的总线，驱动，设备模型结构体。也是在标准linux模型基础上封装的。
 
4.2.2 基本通用模块驱动接口 common/dev
HiSTBLinuxFS/source/common/dev
drv_dev_ext_k.c 重要
HI_DRV_DEV_Init 所有模块宏定义在这里，注册模块结构体在这里
himedia.c himedia_bash.c     模块注册，注销基础函数
#define DYNAMIC_MINORS 128 /* like dynamic majors */            himedia主设备号218
static unsigned char himedia_minors[DYNAMIC_MINORS / 8];
 
typedef struct tagPM_BASEDEV_S{
    HI_S32        id;
    const HI_S8    * name;
    struct device    dev;
}PM_BASEDEV_S;
 
#define TO_PM_BASEDEV(x) container_of((x), PM_BASEDEV_S, dev)
 
typedef struct tagPM_BASEOPS_S {
    HI_S32  (*probe)(PM_BASEDEV_S *);
    HI_S32  (*remove)(PM_BASEDEV_S *);
    HI_VOID (*shutdown)(PM_BASEDEV_S *);
    HI_S32  (*prepare)(PM_BASEDEV_S *);
    HI_VOID (*complete)(PM_BASEDEV_S *);
    HI_S32  (*suspend)(PM_BASEDEV_S *, pm_message_t state);
    HI_S32  (*suspend_late)(PM_BASEDEV_S *, pm_message_t state);
    HI_S32  (*resume_early)(PM_BASEDEV_S *);
    HI_S32  (*resume)(PM_BASEDEV_S *);
}PM_BASEOPS_S;
 
 
typedef struct tagPM_BASEDRV_S {
    HI_S32  (*probe) (PM_BASEDEV_S *);
    HI_S32  (*remove)(PM_BASEDEV_S *);
    HI_VOID (*shutdown)(PM_BASEDEV_S *);
    HI_S32  (*suspend)(PM_BASEDEV_S *, pm_message_t state);
    HI_S32  (*suspend_late)(PM_BASEDEV_S *, pm_message_t state);
    HI_S32  (*resume_early)(PM_BASEDEV_S *);
    HI_S32  (*resume)(PM_BASEDEV_S *);
    struct device_driver driver;
}PM_BASEDRV_S;
 
typedef struct tagPM_DEVICE_S  {
    HI_S32 minor;
    const HI_S8 *name;
    struct module *owner;
    const struct file_operations *app_ops;
    PM_BASEOPS_S *base_ops;
    struct list_head list;
    struct device *app_device;
    PM_BASEDEV_S *base_device;
    PM_BASEDRV_S *base_driver;
}PM_DEVICE_S;
 
static struct class *himedia_class;
static struct file_operations himedia_fops = {
    .owner        = THIS_MODULE,
    .open        = himedia_open,
};
 
设备模型结构体
struct himedia_devobj {
    PM_BASEDEV_S pdev;
    char name[1];
};
 
typedef struct tagPM_BASEDEV_S{
    HI_S32        id;
    const HI_S8    * name;
    struct device    dev;
}PM_BASEDEV_S;
 
海思模块顶层总线 himedia_bus
struct device himedia_bus = {
         .init_name        = "himediaBusDev",
         .release    = himedia_bus_release
};  /*top level bus, parent and bus member are both NULL*//*CNcomment:这是顶层总线，parent 和 bus 成员为 NULL*/
struct bus_type himedia_bus_type = {
         .name                = "himediaBus",
         .dev_attrs        = himedia_dev_attrs,
         .match               = himedia_match,
         .uevent              = himedia_uevent,
         .pm                     = HIMEDIA_PM_OPS_PTR,
};
定义HIMEDIA_PM_OPS_PTR
                            static struct dev_pm_ops himedia_dev_pm_ops = {
                                     .prepare        = himedia_pm_prepare,
                                     .complete       = himedia_pm_complete,
                                     .suspend        = himedia_pm_suspend,
                                     .resume         = himedia_pm_resume,
                                     .freeze         = himedia_pm_freeze,
                                     .thaw           = himedia_pm_thaw,
                                     .poweroff       = himedia_pm_poweroff,
                                     .restore        = himedia_pm_restore,
                                     .suspend_noirq  = himedia_pm_suspend_noirq,
                                     .resume_noirq   = himedia_pm_resume_noirq,
                                     .freeze_noirq   = himedia_pm_freeze_noirq,
                                     .thaw_noirq     = himedia_pm_thaw_noirq,
                                     .poweroff_noirq = himedia_pm_poweroff_noirq,
                                     .restore_noirq  = himedia_pm_restore_noirq,
                            };
                            #define HIMEDIA_PM_OPS_PTR     (&amp;himedia_dev_pm_ops)


内核到用户往用户空间写文件调试
drv_file_ext.c 提供内核空间创建，读写用户空间文件函数，/mnt 文件存储路径。提供了内核数据导出到用户空间的方法。
应该是 echo * &gt; /proc/msp/** 这种调试方式的实现方式
内核 log 日志
drv_log_ioctl.h  打印日志相关。  这里日志位置可选0:串口 1:网络 2:U盘
/*structure of mode log level */
/*CNcomment: 模块打印级别控制信息结构 */
typedef struct hiLOG_CONFIG_INFO_S
{
    HI_U8 ModName[16+12];     /*mode name 16 + '_' 1 + pid 10 */
    HI_U8 u8LogLevel;         /*log level*//*CNcomment:  模块打印级别控制 */
    HI_U8 u8LogPrintPos;      /*log output location, 0:serial port; 1:network;2:u-disk*//*CNcomment:  模块打印位置控制 0:串口 1:网络 2:U盘 */
    HI_U8 u8UdiskFlag;        /* u-disk log flag */
}LOG_CONFIG_INFO_S;
 
 
hi_debug.h    log调试级别
/**Default level of the output debugging information*/
/**CNcomment: 默认的调试信息输出级别*/
#define HI_LOG_LEVEL_DEFAULT HI_LOG_LEVEL_ERROR
 
/**Level of the output debugging information*/
/**CNcomment: 调试信息输出级别*/
typedef enum hiLOG_LEVEL_E
{
    HI_LOG_LEVEL_FATAL   = 0,     /**&lt;Fatal error. It indicates that a critical problem occurs in the system. Therefore, you must pay attention to it.*/
                                  /**&lt;CNcomment: 致命错误, 此类错误需要特别关注，一般出现此类错误代表系统出现了重大问题 */
    HI_LOG_LEVEL_ERROR   = 1,     /**&lt;Major error. It indicates that a major problem occurs in the system and the system cannot run.*/
                                  /**&lt;CNcomment: 一般错误, 一般出现此类错误代表系统出现了比较大的问题，不能再正常运行 */
    HI_LOG_LEVEL_WARNING = 2,     /**&lt;Warning. It indicates that a minor problem occurs in the system, but the system still can run properly.*/
                                  /**&lt;CNcomment: 告警信息, 一般出现此类信息代表系统可能出现问题，但是还能继续运行 */
    HI_LOG_LEVEL_INFO    = 3,     /**&lt;Message. It is used to prompt users. Users can open the message when locating problems. It is recommended to disable this message in general.*/
                                  /**&lt;CNcomment: 提示信息, 一般是为提醒用户而输出，在定位问题的时候可以打开，一般情况下建议关闭 */
    HI_LOG_LEVEL_DBG     = 4,     /**&lt;Debug. It is used to prompt developers. Developers can open the message when locating problems. It is recommended to disable this message in general.*/
                                  /**&lt;CNcomment: 提示信息, 一般是为开发人员调试问题而设定的打印级别，一般情况下建议关闭 */
 
    HI_LOG_LEVEL_BUTT
} HI_LOG_LEVEL_E;
 
drv_media_mem_v2.c    实现了cat /proc/media-mem
 
drv_mem_ext.c 实现了 KMEM_POOL_S 的管理，
 
 
内核模块管理
drv_module_ext.c

COMMON_DRV_ModInit

         MMNGR_DRV_ModInit

        

    s32Ret = HI_DRV_MODULE_Register(HI_ID_SYS,    "HI_SYS",      HI_NULL);

    s32Ret |= HI_DRV_MODULE_Register(HI_ID_MODULE, "HI_MODULE",   HI_NULL);

    s32Ret |= HI_DRV_MODULE_Register(HI_ID_LOG,    "HI_LOG",      HI_NULL);

    s32Ret |= HI_DRV_MODULE_Register(HI_ID_PROC,   "HI_PROC",     HI_NULL);

    s32Ret |= HI_DRV_MODULE_Register(HI_ID_STAT,   "HI_STAT",     HI_NULL);

    s32Ret |= HI_DRV_MODULE_Register(HI_ID_MEM,    "HI_MEM",      HI_NULL);

 

drv_media_mem.c  使用dma_alloc_from_contiguous来分配

HI_DRV_MMZ_Init 这里根据bootargs传递的mmz参数分配内存大小。 mmz分配时的参数：&lt;mmz_name&gt;,&lt;gfp&gt;,&lt;phys_start_addr&gt;,&lt;size&gt;,&lt;alloc_type&gt;"

内核 Proc 的实现
drv_proc_ext.c
HI_DRV_PROC_Init 实现cat /proc/hisi/msp/
    proc_mkdir("graphics", g_pHisi_proc);
    proc_symlink("msp", NULL, "hisi/msp");
    proc_symlink("graphics", NULL, "hisi/graphics");
drv_userproc.c    proc 使用红黑树管理目录路径
​    创建销毁目录，路径在这里实现，具体每一个不同模块的 proc 文件读写在每个模块内部实现，使用函数指针。
4.2.3 业务模块应用层通用组件 source/component
/home/andy/HiSTBLinuxFS/source/component  这个目录里面很多目录只有.so .a 库，没有源代码。
/source/component/hiplayer 没有源码。
hi_debug.h   各种调试宏定义，不同级别调试定义
HI_MALLOC   内存分配使用了内核链表管理
内存在一个模块内分配，往用户空间传递物理地址，其它模块使用这个物理地址映射到虚拟地址，这样来共享内存
​    海思这里大多数模块都只提供了编译后的库
4.3 海思专用组件
4.3.1 海思 MSP 模块应用层接口 source/msp/api
Avplay 分析
HI_MPI_AVPLAY_Create
         AVPLAY_FrcCreate  帧率控制？    
         HI_MPI_SYNC_Create     音视频同步
         AVPLAY_CreateThread
​     
上图插图的是 svg 格式图片，可以使用 IE，firefox 打开，最好使用专门的看图软件打开。
HI_MPI_VDEC_AllocChan
         VPSS_Control(pstVdec-&gt;hVdec,VPSS_CMD_CREATEVPSS,&amp;(pstVdec-&gt;hVpss))
        
UNF调用一般过程，最终采用ioctl调用驱动   
HI_UNF_AVPLAY_GetBuf
         HI_MPI_AVPLAY_GetBuf
                   HI_MPI_VDEC_ChanGetBuffer
                            VDEC_GetStreamBuf                /* If get but not put, return last address */    这里有对不对称调用特殊处理
                                     ioctl(s_stVdecAdpParam.s32DevFd, UMAPC_VDEC_GETBUF, &amp;stBufParam);     
                                    
HI_MPI_AVPLAY_Start
         AVPLAY_StartVidChn
                   HI_MPI_SYNC_Start
                   HI_MPI_VDEC_ChanStart
                             ioctl(g_SyncDevFd, CMD_SYNC_START_SYNC, &amp;SyncId);
         HI_MPI_SYNC_Play 结构体状态改变
         AVPLAY_Play             结构体状态控制
         HI_MPI_STAT_Event                                   
 
HI_MPI_AVPLAY_Stop
         AVPLAY_StopVidChn
                   HI_MPI_VDEC_ChanStop
                            VDEC_ChanStop      这里调用函数指针
                   HI_MPI_VDEC_ResetChan
                            VDEC_ResetStreamBuf
                            VDEC_VPSSCMD(hVdec, VPSS_CMD_RESETVPSS, HI_NULL);         调用函数指针，指向VPSS_Control
                   AVPLAY_ResetWindow
                   HI_MPI_SYNC_Stop
         HI_MPI_STAT_Event(STAT_EVENT_VSTOP, 0);
 
VDEC使用函数指针集来支持多种解码方式，内部vfmw。mjpeg，内部硬件265协处理器
mpi_vdec_vpu.c
HI_MPI_VDEC_Init
         HI_CODEC_Register(VDEC_MJPEG_Codec());
         HI_CODEC_Register(VDEC_VFMW_Codec());
 
static HI_CODEC_S hi_codecVPU_entry =
{
    .pszName                  = "VPU",
    .unVersion                 = {.stVersion = {1, 0, 0, 0}},
    .pszDescription = "Hisilicon H265 codec",
 
    .GetCap                      = HI_VPU_GetCap,
    .Create                       = HI_VPU_Create,
    .Destroy            = HI_VPU_Destroy,
    .Start                           = HI_VPU_Start,
    .Stop                            = HI_VPU_Stop,
    .Reset                         = HI_VPU_Reset,
    .SetAttr             = HI_VPU_SetAttr,
    .GetAttr            = HI_VPU_GetAttr,
    .DecodeFrame          = HI_VPU_DecodeFrame,
    .EncodeFrame = HI_NULL,
    .RegFrameBuffer = HI_VPU_RegFrameBuffer,
    .GetStreamInfo        = HI_VPU_GetStreamInfo,
    .Control             = HI_VPU_Control,
};
 
avplay，vi和 vo之间使用vpss关联。
HI_UNF_VO_DetachWindow
         HI_MPI_AVPLAY_DetachWindow
                   HI_MPI_VDEC_DestroyPort
         HI_MPI_VI_Detach(hSrc, hWindow);
                   VI_DetachFromVpss
        
HI_MPI_AVPLAY_ChnClose
         AVPLAY_FreeVidChn
                   HI_MPI_VDEC_ChanBufferDeInit
                            VDEC_VFMWSpecCMD(hVdec, VFMW_CMD_DETACHBUF, HI_NULL);
                            VDEC_DestroyStreamBuf(pstVdec-&gt;hStreamBuf);                   ummap内存块，ioctl通知内核vdec销毁内存
                   AVPLAY_FreeVdec
                            HI_MPI_VDEC_FreeChan
                                     VPSS_Control(pstVdec-&gt;hVdec,VPSS_CMD_DESTORYVPSS,&amp;(pstVdec-&gt;hVpss));
                                     VDEC_DestroyCodec(pstVdec);
 
HI_UNF_AVPLAY_Destroy
         HI_MPI_AVPLAY_Destroy
                   HI_MPI_SYNC_Destroy(pAvplay-&gt;hSync);
                   ioctl(g_AvplayDevFd, CMD_AVPLAY_DESTROY, &amp;AvplayUsrAddr.AvplayId);
                  
avplay内部的线程
    (HI_VOID)pthread_join(pAvplay-&gt;AvplayDataThdInst, HI_NULL);
#ifdef AVPLAY_VID_THREAD
    (HI_VOID)pthread_join(pAvplay-&gt;AvplayVidDataThdInst, HI_NULL);
#endif
    (HI_VOID)pthread_join(pAvplay-&gt;AvplayStatThdInst, HI_NULL);          
4.3.2 海思 MSP 模块驱动层接口 source/msp/drv/
VENC

VENC 模块的具体工作原理如上图所示，注意图中褐色箭头，是 VENC 调用到 VPSS 模块，来对帧信息做缩放处理后编码的数据流，该处理只用于外部用户送帧的模式。若在绑定情况下出现帧信息分辨率与编码分辨率不匹配， VENC 模块会通知绑定的前级模块进行缩放处理，而不会自行调用 VPSS 模块缩放。
VENC_DRV_ModInit
         VENC_DRV_Init
                   HI_DRV_MODULE_Register(HI_ID_VENC, "HI_VENC", (HI_VOID*)&amp;s_VencExportFuncs);
                            MODULE_DRV_Register
                                     ModuleMgr_Link_AddNode(g_pstKModuleHeader, &amp;stModule); 链表管理
                                     LOGAddModule((HI_PCHAR)pu8ModuleName, (HI_MOD_ID_E)u32ModuleID);  在log模块中注册
         HI_DRV_DEV_Register(&amp;g_VencRegisterData)
                   HI_DRV_PM_Register     海思模块管理非常重要的模块，了解这个函数实现过程就大概明白海思内核模块实现思想了
         VENC_DRV_BoardDeinit();      一些寄存器配置，reset，clock操作。
         venc调用硬件协处理器，涉及263,264，mpeg4，
    snprintf(g_VencRegisterData.devfs_name, 64, "%s", UMAP_DEVNAME_VENC);
    g_VencRegisterData.fops   = &amp;VENC_FOPS;
    g_VencRegisterData.minor  = UMAP_MIN_MINOR_VENC;
    g_VencRegisterData.owner  = THIS_MODULE;
    g_VencRegisterData.drvops = &amp;venc_drvops;      
avplay


AVPLAY 主要由以下三部分组成：

音视频解码器
同步播放控制模块
命令与状态管理模块



主要负责响应外部控制命令的执行、状态查询上报、使解码后的帧数据通过同步控制
模块输出
avplay 初始化分析
AVPLAY_DRV_ModInit
​    HI_DRV_MODULE_Register
​         HI_DRV_MODULE_Register(HI_ID_AVPLAY, AVPLAY_NAME, HI_NULL);
​             ModuleMgr_Link_AddNode  内核模块管理
​             KMODULE_MEM_POOL_AddModule
​                 KMODULE_MEM_POOL_FindNode    找到空的没有使用的节点
​                 KMODULE_MEM_POOL_MALLOC 分配内存，然后放到链表
​             LOGAddModule                    日志
​    HI_DRV_DEV_Register(&amp;g_AvplayRegisterData)
​         HI_DRV_PM_Register(&amp;s_umap_devs[i]);   himedia封装处理
​             himedia_device_alloc(himedia-&gt;name, -1);
​             himedia_device_add(bdev);
​                 dev_set_name(&amp;pdev-&gt;dev, "%s.%d", pdev-&gt;name, pdev-&gt;id);
​                 device_add(&amp;pdev-&gt;dev);
​             device_create(himedia_class, &amp;(bdev-&gt;dev), dev, NULL, "%s", himedia-&gt;name);
​             himedia_driver_alloc(himedia-&gt;name, himedia-&gt;owner, himedia-&gt;base_ops);
​             himedia_driver_register(bdrv);
​                 driver_register(&amp;drv-&gt;driver);
​   
 
  g_AvplayRegisterData.fops = &amp;AVPLAY_FOPS;
  g_AvplayRegisterData.minor = UMAP_MIN_MINOR_AVPLAY;
  g_AvplayRegisterData.owner = THIS_MODULE;
  g_AvplayRegisterData.drvops = &amp;AVPLAY_DRVOPS;  
 
  s_umap_devs[i].minor = umapd-&gt;minor;
  s_umap_devs[i].name = umapd-&gt;devfs_name;
  s_umap_devs[i].owner = umapd-&gt;owner;
  s_umap_devs[i].app_ops = umapd-&gt;fops;
  s_umap_devs[i].base_ops = umapd-&gt;drvops;
IOCTL 实现分析 基于 avplay
在 HI_DRV_DEV_Register 中注册
static struct file_operations AVPLAY_FOPS =
{
    .owner          =  THIS_MODULE,
    .open           =  AVPLAY_DRV_Open,
    .unlocked_ioctl =  AVPLAY_DRV_Ioctl,
    .release        =  AVPLAY_DRV_Close,
};      
AVPLAY_DRV_Ioctl
         HI_DRV_UserCopy(ffile-&gt;f_dentry-&gt;d_inode, ffile, cmd, arg, AVPLAY_Ioctl);
                   func(inode, file, cmd, (parg));           这里对ioctl进行了一层封装，copy_from_user，copy_to_user的自动化处理
AVPLAY_Ioctl(struct inode *inode, struct file *file, unsigned int cmd, HI_VOID *arg)  
                   CMD_AVPLAY_CREATE            
                            AVPLAY_Create
                                     HI_DRV_MMZ_AllocAndMap(BufName, MMZ_OTHERS, 0x2000, 0, &amp;MemBuf);
                                     HI_DRV_PROC_AddModule(ProcName, HI_NULL, HI_NULL);                 这里实现了proc目录的生成，下面是读写proc
                                pProcItem-&gt;read = AVPLAY_ProcRead;
                                pProcItem-&gt;write = AVPLAY_ProcWrite;
avplay 多个实例如何找到对应实例
AVPLAY_GET_INST_AND_LOCK();
         AVPLAY_CheckHandle
                   pAvplayUsrAddr-&gt;AvplayId = hAvplay &amp; 0xff;
                   ioctl(g_AvplayDevFd, CMD_AVPLAY_CHECK_ID, pAvplayUsrAddr);
drv 中的实现
AVPLAY_Ioctl            
         AVPLAY_CheckId              
                   pAvplayUsrAddr-&gt;AvplayUsrAddr = g_AvplayGlobalState.AvplayInfo[pAvplayUsrAddr-&gt;AvplayId].AvplayUsrAddr;
VPSS

    g_VpssRegisterData.fops   = &amp;s_VpssFileOps;
    g_VpssRegisterData.minor  = UMAP_MIN_MINOR_VPSS;
    g_VpssRegisterData.owner  = THIS_MODULE;
g_VpssRegisterData.drvops = &amp;s_VpssBasicOps;
VPSS_DRV_Init
VPSS_CTRL_Init
         VPSS_CTRL_RegistISR     注册中断
         VPSS_CTRL_InitInstList((VPSS_IP_E)i)     管理vpss实例链表初始化
         VPSS_HAL_Init                   内存，寄存器配置
         VPSS_CTRL_CreateThread      内核线程
                   VPSS_CTRL_ThreadProc
                            VPSS_CTRL_CreateTask           创建任务
                            VPSS_CTRL_StartTask               开始任务
VDEC


Avplay 解码 ES 流过程
步骤 1 初始化并配置相关设备，如 DISPLAY、 VO、 SOUND、 DEMUX 设备等。
步骤 2 调用 HI_UNF_AVPLAY_Init 接口初始化 AVPLAY 设备。
步骤 3 调用 HI_UNF_AVPLAY_GetDefaultConfig 接口获取缺省的 AVPLAY 配置，注意选择 HI_UNF_AVPLAY_STREAM_TYPE_ES 模式。
步骤 4 根据应用需要，修改码流属性参数。
步骤 5 调用 HI_UNF_AVPLAY_Create 接口创建 AVPLAY 播放器。
步骤 6 调用 HI_UNF_AVPLAY_ChnOpen 接口打开音频或视频通道。
步骤 7 调用 HI_UNF_AVPLAY_SetAttr 接口设置音频解码器或视频解码器属性，同步设置为自由播放。
步骤 8 调用 HI_UNF_SND_CreateTrack 创建 Track。
步骤 9 调用 HI_UNF_SND_Attach 接口将音频播放器与 Track 绑定。
步骤 10 调用 HI_UNF_VO_AttachWindow 接口将视频播放器与 VO 的窗口绑定。
步骤 11 调用 HI_UNF_VO_SetWindowEnable 接口使能窗口。
步骤 12 调用 HI_UNF_AVPLAY_Start 接口发送 Start 命令，开始播放音频或视频。
步骤 13 调用 HI_UNF_AVPLAY_GetBuf 接口申请存放音频或视频的缓冲区。
步骤 14 通过内存拷贝或文件读取等方式，将音频或视频数据直接写到缓冲区中。
步骤 15 调用 HI_UNF_AVPLAY_PutBuf 接口更新音视频缓冲区中的读写指针。
步骤 16 播放任务结束后，首先调用 HI_UNF_AVPLAY_Stop 接口停止 AVPLAY，再调用 HI_UNF_AVPLAY_Destroy 接口销毁 AVPLAY，释放相关资源。
步骤 17 关闭相关设备，如 DISPLAY 设备、 VO 设备、 SOUND 设备、 DEMUX 设备和 AVPLAY

MCE 实现了启动过程画面的平滑切换
IR

驱动层
负责完成红外模块的中断处理，在底半部中遍历所有协议并调用 match 函数来判定当前收到的红外帧属于哪种协议。如果没有匹配，则丢弃当前帧。完成最顶层的错误处理：如果当前帧当前时刻还不能被解析，则会等待大约 200ms 之后再次尝试，如果失败，则丢弃当前帧。
协议适配层
完成各个协议的初始化工作，向上提供遍历协议的接口，向下提供容纳协议描述符的存储空间。
协议处理层
协议处理层完成判定：由从某个 symbol 开始的一连串 symbol 是不是符合本协议的一
帧。在判定某一帧符合本协议的前提条件下，完成一帧 symbol 的解析，将对应的键值解析出来。如果在解析过程中出错，或者判定是本协议的帧，但无法解析时，完成错误处理。

​    



4.4 Sample_mosaic 分析
应用层调用

上图是部分截图，完整大的原图见目录中 svg 文件
valgrind --tool=callgrind ./sample_mosaic 1080P.h264 h264

系统调用
Strace 分析

5: 小结：
海思 MPI 驱动其实就是在标准 linux 驱动基础之上封装了一层，增加了 log，proc，内存管理（映射，链表）功能。MPI 是在标准 linux 驱动基础上封装了 DVR 常用外围逻辑接口，并且统一并简化了接口操作方式，原来各个外围子系统操作方式差别很大，不同实现框架，实现方式使用方法也不一样（如 VI，VO，AI/AO，VPSS，如果自己用标准 linux 子系统实现要复杂得多）。
应用层 MPI 接口是在 MPI 驱动基础上再次封装了一层，封装了驱动的调用，配置等操作，在驱动功能的基础上进一步封装完成了一些简单的业务功能接口，方便了用户的使用。UNF 就是在 MPI 基础上增加了业务逻辑封装，把常用的业务逻辑封装成接口，大大方便用户的应用程序开发。
5.1 UNF 相对标准内核模块区别
5.1.1 Proc 读写调试。
实时查询运行状态，修改设置。通用的 proc 目录、文件创建销毁有通用接口。读写 proc 文件在每个内核模块中有单独实现。
5.1.2 内核空间往应用空间写文件
方便调试，Dump 内核数据到用户控件方便定位 Bug。
HI_DRV_FILE_Open
filp_open
HI_DRV_FILE_Close
​    filp_close
HI_DRV_FILE_Read
​    pFile-&gt;f_op-&gt;read
HI_DRV_FILE_Write
​    pFile-&gt;f_op-&gt;write
HI_DRV_FILE_Lseek
​    vfs_llseek
5.1.3Log 管理
日志打印分级，实时修改。如何实现的见前面章节。
5.1.4 内存映射
物理地址，虚拟地址映射关系管理，小块内存使用 kmalloc 申请，大块内存使用 dma_alloc_from_contiguous 申请。
使用内核链表管理。
打印到 proc，log 模块中，实时查看运行状态，内存。
方便查找，打印。
在多个内核共享数据也是这样实现的。
5.2 代码分析方法
5.2.1 查看代码，静态分析应用层，驱动层实现方法
5.2.2 图示静态分析函数调用关系.
Cflow, dot
5.2.3 图示动态分析函数调用关系：库函数，系统调用，内核调用
​    Ltrace, strace, valgrind, perf
具体分析方法，使用工具见前面章节。
参考文档：

03-HMS 开发指南.pdf
HiSTBAndroidV600R001C00SPC060_cn\document\01-Development Guide
HiMPP V3.0 媒体处理软件开发参考.pdf
HiSTBAndroidV600R001C00SPC060_cn\document\01-Development Guide
3798m SDK 代码
 HMS API Development Reference.chm
HiSTBAndroidV600R001C00SPC060_cn\document\01-Development Guide\09-API Reference


]]></content>
      <categories>
        <category>embeded</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>embeded</tag>
        <tag>hisilicon</tag>
        <tag>Driver</tag>
        <tag>3798M</tag>
        <tag>MPP</tag>
        <tag>UNF</tag>
        <tag>Kernel</tag>
      </tags>
  </entry>
  <entry>
    <title>宝塔 linux 面板重启、重置等命令整合</title>
    <url>/posts/7b4e434c/</url>
    <content><![CDATA[宝塔 linux 面板重启、重置等命令整合
宝塔对新手入门还是比较友好的，方便了入门小站搭建。入门可用，一些新东西也可以在里面看看。大型应用还是的自己搭建。
来源于网络，原作已经不可考据，整理更新到目前最新版。
现在有很多网友都在使用宝塔主机管理系统、对一些不懂 linux 操作的朋友来说，是一个很好的管理系统、
但是有些朋友重启服务器以后，有可能造成一些服务无法重启。今天我们搜集下关于宝塔面板的命令集锦
Linux 面板 7.6.0 安装命令：
Centos 安装命令：
yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh
复制代码
咨询离线安装版本
试验性 Centos/Ubuntu/Debian 安装命令 独立运行环境（py3.7） 可能存在少量兼容性问题 不断优化中
curl -sSO http://download.bt.cn/install/install_panel.sh &amp;&amp; bash install_panel.sh
复制代码
Ubuntu/Deepin 安装命令：
wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh &amp;&amp; sudo bash install.sh
复制代码
Debian 安装命令：
wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh &amp;&amp; bash install.sh
复制代码
Fedora 安装命令:
wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; bash install.sh
复制代码
**
**Linux 面板 7.6.0 升级命令：**curl http://download.bt.cn/install/update6.sh|bash 复制代码
以上节点无法使用的情况下，请使用下面的备用节点：
**
备用节点【香港】：
（宝塔推荐使用 CN2 双程 GIA 高品质，免备案的尊云 zun.com 香港云服务器安装）
yum install -y wget &amp;&amp; wget -O install.sh http://103.224.251.67:5880/install/install_6.0.sh &amp;&amp; sh install.sh
管理宝塔
#停止
/etc/init.d/bt stop
#启动
/etc/init.d/bt start
#重启
/etc/init.d/bt restart
#卸载
/etc/init.d/bt stop &amp;&amp; chkconfig --del bt &amp;&amp; rm -f /etc/init.d/bt &amp;&amp; rm -rf /www/server/panel
#查看当前面板端口
cat /www/server/panel/data/port.pl
#修改面板端口，如要改成8881（centos 6  系统）
echo '8881'  &gt;  /www/server/panel/data/port.pl &amp;&amp;  /etc/init.d/bt restart
iptables -I INPUT -p tcp -m state --state NEW -m tcp --dport 8881  -j ACCEPT
service iptables save
service iptables restart
#修改面板端口，如要改成8881（centos 7  系统）
echo '8881'  &gt;  /www/server/panel/data/port.pl &amp;&amp;  /etc/init.d/bt restart
firewall-cmd --permanent --zone=public  --add-port=8881/tcp
firewall-cmd --reload
#强制修改MySQL管理(root)密码，如要改成123456
cd /www/server/panel &amp;&amp; python tools.pyc root 123456
#修改面板密码，如要改成123456
cd /www/server/panel &amp;&amp; python tools.pyc panel 123456
#查看宝塔日志
cat /tmp/panelBoot.pl
#查看软件安装日志
cat /tmp/panelExec.log
#站点配置文件位置
/www/server/panel/vhost
#删除域名绑定面板
rm -f /www/server/panel/data/domain.conf
#清理登陆限制
rm -f /www/server/panel/data/*.login
#查看面板授权IP
cat /www/server/panel/data/limitip.conf
#关闭访问限制
rm -f /www/server/panel/data/limitip.conf
#查看许可域名
cat /www/server/panel/data/domain.conf
#关闭面板SSL
rm -f /www/server/panel/data/ssl.pl &amp;&amp; /etc/init.d/bt restart
#查看面板错误日志
cat /tmp/panelBoot
#查看数据库错误日志
cat /www/server/data/*.err
#站点配置文件目录(nginx)
/www/server/panel/vhost/nginx
#站点配置文件目录(apache)
/www/server/panel/vhost/apache
#站点默认目录
/www/wwwroot
#数据库备份目录
/www/backup/database
#站点备份目录
/www/backup/site
#站点日志
/www/wwwlogs
Nginx 服务管理
#nginx安装目录
/www/server/nginx
#启动
/etc/init.d/nginx start
#停止
/etc/init.d/nginx stop
#重启
/etc/init.d/nginx restart
#启载
/etc/init.d/nginx reload
#nginx配置文件
/www/server/nginx/conf/nginx.conf
Apache 服务管理
#apache安装目录
/www/server/httpd
#启动
/etc/init.d/httpd start
#停止
/etc/init.d/httpd stop
#重启
/etc/init.d/httpd restart
#启载
/etc/init.d/httpd reload
#apache配置文件
/www/server/apache/conf/httpd.conf
MySQL 服务管理
#mysql安装目录
/www/server/mysql
#phpmyadmin安装目录
/www/server/phpmyadmin
#数据存储目录
/www/server/data
#启动
/etc/init.d/mysqld start
#停止
/etc/init.d/mysqld stop
#重启
/etc/init.d/mysqld restart
#启载
/etc/init.d/mysqld reload
#mysql配置文件
/etc/my.cnf
FTP 服务管理
#ftp安装目录
/www/server/pure-ftpd
#启动
/etc/init.d/pure-ftpd start
#停止
/etc/init.d/pure-ftpd stop
#重启
/etc/init.d/pure-ftpd restart
#ftp配置文件
/www/server/pure-ftpd/etc/pure-ftpd.conf
PHP 服务管理
#php安装目录
/www/server/php
#启动(请根据安装PHP版本号做更改，例如：/etc/init.d/php-fpm-54 start)
/etc/init.d/php-fpm-{52|53|54|55|56|70|71} start
#停止(请根据安装PHP版本号做更改，例如：/etc/init.d/php-fpm-54 stop)
/etc/init.d/php-fpm-{52|53|54|55|56|70|71} stop
#重启(请根据安装PHP版本号做更改，例如：/etc/init.d/php-fpm-54 restart)
/etc/init.d/php-fpm-{52|53|54|55|56|70|71} restart
#启载(请根据安装PHP版本号做更改，例如：/etc/init.d/php-fpm-54 reload)
/etc/init.d/php-fpm-{52|53|54|55|56|70|71} reload
#配置文件(请根据安装PHP版本号做更改，例如：/www/server/php/52/etc/php.ini)
/www/server/php/{52|53|54|55|56|70|71}/etc/php.ini
Redis 服务管理
#redis安装目录
/www/server/redis
#启动
/etc/init.d/redis start
#停止
/etc/init.d/redis stop
#redis配置文件
/www/server/redis/redis.conf
Memcached 服务管理
#memcached安装目录
/usr/local/memcached
#启动
/etc/init.d/memcached start
#停止
/etc/init.d/memcached stop
#重启
/etc/init.d/memcached restart
#启载
/etc/init.d/memcached reload
]]></content>
      <categories>
        <category>vps</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>宝塔</tag>
        <tag>VPS</tag>
        <tag>建站</tag>
        <tag>Nginx</tag>
        <tag>Apache</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>docker 使用简明教程</title>
    <url>/posts/42b6a86d/</url>
    <content><![CDATA[关于 docker 安装，查看，镜像管理，以及一个实用 Dockerfile， LAMP，PHP，LTMJ。

关于本 blog，图床一般使用 github，已经配置了 CDN，如果图片还是未显示请自行代理解决

一、Docker 安装

在 Ubuntu 系统下安装：

apt-get install docker

在 Fedora/CentOS 系统下安装：

yum install docker
dnf install docker # Fedora 25+

在 SUSE 系统下安装：

zypper install docker
二、Docker 容器

首先启动 Docker

# 启动Docker
systemctl start docker
# 设置开机自启动，可选
systemctl enable docker

启动 Docker 测试容器 

docker run "hello-world"

在启动容器时，如果使用的镜像在本地不存在，会尝试从网络上获取。
在一般情况下，启动 Web 服务的容器，使用以下命令：

# -d：daemon，使容器在后台运行
# -p：port，指定容器的端口，这里是将容器的80端口映射到主机的8001端口
docker run -d -p 8001:80 "image_name"

查看容器运行情况 

docker ps

Docker 会为容器分配一个 Container ID 和一个 Container Name，Name 可以在运行时通过 -name 自行指定，这两个可以用来标识容器。
需要停止容器时，使用以下命令：

docker stop "container_name"
# 或使用ID查找
docker stop "container_id"
# 重启
docker restart "container_id"
三、Docker 镜像
Dokerfile 编译镜像

Docker 容器是运行的 Docker 镜像实例，一般情况下，我们需要制作自己的 Docker 镜像。
Docker 镜像的制作依赖于 Dockerfile，我们稍后在讨论 Dockerfile 的编写，这里假定我们有一个编写好的 Dockerfile。
下面的命令将在当前路径查找 Dockerfile 并构建一个名为 “image_name” 的镜像。

docker build -t "image_name" ./
查看本地所有镜像

在构建过程中需要在网络上下载来源镜像，可能需要一段时间。
如果 Dockerfile 中的命令都正确结束（Exit code 0），那么 Docker 镜像的构建也将顺利完成，我们可以通过下面的命令查看我们的所有镜像：

docker images
导出备份已有镜像文件

我们还可以导出我们制作好的 Docker 镜像，下面的命令将 image_name 镜像导出为 image_name.tar

docker save "image_name" &gt; image_name.tar
导入已有镜像备份

在另一台机器上，我们不需要网络就可以导入并使用该镜像：

docker load &lt; image_name.tar
四、Dockerfile

Dockerfile 本质上是一组命令集合，用于自动化构建镜像，下面以几个实例来说明 Dockerfile 的编写方法：

实例一：LAMP（Linux+Apache+MySQL+PHP）环境配置
# 来源镜像，一般可以使用标准的系统或者带有各种环境的系统
# 显然这里使用的是标准的Ubuntu 14.04系统
FROM ubuntu:14.04
# 镜像作者
MAINTAINER wrlu
# 刷新日期
ENV REFRESHED_AT 2018-08-05
# 设定字符集
ENV LANG C.UTF-8
# RUN命令用于执行系统命令
# 因为需要自动化安装，所以最好通过-y命令跳过确认
# 更新APT软件源
RUN apt-get update -y
# 安装MySQL
RUN apt-get -y install mysql-server
# 安装Apache
RUN apt-get -y install apache2
# 安装PHP5
RUN apt-get -y install php5 libapache2-mod-php5
RUN apt-get install -yqq php5-mysql php5-curl php5-gd php5-intl php-pear php5-imagick php5-imap php5-mcrypt php5-memcache php5-ming php5-ps php5-pspell php5-recode php5-snmp php5-sqlite php5-tidy php5-xmlrpc php5-xsl
# 删除Apache2列出目录配置
RUN sed -i 's/Options Indexes FollowSymLinks/Options None/' /etc/apache2/apache2.conf
# COPY命令可以复制文件，但是似乎不能递归复制文件
COPY IncludeAirline/* /var/www/html/
COPY IncludeAirline/airlines/* /var/www/html/airlines/
# 删除默认的主页
RUN rm /var/www/html/index.html
# 复制启动脚本
COPY start.sh /root/start.sh
RUN chmod +x /root/start.sh
# 设置启动目录以及启动脚本
ENTRYPOINT cd /root; ./start.sh
# 设置需要暴露的端口
EXPOSE 80,3306 

本例中还有一个启动脚本 start.sh，用于导入数据库，编写如下：

#!/bin/bash
# 启动后延时
sleep 1
# 启动Apache服务器
/etc/init.d/apache2 start
# 启动MySQL数据库
find /var/lib/mysql -type f -exec touch {} ; &amp;&amp; service mysql start
# 定义SQL文件路径
sqlfile=/var/www/html/includeAirline.sql
if [ -f $flagfile ]; then
	# 修改MySQL的密码
    mysqladmin -u root password "root"
    # 登录MySQL并导入SQL文件执行
    mysql -uroot -proot &lt; $sqlfile
    # 删除SQL文件
    rm -f $sqlfile
fi
# 此处注意，如果命令执行完后脚本退出
# 则Docker容器也会因为没有前台应用运行而中止
# 所以这里使用一个前台命令来保活Docker容器
tail -f /var/log/apache2/error.log
实例二：PHP 环境配置：
# 来源镜像，自带Apache+PHP环境
FROM php:7.0-apache
MAINTAINER tl
ENV REFRESHED_AT 2018‐08‐03
ENV LANG C.UTF‐8
# ADD命令在COPY命令的基础上，具有自动解包tar的功能
ADD web_tired.tar /var/www/html/
EXPOSE 80
实例三：LTMJ（Linux+Tomcat+MySQL+JSP）环境配置
FROM ubuntu:16.04
MAINTAINER wrlu
ENV REFRESHED_AT 2018-08-05
ENV LANG C.UTF-8
RUN apt-get update -y
RUN apt-get -y install mysql-server
# 安装wget，因为Docker提供的镜像是最小镜像，所以用到的其他工具需要自行安装
RUN apt-get -y install wget
# 安装Java 8
RUN apt-get -y install openjdk-8-jre
# 下载Tomcat 8服务器
RUN wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz
# 解压tar.gz
RUN tar -xzf apache-tomcat-8.5.32.tar.gz -C /root
RUN mv /root/apache-tomcat-8.5.32 /root/tomcat
# 删除默认页面
RUN rm -rf /root/tomcat/webapps/*
# 拷贝war文件
COPY CAAC-SQL-Injection.war /root/tomcat/webapps/
COPY wafwtf.sql /root/
COPY start.sh /root/start.sh
RUN chmod +x /root/start.sh
ENTRYPOINT cd /root; ./start.sh
# Tomcat使用8080端口，不同于Apache
EXPOSE 8080

启动脚本如下：

#!/bin/bash
sleep 1
find /var/lib/mysql -type f -exec touch {} ; &amp;&amp; service mysql start
chmod +x /root/tomcat/bin/startup.sh
# 启动Tomcat服务器
/root/tomcat/bin/startup.sh
sqlfile=/root/wafwtf.sql
if [ -f $flagfile ]; then
    mysqladmin -u root password "root"
    mysql -uroot -proot &lt; $sqlfile
    rm -f $sqlfile
fi
# 容器保活
tail -f /root/tomcat/conf/server.xml
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MySQL</tag>
        <tag>Docker</tag>
        <tag>LAMP</tag>
        <tag>PHP</tag>
        <tag>Tomcat</tag>
        <tag>JSP</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>Gitlab 的安装及使用教程完全版</title>
    <url>/posts/acc13b70/</url>
    <content><![CDATA[1. Gitlab 概述

1.1 GitLab 介绍
GitLab 是利用 Ruby on Rails 一个开源的版本管理系统，实现一个自托管的 Git 项目仓库，可通过 Web 界面进行访问公开的或者私人项目。
GitLab 能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序 (Wall) 进行交流。
它还提供一个代码片段收集功能可以轻松实现代码复用，便于日后有需要的时候进行查找
1.2 Gitlab 服务构成
Nginx：静态 web 服务器。
gitlab-shell：用于处理 Git 命令和修改 authorized keys 列表。
gitlab-workhorse: 轻量级的反向代理服务器。
logrotate：日志文件管理工具。
postgresql：数据库。
redis：缓存数据库。
sidekiq：用于在后台执行队列任务（异步执行）。
unicorn：An HTTP server for Rack applications，GitLab Rails 应用是托管在这个服务器上面的。
1.3 Gitlab 工作流程

1.4 GitLab Shell
GitLab Shell 有两个作用：为 GitLab 处理 Git 命令、修改 authorized keys 列表
当通过 SSH 访问 GitLab Server 时，GitLab Shell 会：

限制执行预定义好的 Git 命令（git push，git pull，git annex）
调用 GitLab Rails API 检查权限
执行 pre-receive 钩子（在企业版中叫做 Git 钩子）
执行用户请求的动作，处理 GitLab 的 post-receive 动作
处理自定义的 post-receive 动作

当通过 http (s) 访问 GitLab Server 时，工作流程取决于你是从 Git 仓库拉取 (pull) 代码还是向 git 仓库推送 (push) 代码：
如果是从 Git 仓库拉取 (pull) 代码，GitLab Rails 应用会全权负责处理用户鉴权和执行 Git 命令的工作
如果是向 Git 仓库推送 (push) 代码，GitLab Rails 应用既不会进行用户鉴权也不会执行 Git 命令，它会把以下工作交由 GitLab Shell 进行处理：

调用 GitLab Rails API 检查权限
执行 pre-receive 钩子（在 GitLab 企业版中叫做 Git 钩子）
执行你请求的动作
处理 GitLab 的 post-receive 动作
处理自定义的 post-receive 动作

1.5 GitLab Workhorse
GitLab Workhorse 是一个敏捷的反向代理。它会处理一些大的 HTTP 请求，比如文件上传、文件下载、Git push/pull 和 Git 包下载。其它请求会反向代理到 GitLab Rails 应用，即反向代理给后端的 unicorn。
2. Gitlab 的安装部署

Gitlab 要求服务器内存 2G 以上

2.1 方式一：下载 gitlab-ce 的 rpm 包

gitlab 官方 rpm 包下载
清华的源

将对应版本的 gitlab-ce 下载到本地后，直接 yum 安装即可
# 要先将这个rpm包下载到本地
yum install -y gitlab-ce-13.6.1-ce.0.el7.x86_64.rpm
2.2 方式二：配置 yum 源
在 /etc/yum.repos.d/ 下新建 gitlab-ce.repo，写入如下内容：
[gitlab-ce]
name=gitlab-ce
baseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/
Repo_gpgcheck=0
Enabled=1
Gpgkey=https://packages.gitlab.com/gpg.key
然后创建 cache，再直接安装 gitlab-ce
yum makecache  # 这一步会创建大量的数据
 
# 直接安装最新版
yum install -y gitlab-ce
 
# 如果要安装指定的版本，在后面填上版本号即可
yum install -y  gitlab-ce-13.6.1
 
# 如果安装时出现gpgkey验证错误，只需在安装时明确指明不进行gpgkey验证
yum install gitlab-ce -y --nogpgcheck
2.2.1. 单服务启动模式
docker run -d --name gitlab --hostname gitlab.example.com \
-e GITLAB_OMNIBUS_CONFIG="
    external_url 'https://gitlab.example.com'
    gitlab_rails['gitlab_shell_ssh_port'] = 22
    nginx['redirect_http_to_https'] = true
    nginx['ssl_dhparam'] = '/etc/gitlab/ssl/dhparam.pem'
    nginx['ssl_certificate'] = '/etc/gitlab/ssl/domain.crt'
    nginx['ssl_certificate_key'] = '/etc/gitlab/ssl/domain.key'
    nginx['custom_gitlab_server_config'] = 'location ^~ /.well-known {\n alias /var/opt/gitlab/letsencrypt/.well-known;\n}\n'
    high_availability['mountpoint'] = ['/etc/gitlab', '/var/log/gitlab' '/var/opt/gitlab'  # 严格限定gitlab服务启动前，指定文件系统挂完毕
" \
-p 22:22 -p 80:80 -p 443:443 \
-v /srv/gitlab/config:/etc/gitlab \
-v /srv/gitlab/logs:/var/log/gitlab \
-v /srv/gitlab/data:/var/opt/gitlab \
-v /etc/certs:/etc/gitlab/ssl \
--restart=always gitlab/gitlab-ce:latest
 
2.2.1. Compose 服务编排模式 (推荐方式)
docker pull gitlab/gitlab-ce:latest
 
############################ 多行命令开始 ##########################
cat &gt; docker-compose.yaml &lt;&lt;EOF
version: '2'
 
services:
 
  Gitlab:
    image: 'gitlab/gitlab-ce:latest'
    container_name: 'gitlab'
    hostname: 'gitlab.example.com'
    restart: always
    ports:
      - '22:22'
      - '80:80'
      - '443:443'
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        # Add any other gitlab.rb configuration here, each on its own line
        external_url 'https://gitlab.example.com'
        gitlab_rails['gitlab_shell_ssh_port'] = 22
        nginx['redirect_http_to_https'] = true
        nginx['ssl_dhparam'] = "/etc/gitlab/ssl/dhparam.pem"
        nginx['ssl_certificate'] = "/etc/gitlab/ssl/domain.crt"
        nginx['ssl_certificate_key'] = "/etc/gitlab/ssl/domain.key"
        nginx['custom_gitlab_server_config'] = "location ^~ /.well-known {\n alias /var/opt/gitlab/letsencrypt/.well-known;\n}\n"
        high_availability['mountpoint'] = ["/etc/gitlab", "/var/log/gitlab", "/var/opt/gitlab"]  # 严格限定gitlab服务启动前，指定文件系统挂完毕
    volumes:
      - /srv/gitlab/config:/etc/gitlab
      - /srv/gitlab/logs:/var/log/gitlab
      - /srv/gitlab/data:/var/opt/gitlab
      - /etc/certs:/etc/gitlab/ssl
EOF
############################ 多行命令结束 ##########################
 
# 启动服务
docker-compose -f docker-compose.yaml up -d
 
2.3 gitlab 的配置
配置文件位置  /etc/gitlab/gitlab.rb
[root@centos7 test]# vim /etc/gitlab/gitlab.rb
 
[root@centos7 test]# grep "^[a-Z]" /etc/gitlab/gitlab.rb
 
external_url 'http://10.0.0.51'  # 这里一定要加上http://
 
# 配置邮件服务
gitlab_rails['smtp_enable'] = true
gitlab_rails['smtp_address'] = "smtp.qq.com"
gitlab_rails['smtp_port'] = 25
gitlab_rails['smtp_user_name'] = "hgzerowzh@qq.com"  # 自己的qq邮箱账号
gitlab_rails['smtp_password'] = "xxx"  # 开通smtp时返回的授权码
gitlab_rails['smtp_domain'] = "qq.com"
gitlab_rails['smtp_authentication'] = "login"
gitlab_rails['smtp_enable_starttls_auto'] = true
gitlab_rails['smtp_tls'] = false
gitlab_rails['gitlab_email_from'] = "hgzerowzh@qq.com"  # 指定发送邮件的邮箱地址
user["git_user_email"] = "shit@qq.com"   # 指定接收邮件的邮箱地址
修改好配置文件后，要使用 gitlab-ctl reconfigure 命令重载一下配置文件，否则不生效。
gitlab-ctl reconfigure # 重载配置文件
gitlab-ctl restart
测试邮件服务器
gitlab-rails console
Notify.test_email('rollinghell@foxmail.com','testbiaoti','testzhegnwen1').deliver_now
[root@test102 ~]# gitlab-rails console
--------------------------------------------------------------------------------
 GitLab:       12.5.0 (1f0ab8978ef)
GitLab Shell: 10.2.0
 PostgreSQL:   10.9
--------------------------------------------------------------------------------
Loading production environment (Rails 5.2.3)
irb(main):001:0&gt; Notify.test_email('andycrusoe@gmail.com','test','test').deliver_now
Notify#test_email: processed outbound mail in 1.4ms
Sent mail to anliven@126.com (73.0ms)
Date: Wed, 27 Nov 2019 15:12:58 +0800
From: GitLab &lt;gitlab@192.168.16.102&gt;
Reply-To: GitLab &lt;noreply@192.168.16.102&gt;
To: anliven@126.com
Message-ID: &lt;5dde21fa612d4_3a1b3fcb38fcf9c0651b@test102.mail&gt;
Subject: test
Mime-Version: 1.0
Content-Type: text/html;
charset=UTF-8
Content-Transfer-Encoding: 7bit
Auto-Submitted: auto-generated
X-Auto-Response-Suppress: All
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"&gt;
&lt;html&gt;&lt;body&gt;&lt;p&gt;test&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;
=&gt; #&lt;Mail::Message:70141649239780, Multipart: false, Headers: &lt;Date: Wed, 27 Nov 2019 15:12:58 +0800&gt;, &lt;From: GitLab &lt;gitlab@192.168.16.102&gt;&gt;, &lt;Reply-To: GitLab &lt;noreply@192.168.16.102&gt;&gt;, &lt;To: anliven@126.com&gt;, &lt;Message-ID: &lt;5dde21fa612d4_3a1b3fcb38fcf9c0651b@test102.mail&gt;&gt;, &lt;Subject: test&gt;, &lt;Mime-Version: 1.0&gt;, &lt;Content-Type: text/html; charset=UTF-8&gt;, &lt;Content-Transfer-Encoding: 7bit&gt;, &lt;Auto-Submitted: auto-generated&gt;, &lt;X-Auto-Response-Suppress: All&gt;&gt;
irb(main):002:0&gt;
irb(main):003:0&gt; exit
[root@test102 ~]#
 
配置 gitlab 代理
https://docs.gitlab.com/omnibus/settings/environment-variables.html
gitaly['env'] = {
    "http_proxy" =&gt; "http://USERNAME:PASSWORD@example.com:8080",
    "https_proxy" =&gt; "http://USERNAME:PASSWORD@example.com:8080"
}
2.4 Gitlab 常用命令
gitlab-ctl start         # 启动所有 gitlab 组件
gitlab-ctl stop          # 停止所有 gitlab 组件
gitlab-ctl restart       # 重启所有 gitlab 组件
gitlab-ctl status        # 查看服务状态
 
gitlab-ctl reconfigure   # 启动服务
gitlab-ctl show-config   # 验证配置文件
 
gitlab-ctl tail          # 查看日志
 
gitlab-rake gitlab:check SANITIZE=true --trace    # 检查gitlab
 
vim /etc/gitlab/gitlab.rb # 修改默认的配置文件
2.5 gitlab-ctl 常用命令介绍



命令
说明




 check-config
 检查在 gitlab 中是否有任何配置。在指定版本中删除的 rb


deploy-page
 安装部署页面


 diff-config
 将用户配置与包可用配置进行比较


 remove-accounts
 删除所有用户和组


 upgrade
 升级


 service-list
 查看所有服务


 once
 如果 GitLab 服务停止了就启动服务，如果已启动就不做任何操作


 restart
 重启 GitLab 服务


 start
 如果 GitLab 服务停止了就启动服务，如果已启动就重启服务


 stop
 停止 GitLab 服务


 status
 查看 GitLab 服务状态


 reconfigure
 重新配置 GitLab 并启动



3. Gitlab 的使用

Gitlab 安装好后，设置密码，管理账户为 root

3.1 创建 Group

填上组名即可，这里组名为 java



3.2 创建 User

创建四个 User：pm、dev1、dev2、dev3



3.3 添加 User 到 Group 中并授权

3.4 创建 Project 并配置 SSH




3.5 在项目中添加成员


3.6 将本地文件推送到 Gitlab
# 将app01项目克隆下来
git clone git@10.0.0.51:java/app01.git
 
# 初始化配置
git config --global user.name "hgzero"
git config --global user.email "hgzero@qq.com"
 
# 在app01目录下新建一些文件
 
# 推送到gitlab
git add .
git commit -m "first edition"
git push origin master

4. 制定开发计划
4.1 创建开发计划

项目：app01
 版本：v1.0


4.2 创建里程碑 Milestones

用 pm 账号登录 gitlab 后操作（先要在 admin 中设置 pm 账号的密码）
要根据开发计划来创建 Milestones





4.3 根据开发计划创建 issue

创建 4 个 issue，分派给 dev1 和 dev2 这两个开发人员







**4.4 开发者登录账号查看分派的任务 **

然后开发 dev1 登录 gitlab，就能看到任务已经分配过来了


4.5 开发流程

公司里的开发开始任务

# 1. 先从仓库把项目拉下来
git clone git@10.0.0.51:java/app01.git
cd app01/
 
# 2.先创建一个自己的分支，然后进行开发
git checkout -b index   # 创建一个叫index的分支，并切换到这个分支
git status
 
# 3. 开始开发首页
echo "&lt;h1&gt;welcome to this app&lt;/h1&gt;" &gt; index.html  # 假设就开发了一个index页面
 
# 4. 开发完成后，把项目传到仓库
git add .
git commit -m "index"
# 如果写成 git commit -m "close #2" ，则表示merge请求允许且merge成功之后，自动删除编号为#2的issue
 
# 传到index分支
git push origin index
4.6 合并分支
1）开发 dev1 发送合并分支请求给 pm



2）pm 收到开发的 Merge 请求后进行处理

使用 pm 登录，就可以看到 pm 已经收到了合并请求 merge request





3）开发 dev1 确认任务完成

退出 pm 账户，登入 dev1 账户：



或者点进去后，在侧边栏进行标识 Done，然后已经完成的 issue，可以将其 Close



 这个时候 Milestones 的进度已经往前进了一些了：


4.7 开发其他功能

然后其他开发者或者自己再次进行开发时，先要把刚刚更新后的内容（master 主干）拉回来，然后再进行开发

git checkout master  # 切换到 master
git pull             # 从远端仓库拉取数据
# 然后再进行其他操作
5. Gitlab 备份恢复
5.1 备份 gitlab
1）修改配置文件

/etc/gitlab/gitlab.rb

# 备份保存的位置，这里是默认位置，可修改成指定的位置
gitlab_rails['backup_path'] = "/var/opt/gitlab/backups"
 
# 设置备份保存的时间，超过此时间的日志将会被新覆盖
gitlab_rails['backup_keep_time'] = 604800  # 这里是默认设置，保存7天
 
# 特别注意：
#     如果自定义了备份保存位置，则要修改备份目录的权限，比如：
#     chown -R git.git /data/backup/gitlab

配置完成后要重启以使配置生效

# 重读配置文件
gitlab-ctl reconfigure
 
# 重启gitlab
gitlab-ctl restart
2）设置定时任务
# 每天凌晨2点定时创建备份
# 将一下内容写入到定时任务中 crontab -e
0 2 * * * /usr/bin/gitlab-rake gitlab:backup:create
 
# 备份策略建议：
#     本地保留3到7天，在异地备份永久保存
3）备份时间的识别
# 备份后的文件类似这样的形式：1494170842_gitlab_backup.tar，可以根据前面的时间戳确认备份生成的时间
 
data  -d  @1494170842
5.2 恢复 gitlab
1）停止停止相关数据连接，数据写入服务
# 停止数据写入服务
gitlab-ctl stop puma
gitlab-ctl stop sidekiq
2）进行数据恢复并重启
# 进行恢复
gitlab-rake gitlab:backup:restore BACKUP=1627839447_2021_08_01_14.1.1-ee  # 这个时间戳就是刚刚备份的文件前面的时间戳
 
# 重启
gitlab-ctl restart
6. gitlab 邮件通知配置

vim  /etc/gitlab/gitlab.rb

gitlab_rails['time_zone'] = 'Asia/Shanghai'
 
gitlab_rails['gitlab_email_enabled'] = true
gitlab_rails['gitlab_email_from'] = 'example@163.com' # 填写发件人的邮箱地址
gitlab_rails['gitlab_email_display_name'] = 'gitlab'
 
gitlab_rails['smtp_enable'] = true
gitlab_rails['smtp_address'] = "smtp.163.com"  # smtp服务器的地址,如网易的地址
gitlab_rails['smtp_port'] = 25                 # 要注意如果使用了SSL/TLS的话,端口可能不是25
gitlab_rails['smtp_user_name'] = "smtp用户名"
gitlab_rails['smtp_password'] = "smtp用户密码"
gitlab_rails['smtp_domain'] = "163.com"
gitlab_rails['smtp_authentication'] = "login"
启用邮件功能
Gitlab 的 Compose 配置 GITLAB_OMNIBUS_CONFIG 节点下增加如下几行：
########## 邮件服务配置 ##########
gitlab_rails['smtp_enable'] = true
gitlab_rails['smtp_address'] = "smtp.exmail.qq.com"
gitlab_rails['smtp_port'] = 465
gitlab_rails['smtp_tls'] = true
gitlab_rails['smtp_user_name'] = "账号"
gitlab_rails['smtp_password'] = "密码"
gitlab_rails['smtp_authentication'] = "login"
gitlab_rails['smtp_enable_starttls_auto'] = true 
gitlab_rails['gitlab_email_from'] = "发件人邮箱"
 
7. 使用 SourceTree 进行项目开发

7.1 项目拉取

先把项目克隆下来




如果 ssh 的方式克隆失败，可能是因为 SSH Key 没找到，可以在这里添加



7.2 创建分支进行功能开发
1）新建立一个叫 “pay” 的分支


2）进行功能开发

7.3 提交项目
1）开发 pay 功能完成后进行提交

可以看到 SourceTree 中已经有 “未提交的更改”



2）添加 “用户信息”

** 3）进行提交 **


注释也可以写成  close #3    ，作用是提交完成后关闭 3 号 issue

7.4 推送到仓库



然后就可以在 gitlab 上进行发送 merge 请求了，后面就可以进行其他操作了

7.5 项目上线
1）当所有工作完成之后，就可以进行上线了

2）打标签

上线先打个标签




** 3）删除无用分支 **

然后删除已经合并到主干中的不必要的分支，如 index、pay 等
最后一定要注意时间一定要同步，不然会错乱

8. Gitlab 调优
gitlab 对内存资源的消耗比较厉害
其中尤以 sidekiq 队列 及 unicorn 服务 两个组件对内存消耗最多
可以再容器启动时对相关参数进行微调：
unicorn['worker_processes'] = 1
unicorn['worker_memory_limit_min'] = "300 * 1 &lt;&lt; 20"
unicorn['worker_memory_limit_max'] = "400 * 1 &lt;&lt; 20"
unicorn['worker_timeout'] = 15
sidekiq['concurrency'] = 10
sidekiq_cluster['enable'] = false
sidekiq_cluster['ha'] = false
redis['maxclients'] = "100"
nginx['worker_processes'] = 2
nginx['worker_connections'] = 512
nginx['keepalive_timeout'] = 300
nginx['cache_max_size'] = '200m'
mattermost['enable'] = false
mattermost_nginx['enable'] = false
gitlab_pages['enable'] = false
pages_nginx['enable'] = false
postgresql['shared_buffers'] = "256MB"
postgresql['max_connections'] = 30
postgresql['work_mem'] = "8MB"
postgresql['maintenance_work_mem'] = "16MB"
postgresql['effective_cache_size'] = "1MB"
postgresql['checkpoint_timeout'] = "5min"
postgresql['checkpoint_warning'] = "30s"
 
配置调整后需要重载一下
docker exec gitlab gitlab-ctl reconfigure
docker-compose down
docker-compose up -d
 

9. Gitlab 启用 ContainerRegistry

ContainerRegistry 是 Gitlab 内置的 Docker Registry 集成组件
集成后每个项目可获得私有的 Docker 镜像存储空间
ContainerRegistry 可以复用 Gitlab 域名 或者 独立域名
这里配置为复用域名（此时 ContainerRegistry 将复用 Gitlab 的 TLS 证书）


docker-compose.yaml 中 Gitlab 服务的 GITLAB_OMNIBUS_CONFIG 节点下增加如下配置：

registry_external_url "https://gitlab.example.com:4567"  # ContainerRegistry的外部访问地址
registry_nginx['ssl_certificate'] = "/etc/gitlab/ssl/domain.crt"
registry_nginx['ssl_certificate_key'] = "/etc/gitlab/ssl/domain.key"
gitlab_rails['registry_host'] = "gitlab.example.com"
gitlab_rails['registry_port'] = "4567"
gitlab_rails['registry_api_url'] = "http://localhost:5000"
gitlab_rails['gitlab_default_projects_features_builds'] = false
gitlab_rails['gitlab_default_projects_features_container_registry'] = false
 

端口开放增加 - 4567:4567
服务重启 docker-compose restart Gitlab

ContainerRegistry 集成后可以通过 Gitlab 账户登录： docker login gitlab.example.com:4567

日常维护命令
# Gitlab维护
docker exec gitlab gitlab-ctl status  # gitlab各组件服务状态
docker exec gitlab gitlab-ctl start/restart/stop [组件名]  # gitlab所有组件的统一控制（其中Unicorn组件重启完成前GitLab会报502）
docker exec gitlab gitlab-ctl tail [/var/log/gitlab下的某子目录]  # 实时查看日志
 
docker exec gitlab update-permissions  # 修复gitlab版本升级后出现的权限问题
docker exec gitlab gitlab-ctl reconfigure  # 重载配置
docker exec -t gitlab gitlab-rake gitlab:backup:create  # 创建备份
 
# ContainerRegistry维护
docker exec gitlab gitlab-ctl registry-garbage-collect  # 垃圾回收，清理废弃layer（registry停机）
 

Import Repository(Repo By Url)
# 账号密码若存在特殊字符则需要url编码
https://username:password@host:port/group/project.git
 
10. GitLab 重置用户名密码
打开终端，访问：
gitlab-rails console
输入：
user = User.where(id: 1).first
user.password='123456'
user.password_confirmation = '123456'
user.save! #注意加上 “！”
然后退出命令行即可。
quit
 gitlab-rails console production 命令 开始初始化密码
# 在irb(main):001:0&gt; 后面通过 u=User.where(id:1).first 来查找与切换账号（User.all 可以查看所有用户）
# 通过u.password='12345678'设置密码为12345678(这里的密码看自己喜欢)：
# 通过u.password_confirmation='12345678' 再次确认密码
# 通过 u.save!进行保存
11. HTTPS SSL 支持


nginx 反向代理方式

注意 docker 内部没有 ca 支持， 需要手动添加



域名提供商提供的免费证书

这种证书直接用，如果是自签名证书，需要添加自己的 ca root 证书到服务器



12. Gitlab 恢复数据出现 must be owner of 解决方法
按正常 Gitlab 备份数据 gitlab-rake gitlab:backup:create
ERROR: must be owner of extension plpgsql
ERROR: must be owner of schema public
ERROR: schema “public” already exists
ERROR: must be owner of schema public
ERROR: must be owner of extension plpgsql
WARNING: no privileges could be revoked for “public”
WARNING: no privileges could be revoked for “public”
WARNING: no privileges were granted for “public”
WARNING: no privileges were granted for “public”
解决方法：
**1. 修改 postgresql 配置 **
cd /var/opt/gitlab/postgresql/data
$ vi /var/opt/gitlab/postgresql/data/postgresql.conf
listen_addresses = '*'
找到 listen_addresses = ” 改为 listen_addresses = ‘*’
修改 /var/opt/gitlab/postgresql/data/pg_hba.conf
在这个文件最后面加入
$ vi /var/opt/gitlab/postgresql/data/pg_hba.conf
local   all         all                               trust
host    all         all                               127.0.0.1/32 trust
host    all         all                               ::1/128 trust    #ipv6 可以不配置
2. 重启 gitlab 生效
gitlab-ctl restart
3. 修改 gitlab 账号为超级用户
进入 postgresql 命令行
cd /opt/gitlab/embedded/bin
su gitlab-psql
./psql -h 127.0.0.1 gitlabhq_production
查看账户权限
\du
执行修改 gitlab 用户为超级权限
ALTER USER gitlab WITH SUPERUSER;
退出
\q

4. 从 1462989681 编号备份中恢复
gitlab-rake gitlab:backup:restore BACKUP=1462989681
这样 Gitlab 恢复数据就不会再报 must be owner of extension plpgsql 错误。
4. 重启 gitlab
gitlab-ctl restart
本文作者：夜法之书       写作不易，转载请注明来源地址！
参考链接：

https://www.cnblogs.com/hgzero/p/14088215.html
http://www.51blogs.net/2017/11/10/1110113243.html
https://my.oschina.net/u/2400083/blog/808097


]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
        <tag>Git</tag>
        <tag>Docker</tag>
        <tag>教程</tag>
        <tag>Rigistry</tag>
        <tag>email</tag>
        <tag>https</tag>
        <tag>ssl</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Lenny Laptop 安装记录</title>
    <url>/posts/b1fe1bb8/</url>
    <content><![CDATA[Debian Lenny Laptop 安装记录
这是一篇非常有历史的文章了，写了十多年了。只在个人 google doc 中公开共享过。时至今日，参考价值还是非常大的。
目的是完全采用 Linux 系统来完成所有工作。
这篇文章当年我写了一周，每个步骤都是实践后仔细记录的。
摘 要
​        在现在电子信息化社会中，网络越来越重要，各种电子商务，网上银行，网络交友，SNS 社区等越来越红火，各国政府都在进行电子信息化建设，准备网上办公，无纸化作业。信息化就是现代化的思想已经深入人心，然而信息化建设的基础硬件和软件：
硬件：CPU、主板、内存，硬盘等
软件：操作系统（Operate System 如 Linux,Windows,Mac OS 等），浏览器 (如 Firefox，Opera，Maxthon，IE 等)，文档处理（OpenOffice,WPS,Word 等），媒体播放（Mplayer,Realplayer 等），以及其它软件工具。
则是其中的重中之重，电子信息化社会信息安全最为关键。因为你不知道微软的 Windows 中给你预留了多少漏洞和后门，你不知道 Intel 或者 AMD 在它们生产的硬件中留下了什么缺陷，了解一点软硬件知识的人都知道，软件后门可以使微软进入你的电脑如同自己的电脑一样，微软可以看到所有你的文档，照片，工作生活的数据，你的电脑中的数据对微软而言没有任何秘密而言；硬件缺陷同样可以做后门用，甚至发送一段短码瞬间可以使你的电脑崩溃。可见安全多么重要，那么如何提高安全了？
​        答案就是使用开源！开源早已经形成了一套完整的套件，上面介绍的软件中每样的地一种都是开源工具，完全免费！而且开放源代码，你可以知道每行代码的作用，后门、间谍将不复存在！你常用的 Windows 工具每样 Linux 都有替代品，很多工具甚至本来就是 Linux 中移植到 Windows 中来的，如暴风影音，比特精灵，Vim，Emacs 等。
​        本文简单的介绍了开源操作系统 Debian 的安装和配置，包括操作系统的安装、配置，常用工具的安装等详细过程，下文所叙全部经过测试，稳定运行。通过本文，您可以了解 Linux 操作系统大体组成结构，并且获得一部完全自己定制的操作系统！
[TOC]
一：前言
从今天开始做个 Debianer
刚从 OpenSuSE 换过来的，感觉 Debian 非常强大。SuSE 的 yast2 真的非常强大，刚离开 yast 感觉很痛苦，Novll 的 yast 系统设置几乎在里面实现，它包括了系统硬件，软件设置，网络配置，服务器配置，各种系统设置等等。它把很多底层配置都接管了，使用 SuSE 的用户会发现 SuSE 比其他 Linux 发行版少很多配置文件。SuSE 的 yast2 有命令行和图形界面两种操作方式，还有 zypper 这种完全命令行包管理工具。不过 Debian 的 apt 包管理更加强大，比 zypper 强大多了。
Debian 以定制性非常强，运行稳定而著称，是最符合 GNU 精神的发行版，对各种硬件构架都支持，是世界上唯一一种几乎可以在所有硬件平台运行的操作系统。Ubuntu 就是在 Debian 的基础上发行的衍生版。但是本人使用感觉 Ubuntu 的感觉不好，Ubuntu 就像一个在 Debian testing 基础上优化过得 Debian 一样，而且阉割的厉害。不过正由于阉割的厉害，把用户管理的东西 Ubuntu 都自己设置了，Ubuntu 才成为最容易操作的 Linux 操作系统，而且也是最流行的 Linux 操作系统。不过 Ubuntu 限制用户操作非常严，感觉这样很大程度上失去了 Linux 的自由，可定制等特性。对 Linux 新人来说一开始使用 Debian 会非常困难的，强烈建议对 Linux 包管理，运行结构了解大概后再开始使用 Debian。
推荐的发行版有：
OpenSuSE：优点是从 Windows 转过来几乎马上就可以上手，用户不需要改变多少使用习惯，并且图形界面非常华丽，号称是最华丽的 Linux 操作系统。默认的就比 Windows XP 漂亮多了，开启 Compiz Fusion 后的 3D 特效比 Vista,Win 7 都要漂亮。对一般用户家庭使用和办公使用完全可以满足要求。缺点就是国内源很少，官方源在国外比较慢，速度也不保证，升级只能是半夜了，不过采用 DVD 安装的话就没多大问题。SuSE 的中文社区不完善也是一大缺点。
Fedora：著名的 Redhat 公司出品，国内源非常多，中文化非常好，中文社区也非常活跃，很多问题可以直接中文搜出结果。缺点是对习惯 Windows 的用户来说，一开始就使用 Fedora 对大家的入门门坎比 OpenSuSE 高。
Ubuntu：最流行的 Linux 发行版，使用非常简单，中文社区建设的非常好，源很多，缺点就是阉割的太厉害了。感觉这样的版本对深入了解 Linux 不好，个人看法，不过对非技术型用户使用到是个不错的选择。
Debian 是最自由，定制性最高的发行版，当然对用户的入门要求就更高了。但是，一经你上手了，那么就再别无他求。Debian 的好是谁用谁知道！
刚用上 Debian，总结下，下面可能有错误之处，希望大家指出来。参考了很多人的文章下来的，对他们表示感谢！
注意：本教程为
二：安装 Debian 之前的准备工作
●   强烈建议新人刚开始装不要按《 Debian etch 简要安装指南》那篇文章来，特别是笔记本用户，除非你对你的硬件非常熟悉。建议大家安装的时候选择图形界面安装。安装的时候选择图形界面，把 Base system,Loptop,Desktop 都安装上，这样会少很多麻烦的，它装了多余的东西和服务还是等进入桌面后再自己删除比较好。发现这样安装还是非常干净的，比之 SuSE，Fedora 之类的发行版默认安装东西要少多了。
●   阵痛了好几天了，这几天重装了好多次 Debian 了，现在终于差不多了，3d 打开了，系统很稳定。
笔记本是 Dell Inspiron6400。
●   强烈建议大家装机之前看看 debian 的官方 wiki
例如我，就看下面这个：
http://wiki.debian.org/InstallingDebianOn/Dell/Inspiron6400/lenny
●   大家的笔记本其他型号的话到下面网址找对应的型号
http://wiki.debian.org/InstallingDebianOn/
上面网址的参考下就可以了，有些问题很多种解决方法的。
三：开始安装 Debian
3.1：安装前的准备和安装方法选择
debian 提供了很多安装方法，有网络安装，光盘安装，U 盘安装，硬盘安装等多种方法。这里介绍下载光盘安装，这是对大多数人来说最为方便的安装发放，下载第一张光盘 CD 或者 DVD 镜像准备刻录安装。
注意：先备份好重要的资料！比如 copy 到移动硬盘，或者其它主机上等以免错误的操作造成不必要的损失。
进入 Bios 中设置光驱第一启动，放入光盘，等加载内核界面过去后，就进入安装界面了。
3.2：开始安装 Debian


选择安装程序使用的语言，推荐选择 English，选中文会装 zhcon。


选择国家，首先选择 other ，然后在选择 Asia ，最后选上 China 。


选择键盘，直接默认就好了，也就是 American English ，如果你的不是美式键盘，就选择相应的键盘。


设置网络，如果是 DHCP ，填上主机名和所在的域名就好了，如果是静态 IP ，根据相应的填上就 OK。这里有无线网卡的朋友就有些郁闷了，记得先去下载你的无线驱动的 deb 包，放到 u 盘根目录插上 usb 结构，系统会自动安装你的无线驱动。（但是这里安装好了还是无法 dhcp 连上无线，我采用有线装的，不知道谁这里无线配成功了。装完系统后再使用＃apt-get install firmware-iwlwifi 也可以。）


磁盘分区，根据个人的情况进行。这里要小心了，如果你有重要的资料的话，推荐手动分区。


对分区进行确认后就开始安装基本的系统，等待一段时间。


然后就是设置 root 账户的密码，以及日常使用的一个账户名称和密码。


账户设置好后对源进行设置，这里推荐手工输入。选择最上面一项。


○   输入：debian.cn99.com 或者：mirrors.163.com
○   目录就是 /debian/   不需要改动。这两个其实都是一个源，我看到主机 ip 地址一样。这个应该是国内最快的源了。至少对大部分人来说。


根据个人的情况选择安装软件，推荐选择 base system,laptop,desktop。


安装中，看网络状况时间不同，等待.........。


安装 GRUB ，Yes 安装到 MBR。


安装完毕，最后 Continue 回车重启进入期待已久的 Debian Lenny GNU/Linux。


四：配置 Debia 的基本中文操作环境
他哦难过上面二、三步，到现在你已经获得了一个基本的 Debian Lenny 操作系统了。但是到现在为止说能够顺手使用还太早，在正是使用之前还有几个事情需要做。
（注意＃号提示的是 root 用户权限）
4.1：中文语言环境
4.1.1: 重新配置 locale，添加中文 locale
​        选择以下 locale，以下为推荐语言环境，用户可以根据自己语言习惯自由选择：
#dpkg-reconfigure locales
en_US ISO-8859-1
en_US.UTF-8 UTF-8
zh_CN GB2312
zh_CN.GB18030 GB18030
zh_CN.GBK GBK
zh_CN.UTF-8 UTF-8
zh_HK BIG5-HKSCS
zh_HK.UTF-8 UTF-8
zh_TW BIG5
zh_TW.EUC-TW EUC-TW
zh_TW.UTF-8 UTF-8
选择默认的 locale 为 en_US.UTF-8 或者 zh_CN.UTF-8。
4.1.2: 安装 localepurge
＃apt-get install localepurge
​       在对话框中选择你要保留使用的 locale，默认情况下它已经选好了你现前设置的那些 locale，不过还是请仔细确认后再回车。当然你也可以使用 dpkg-reconfigure localepurge 来进行详细的配置。
●   清除你用不着的 locale，让他们释放你的磁盘空间
＃localepurge
​       以后你不管安装什么软件，它都将自动帮你清除那些没用的 locale。清除完，它会提示你释放了多少磁盘空间。当然你可以配置它让它显示清除了哪些 locale。
​       Linux 下面还有其他工具清理，如 BleachBit，这是一款专为 Linux 设计的系统清理工具。使用 BleachBit，你可以清理系统中的缓存、不要的语言文件，历史、临时文件、cookies 等不需要的东西，这样可以释放你空间。推荐，不过 Stable 的源中没有该包，需要手动下载安装。
4.2: 实现 root 用户登录自动 Tab 补全
修改 .bashrc ，打开 bash_completion，让 apt-get install 在 ROOT 登录的情况下自动补全，其他用户自动设置好了的，不用修改。你可以先用 VI 打开 /etc/bash.bashrc , 在最下面用命令模式下的 V 再按上下左右键老选择，按 y 键复制，（默认打开 VI 就处于命令模式。i a o s 键插入，编辑模式，ESC 返回，：q! 退出。） 然后 vi ~/.bashrc 按 p 键粘贴。最后象这样
if [ -f /etc/bash_completion ]; then
. /etc/bash_completion
fi
当然你也可以用 nano , 更简单。要复制功能，那么 apt-get install gpm 然后 /etc/init.d/gpm start ，现在动下鼠标。是不是在动了，gpm 是一个控制台下的鼠标服务。用鼠标左击拖动选中，右键粘贴。
4.3：将用户加入到 sudoers 列表中
#chmod +w /etc/sudoers
#vim /etc/sudoers
添加一行：username ALL=(ALL) ALL
其中 username 是你的用户名，保存
#chmod 0440 /etc/sudoers
这样，您的普通用户可以使用 "sudo + [命令]" 来执行需要管理员权限的操作
4.4: 配置更新源并更新系统
4.4.1: 备份旧的源
＃cp /etc/apt/sources.list /etc/apt/sources.list.old
4.4.2: 配置新源
把下面的加进去，应该可以满足绝大多数人的要求了。
#gedit /etc/apt/sources.list
＃＃＃====sources.list Begin===＃＃＃
##cn99
deb http://debian.cn99.com/debian/ lenny main non-free contrib
deb-src http://debian.cn99.com/debian/ lenny main non-free contrib
deb http://debian.cn99.com/debian/ lenny-proposed-updates main non-free contrib
deb-src http://debian.cn99.com/debian/ lenny-proposed-updates main non-free contrib
 
deb http://debian.cn99.com/debian-security/ lenny/updates main contrib non-free
deb-src http://debian.cn99.com/debian-security/ lenny/updates main contrib non-free
deb http://debian.cn99.com/debian-backport/ lenny-backports main contrib non-free
deb-src http://debian.cn99.com/debian-backport/ lenny-backports main contrib non-free
deb http://security.debian.org/ lenny/updates main contrib non-free
deb-src http://security.debian.org/ lenny/updates main contrib non-free

deb http://volatile.debian.org/debian-volatile lenny/volatile main contrib non-free
deb-src http://volatile.debian.org/debian-volatile lenny/volatile main contrib non-free 

deb http://http.us.debian.org/debian/ lenny main contrib non-free
deb-src http://http.us.debian.org/debian/ lenny main contrib non-free
deb http://www.debian-multimedia.org/ lenny main
deb-src http://www.debian-multimedia.org/ lenny main 

deb http://download.virtualbox.org/virtualbox/debian lenny non-free
＃＃＃===sources.list End===＃＃＃
注意：debian-multimedia.org 的源需要安装 KEY，在 http://debian-multimedia.org 下载安装 debian-multimedia-keyring_2008.10.16_all.deb
Debian 采用严格的 GPG 认证来保证安装包不被恶意篡改，使您已经安装就是最新最稳定的系统！
4.4.3: 更新源并升级系统
#apt－get update
这里就会提醒你有那些源没有 GPG 密匙，把错误密匙代号放到 iceweasel 的搜索框，回车，就会看到大量的相关问题，随便点开 2 个就可以看到怎么样取得密匙。这个是偷懒的办法，但是非常有效！建议。
＃apt-get update &amp;&amp; apt-get upgrade
这次才是真的升级系统。如果通过网络安装，一般安装过程中就会自动选择最新的稳定的最新无漏洞包，一般来说没有更新包。
四：网卡，声卡及显卡驱动安装
4.1: 配置无线网卡和 ADSL 来上网
系统默认一般会识别有线的网卡驱动，Linux 几乎可以识别现在所有的有线网卡，而无线网卡驱动由于是非
4.1.1: 配置无线网卡
●   驱动 这个看个文的硬件了
​                   ＃apt-get install firmware-iwlwifi
​                        ＃modprobe iwl3945   ＃加载内核模块
​                   这个我的 Dell Inspiron6400 的无线网卡是 Intel 3945，其他无线网卡型号的用户请自己查找相关驱动包。
●   安装管理工具
​                   apt-get install wifi-radar
●   配置无线
看大家的无线设置，选择 Essid, 加密方式，频段等。
4.1.2: 使用 PPPOE 连接 ADSL
●   使用 PPPOE 连接 Adsl
#apt-get install pppoeconf
#pppoeconf #设置用户名与密码
#pon dsl-provider #连接
#poff #断开
4.2: 让 alsa 把你的声卡驱动起来
#apt-get install alsa-base alsa-utils alsa-oss
** 配置声卡：** 执行 alsaconf 一路回车。 再执行 alsa-mixer 设置音量，M 键取消静音，ESC 键退出。保存设置 alsactl store。
** 测试 声卡：**cat /dev/urandom &gt; /dev/dsp 你将会听到非常好听的声音，恭喜你，你的声卡工作了。
ctrl+c 终止它，当然你喜欢它的话，可以不那么做_
到这里，你的 X 服务器和声卡就安装配置好了。
#apt-get install gnome-audio esound
esound 是 gnome 下的软件混音器
4.3: 显卡驱动的安装及配置
http://wiki.cchtml.com/index.php/Ubuntu_Dapper_Installation_Guide
安装编译驱动所需的环境
sudo apt-get update
sudo apt-get install module-assistant build-essential
sudo apt-get install fakeroot dh-make debconf libstdc++5 linux-headers-$(uname -r)
创建安装包
sudo ./ati-driver-installer-8.x.x.run --buildpkg debian/testing
安装这些创建的包 b
sudo dpkg -i xorg-driver-fglrx_8.x.x-1_i386.deb -f
sudo dpkg -i fglrx-kernel-source_8.x.x-1_i386.deb -f
sudo dpkg -i fglrx-control_8.x.x-1_i386.deb -f
删除旧的源码包
sudo rm /usr/src/fglrx-kernel*.deb
编译并安装驱动模块
sudo module-assistant build fglrx
sudo module-assistant install fglrx
sudo depmod -a
编辑你的 /etc/X11/xorg.conf
在 Section "Module" 中加入
Load "fglrx"
Load "dri"
Load "glx"
在 Section "Device" 中把驱动换成
Driver "fglrx"
4.3.1:ATI 显卡驱动安装
To build your own .deb packages you will need to install at least the following packages from the apt repositories:
●   fakeroot
●   debhelper
●   build-essential
●   make
●   module-assistant
Installing from Debian non-free
Note: in lenny, they've renamed fglrx-kernel-src to fglrx-source (but the following worked for me with that substitution).
Install the driver
sudo apt-get update
sudo apt-get install module-assistant fglrx-driver fglrx-kernel-src
build and install the module
#:sudo module-assistant auto-install fglrx-kernel-src
After this, you need
#:sudo aticonfig --initial
This will update your xorg.conf to use the new driver. Restart for the changes to take effect.
＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝
1  构建相应的系统驱动包：
./ati-driver-installer-8.41.7-x86.x86_64.run --buildpkg Debian/unstable
我们可以用下面的命令来列出所有可以构建的程序包：
./ati-driver-installer-8.41.7-x86.x86_64.run --listpkg
我们可以从这个输出中选择适合我们系统的参数来进行构建相应的程序包。
2  安装所构建的程序包：
# dpkg -i fglrx*.deb
3  安装 module-assistant 工具：
# apt-get install module-assistant
4  使用 m-a 安装驱动模块
# m-a prepare
# m-a a-i fglrx
驱动模块的安装需要相应的内核头文件，所以我们在进行这一步之前需要安装相应的头文件：
# apt-get install linux-headers-`uname -r`
这样就可以自动来安装 fglrx 驱动模块了。
此时我们可以通过下面的命令来测试 fglrx 驱动模块是否安装成功：
# modprobe fglrx 
5  配置 Xorg.conf
在配置中我们要做的主要工作就要载入 fglrx 模块，在 "Deveice" 部分，将 vesa 驱动改为 fglrx，重新启动 X。如果一切正常，我们就可以享受到 ATI 驱动的带来的视觉效果了。
我们可以用下面的命令来检测我们的 ATI 驱动是否安装成功：
$ fglrxinfo
我们应得到下面的输出：
display: :0.0 screen: 0
OpenGL vendor string: ATI Technologies Inc.
OpenGL renderer string: ATI Mobility Radeon HD 2400 XT
OpenGL version string: 2.1.7059 Release
$ glxinfo | grep direct
我们希望的输出结果为：
direct rendering: Yes
而我们在源中也可以找到相应的 fglrx 程序包：
# apt-cache search fglrx
个人觉得没有必要非得安装所谓的官方驱动包，因为由所谓的官方驱动包中所解出正是源中的几个程序包，而我在安装了官方的驱动程序包后进行了一下 upgrade，居然更新其中的两个包，既然这样，我们还不如直接安装源中的驱动程序包方便：
# apt-get install fglrx* 
使用 m-a 安装驱动模块时，我们也可以使用分步的安装方式，先编译，再安装，而不必一步到位：
# m-a get fglrx
# m-a build fglrx
这 时就会在 /usr/src/ 目录下生成一个 fglrx 的 deb 包。编译驱动程序模块时需要安装 Linux 内核头文件，我的内核是自己编译的 2.6.23， 但是在源中却迟迟没有相应的头文件包，真是相当郁闷的说。但是即使是这样，我却依然得到了一个编译生成的 fglrx 的 deb 包。我们可以使用 dpkg 来进 行安装。
最后需要进行 Xorg 的配置。最简单的就是将驱动改为 fglrx。当然我们也可以使用 ati 所提供的相应工具来进行配置：
# aticonfig --initial --input=/etc/X11/xorg.conf
这会进行相应的检测，并且修改 xorg.conf 文件。
4.3.2:NVIDIA 显卡驱动的安装
五：常用软件安装及配置
​            发现 Debian 即使是选择了 base system,laptop,desktop 其实也没有装多少东西，很多还需要自己安装，例如 alsa-oss,gnome-audio 等默认没有安装（应该没有记错）。下面很多东西可能系统已经安装了，但是这么做没有错的，下面的都是几乎不可缺少的组件。
5.1:Gnome 相关
5.1.1:Gnome 基本系统及基本管理工具
#apt-get install xorg gnome-core gdm gdm-themes gnome-system-tools gconf-editor nautilus-open-terminal gnome-power-manager gnome-screensaver
xorg X 窗口系统

gnome-core     gnome 核型组件
gdm  #gnome 默认的窗口管理器
gnome-system-tools     服务、网络等系统工具
gconf-editor     配置编辑器
nautilus-open-terminal    在右键菜单中加入终端
gnome-power-manager   #电源管理，休眠支持
gnome-screensaver      #锁屏
gconf-editor     #配置编辑器
ntfs-3g  #支持 NTFS 文件格式的读写
nautilus-gksu #以管理员权限打开目录

5.1.2: 安装 gnome 主题、图标、背景
#apt-get install  gnome-themes gnome-icon-theme-dlg-neu gnome-backgrounds
5.3: 常用软件工具安装
5.3.1: 字体安装
●   使用 apt
＃ apt-get install ttf-bitstream-vera ttf-arphic-uming  ttf-freefont #ttf-freefont 解决flash菜单可能的乱码，
WQY 点整字体: apt-get install xfonts-wqy
ttf-wqy-zenhei #文泉驿正黑字体
●   手工安装字体
把字体 ".ttf" 字体 copy 到 "/usr/share/fonts" 下面的某目录中
sudo mkfontscale
sudo mkfontdir
sudo fc-cache
●   系统字体优化：
1. 右击桌面，打开外观管理器中的字体选项卡，将其中的字体全部改成雅黑字体，同时把窗口标题设置为加粗，并选择 LCD 模式。
2. 在终端里输入指令
sudo gedit /etc/fonts/conf.d/49-sansserif.conf
将其中的字体全部改成雅黑，该操作也可以同时解决 flash 中出现方框的问题。

5.3.2: 输入法
●   安装 scim 中文输入法，可选其他的如 fcitx
#apt-get install scim scim-pinyin scim-tables-zh im-switch
#im-switch -z en_US -s scim #英文系统下使用SCIM：
scim-qtimm #scim兼容QT程序
#im-switch -s scim -z default
●   光标跟随
#gedit /etc/X11/xinit/xinput.d/scim
#GTK_IM_MODULE=xim
#QT_IM_MODULE=xim
GTK_IM_MODULE=scim
QT_IM_MODULE=scim
●   或者选择 fctix
不管你是 kde 还是 gnome 安装 fcitx 就这样：
apt-get install fcitx im-switch
im-switch -s fcitx -z default
5.3.3: 双击安装 deb 文件
#apt-get install gdeb
5.3.4: 压缩与解压缩
#apt-get install file-roller p7zip-full cabextract rar unrar  p7zip-rar rar unrar cabextract#7z,rar，cab

＃apt-get install gnochm
gnochm #CHM 阅读，或者 chmsee
5.3.5: 安装 OpenOffice.org
#apt-get install openoffice.org-writer openoffice.org-calc openoffice.org-math openoffice.org-impress openoffice.org-gtk openoffice.org-help-en-us
#apt-get install openoffice.org-l10n-zh-cn openoffice.org-help-zh-cn #中文界面和中文帮助
5.3.6: 安装视频播放器
#apt-get install mplayer w32codecs smplayer
w32codecs #多媒体库
5.3.7:PDF 阅读
#apt-get install evince xpdf xpdf-chinese-simplified xpdf-chinese-traditional poppler-data
xpdf-chinese-simplified xpdf-chinese-traditional poppler-data 完美中文支持
5.3.8: 图像处理
#apt-get install gimp
5.3.9: 网络通讯
#apt-get install pidgin

编程环境支持

#apt-get install build-essential libgtk2.0-dev freeglut3-dev libtool autoconf automake subversion
deb http://apt.jenslody.de/ any main
deb-src http://apt.jenslody.de/ any main
deb http://apt.wxwidgets.org/ etch-wx main
#KEY：
wget -q http://apt.jenslody.de/jens.asc -O- | sudo apt-key add -
wget -q http://apt.wxwidgets.org/key.asc -O- | sudo apt-key add -

其他安装

安装 Multiget：http://multiget.sourceforge.net/download.html
安装 Opera：http://www.opera.com/download/
安装 RealPlayer：http://www.real.com/linux
安装 AdobeReader：http://www.adobe.com/products/acrobat/readstep2_allversions.html
安装 FlashPlayer：http://www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash&amp;P2_Platform=Linux
编译 CodeBlocks 的 SVN 版本：
svn checkout svn://svn.berlios.de/codeblocks/trunk ~/Downloads/CodeBlocks
安装 CodeBlocks：
sudo apt-get install codeblocks
alien    a package converter, 将 rpm,dpkg,stampede slp 己 slackware tgz 档格式间的转换
pdfedit 修改 pdf 文件
linux 开发工具： gcc,make,autoconf,diff,patch,rcs,emacs
mysql-admin,mysql-navigator,mysql-query-browser
安装版本控制软件
sudo apt-get install subversion cvs
安装中文输入法
sudo apt-get install scim-pinyin
安装词典 http://stardict.sourceforge.net
sudo apt-get install stardict sox
/usr/share/stardict/dic/stardict-langdao-ce-gb-2.4.2 (郎道汉英辞典)
/usr/share/stardict/dic/stardict-langdao-ec-gb-2.4.2 (郎道英汉辞典)
/usr/share/WyabdcRealPeopleTTS (英文语音词库)
安装邮件客户端
sudo apt-get install thunderbird
安装 win-xchm 查看器
sudo apt-get install xchm
安装 msn for linux
sudo apt-get install emesene
安装下载工具 (bt 工具 transmission 默认已安装；amule 对应 windows 平台的 emule)
sudo apt-get install gwget amule
安装 rss 订阅工具
sudo apt-get install liferea
硬件监控工具
sudo apt-get install sensors-applet
远程桌面管理，RDP 默认已安装
sudo apt-get install xvnc4viewer
安装视频 / 音频解码器
gnome 平台推荐用 totem+gstreamer*, 直接点击多媒体文件，totem 会自动搜索匹配解码器安装
特殊的 rm, rmvb 格式文件，RealPlayer 11 for Linux 刚发布 (http://www.real.com/linux) , 效果不错，可以不用 w32codecs 了.
安装 flash for firefox, 新版多了一个选项”swfdec player”, 推荐，其对 CPU 消耗改善了


swfdec player for adobe/macromedia flash


adobe flash player


gnash swf player


中文编码配置
sudo vi /var/lib/locales/supported.d/zh
加入以下编码支持
zh_CN.GB18030 GB18030
zh_CN.GBK GBK
zh_CN.GB2312 GB2312
zh_HK.BIG5 BIG5
zh_TW.BIG5 BIG5
立即应用更新
sudo locale-gen
安装 vim
sudo apt-get install vim
配置 vim
sudo vi /etc/vim.local
加入以下设置 (个人喜好)
syntax on

set expandtab

set tabstop=4

set shiftwidth=4

set sts=4

set autoindent

set smartindent

set cindent

set number

let &amp;termencoding=&amp;encoding

set fileencodings=utf-8,gb18030,gbk,gb2312,big5
配置 gedit
执行 sudo gconf-editor
选择 apps/gedit-2/preferences/encodings
找到 auto_detected 编辑，在 Values 中分别加入 GB18030,GBK,GB2312,BIG5
界面风格 http://art.gnome.org
Ubuntu 默认的橘黄风格让我” 焦躁”, 一直偏向用蓝，灰的风格
窗体用 SimpleBox (2.6 kb, 下载安装)
图标用 tango (apt-get install tango-icon-theme)
Others
apt-show-source apt-show-versions archmage chmsee aria2 debian-faq-zh-cn fontforge gedit-plugins gtkcookie gupnp-tools htmldoc powersaved tor ttf-bitstream-vera vim-addon-manager
六：笔记本配置专辑
Dell Inspiron 6400




- Video card: Intel Corporation- Mobile 945GM/GMS/940GML Express Integrated Graphics Controller- RAM: 2Go- Hard disk drive: 100Go- Processor: Pentium Dual-core 1.86GHz (T2130)- Ethernet card: Broadcom Corporation BCM4401-B0 100Base-TX- Wifi Card: Intel Corporation PRO/Wireless 3945ABG Network Connection- Optical device: DVD+RW- Screen WSXGA+: resolution=1200x800, size=15,4" wide









Overall Status



Core Components






Boot Standard Kernel:




LAN network card:




Detect CD/DVD:




Detect hard drives:




Extra Features




CPU Frequency Scaling




Hibernation




Sleep / Suspend




Xorg




- OpenGL




- Resize-and-Rotate(randr)




Switch to External Screen




Mouse




- Built-in (Trackpoint)
[-]



- Built-in (Touchpad)




Modem
[?]



Wireless/Wifi




Keyboard's Hotkeys





Legend :


 = OK ;


 Unsupported(No Driver) ;


 = Error (Couldn't get it working);


[?] Unknown, Not Test ;


[-] Not-applicable


 = Configuration Required;


 = Only works with a non-free driver/firmware


Configuration
Display
You will need to install the 915resolution package:
# apt-get install 915resolution xserver-xorg-video-intel
# 915resolution
The 915resolution will try to get highest resolution, you can change this at /etc/default/915resolution.
If you wish to enable DRI, GLX, etc. see Xorg.conf_Lenny_DellInspiron6400.txt . My configuration works fine with Compiz.
If using newer "xserver-xorg" (version 7.3 +), do not install "915resolution" as it conflicts with "xserver-xorg-video-all" and "xserver-xorg-video-intel". Also install "libgl1-mesa-dri" (and this also installs "libgl1-mesa-glx") for OpenGL support. Use "glxinfo | grep direct" to check for direct rendering. The "glxinfo" util comes with the "mesa-utils" package. (Thanks to enouf and Nemoder on #debian@OFTC)
Hibernation and Sleep/Suspend
Works fine. Install,
# apt-get install acpid hal pm-utils uswsusp powermgmt-base
We will need to unload the "b44" module before hibernating, add the following to "/etc/pm/config.d/unload_modules":
SUSPEND_MODULES="b44"
The wireless drivers will be automatically handled by pm-utils. You should then be able to hibernate:
# pm-hibernate
And suspend:
# pm-suspend
Note that if you are trying to hibernate/suspend from within GNOME, you will need to be a member of the " powerdev" group.
CPU Power Scaling
Add a few modules to be loaded,
# echo "acpi-cpufreq" &gt;&gt; /etc/modules
# echo "speedstep_centrino" &gt;&gt; /etc/modules
Then, install the "powernowd" daemon:
# apt-get install powernowd
Powenowd's default settings should be OK for most people.
Hotkeys
These are automatically configures by:
# apt-get install hotkey-setup
WiFi
We need to install the firmware:
# apt-get install firmware-iwlwifi
And it should work. If you get an error like "Kill switch must be turned off in order for wireless networking to work." during system boot, you need to press the magic Fn + F2 button.
七：其他问题
0. 多源混合使用
安装完稳定版系统，请先为整个系统所有软件包设置 hold on 状态，aptitude 可以很容易的完成此任务。 接着，添加多个版本的源，即由上而下依次为： stable stable-backports （当前是 lenny-backports，http://wiki.debian.org/Backports） testing sid experimental， 然后，请针对特定软件包的特定版本升级，注意一次升级一个包彻底解决一个包，勿贪心。 升级完成，再次设置 hold on 状态，如此反复。
有时需要人工介入满足特定软件包的依赖关系。 如，为了使用 DRI，给 lenny 安装新版 ati 开源驱动 radeon 软件包， 需要先手工升级 mesalib-7.4.、xorg-server-1.6. 等， 再手工安装 radeon 软件包，而不能直接安装 radeon 软件包的新版本， 混用多个版本的源时，aptitude 自动计算的依赖关系并不总是可靠的。
如果仍不够新，那就要自己动手配置编译。 如果愿意可以使用 debian 方式编译打包。
如果升级的软件包依赖一些基本的软件包如 glibc，最终得到的系统将不再是 debian 稳定版。


自动挂载 U 盘中文文件名乱码问题


解决方法：系统工具 -&gt; 配置编辑 -&gt;/system/storage/default_options/vfat，双击 mount_options，” 添加”，在 “新列表值” 中填入 “utf8”。


apt-get 与 dpkg 的基本用法


#apt-get install packagename #安装一个新软件包
#apt-get remove packagename #卸载一个已安装的软件包（保留配置文件）
#apt-get --purge remove packagename #卸载一个已安装的软件包（删除配置文件）
#dpkg --force-all --purge packagename #强制卸载，风险大！
#apt-get upgrade #更新所有已安装的软件包
#apt-get dist-upgrade #将系统升级到新版本
$apt-cache search 正则表达式 #在软件包列表中搜索字符串
$dpkg -l 正则表达式 #列出所有与模式相匹配的软件包
#apt-get clean #清理所有软件缓存
#apt-get autoclean #清理旧版本的软件缓存
#apt-get autoremove #删除系统不再使用的孤立软件
#apt-cdrom add #增加一个光盘源
$dpkg -l |grep ^rc|awk '{print $2}' | #xargs dpkg -P #清除所有已删除包的残馀配置文件
#auto-apt run ./configure #编译时缺少h文件的自动处理


安装 RealPlay


下载 bin 包，到 realplayer 主页上下载 http://www.real.com/linux
#chmod 755 ./*.bin #或chmod +x ./*.bin
#./*.bin #一定要 root 安装，否则安装后无法启动。


安装 FlashPlayer


在 iceweasel 提示安装时选择安装，如果安装失败：
下载 install_flash_player_9_linux.tar.gz 并解压，进入解压目录，执行
安装：
sudo ./flashplayer-installer
若 flashplayer 菜单有乱码问题的话，执行：sudo mv /etc/fonts/conf.d/49-sansserif.conf/etc/fonts/conf.d/49-sansserif.conf.bak
安装 ttf-freefont 字体可解决 swf 文件中文乱码。

编译 Code::Blocks 的 SVN 版本

(a) 下载源码
svn checkout svn://svn.berlios.de/codeblocks/trunk ~/Sources/CodeBlocks
(b) 编译
export ACLOCAL_FLAGS="-I `wx-config --prefix`/share/aclocal"

./bootstrap

./configure 或 ./configure --with-contrib-plugins=all

make

sudo make install
(c) 缷载
sudo make uninstall
(d) 重新编译
make clean
make distclean
make clean-bin
make clean-zipfiles
详情：http://wiki.codeblocks.org/index.php...ource_on_Linux
●   关于 64 位系统使用 32 位软件额外需求
64 位系统同样能使用 32 位的软件，只要在终端输入以下命令，安装相应的 32 位包：
sudo apt-get install ia32-libs ia32-libs-gtk linux32 lib32asound2
●   MLdonkey+sancho 安装
MLdonkey 被誉为速度最快的电驴，同时支持很多种 P2P 的下载协议，包括 edonkey2000、gnutella、gnutella2、bt、FileTP
等等。网上有很多安装和设置的文章，但是有点乱，有些也不够完整，今天有空将它整理如下
下载最新版 MLdonkey &amp; sancho（左键点击）
一。安装 mldonkey：
解压缩 mldonkey 源代码并进入其目录，然后
$ sudo apt-get install ocaml
$ ./configure
$ make
$ make install
（使用新版本的 mldonkey 源代码编译安装后已不会有下载后文件名不支持中文的问题）
二。安装 sancho：
sancho 是 mldonkey 最好用的一个前端，下载回来的 sancho 只有一个文件，是一个脚本，先右键单击它，找到属性 - 权限部分，钩上 “可执行”，然后在终端中运行之：
$ ./sancho-*-linux-gtk.sh
然后会显示
Extract to directory [&lt;sancho-*-linux-gtk&gt;]:
输入自定义安装目录，随便你，我安装在 /usr/local/sancho
稍等一会就装好了，在 /usr/local/sancho/ 下有个 sancho，双击它就能运行 sancho
# 下载 sancho 后用 root 权限安装
user@~$ sudo sh sancho-0.9.4-59-linux-gtk.sh
# 选择安装目录，这里我安装在 /opt/sancho/
# 修改用户配置文件目录的权限
user@~$ sudo chown user:user -R ~/.sancho/
# 把 user 改成自己的用户名
三.sancho 设置
先运行 mlnet，在 /usr/local/bin 或 /usr/bin 下，然后运行 sancho，首次运行会有配置向导，需要设置 mlnet 位置。在 sancho 里面也可以设置 mlnet 的运行路径
在工具 -&gt; 首选项 -&gt;**sancho:** 主要 -&gt; 可选的可执行 core 那里填上你的 mlnet 路径。这样以后就可以直接启动 sancho。
设置中文：在工具 -&gt; 首选项 -&gt;**sancho:** 主要 -&gt; 使用本地文件 选择 zh-CN, 重启 sancho 后即为中文。
在工具 -&gt; 首选项 -&gt;Main 设置 client_name 推荐设置成 [CHN][VeryCD]yourname 的形式，支持中文。
在工具 -&gt; 首选项 -&gt;Bandwidth 设置 max_hard_upload_rate 和 max_hard_download_rate 分别是上传和下载速度，单位是 KB
在工具 -&gt; 首选项 -&gt;Networks 勾选 enable_overnet 和 enable_kademlia
在工具 -&gt; 首选项 -&gt;Networks-&gt;Donkey 有这两项：
ED2K-force_client_high_id
ED2K-force_high_id
如果你是公网用户，或者你是内网，且设置了端口映射，则勾选它们，如果你打死都是内网低 ID 用户，就不要选了，否则会很难连上服务器。
你可以选上试试看，不行再取消。
在工具 -&gt; 首选项 -&gt;Networks-&gt;Donkey-&gt;ED2K-port 设置端口，如果你有 windows 下的 emule，最好把他们的端口 (tcp 的) 设成一样，因为有些路由器有记忆功能，导致 windows 下的端口在重启后仍然保留。一般 emule 默认端口为 4662, 但有些宽带运营商会封掉该端口，建议改掉。
在工具 -&gt; 首选项 -&gt;Networks-&gt;Donkey-&gt;ED2K-max_connected_servers 设置服务器最大连接数，默认为 3，不用太大，大了也没用，一般稳定下来也就三四个左右，我把它设为 7
打开 sancho 主界面，点击控制台，然后在最下方的命令输入框那里
用如下命令导入服务器
servers http://www.emule.org.cn/server.met
用 ov_load 命令导入 overnet 的 node 列表，推荐下载 http://download.overnet.org/contact.dat
用 kad_load 命令导入 kad 的 node 列表，推荐下载 http://www.emule-inside.net/nodes.dat
或 http://renololo1.free.fr/e/nodes.dat，也可使用 eMule 的 nodes.data
对于 ov_load 和 kad_load，需要先下载回本地，比如把 contact.dat 下载到桌面后，输入：
ov_load /home/xxb/ 桌面 /contact.dat
路径请修改为适合你自己的。
修改下载目录和 temp 目录：默认目录分别为～/.mldonkey/incoming/files （BT 则为～/.mldonkey/incoming/directories) 和～/.mldonkey/temp
修改～/.mldonkey/downloads.ini，找到 “SECTION : Paths”，然后修改第一段和倒数第二段的路径，注意这里是相对路径。下载目录和 temp 目录最好放在同一个硬盘分区，否则下载完成转移临时文件时，硬 盘灯会狂闪。或者通过建立软链接来更改下载目录也可以（推荐）。
比如我把下载目录和临时目录都移到 /home/xxb/Videos/ 下，则把～/.mldonkey/ 下的 incoming 和 temp 目录都剪切到 /home/xxb/Videos/ 下，然后建立软链接：
$ ln -s ~/Videos/incoming ~/.mldonkey/incoming

$ ln -s ~/Videos/temp ~/.mldonkey/temp
四。设置浏览器关联
这里只说 firefox 的关联，如果需要设置其它浏览器，请参考 mldonkey 和浏览器关联的办法，适用 firefox, konqueror
先建立脚本，这里我们把它取名为 submit, 放在～/.mldonkey 下面。内容如下:
#!/bin/bash

echo dllink $*|nc -q 1 127.0.0.1 4000
如果系统是 ArchLinux，则需安装 netcat (gnu-netcat), 并改为
#!/bin/bash

echo dllink $*|nc 127.0.0.1 4000
然后右键单击它，找到属性 - 权限部分，钩上 “可执行”
接下来在 firefox 地址栏输入 about:config
新建 字符串 (string)
network.protocol-handler.app.ed2k
值为 submit 脚本的位置，比如我的是 /home/xxb/.mldonkey/submit
也可以安装 firefox 扩展，以关联 ed2k、bt 等，解压后的 mldoneky-distrib-xxx/ed2k_mozilla / 文件夹下 有个 mldonkey_protocol_handler-xx.xpi，把它拖到 fx 窗口选择安装。重启后就可以双击 MLdonkey Protocal Handler 这个扩展设置关联了，这个扩展也可以关联到 amule。不过扩展当然是能不装就不装，所以推荐使用 submit 脚本的方法。
五.WEB 界面
你也可以用浏览器控制和观察 mldonkey，地址是 http://localhost:4080/
我比较推崇用这个，不占额外资源（不必一直开着 sancho，毕竟 java 的东西会占不少内存和 cpu），设置更强，不过是英文的。你还可以编辑～/.mldonkey 下的各个文件进行设置，这里不再敖述。
六。端口映射
打开 http://localhost:4080/ 后，点击 Help+-&gt;Sysinfo 这里可以查看 mldonkey 的端口使用情况，除了 core 那 3 个，建议其余的都在路由器里设置端口映射，如果有防火墙，还要打开相应端口。
点击查看各种主流路由器映射的设置方法
七。其它
本文基本只涉及电驴部分，如果还需要其它比如 BT 功能，请自行摸索，附一些主要的配置文件：


~/.mldonkey/downloads.ini 基本的设置 (这个是 for edonkey 和其他协议的)


~/.mldonkey/servers.ini 服务器列表文件


~/.mldonkey/files.ini 当前已经完成的和未完成的文件列表


~/.mldonkey/friends.ini 好友列表


~/.mldonkey_gui.ini 图形前端的配置文件


另外其他的网络协议都有其单独的配置文件，一般都放在～/.mldonkey 目录下
祝骑驴愉快 _
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Driver</tag>
        <tag>Debian</tag>
        <tag>Laptop</tag>
        <tag>ED2K</tag>
        <tag>ATI</tag>
        <tag>WIFI</tag>
        <tag>Hotkey</tag>
      </tags>
  </entry>
  <entry>
    <title>qnap IO 错误消除</title>
    <url>/posts/5b1993ac/</url>
    <content><![CDATA[处理步骤
备份
先备份数据，rsync 比 HBS3 好用多了。
如果没有坏块
如果没有坏块，就在下图位置扫描坏块，扫描完，自动清除异常标志

如果有坏块
坏块修复
如果有坏块，可以使用 “DiskGenius” 扫描修复


强制消除异常标志


開啟 SSH
 登入 console
# sed -i '/pd_err_wwn_/d' /mnt/HDA_ROOT/.conf
重啟 NAS.


总结：
为了安全和稳定性，有坏块后，备份数据，使用 DiskGenius 修复坏块，（只能修复逻辑坏块，不能修复物理坏块），然后最好全盘格式化再使用。
SDD 可以使用低级格式化，但会全盘减少一次写寿命。尽量少用。
]]></content>
      <categories>
        <category>qnap</category>
      </categories>
      <tags>
        <tag>QNAP</tag>
        <tag>nas</tag>
        <tag>SSD</tag>
        <tag>HDD</tag>
      </tags>
  </entry>
  <entry>
    <title>几种常用管理模型和方法</title>
    <url>/posts/ca630feb/</url>
    <content><![CDATA[这些只是基本的工具，你需要了解。但是，和行业相关的知识更重要。就像做数学题，把一堆错综复杂的线索中归纳总结出来问题，提出解决方法，这中间需要丰富的行业知识，这个没法速成。总结完后，执行阶段，就像数学加减乘除一样，这些是基本的工具和方法。

PDCA 原则意义
Plan：制定目标与计划；
Do：任务展开，组织实施；
Check：对过程中的关键点和最终结果进行检查；
Action：纠正偏差，对成果进行标准化，并确定新的目标，制定下一轮计划。
意义：每一项工作，都是一个 pdca 循环，都需要计划、实施、检查结果，并进一步进行改进，同时进入下一个循环，只有在日积月累的渐进改善中，才可能会有质的飞跃，才可能取得完善每一项工作，完善自己的人生。


PDCA 原则的八大步骤



5W2H 分析法的意义
What：工作的内容和达成的目标；
Why：做这项工作的原因；
Who：参加这项工作的具体人员，以及负责人；
When：在什么时间、什么时间段进行工作；
Where：工作发生的地点 ；
Which：哪一种方法或途径；
How：用什么方法进行；
How much：需要多少成本？
意义：做任何工作都应该从 6W2H 来思考，这有助于我们的思路的条理化，杜绝盲目性。我们的汇报也应该用 6W2H，能节约写报告及看报告的时间。


5W2H 分析法的内容



SMART 原则的意义
Specific 具体的；
Measurable 可测量的；
Attainable 可达到的；
Relevant 相关的；
Time based 时间的；
意义：人们在制定工作目标或者任务目标时，考虑一下目标与计划是不是 SMART 化的。只有具备 SMART 化的计划才是具有良好可实施性的，也才能指导保证计划得以实现。
有的又如此解释此原则：
——S 代表具体 (Specific)，指绩效考核要切中特定的工作指标，不能笼统；
——M 代表可度量 (Measurable)，指绩效指标是数量化或者行为化的，验证这些绩效指标的数据或者信息是可以获得的；
——A 代表可实现 (Attainable)，指绩效指标在付出努力的情况下可以实现，避免设立过高或过低的目标；
——R 代表现实性 (realistic)，指绩效指标是实实在在的，可以证明和观察；
——T 代表有时限 (time bound)，注重完成绩效指标的特定期限。


SMART 原则实施要领



STAR 法则的意义


STAR 法则的内容



SWOT 分析模型的意义
Strengths：优势
Weaknesses：劣势
Opportunities：机会
Threats：威胁
意义：帮您清晰地把握全局，分析自己在资源方面的优势与劣势，把握环境提供的机会，防范可能存在的风险与威胁，对我们的成功有非常重要的意义。


SWOT 分析模型组合



GROW 教练模型的意义


GROW 教练模型的内容


时间管理 - 重要与紧急
A、重要且紧急
紧急状况
迫切的问题
限期完成的工作
你不做其他人也不能做
B、重要不紧急
准备工作
预防措施
价值观的澄清
计划
人际关系的建立
真正的再创造
增进自己的能力
C、紧急不重要
造成干扰的事、电话、
信件、报告
会议
许多迫在眉捷的急事
符合别人期望的事
D、不重要不紧急
忙碌琐碎的事
广告函件
电话
逃避性活动
等待时间
优先顺序 = 重要性 * 紧迫性在进行时间安排时，应权衡各种事情的优先顺序，要学会 “弹钢琴”；对工作要有前瞻能力，防患于未然，如果总是在忙于救火，那将使我们的工作永远处理被动之中。

任务分解法 [WBS]
即 Work Breakdown Structure，如何进行 WBS 分解：目标→任务→工作→活动
WBS 分解的原则：
将主体目标逐步细化分解，最底层的任务活动可直接分派到个人去完成；每个任务原则上要求分解到不能再细分为止。
WBS 分解的方法：
至上而下与至下而上的充分沟通；
一对一个别交流；
小组讨论。
WBS 分解的标准：
分解后的活动结构清晰；
逻辑上形成一个大的活动；
集成了所有的关键因素包含临时的里程碑和监控点；
所有活动全部定义清楚。
意义：学会分解任务，只有将任务分解得足够细，您才能心里有数，您才能有条不紊地工作，您才能统筹安排您的时间表。
OKR，目标与关键结果
OKR 实施过程中起草制定好目标和关键结果是非常重要的一环，有效的 OKR 制定需要满足 SMART 原则 —— 明确的、可衡量的、可实现的、有相关性和有时限性。
目标（O）回答的是 “我们想做什么” 的问题，是定性的，要求能够鼓舞人心，激发团队共鸣。
关键结果（KR）回答的是 “我们如何知道自己是否达成了目标要求” 的问题，是定量的，设计 KR 最具挑战的部分是如何把目标中定性的描述抽象为定量的表示。
最后：只有掌握了正确科学的工作方法，才可能在未来的工作中，做到事半功倍的效果，才能更加从容且有重点的开展工作。好的工作方法，是成功的一半！
]]></content>
      <categories>
        <category>PMBOK</category>
      </categories>
      <tags>
        <tag>管理</tag>
        <tag>PDCA</tag>
        <tag>5W2H</tag>
        <tag>SMART</tag>
        <tag>SWOT</tag>
        <tag>GROW</tag>
        <tag>OKR</tag>
        <tag>WBS</tag>
      </tags>
  </entry>
  <entry>
    <title>qBittorrent 参数详细设置教程</title>
    <url>/posts/f6b32521/</url>
    <content><![CDATA[全文将以目前的最新版 v4.2.1 为例，进行参数设置，老版本某些功能不太一致，请知悉。特别鸣谢 原创者：Evine！
行为参数

下载参数

连接参数

速度参数

BT 参数

RSS 设置

web 参数

高级参数

关于磁盘缓存的补充说明：
经常有人吐槽 qB 特别吃内存，个人猜测应该是磁盘缓存设置不正确导致的。磁盘缓存设置过小，磁盘缓存到期间隔过长，先下载的文件块来不及写入硬盘，新的文件块又到了，可能就会导致内存爆掉甚至磁盘 I/O 错误。个人建议：在进行高速下载时，适当将磁盘缓存调高，磁盘缓存到期间隔调低（下载时间隔越低写入越频繁，自己根据电脑的资源占用情况调整最适合自己的值）。实在不知道怎么调的，就干脆把磁盘缓存设置为 - 1（自动）好了，还不行，就把磁盘缓存到期间隔再调低一些。举一个例子，比如设置 2048MiB 磁盘缓存、300s 磁盘缓存到期间隔时，当下载速度为 50MiB/s 的时候，300s 的时间总共可以下载 15000MiB，早就远远超过 2048MiB 了，不爆内存、不 I/O 错误才怪。所以当达到这个下载速度的时候，在磁盘缓存不变的情况下，根据简单的除法（磁盘缓存除以下载速度）可知，磁盘缓存到期间隔就应该设置到 40s 以下了。
qB 在正常运行后，其占用的内存会比你所设置的磁盘缓存多几百 M。所有的参数没有标准答案，一切都得根据你机子的本身属性以及实际的使用场景（比如 CPU 性能、内存大小、硬盘写入速度、下载速度等）来设置，建议大家多试验。
关于 TCP、UTP 的补充说明：
TCP 是 Internet 上最常用的协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议。TCP 的优势在于双向互动机制兼顾数据传输的完整性、可控制性和可靠性，但复杂的校验与控制机制也使其没有 UDP 传输效率高。
UDP 协议与 TCP 协议一样用于处理数据包，是一种无连接的协议。UDP 的缺点是不提供数据包分组、组装和不能对数据包进行排序的缺点，也就是说，当报文发送之后，是无法得知其是否安全完整到达的。UDP 优势在于带宽占用小、传输效率和连接成功率高，有益于内网用户（如通过 UDP 内网穿透 UDP Hole Punching 连接），但 UDP 与 TCP 协议相比也存在无反向确认机制、无流量和序列控制等弊端。
uTP (Micro Transport Protocol) 是一种正在标准化的开放式 BT 协议，主要功能是提高宽带使用效率、减少网络问题。在减缓网络延迟和拥堵的同时最大化网络吞吐量、克服多数防火墙和 NAT 的阻碍，增强网络穿透和传输效率，同时增益流量控制，这对 BT 用户和 ISP 都是互利的。uTP 虽基于 UDP 协议但有所不同，uTP 通过拥堵控制算法（Ledbat）可限制延时，当延时不严重时可最大限度利用带宽，并能通过 uTP 提供的信息用于选择 TCP 连接的传输率，即使在不作限速设置的情况下，也能减少网络拥堵产生，当用户端之间都启用 uTP 时，可见明显的传输速率提升。内网无法实现端口映射的用户启用 uTP，可以改善与网外用户的连接。
使用 uTP 进行连接的用户，其标志将包含 “P”。
]]></content>
      <categories>
        <category>bt</category>
      </categories>
      <tags>
        <tag>QNAP</tag>
        <tag>nas</tag>
        <tag>PT</tag>
        <tag>BT</tag>
        <tag>qbittorrent</tag>
      </tags>
  </entry>
  <entry>
    <title>transmission 使用及其配置</title>
    <url>/posts/8f76d9dd/</url>
    <content><![CDATA[安装
qnapclub

docker
docker hub

version: "2.1"
services:
  transmission:
    image: ghcr.io/linuxserver/transmission
    container_name: transmission
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/London
      - TRANSMISSION_WEB_HOME=/combustion-release/ #optional
      - USER=username #optional
      - PASS=password #optional
      - WHITELIST=iplist #optional
      - HOST_WHITELIST=dnsnane list #optional
    volumes:
      - &lt;path to data&gt;:/config
      - &lt;path to downloads&gt;:/downloads
      - &lt;path to watch folder&gt;:/watch
    ports:
      - 9091:9091
      - 51413:51413
      - 51413:51413/udp
    restart: unless-stopped

控制脚本
/etc/init.d/QTransmission.sh start
/etc/init.d/QTransmission.sh stop
Transmission 配置详解
vi /share/CACHEDEV1_DATA/.qpkg/QTransmission/etc/settings.json
"alt-speed-up": 500, # 限速时段上传限速值
"alt-speed-down": 500, # 限速时段下载限速值
"alt-speed-enabled": false,
"alt-speed-time-begin": 540,
"alt-speed-time-day": 127, # 时段限速日期（星期几），127 表示每天，更复杂配置参考官网。用 7 位二进制数表示，然后转换成十进制数，0000001 表示周日，1000000 表示周六，0000010 表示周一，0000100 表示周二。如果你只要在周末限速，该数应该 1000001，转换为十进制就是 65
"alt-speed-time-enabled": true, # 启用限速，为 false 时，以上计划配置则不生效，生效时会自动禁用 alt-speed-enabled 配置，二者只能选一个
"alt-speed-time-end": 420, # 限速时段结束时间，这个配置表示的是凌晨零点到开始时间的分钟数，比如 7:00 就是 7*60=420。需要注意的是，该时间是用的 GMT 时间，即北京时间 -8 小时。比如你计划北京时间 7 点 30 分开始，这个数字应该是（7-8+24）*60+30=1410
"bind-address-ipv4": "0.0.0.0", # IPv4 地址绑定，一般不要改动
"bind-address-ipv6": "::", #IPv6 地址绑定，一般不要改动
"blocklist-enabled": true, # 启动白名单，默认不启动，需要启动改为 true
"blocklist-updates-enabled": false,
"blocklist-url": "http://www.example.com/blocklist",
"cache-size-mb": 4, #缓存大小，以 MB 为单位，建议设大一些，避免频繁读写硬盘而伤硬盘，建议设为内存大小的 1/6～1/4
"compact-view": false,
"dht-enabled": false, #关闭 DHT（不通过 tracker 寻找节点）功能，不少 PT 站的要求，但 BT 下载设置为 true 会使得下载更好
"download-dir": "/share/Downloads", #下载的内容存放的目录
"download-queue-enabled": true,  # 下载队列开关
"download-queue-size": 5, # 下载队列数量
"encryption": 1, # 加密。指定节点的加密模式，默认 1。0 表示关闭 , 0= 不加密，1= 优先加密，2= 必须加密
"lazy-bitfield-enabled": true, # 默认为 true，设置为 true 时可以避免某些 ISP 通过查询完整位段来屏蔽 BT，从而破解部分 ISP 对 BT 的封杀，当然不一定完全有效
"idle-seeding-limit": 30,
"idle-seeding-limit-enabled": false,
"incomplete-dir": "/share/Downloads",  # 临时文件路径
"incomplete-dir-enabled": false,
"inhibit-desktop-hibernation": true,
"lpd-enabled": false, #禁用 LDP（本地节点发现，用于在本地网络寻找节点）, 不少 PT 站的要求
"main-window-height": 500,
"main-window-is-maximized": 0,
"main-window-width": 615,
"main-window-x": 337,
"main-window-y": 211,
"message-level": 2,
"open-dialog-dir": "/share/Download",  # 网页对话框打开的根目录
"peer-congestion-algorithm": "",
"peer-limit-global": 240, # 全局连接数
"peer-limit-per-torrent": 60, # 每个种子最多的连接数
"peer-port": 51413, # 传入端口，预设的 port 口
"peer-port-random-high": 65535, # 传入端口随机值范围上限
"peer-port-random-low": 49152, # 传入端口随机值范围下限
"peer-port-random-on-start": false, # 启用随机端口，默认关闭，不建议改为 true
"peer-socket-tos": "default",
"pex-enabled": false, # 是否启用用户交换，默认为 true，关于 PEX，有兴趣的朋友可参考 http://en.wikipedia.org/wiki/Peer_exchange，对于只用 PT 的朋友，可以设为 false, 禁用 PEX（节点交换，用于同已与您相连接的节点交换节点名单）, 不少 PT 站的要求
"port-forwarding-enabled": true, # 启用端口转发（uPnP），如果路由支持并且也开启了 uPnP，则路由会自动做端口映射，但是需要注意的是如果内网有几台机器同时使用 transmission，就必须更改 peer-port 值为不一样
"preallocation": 1, # 预分配文件磁盘空间，0= 关闭，1= 快速，2= 完全。建议取 1 开启该功能，防止下载大半了才发现磁盘不够。取 2 时，可以减少磁盘碎片，但速度较慢。
"prefetch-enabled": 1,
"queue-stalled-enabled": true,
"queue-stalled-minutes": 30,
"ratio-limit": 2, # 分享率限制
"ratio-limit-enabled": false, # 启用分享率限制，默认不启用
"rename-partial-files": true, #在未完成的文件名后添加后缀.part,false= 禁用
"rpc-authentication-required": true, # 远程控制需要验证，默认为需要
"rpc-bind-address": "0.0.0.0", # 远程控制地址绑定，允许 IP 通过 RPC 访问，默认值表示任何地址都可以访问
"rpc-enabled": true, # 启用远程控制，默认启用
"rpc-host-whitelist-enabled": true, # 是否开启主机白名单
"rpc-host-whitelist": "", # 白名单，如果需要远程访问，最好配置
"rpc-password": "{cxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxaE", #web-ui 的密码，可直接修改，重新运行或者 reload 服务的时候密码会自动 HASH 增加安全性
"rpc-port": 9091, # 默认 web-ui 的 port 口，也是远程控制端口，可自行更改
"rpc-url": "/transmission/",
"rpc-username": "transmission", #默认登入名称，也是远程控制用户名
"rpc-whitelist": "127.0.0.1", # 远程控制白名单，默认值为所有地址，支持通配符*，如 192.168.2.*
"rpc-whitelist-enabled": true, # 启用远程控制白名单，如果启用，则仅仅上面列出的地址可以远程连接
"scrape-paused-torrents-enabled": true,
"script-torrent-done-enabled": false,
"script-torrent-done-filename": "/home/",
"seed-queue-enabled": false,
"seed-queue-size": 10,
"show-backup-trackers": true,
"show-extra-peer-details": false,
"show-filterbar": true,
"show-notification-area-icon": false,
"show-options-window": true,
"show-statusbar": true,
"show-toolbar": true,
"show-tracker-scrapes": true,
"sort-mode": "sort-by-age",
"sort-reversed": false,
"speed-limit-down": 300, #平时的下载限速
"speed-limit-down-enabled": true, #启用平时下载限速
"speed-limit-up": 30, #平时上传限速
"speed-limit-up-enabled": true, #启用平时上传限速
"start-added-torrents": false,
"statusbar-stats": "total-ratio",
"torrent-added-notification-enabled": true,
"torrent-complete-notification-enabled": true,
"torrent-complete-sound-enabled": true,
"trash-can-enabled": true,
"trash-original-torrent-files": false,
"umask": 18,
"upload-slots-per-torrent": 14
"utp-enabled": true, #启用μTP 协议
"watch-dir": "/share/bt",  # 监听文件夹目录
"watch-dir-enabled": false # 是否监听文件夹
Q：TR 提示 FILE NAME TOO LONG
A：TR 最大文件名 MAX_PATH ,260 个字符
方法 1：改路径和保存路径的文件夹名字，越短越好，在 web control 种子上面右键，修改种子文件或目录名称。次选方法，不勾选下载文件名过长的文件
方法 2：遇到个名字特长的，一直下载失败，使用软连接进一步缩短路径名长度
#cd /
#ln -s  /share/CACHEDEV1_DATA/Download/ DL
方法 3：
上面两种还是不行，换 QBittorrent 吧
不过，最近有好消息，这个 bug 我去看了下源代码，找到原来有人试图修复过它，但是并没有合并到最新版本。发个 post 提醒 bug 没有修复，居然有回复了。这个 bug 将在 3.0 版本修复，见下图。

Q: transmission 如何修改登陆密码
A: 第一种方式
qnap 中，transmission3.0 的配置文件路径如下
/share/CACHEDEV1_DATA/.qpkg/QTransmission3/etc/settings.json
 
cd /share/CACHEDEV1_DATA/.qpkg/QTransmission3/etc/settings.json
vim settings.json
找到”rpc-password”:
后面引号内就是经过加密的密码，不要管他怎么加密的，直接把引号内的内容修改为你的新密码就可以了，比如”rpc-password”:”xxorg.com”
然后按 “ESC” 键，输入:wq 保存退出，然后重启 tr 即可
第二种方式：
# 1、控制台输入，-u后边是用户名，-v后边跟着的是登陆密码
transmission-daemon --paused -t -u admin -v 123456
# 将会把生成的密码保存到：~/.config/transmission-daemon/settings.json
# 其实是生成配置文件并保存到当前登陆用户的家目录下
# 2、打开~/.config/transmission-daemon/settings.json并复制加密的密码
# 3、将加密的密码粘贴到/media/AiCard_01/transmission/config/settings.json
# 替换掉内容为：rpc-password 后面的密码
# 4、重启Transmission
ps: 通过 ps 定位 transmission 位置
ps aux | grep trans
# cd /share/CACHEDEV1_DATA/.qpkg/QTransmission3/bin
# ./transmission-daemon --paused -t -u [name] -v [password]
# cd ~/.config/transmission-daemon
[~/.config/transmission-daemon] # vi settings.json
复制生成的密码到前面的配置文件里面。
Q: 为 Transmission 增加种子目录监控，实现自动下载
/share/CACHEDEV3_DATA/.qpkg/QTransmission3/etc
改/var/packages/transmission/target/var/settings.json 在最后面增加2行。
"upload-slots-per-torrent": 14,（原文件最后一行，注意添加个逗号，不添加transmission好像不能启动） 
"watch-dir": "/XXXXX/XXXXX", （修改成自己nas上的同步目录） 
"watch-dir-enabled": true（无逗号）
保存，退出。
启动 Transmission  等待 1-2 分钟，就好了。
    "speed-limit-up-enabled": false,
    "start-added-torrents": true,
    "trash-original-torrent-files": false,
    "umask": 18,
    "upload-slots-per-torrent": 14,
    "utp-enabled": true,
    "watch-dir": "/share/Download/Seed/complete",
    "watch-dir-enabled": true
}
Q: Nas 上面 Transmission 如何做种？
A:
注意，此方法仅适用于开启了 ssh 的机器
可以看到可执行文件目录下有这么几个文件，每个人的安装目录都不一样，自行查找，或用
我的文件位置是在 /volume1/@appstore/transmission/bin，用到的命令是 transmission-create
方法也很简单，写一个范例
./transmission-create -p -o /volume1/data/Wi
kiLeaks-Year-Zero-2017-v1.torrent -t https://announce.XXXXXXXXXX.cc/announce.php -s 2048 /volume1/da
ta/WikiLeaks-Year-Zero-2017-v1.7z &amp;
参数
-p 表示这是私用的种子，这个必须要加上
-o 生成的种子输出位置，不要忘记把名字打上
-t tracker 的地址，我用的家园的做范本，大家自行修改
-s 每个文件块的大小，单位是 KB，我设置的是 2M，也就是 2048KB
最后空一格写源文件的位置，也就是文件的存放位置，可以是一个文件或者一整个目录
最后可以空一行加一个 &amp;，这样即使关掉窗口也可以在后台运行
填完，回车，种子就在制作了
种子已经躺在这了
[/opt/QTransmission3/bin] # ./transmission-create -p -o /share/CACHEDEV1_DATA/Download/Seed/海贼王\ \(1999\).torrent -t https://announce.XXXXXXXX.video/announce.php -s 2048 /share/CACHEDEV1_DATA/Download/海贼王\ \(1999\)/ &amp;
]]></content>
      <categories>
        <category>bt</category>
      </categories>
      <tags>
        <tag>QNAP</tag>
        <tag>nas</tag>
        <tag>PT</tag>
        <tag>BT</tag>
        <tag>transmission</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 jeckett,sonarr,iyuu,qt,emby 打造全自动追剧流程</title>
    <url>/posts/9912bd5d/</url>
    <content><![CDATA[
使用 jeckett,sonarr,iyuu,qt,emby 打造全自动追剧流程，打造一个完整的 HTPC。
持续滚动更新，欢迎收藏关注。也可以 RSS 订阅本博客！
jackett 作为种子源，sonarr 剧集管理，bt 下载，qbittorrent 主力下载，使用 iyuu 转移辅种，emby，jellyfin 做海报墙，sunfinder 自动下载字幕。基本算是完美打通全流程自动追剧。bt 种子文件命名规则 SxxExx 的自动识别下载，国内的资源手动查找下载，自动推送到 emby 刮削好。
结合本地 DNS 管理，DNS 去广告，Nginx 反向代理去端口访问，形成一个完整解决方案。
硬链接工具导入到新目录，使用 TMM 刮削。
Tips：博主只是把个人使用经验的一部分无偿写下来，写完后发现整理流程很复杂，要求很高，博主整体软硬件成本上 2W 以上了。各位读者赶着看得懂的做，如果看不懂，请略过，或者 Google 之。

indexer 种子索引源
种子索引来源。
jackett

docker: linuxserver/jackett:latest
 老牌选手，种子源非常丰富。


prowlarr

indexer manager/proxy
Docker:  linuxserver/prowlarr:develop
 新开发的，和 sonarr, lidarr 等结合比 jackett 配置更简单。


sonarr 动画剧集管理
管理剧集名，查找剧集种子推送到下载工具
剧集管理示例图片
管理剧集目录，剧集日历，提醒你那一天哪些节目播放



自动识别下载对英文剧集支持较好，对于中文资源，结合手动识别下载更佳。
手动识别下载
示例图片

电影使用 radarr, 音乐使用 lidarr，同样可以自动化过程
多媒体中心

Emby，Jellyfin, Plex 都是优秀的多媒体中心。Jellyfin 是开源的，基于 Emby 早期版本。

emby 海报墙，流媒体中心
emby 作为海报墙，元数据查看器，结合 tampermonkey js 脚本调用外部 potplayer 播放减少 nas 服务器压力，并且得到更好解码性能。手机端也有 emby 客户端。jellyfin，plex 也可以
js 脚本: embyLaunchPotplayer


jellyfin 开源版本的 emby

jellyfin 硬件解码
 jellyfin 中文字体显示方块问题

上面两个问题见下面 compose 配置解决方法
version: '3'
services:
  jellyfin:
    image: jellyfin/jellyfin
    container_name: jellyfin
    user: ${PUID}:${PGID}
    hostname: jellyfin
    restart: always
    devices:
     - /dev/dri:/dev/dri     #使jellfin支持硬件解码
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      # 给一些插件做代理
      - http_proxy=http://xxx.17lai.site:1089/
      - https_proxy=http://xxx.17lai.site:1089/
    # ports:    # 使用nginx 反向代理，所以这里就不用开端口了
      # - 8098:8096
    volumes:
      - ${USERDIR}/jellyfin/config:/config
      - ${USERDIR}/jellyfin/cache:/cache
      # 把windowsfonts目录下面的字体都复制到`jellyfin/fonts`目录中
      - ${USERDIR}/jellyfin/fonts:/usr/share/fonts    # 给jellyfin装载更多字体，使中文显示正确，不再是方块
      - ${USERDIR}/nginx/resolv.conf:/etc/resolv.conf    # 定制dns
 
赋予 emby，jellyfin 访问硬件加速驱动权限
chmod 755 /dev/dri
chmod 666 /dev/dri/renderD128
TMM 刮削，改名，目录整理

电影，电视剧，动画等视频为了更好的体验效果，需要刮削元数据。

一些命名不规范，不能被 emby 识别的剧集使用 tmm 刮削改名，配合硬链接工具，可以不影响做种的前提下改名，该目录。大文件硬链接，小文件直接复制方便刮削，推荐一个自己写的硬链接 bash shell 脚本，PTtool 在 nas，linux 环境使用更方便。
电影，电视剧，动画完整刮削教程，见如何使用 tinyMediaManager 刮削电影和电视剧，动画，并自动下载字幕。



Github: appotry/PTtool


Gitee: 镜像 bloodwolf/PTtool


如何使用 tinyMediaManager 刮削电影和电视剧，动画，并自动下载字幕




注意：使用 v3 版本，不要升级到 v4，v4 版本收费。
硬链接工具



博主编写的脚本，自推一下，在 Nas，linux 环境使用的 Shell 脚本。


PT hard link tools。方便 PT 用户硬链接文件，在最大可能情况下节约空间，并保持做种。 小于 1M 的文件直接复制，方便 emby，tmm 等工具刮削修改 nfo 等小文件。 大于 1M 的文件硬链接到目的目录，可以随意修改文件名，但是不能修改文件内容！


从此，做种，刮削改名两不误！





Github: PTools
 使用教程： Linux PT 硬链接助手使用教程


BT 下载工具

qBittorrent 下载，种子分类整理较好，但占用资源，内存较多。Transmissoin 种子整理分类远不如 qBittorrent，但资源占用低，是 PT 做种混魔力的首选！建议 qBittorrent 和 Transmissoin 搭配使用，使用 Iyuu 自动在两者之间转移种子。

Transmissoin

transmission 使用及其配置

qBittorrent

qBittorrent 参数详细设置教程

都分别有 docker 版本和套件版本。
虽然下载工具很多，但 IYUU 只支持这两个辅种工具，开发者的话是这两个工具的 RPC 调用接口稳定。


辅种工具 IYUU
Doker 版本


iyuucn/iyuuautoreseed

命令行版本



iyuucn/iyuuplus

图形界面版本，更轻松上手。



自动辅种，解放双手，更多魔力，更容易养多站。

字幕下载
想要较好的自动下载字幕，最好用前面介绍的 tmm 刮削改名之后再使用下面工具。
subfinder 自动下载字幕

Docker： superng6/subfinder

下载完成，刮削后的目录，挂载到 subfinder 的 media 目录，就会自动下载字幕。
字幕下载对电影，英文剧集支持较好。对于一些 tv，动画手动下载字幕会更好一些。
注意：官方的配置文件有问题，时效问题。修改 URL 到最新即可。
chinesesubfinder


Docker： allanpk716/chinesesubfinder


新开发的中文字幕查找工具，上面那个很久没更新了，这个刚出来。使用 nfo 里面刮削出来的文件名来匹配字幕。所以就原理来说，这个字幕匹配更准确。


bazarr

Docker：linuxserver/bazarr
 字幕下载管理，配合 sonarr, radarr 使用效果更好。对于英文剧集命名规范的支持较好，比如 [name]S01E01



电影管理

电影，电视剧，动画等视频都是类似。

使用 radarr 管理电影
radarr 示例图片
使用 Emby 观看电影

音乐管理
使用 lidarr 管理音乐

音乐刮削

使用 Mp3tag, MediaGo, MusicBrainZ 等工具刮削
音乐刮削教程： 如何使用 media Go,MusicBrainz,Mp3tag 工具刮削音乐 整理音乐资料库


使用 Mstream 听音乐

教程： 私人在线音乐服务器搭建与使用介绍


Docker 管理
使用 docker compose 管理 docker 配置文件，一键安装，升级
使用 portainer 管理 docker

version: '3'
services:
  portainer-ce:
    container_name:  portainer-ce
    image: portainer/portainer-ce
    command: -H unix:///var/run/docker.sock
    restart: always
    ports:
      - 9300:9000
      - 9301:8000
    environment:
      - TZ=Asia/Shanghai
      - LANG=en_US.UTF-8
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /share/Container/portainer_data:/data
使用 watchtower 自动升级 docker
使所有软件保持最新最佳状态

version: '3'
services:
  watchtower:
    container_name: watchtower
    image: containrrr/watchtower:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - TZ=Asia/Shanghai
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_SCHEDULE=0 0 1 * * *
    restart: always
    command: nginx redis
上述配置文件中 volumes 使用了绝对路径，使这个容器能访问系统 docker.sock 目录，用于方便监控容器镜像的版本以便更新。其他的一些环境变量，例如时区，清理旧镜像，定时任务都转换为 environment, 而特殊的 command 命令则定义了指定监控 nginx 和 redis 两个容器。没有 command 这一行，默认监控升级所有运行中的 docker
# 运行一次，更新所有的容器，并清除旧的容器 
docker run -d --name watchtower -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --cleanup --run-once
#只更新nginx和redis
docker run -d --name watchtower -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --cleanup --run-once nginx redis
使用 muximux 来管理多个 docker 入口
主页面

配置页面

更进阶定制本地域名访问
nginx 管理域名访问

Docker: bloodstar/nginx-purge
Github： nginx
 去掉烦人的端口后缀，实现 80,443 端口复用。这个 docker 是博主定制功能版。
配置 SSL 证书访问，密码等敏感数据从此加密传输。并可以使用 http2 高级特性。


version: '3'
services:
  nginxweb:
    image: bloodstar/nginx-purge
    container_name: "nginxweb"
    hostname: nginxweb
    ports:
      - "80:80"
      - "443:443"
    restart: always
    volumes:
      # 映射主机目录
      - ${USERDIR}/nginx/conf.d:/etc/nginx/conf.d:ro
      - ${USERDIR}/nginxproxy/certs:/etc/nginx/certs:ro
      - ${USERDIR}/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
这里推荐博主制作的 nginx docker 镜像： bloodstar/nginx-purge

支持 ARM64, ARMV7, AMD64 ，增加 CA 证书，防火墙，brotli, Proxy-cache-purge, htpasswd 支持

DNS 域名管理



和 nginx 配合使用。 简单的可以直接修改 /etc/hosts。


DNSCrypt Proxy： 作为 DNS 前端访问 DOH 的 DNS


DNSMasq： 作为 DNS 后端，连接到 DNSCrypt Proxy，并配置本地域名。还可以添加 DNS 去广告功能，浏览器插件去广告非常消耗 CPU 和内存，但是在 DNS 前端去广告，资源消耗低，并一次性解决所有的访问终端（pc，手机，平板）广告问题。

配置一个去广告，本地域名管理工具。



Xteve 看 IPTV
Docker: dnsforge/xteve
结合 Emby， jellyfin 直接看 iptv。

注意事项


tmm，jackett，sonarr 最好配置代理。否则，刮削，图片墙可能工作不正常。


docker 最好配置镜像加速，提高安装 docker 速度


一些 docker 初始化安装，运行、更新时需要访问 github，最好配置代理。推荐博主定制 Docker bloodstar/v2fly-privoxy


]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>Emby</tag>
        <tag>Sonarr</tag>
        <tag>Jeckett</tag>
        <tag>Portainer</tag>
        <tag>Watchtower</tag>
        <tag>DNSMasq</tag>
        <tag>DNSCrypt</tag>
      </tags>
  </entry>
  <entry>
    <title>QNAP 修改应用启动顺序</title>
    <url>/posts/77da2f80/</url>
    <content><![CDATA[
关于本 blog，图床一般使用 github，已经配置了 CDN，如果图片还是未显示请自行代理解决

有时候，你想修改一下安装的应用启动顺序。该怎么做了？
在无意中，博主发现了这个技巧。配置方法如下：
配置文件路径

配置文件内容

RC_Number 是 qnap 配置应用启动顺序，数字越小优先级越高。看着 100 差不多就是用户程序高优先级上限了。如此，你可以把一些应用调整高优先级启动，例如代理配置 v2ray, dns 配置 DNSCrypt Proxy 和 DNSMasq，以实现其它应用采用这些服务。把一些应用调整低优先级，如 qbittorrent 等。
ls /etc/config -alh
lrwxrwxrwx 1 admin administrators 21 2021-08-31 17:20 /etc/config -&gt; /mnt/HDA_ROOT/.config/
qnap 使用 init v 系统。
如果改为 systemd 系统启动，可以加快启动速度。一些应用延迟加载技术看起来也没做好。用户这里修改 RC_Number 可以手动实现一些延迟加载功能。
/etc/init.d/QTransmission3.sh start         #启动
/etc/init.d/QTransmission3.sh stop            #停止
/etc/init.d/QTransmission3.sh restart        #重启
原创首发
可以转载，但必须完整转载，并且带上原始地址链接。

]]></content>
      <categories>
        <category>qnap</category>
      </categories>
      <tags>
        <tag>QNAP</tag>
        <tag>nas</tag>
        <tag>启动</tag>
      </tags>
  </entry>
  <entry>
    <title>通过宝塔面板实现 MySQL 性能简单调优</title>
    <url>/posts/d5f56dd0/</url>
    <content><![CDATA[
在 PHP+MYSQL 架构网站运行过程中，往往会遇到各种性能问题影响，如 MySQL、PHP、CPU、磁盘 IO、缓存等，其中 MySQL 瓶颈就是最常见也最难解决的一种影响网站性能的因素；通常，我们会使用 redis、memcached 等缓存软件来缓存内容，这确实是最优的解决方案之一，但这需要网站程序的支持，然而多数常用网站程序并不支持或者不能完美支持这些缓存软件，今天我们就来谈谈如何通过 MySQL 自身的配置调整来优化 MySQL 性能，以缓解 MySQL 瓶颈问题。

准备：

​    1、宝塔 Linux 面板 正式版 5.2.0+ (2017/09/20 发布)  测试版 5.2.4+
​    2、MySQL 5.x

通常 MySQL 调优我们分以下几部分：

​    1、MySQL 配置参数调优 (需要根据网站运行情况调整)
​    2、数据表索引调优 (效果明显，但通常优秀的开源程序都不需要调整)
​    3、SQL 语句调优 (这是程序员或 DBA 干的事)

今天我们主要谈谈如果配合宝塔面板的新功能来进行 MySQL 配置参数调优，我们先来看两张图片：
(图 1)

(图 2)

很明显，(图 1) 显示的是 MySQL 当前的运行状态，(图 2) 显示的是 MySQL 主要配置参数
下面我们就来解读一下这两张图：
1、活动 / 峰值连接数
​      (图 1) 中当前活动的连接为 1 个，自 MySQL 服务启动以来，最高连接数为 54；当最高连接数接近或等于 (图 2) 中的 max_connections 时，应适当增加 max_connections，需要注意的是，不要一下子增加过多，建议每次增加 50，观察一段时间，不够再继续增加。
2、线程缓存命中率
​      (图 1) 中线程缓存命中率为 99.78%，若这个值小于 90%，建议适当增加 (图 2) 中的 thread_cache_size，建议每次增加 8。
3、索引命中率
​      (图 1) 中索引命中率为 99.50%，若这个值小于 95%，建议适当增加 (图 2) 中的 key_buffer_size，建议每次增加 64，需要说明的是，若您的数据库使用的是 Innodb 引擎，可忽略这个选项
4、Innodb 索引命中率
(图 1) 中 Innodb 索引命中率为 100%，若这个值小于 95%，建议适当增加 (图 2) 中的 innodb_buffer_pool_size，建议每次增加 64，需要说明的是，若您的数据库没有使用 Innodb 引擎，可忽略这个选项
5、查询缓存命中率
​      MySQL 查询缓存是个比较受争议的功能，个人建议当你有在使用 redis、memcached 等缓存软件时，在 (图 2) 中将 query_cache_size 设为 0 可以将其关闭，当你没有使用缓存软件，有多余的内存使用，且数据库瓶颈明显存在时，可以尝试开启查询缓存，这是个非常依赖数据表结构及 SQL 语句优化的功能，若数据表结构和 SQL 语句都针对查询缓存进行过优化，它的效果还是很不错的。
6、创建临时表到磁盘
​      (图 1) 中创建临时表到磁盘的比例是 0.42%，这说明大部分临时表创建到内存了，不会过多增加磁盘 IO 的开销，建议，当比例大于 2% 时适当增加 (图 1) 中的 tmp_cache_size，建议每次增加 32，当比例大于 60% 时，放弃吧，有些开源程序并没有专门优化过 SQL 语句，所以在运行过程中会开启大量临时表，加多少缓存都是不够用的。
7、已打开的表
​      当 (图 1) 中的已打开的表接近或等于 (图 2) 中的 table_open_cache 时，可以适当增加 table_open_cache，但若设置过大可能导致您的程序频繁中断 MySQL 连接，建议在 1024 以内，最大不要超过 2048。
8、没有使用索引的量、没有使用索引的 JOIN 量
​      若不为 0，就检查下数据表索引吧，其实只要没有疯涨，比如一天增涨几千，一般可以忽略，必竟优化索引还是程序员或 DBA 去干比较合适。
9、排序后的合并次数
​      如果这个值在缓慢增张，建议适当增加 (图 2) 中的 sort_buffer_size，建议每次增加 512，但最大不要超过 8192，如果这个值一直在疯涨，增加 sort_buffer_size 也没用，就放弃这个选项吧，这个锅还是给程序开发者背。
10、锁表次数
​      如果服务器 CPU 开销不大的情况下，疯狂锁表，建议你将所有数据表转换成 innodb，记得转换前备份哦。
11、优化方案
​      这个是我们根据内存大小给的一个推荐优化方案，仅是建议仅用于基础参考值，还是要根据实据情况来调整每一个配置项。
注意：保存参数配置后不会立即生效，记得要重启 MySQL 服务。
写在最后：
因我本人并不是专业 DBA，难免有错误或遗漏的地方，还请大家给予指正，另外，可能面板提供的参考数据及调整选项还不够丰富，我们在往后的更新中会根据需要考虑继续增加更多的调整选项，谢谢大家的支持。
来自网络整理。
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MySQL</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title>ESNI 和加密 DNS - 保护信息隐私的最后一块拼图</title>
    <url>/posts/ec2cad2/</url>
    <content><![CDATA[随着 TLS1.3 的发布，让该协议成为有史以来最安全、也是最复杂的 TLS 协议。在该协议之中，有很多的对于以往协议安全漏洞的修复，包括废弃 RSA 启用新的秘钥交换机制 PSK 等等。而 Encrypted SNI 作为一个 TLS1.3 的扩展协议用来防止传统的 HTTPS 流量受到 ISP 或者陌生网络环境的窥探以及一些网络审查。在过去，由于 HTTPS 协议之中 Server Name Indication - SNI 的使用，我们的 HTTPS 流量经常被窥探我们所访问站点的域名
那么什么是 SNI？⌗

服务器名称指示（英语：Server Name Indication，简称 SNI）是一个扩展的 TLS 计算机联网协议，在该协议下，在握手过程开始时客户端告诉它正在连接的服务器要连接的主机名称。这允许服务器在相同的 IP 地址和 TCP 端口号上呈现多个证书，并且因此允许在相同的 IP 地址上提供多个安全（HTTPS）网站（或其他任何基于 TLS 的服务），而不需要所有这些站点使用相同的证书。它与 HTTP/1.1 基于名称的虚拟主机的概念相同，但是用于 HTTPS。所需的主机名未加密， 因此窃听者可以查看请求的网站 为了使 SNI 协议起作用，绝大多数访问者必须使用实现它的 Web 浏览器。使用未实现 SNI 浏览器的用户将被提供默认证书，因此很可能会收到证书警告


SNI 协议示意图



 TLS1.3 完整握手流程


为了弥补缺陷因应运而生的 ESNI⌗
在上述过程之中，存在的问题就是，在 ClientHello 环节中，TLS 会在这个位置以明文的形式讲要请求的 Host 写在数据包之中，如果在网络路由中有任何的监听节点，那么用户所访问网站的域名将暴露无遗，这将是巨大的用户隐私泄露: 
所以在最新的关于 ESNI 的草案中，IETF 重新设计了一种加密的 Client Hello 机制，从而修复了这个问题: 
不过这里问题又来了，之前服务器和客户端并没有事先交换任何数据啊，这个加密的凭证从何而来啊？？？
依靠安全 DNS 的 ESNI⌗
上一个问题没有难倒工程师们，他们设计了这样一个办法。首先让网站提供者在 DNS 提供商上公布一个记录，这个记录包含着一个公钥，这个公钥由网站提供者生成，其私钥存储在 Web 服务器等待着被 Web 程序读取。如此，当用户想通过 TLS1.3 协议访问这个域名的时候，首先读取这个公开的公钥，在用公钥加密其想访问的域名Host，装在 Client Hello 里面发送给目标服务器，目标服务器再用自己的私钥解密，从而和用户建立 HTTPS 链接，这样就不会暴露 Host 信息 这时候有人会想，如果有人某 Wall 想给你的 DNS 偷天换日，那会不会很不安全啊，请继续向下看
在 ESNI 的实现草案之中，里面要求安全加密的DNS是推荐的。大家都知道我们的 DNS 查询一般是 TCP 报文或者是 UDP 报文，本身它是不加密的，所以如果有人想在篡改你的 DNS 是相对简单的，大家可能都知道我们伟大的妨炎蔷会使用 DNS 污染的方式干扰一些网站的正常访问。正式由于 DNS 的非加密性，DNS 也成为了审查信息的利器。此时加密的 DNS 势在必行
DNS over TLS (DoT) and DNS over HTTPS (DoH)⌗
于是出现了这两种新型的 DNS 查询方式

DNS over HTTPS (DoH)


DNS Over HTTPS (DOH) 是一个进行安全化的域名解析的方案，当前尚处于实验性阶段。其意义在于以加密的 HTTPS 协议进行 DNS 解析请求，避免原始 DNS 协议中用户的 DNS 解析请求被窃听或者修改的问题（例如中间人攻击）来达到保护用户隐私的目的。 Google 及 Mozilla 基金会正在测试这一协议，作为其提高网络安全性的努力的一部分。 当前，该方案由 IETF 支持，其规范文档以 RFC 8484 的名义发布。2018 年 9 月 5 日发布的 Firefox 62 正式版加入了这项功能，但需要用户手动开启 DNS Over HTTPS 利用 HTTP 协议的 GET 命令发出经由 JSON 等编码的 DNS 解析请求。较于传统的 DNS 协议，此处的 HTTP 协议通信处于具有加密作用的 SSL/TLS 协议（两者统称作 HTTPS）的保护之下。但是，由于其基于 HTTPS，而 HTTPS 本身需要经由多次数据来回传递才能完成协议初始化，其域名解析耗时较原 DNS 协议会显著增加。 传统的 DNS 协议形成于互联网早期，直接基于 UDP 或 TCP 协议，且彼时未虑及现代安全性的需要，未利用密码学等手段进行加密或验证。因而，其无法抵御现代互联网常见的 DNS 投毒污染等攻击手段或监听。虽然后来的 DNSSEC 方案通过电子签名进行验证，强化了 DNS 的安全性，并能够抵御 DNS 投毒污染等篡改通信的手段，但其对于中间网络设备进行的监听仍然没有抵御能力（随后，监听者可以通过获取的通信数据知晓用户访问了哪一域名，而域名往往与具体的网站相关系）。此外，DNSSEC 的起效要求现有的大量 DNS 解析服务的提供商（常为互联网服务提供商或第三方大型互联网机构）对已有的 DNS 服务器进行大范围修改等问题，其推进进程并不理想。而对于 DNS Over HTTPS，在正确部署服务端并妥善配置客户端的前提下，互联网服务提供商或其它中间网络设备无法解密（亦即无法获知请求的实际内容）或者篡改已经加密的 HTTPS 通信，故其能够有效保护互联网用户的安全及隐私；另一方面，其基于已经成熟并已广泛部署的 HTTPS 协议，客户端进行利用较为方便。


DNS over TLS (DoT)


DNS over TLS (DoT) 是通过传输层安全协议（TLS）来加密并打包域名系统（DNS）的安全协议。此协议旨在防止中间人攻击与控制 DNS 数据以保护用户隐私。 RFC 7858 及 RFC 8310 定义了 DNS over TLS。 截至 2018 年，Cloudflare、Quad9 与 CleanBrowsing 均向大众提供支持 DNS over TLS 的公共 DNS 解析服务。2018 年 4 月，Google 宣布 Android P 将包含对 DNS over TLS 的支持。PowerDNS 的 DNSDist 也宣布在其最新的 1.3.0 版本中添加了对 DNS over TLS 的支持。BIND 用户也可以通过 stunnel 代理提供 DNS over TLS 服务。

手动配置⌗
Firefox 所在的 Mozilla 宣布从 Firefox 62 版本之后开始支持 ESNI，默认没有开启，需要用户手动配置打开，那么我们现在试验一下 这里 Firefox 的解决方案是使用 DNS over HTTPS (DoH) 和 ESNI


安装 Firefox Nightly 版本，这个版本是预发布版本，使得开发这和即可门可以提前尝鲜到新功能。下载地址


在浏览器地址栏输入 about:config 并回车，打开配置页面，在搜索位置搜索 network.trr.mode，这个是打开浏览器对于 DoH 的支持，将此项的数值修改为 3（0 对应的是不开启此功能；1 对应的是交由浏览器选择 DoH 与传统方式那种更快；2 代表优先使用加密 DNS 查询，如果失败则回落到普通 DNS 查询；3 代表只使用加密 DNS 查询；5 代表明确的关闭此功能）


继续搜索 network.trr.uri，将此项的值修改为 https://mozilla.cloudflare-dns.com/dns-query，这个是默认的 DoH 查询地址，当然我们也可以使用诸如 https://1.1.1.1/dns-query、https://dns.google.com/experimental 这样的地址，我们可以事先 ping 检测一下对比哪个延迟更低来使用


（可选）搜索 network.trr.bootstrapAddress，讲此值修改位第三步的 DNS 域名的 IP。此举是为了避免使用操作系统 DNS 查询域名受到劫持，一般来说这些 DNS 的 IP 是不会变的





将 network.security.esni.enabled 设置为 true, 此举为了打开浏览器对于 ESNI 的支持（感谢 chenlshi 同学的提醒，在原版的文章中我不小心遗漏了这个关键的步骤）


完成配置后重启浏览器，再打开在线验证页面验证来查询你的浏览器是否完全支持 ESNI 功能，如果出现如图说明配置成功了



验证⌗
为了验证是否真的加密了 Client Hello，我们使用 Wireshark 进行网络抓包 由于这个特性仍在试验阶段，并没有太多站点支持这个特性，CloudFlare 是第一个全站支持 ESNI 的网站，这里我们使用 blog.cloudflare.com 来做测试：

首先打开 Wireshark 的抓包功能，然后开启 Chrome 浏览器打开上述网址，页面加载完后停止抓包，在得到的结果中查询协议为 TLS1.3 和报文为 Client Hello 的报文，通过观察发现域名的 Host 果然被以明文形式写在数据包中（参见 Server_Name 字段）：



然后打开 Firefox Nightly 浏览器重复上述操作，这次发现在整个数据包中根本找不到 Server_Name 字段，说明 Host 已经被加密：


目前来说，我查阅了相关的关键词，仍然没有任何一篇教程有介绍如何在自己的服务器上支持 ESNI，同时我也看到在 Nginx 的论坛里面有人呼吁尽快支持 ESNI，所以我推测这个功能仍然在试验期，还没有被这两个 Web 软件所支持，起劲为止我也没有查阅到任何的 Web 软件预计支持此项功能。这项扩展已经进入 IETF 的草案阶段，可以预见到，在不就的将来，这项技术可以普及开来，为我们的网络隐私保驾护航 目前来说，有了 HTTPS+TLS1.3+ESNI+DoH/DoT 的加持，我们的网络隐私的到了极大的保障，最后还有一个问题是访问服务器 IP 的泄露仍然无法被避免，迫于 IP协议设计的机制，他目前还不能被解决。不过我相信，随着网技术不断的趋于保护个人隐私和更快速的发展方向，这个问题可以最终被解决
From: hackerchai
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>SSL</tag>
        <tag>TLS</tag>
        <tag>隐私</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title>【Gitlab】GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇</title>
    <url>/posts/7790e989/</url>
    <content><![CDATA[上一篇文章介绍了如果用 gitbook 写书，并且我们已经通过 gitbook build 命令把书的内容打包成 HTML 格式发布到了_book 文件夹中。
接下来这篇文章将向大家介绍如何把写好的书发布到 gitlab 上。这里 gitlab 是我们自己搭建在公司内网中的，不过要用到的原理其实都是一样的，就是利用其 CI/CD 功能。
关于 CI/CD 网上有很多详细的介绍，这里我就不不再重复啰嗦，如果有想学习的可以参看文末的致谢 &amp; 引用部分。
原理
简单来说 CI 就类似一个触发器，你可以设定响应触发的条件，比如 master 分支有新的 commit 合并进来，或者带有特殊 tag 的合并，亦或者其他指定分支的特殊提交，可以触发指定的指令。
一般来说标准的流程是 3 步，打包 (build)、测试 (test) 和发布 (deploy)。也就是我们只需要把源码提交上以后，CI 可以帮我们完成自动化部署工作。
考虑到我们在用 gitbook 写书的过程中需要预览时，其实已经在做 build 和 test 的工作了，所以我们只需要在代码传到 gitlab 上后，让服务器帮我们执行发布的工作。
所以前提是我们搭建好了一个 web 服务，然后 CI 帮我们把打包好的内容部署到相应的网站目录中就好了。
实现
我们就按照原理，来一步一步尝试着完成工作吧。
CI 配置
还记得我们上一篇文章中最后介绍目录结构时，有提到一个文件： gitlab-ci.yml。 这个文件是用 YAML 进行配置，我们来看一下我们要用到的配置文件吧
deploy:
  stage: deploy
  script:
    # make backup
    - sudo rm -rf /usr/share/nginx/html/TechDocs/example_bak
    - sudo mv /usr/share/nginx/html/TechDocs/example /usr/share/nginx/html/TechDocs/example_bak
    - sudo mkdir /usr/share/nginx/html/TechDocs/example
    # deploy latest files
    - cd _book
    - sudo cp -rf . /usr/share/nginx/html/TechDocs/example/
  only:
    - master # this job will affect only the 'master' branch
这段 yaml 配置就只有 deploy 的步骤，我们在 script部分进行了一系列的操作，完成旧文件的备份以及新文件的部署。当我们的代码上传到远端后，就会自动执行 script 里的内容了。让我们尝试下吧。
查看 CI 任务执行状态
上传代码到 gitlab 的步骤这里就不介绍了。理论上说，当代码上传到 master 分支后，会自动执行我们设定好的部署任务。我们可以通过访问 gitlab 对应项目的页面， 在左侧菜单栏点击 CI/CD 来查看任务的执行情况。
但是如果你和我一样是第一次处理 CI 任务，我们会得到下面的提示：

原因页面上也给出了我们提示 This job is waiting to be picked by a runner。
Runner
这里就需要引入第 2 个概念： runner。很容易从字面上理解，runner 就是我们任务的执行者，也很形象，我们提交了一个任务以后，总得有人来执行。这些任务有些是需要 shell 脚本执行，有些可能需要登录到远程机器，有些可能需要 docker 的执行权限，所以这些执行者也都有个子的分工，可能有些执行者只负责执行特定项目的任务，有些执行者执行特殊 tag 的。所以接下来我们看看如何才能创建 runner 吧。
shared runner
前文提到了我们可能需要一些高权限的 runner 来跨项目间来执行任务。因为我们要做的是多个项目的技术文档，所以会有多个 gitbook 的项目，那这些项目的 CI 任务自然是公用 1 个 runner 就好，这种 runner 就叫做 shared runner。
shared runner 的创建需要我们用管理员的帐号登录 gitlab 页面，在 admin area 区域，点击 runner 来根据提示创建。

这个页面会显示当前所有的 runner，包括项目独享的 runner 和共享的 shared runner。 我们看到目前还没有一个可用的 runner，所以之前的任务才会停留在等待 runner 来运行的状态。
我们就根据页面的提示来创建 runner 吧。

安装 gitlab-runner 工具
第一步是安装工具，可以通过页面上的提示来进行不同主机环境的安装。我们这里用到的是 RHEL/CentOS，其他版本可以参见页面链接。
我们登录到自建 gitlab 所在的主机，然后执行以下脚本
$ sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64
$ sudo chmod +x /usr/local/bin/gitlab-runner
$ sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash
$ sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner
$ sudo gitlab-runner start
新建 shared runner
工具安装好了之后，我们就可以来创建用户了。
$ gitlab-runner register
之后按照提示，一步一步创建就好了：

输入 URL
 输入 token。 URL 和 token 按照页面上给出的提示来创建就好了。token 用来标识创建的 runner 是某个项目特有的，还是 shared runner
 输入 runner 的描述，这个可以随便填写，只要自己能看明白，能区分就好了
输入特定的 tag。 注意，这里最好留空，否则该 runner 仅会执行特定 tag 的提交
选择执行类型。这里提供了很多常见的执行类型，例如 docker, docker-ssh, shell 等，我们这里输入 shell。


之后我们就创建好了一个可以执行 shell 命令的 shared runner。再次回到之前的 web 页面上查看我们创建的 runner 信息。

可以看到页面提示我们已经创建了一个 runner 可以执行 all unassigned projects 的任务

我们还可以进入到特定的项目，在设置里面查看 runner 的情况，可以看到已经有一个可用的 shared runner。如果想创建该项目特有的 runner，按照页面上的提示，输入特定的 token 就好了。

其他细节
我们重新查看 CI 任务页面，大多数情况下，你的任务状态会是 failed 或者 pendding。 如果是 failed，我们可以点击查看具体失败的原因，例如我遇到的问题就是 gitlab-runner 用户没有 sudo 权限。
如果是 pendding，通常情况下是你的 job 没有合适的 runner 来执行，例如指定了分支或者添加了 tag 导致没有 runner 可用。

如果一切都设置妥当，我们可以看到 CI 页面任务的最终状态是 passed，也就是成功执行了。这样，gitbook 的内容就成功部署到你的 web 页面上了。
致谢 &amp; 引用

基于 GitLab 的 CI 实践 (https://zhuanlan.zhihu.com/p/41330476)
如何使用 GitLab CI (https://medium.com/@mvpdw06/% E5% A6%82% E4% BD%95% E4% BD% BF% E7%94% A8-gitlab-ci-ebf0b68ce24b)
Configuring GitLab Runners(https://docs.gitlab.com/ee/ci/runners/)
Registering Runners(https://docs.gitlab.com/runner/register/)
Gitbook CI With Gitlab(https://xiaosuiba.github.io/Gitbook-CI-With-Gitlab/)
在 Gitlab 平台簡單創建 GitBook 電子書的步驟 (https://www.kenming.idv.tw/simple-create-gitbook_at_gitlab_steps/)
How to create a static website using GitLab Pages(https://getpublii.com/docs/host-static-website-gitlab-pages.html)
Install GitLab Runner manually on GNU/Linux(https://docs.gitlab.com/runner/install/linux-manually.html)

From: lipeng1667
系列教程
Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

]]></content>
      <categories>
        <category>gitbook</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>linux</tag>
        <tag>GitBook</tag>
      </tags>
  </entry>
  <entry>
    <title>【Gitbook】GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇</title>
    <url>/posts/7fe86002/</url>
    <content><![CDATA[随着工作时间越来越久，项目越做越多，很多时候，手里面的技术文档都是零散的技术点。最近一直在着手把项目的技术开发文档 (Technical Document) 系统地整理一下。正好看到了非常棒的 GitBook 工具，又顺带研究了如何借助 Gitlab 的 CI/CD 功能实现自动部署。
正好开个简短的教程，介绍一下 GitBook + GitLab 怎样来撰写并发布文档。
第一部分先来介绍一下 GitBook。
系统环境
惯例列出来我们的环境以及用到的工具。

MacOS 10.12
Node.js (版本&gt; 4.0.0)
Atom/MWebLite

其实 Gitbook 有官方的编辑器，但是似乎对中文的支持不是很好，而且会有 bug，虽然最新版本做了优化，Mardown 格式的文字有些会自动显示成最终样式，而我个人还是比较喜欢原生的 markdown，所以我个人就没有用官方的编辑器。
如果读者注册了 gitbook，并且打算文章都发布到 gitbook 官网上的话，还是建议可以使用官方的编辑器。因为我的目标是发布到公司内网的 gitlab 上，所以这里就用 atom 或者 MWebLite 来编写文档。
其实这篇文章过后，大家对 Gitbook 的工作机制就很清楚了，完全可以自由地创作了。
基本使用
安装
安装过程非常简单
npm install gitbook-cli -g
新建 book
安装成功后，我们就可以开始用 gitbook 的命令来进行各种操作了。如果熟悉 hexo 的同学会发现，其实大同小异，只不过一个用来写 blog，一个用来写 book。
$ mkdir myBook
$ cd myBook
$ gitbook init
初始化后，我们能在 myBook 目录下看到两个 markdown 文 f 件。这两个文件就是我们写一本书唯二必须要用的文件了。

预览 book
先不做任何变动，模拟一下我们发布之后的页面的成品吧。
$ gitbook serve

我们打开浏览器，在浏览器中输入 0.0.0.0:4000 就可以在本地预览了。

可以看到，左侧是我们的菜单栏，自带一个搜索栏，右侧就是我们的 book 的内容了，右上角有默认的诸如 twitter,facebook 等分享快捷方式。基本上和其他人用 gitbook 写出来的页面是一样的。

注：

gitbook 新版本提供了本地预览功能的热更新，也就是说本地预览的页面会随着我们写书的内容变化而自动更新，这着实是一个很使用的功能。
在命令行 ctrl+c 可以关闭本地服务器，即预览页面。


我们可以尝试修改一下书的内容，看一下页面的变化。打开 README.md 文件，修改成如下内容：
# Introduction
 
Hello World!
再回头看一眼我们的预览页面，是不是自动变成了下面的样子。

关于 gitbook 自建的 README.md 文件我就不做过多的介绍了，都是一些 Markdown 的基本语法，相信使用 gitbook 的各位一定是对 markdown 语法非常熟悉的了。
目录
现在我们把注意力放到 gitbook 为我们创建的第二个文件 SUMMARY.md 上，这个文件决定了我们的目录结构。 一个比较简单的目录结构如下：
# Summary
 
* [前言](README.md)
* [第一章](xx.md)
* [第二章](xx.md)
* [第三章](xx.md)
xx.md 就是我们每个章节独立的 markdown 文件，所以用 gitbook 写一本书真的非常方便，一个目录文件，和若干个你的书的内容就好了。

目录分层
简单的目录有一个小的问题就是我们目录都只有一级，如果想要分层，比如第一章有 1，2，3 个小节，该怎么办呢？ 这里有两种方式：
标题区分
我们把 SUMMARY.md 文件修改成如下内容
# Summary
 
## 前言
* [前言](README.md)
 
## 第一章
* [1.1小节]()
* [1.2小节]()
 
## 第二章
* [2.1小节]()
* [2.2小节]()
 
## 第三章
* [3.1小节]()
* [3.2小节]()
最终的样式如下：

缩进区分
我们还可以用缩进的方式对目录进行级别的区分
# Summary
 
* [前言](README.md)
* [第一章]()
    * [1.1小节]()
    * [1.2小节]()
* [第二章]()
    * [2.1小节]()
    * [2.2小节]()
* [第三章]()
    * [3.1小节]()
    * [3.2小节]()
最终的样式如下：

大家可以根据自己的喜好选择不同的样式，也可以把这两者结合起来一起用，as you wish.
打包发布
通过预览模式，我们可以随时掌握书籍的更新内容。当你完成了部分章节或者全书的编写后，我们需要把写好的内容打包并发布。
$ gitbook build
执行完上面的命令后，我们会发现在根目录下出现了_build 文件夹，里面的文件就是我们需要发布的内容，你可以把所有的内容放到你的网站目录下，或者 gitlab/github 的 page 页面，就实现了 gitbook 的线上发布了～
进阶技巧
看完上面的章节，你已经可以独立完成一本书的编写和发布，接下来的章节，我们提供一些进阶的技巧，你可以安装一些插件、更直观地规划你的目录结构等等。
插件
和众多开源的软件一样，gitbook 也有一些插件，这些插件可以让你的书更加完美。这里我仅附上我个人觉得比较有用的几个插件，更多的插件，可以访问社区来获取。
插件的引入和修改都是在配置文件中完成的，那我们可以在根目录下创建 book.json 文件来修改当前书的一些配置，因为是 json 格式的，所以诸如书的标题、作者、内容等都可以在配置文件中完成，我们重点来说插件。
{
     "plugins": [
          "-lunr",
          "-search",
          "search-plus",
          "splitter",
          "copy-code-button",
          "expandable-chapters-small"
     ]
}
以上是我的 book.json 配置文件，只有一个关于插件的配置项，其实总共就 4 个

search-plus 让搜索支持中文，注意需要先把默认的两个插件 lunr 和 serach 禁用掉，禁用的方式就是在前面加上 - 号
 spliter 菜单栏宽度可调节
 copy-code-button 代码可以一键 copy
expandable-chapters-small 菜单栏可以折叠


注：
如果引入了新的插件，需要通过 gitbook install 命令来安装新的插件，否则在打包发布的时候会提示错误。

目录结构
一个基本的目录结构是这样的
.
├── _book/
├── book.json
├── README.md
├── SUMMARY.md
├── xx1.md
├── xx2.md
├── xx3.md
├── xx4.md
├── ...
不过为了我们自己方便，个人建议的目录结构如下
.
├── _book/
├── node_modules/
├── .gitlab-ci.yml
├── book.json
├── SUMMARY.md
├── content/
|   ├── chapter1/
|       ├── README.md
|       └── something.md
|   ├── chapter2/
|       ├── README.md
|       └── something.md
├── res/
|   ├── 1.png
|   └── 2.jpg
|   └── 3.jpeg
|   └── ...
说明：

_book 目录是我们打包后要发布的文件目录
node_modules 目录是我们安装插件后默认生成的目录
.gitlab-ci.yml 这个是 gitlab 要用的 ci 配置文件，下一章节我们马上就会用到
book.json 是我们的配置文件
content 目录是我们的书的内容，所有章节都可以分类继续整理，方便自己查看
res 目录是我们要用到的一些图片资源文件夹，除了用到床图，我们可以把其他本地图片资源也包含进来

参考 &amp; 致谢

Gitbook 简要介绍
GitBook 学习笔记

From: lipeng1667
系列教程
Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

]]></content>
      <categories>
        <category>gitbook</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>linux</tag>
        <tag>GitBook</tag>
      </tags>
  </entry>
  <entry>
    <title>Mariadb/Mysql 命令行常用命令</title>
    <url>/posts/f0b0af52/</url>
    <content><![CDATA[一、初始化等
1、登陆数据库方法
mysql -u用户名 -p用户密码
2、修改 root 及用户密码
use mysql;
update user set password=password('11111111') where user='root' and host='localhost';
flush privileges;
MariaDB [mysql]&gt; update user set password=password('11111111') where user='root' and host='localhost';
Query OK, 1 row affected (0.01 sec)
Rows matched: 1  Changed: 1  Warnings: 0
 
MariaDB [mysql]&gt; flush privileges;
Query OK, 0 rows affected (0.01 sec)
 
MariaDB [mysql]&gt; exit
3、创建用户
insert into mysql.user(host,user,password)values("localhost","test",password("password"));
flush privileges;
4、删除用户
DELETE FROM user WHERE User="test" and Host="localhost";
flush privileges;　　
5、删除用户的数据库
drop database test1;
6、交互模式初始化
mysql_secure_installation
二、 常用操作
1、显示数据库列表
show databases;: 查看所有的数据库
2、创建数据库
create database zxg;：创建名尾 zxg 的数据库
3、进入数据库
use zxg;: 进入 zxg 的数据库
4、显示库中的数据表
show tables;：查看数据库里有多少张表
5、创建数据表
create table t1 (id varchar(20),name varchar(20));: 创建名为 t1 表，并创建两两个字段，id、name，varchar 表示设置数据长度，用字符来定义长度单位，其
6、插入数据
insert into t1 values（"1"，"zxg"）;: 向表中插入数据
7、查看数据表
select * from t1; ：查看 t1 表数据内容
8、多条件查询
select * from t1 where id=1 and age = 'zxg ' ;: id、age 多个条件查询
9、查看字段内容
desc t1;: 查看 t1 表字段内容
10、修改字段长度
alter table t1 modify column name varchar(20);: 修改 name 字段的长度
11、修改该字段内容
update t1 set name='zxg.net' where id=1;：修改 name 字段的内容
12、权限刷新
flush privileges; : 刷新权限
13、清空表单
delete from t1;` : 清空表内容
14、删除数据表
`drop table t1: 删除表
15、删除数据库
drop database zxg;：删除 zxg 数据库
16、查看数据库字符集
show variables like '%char%';: 查看数据库字符集
17、查看存储引擎
show engines;: 查看 MySQL 存储引擎。
18、查看默认存储引擎
show variables like '%storage_engine%';: 查看 MySQL 默认的存储引擎
19、修改存储引擎
alter table t1 engine=innodb;: 修改 MySQL t1 表存储引擎
[root@web2 ~]# mysql
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 2
Server version: 5.5.60-MariaDB MariaDB Server
 
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
 
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
 
MariaDB [(none)]&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
4 rows in set (0.00 sec)
 
MariaDB [(none)]&gt;  create database zxg;                 
Query OK, 1 row affected (0.00 sec)
 
MariaDB [(none)]&gt; use zxg;
Database changed
MariaDB [zxg]&gt; show tables;
Empty set (0.00 sec)
 
MariaDB [zxg]&gt; create table t1(id varchar(20),name varchar(20));
Query OK, 0 rows affected (0.00 sec)
 
MariaDB [zxg]&gt; show tables;
+---------------+
| Tables_in_zxg |
+---------------+
| t1            |
+---------------+
1 row in set (0.00 sec)
 
MariaDB [zxg]&gt;
MariaDB [zxg]&gt; insert into t1 values ("1","zxg");
Query OK, 1 row affected (0.01 sec)
 
MariaDB [zxg]&gt; select *from t1;
+------+------+
| id | name |
+------+------+
| 1 | zxg |
+------+------+
1 row in set (0.00 sec)
 
MariaDB [zxg]&gt; select *from t1 where id=1;
+------+------+
| id | name |
+------+------+
| 1 | zxg |
+------+------+
1 row in set (0.00 sec)
 
MariaDB [zxg]&gt; select *from t1 where id=1 and name='zxg';
+------+------+
| id | name |
+------+------+
| 1 | zxg |
+------+------+
1 row in set (0.01 sec)
 
MariaDB [zxg]&gt; desc t1;
+-------+-------------+------+-----+---------+-------+
| Field | Type | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id | varchar(20) | YES | | NULL | |
| name | varchar(20) | YES | | NULL | |
+-------+-------------+------+-----+---------+-------+
2 rows in set (0.00 sec)
 
MariaDB [zxg]&gt; alter table t1 modify column name varchar(20);
Query OK, 0 rows affected (0.00 sec)
Records: 0 Duplicates: 0 Warnings: 0
 
MariaDB [zxg]&gt; update t1 set name='zxg.net' where id=1;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1 Changed: 1 Warnings: 0
MariaDB [zxg]&gt;
 
三、mysql 数据库字符集设置
mysql 数据库存储数据时，默认编码为 latinl，存储中文字符时，在调用时会显示为乱码，为了解决该乱码问题，需修改该 mysql 默认字符集为 UTE-8
装 mariadb 的是时候看已经默认为 ute-8
MariaDB [(none)]&gt; show variables like '%char%';
+--------------------------+----------------------------+
| Variable_name            | Value                      |
+--------------------------+----------------------------+
| character_set_client     | utf8                       |
| character_set_connection | utf8                       |
| character_set_database   | latin1                     |
| character_set_filesystem | binary                     |
| character_set_results    | utf8                       |
| character_set_server     | latin1                     |
| character_set_system     | utf8                       |
| character_sets_dir       | /usr/share/mysql/charsets/ |
+--------------------------+----------------------------+
8 rows in set (0.00 sec)
如不是，可以设置
SET character_set_client = utf8;
SET character_set_results = utf8;
SET character_set_connection = utf8;
四、mysql 数据库密码管理
设置密码访问，密码破解、密码权限、修改密码；
1、创建用户及授权
grant all on zxg.* to test@localhost identified by 'pas';
grant select,insert,update,delete on *.*to test@"%" identified by 'pas';
grant all on zxg.* to test@`192.168.216.53` identified by 'pas'
2、破解密码方法
停止服务 ---》跳过权限方式启动 ---》单开一个窗口登陆 ---》登陆修改密码即可
1）systemctl stop mariadb
2）mysqld_safe --skip-grant-tables &amp;
[root@web2 ~]# mysqld_safe --skip-grant-tables &amp;
[1] 47542
[root@web2 ~]# 190520 15:45:22 mysqld_safe Logging to '/var/log/mariadb/mariadb.log'.
190520 15:45:22 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql
[root@web2 ~]# mysql
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 1
Server version: 5.5.60-MariaDB MariaDB Server
 
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
 
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
 
MariaDB [(none)]&gt; use mysql;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A
 
Database changed
MariaDB [mysql]&gt; update user set password=password('11111111') where user='root' ;
Query OK, 3 rows affected (0.01 sec)
Rows matched: 4  Changed: 3  Warnings: 0
 
MariaDB [mysql]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)
 
MariaDB [mysql]&gt; exit
Bye
[root@web2 ~]#
然后退出” 跳过权限方式 “ ctrl+c ，正常启动 mysql 就可以了
五、mysql 配置文件详解
1、参数说明
[mysqld]                                                              #服务端配置
port        = 3306                                                    #监听端口
socket      = /tmp/mysql.sock                                         #通信设置
user    = mariadb                                                     #使用mariadb用户启动
basedir = /usr/local/mariadb                                          #安装路径
datadir = /data/mysql                                                 #数据目录
log_error = /data/mysql/mariadb.err                             　　　 #错误日志
pid-file = /data/mysql/mariadb.pid                             　　　　#pid进程文件
skip-external-locking                                                 #避免mysql的外部锁定，减少出错几率提高稳定性
key_buffer_size = 64M                                                 #缓存存储引擎参数，这个参数可以设置为64M
max_allowed_packet = 1M                                               #允许最大接收数据包的大小，防止服务器发送过大的数据包，可以设置为16MB或者更大，但设置太大也可能有危险
table_open_cache = 256                                                #mysql每打开一个表，都会读入一些数据到table_open_cache缓存中，当MYSQL在这个缓存中找不到相应的信息时，才会去磁盘读取，默认值64，假设系统有200个并发连接，则需将此参数设置为200*N（N为每个连接所需的文件描述符数目）；当设置为很大时，如果系统处理不了那么多文件描述符，那么就会出现客户端失效，连接不上
sort_buffer_size = 1M                                                 #在表进行order by和group by 排序操作时，由于排序的字段没有索引，会出现Using filesort，为了提高性能，可用此参数增加每个线程分配的缓存区大小，默认时256k，这个参数不要设置过大，一般128~256k，另外一般出现using filesort的时候，要通过增加索引来解决
net_buffer_length = 8K                                                #包消息缓冲区初始化net_buffer_length字节，但需要时可以增长到max_allowed_packet字节
read_buffer_size = 1M                                                 #该参数用于表的顺序扫描，表示每个线程分配的缓冲区大小，比如在进行全表扫描时，mysql会按照数据的存储顺序一次读取数据块，每次读取的数据块首先会暂存在read_buffer_size中，当buffer空间被写满或者全部数据读取结束后，在将buffer中的数据返回给上层调用者，以提高效率默认128k，也不要设置过大
read_rnd_buffer_size = 512K                                           #该参数用于表的随机读取，表示每个线程分配的缓冲区大小，比如，按照一个非索引字段做order by排序操作时，就会利用这个缓冲区来暂存读取的数据，默认时256k，也不要设置过大
myisam_sort_buffer_size = 16M                                         #当myisam表执行repair table或创建索引时，用以缓冲排序索引，设置太小可能会遇到"myisam_sort_buffer_size is to small"
thread_cache_size = 32                                                #线程池，线程缓冲。用来缓冲空闲的线程，以至于不被销毁，如果线程缓冲在的空闲线程，需要重新建立新连接，则会优先调用线程池中的缓冲，很快就能相应连接请求，每建立一个连接，都需要一个线程与之匹配。
query_cache_size = 32M                                                #缓存select语句和结果集大小的参数。查询缓存会存储一个select查询的文本与被传送到客户端的相应结果。如果之后接收到一个相同的查询，服务器会从查询缓存中检索结果，而不是再次分析和执行这个同样的查询。如果你的环境中写操作很少，读操作频繁，那么打开query_cache_type=1，会对性能有明显提升。如果写操作频繁，则应该关闭它（query_cache_type=0）。
tmp_table_size = 64M                                                  #临时HEAP数据表的最大长度(默认设置是32M); 超过这个长度的临时数据表将被转换为MyISAM数据表并存入一个临时文件。
                                                                      #
explicit_defaults_for_timestamp = true                     　　　　　　 #是否显示默认时间戳
#skip-networking                                                      #
max_connections = 500                                                 #该参数用来设置最大连接数，告诉你当前你的服务器允许多少并发连接。默认为100，一般设置为512-1000即可。请记住，太多的连接会导致内存的使用量过高并且会锁住你的 MySQL 服务器。一般小网站需要 100-200 的连接数，而较大可能需要 500-800 甚至更多。这里的值很大程度上取决于你 MySQL/MariaDB 的使用情况。
max_connect_errors = 100                                              #如果有时网络抽风，或者应用配置错误，或者其他原因导致客户端短时间内不断的尝试连接，客户端可能会被列入黑名单，然后将无法连接，直到再次刷新主机缓存。这个选项默认值太小了，可以考虑设的足够大（如果你的服务器配置够强大的话）。
open_files_limit = 65535                                              #mysql打开最大文件数
                                                                      #
log-bin=mysql-bin                                                     #这些路径相对于datadir
binlog_format=mixed                                                   #日志格式
server-id   = 1                                                       #给服务器分配一个独一无二的ID编号; n的取值范围是1~2的32次方启用二进制日志功能。在复制数据同步的时候会用到，Helloweba后面会有文章介绍。
expire_logs_days = 10                                                 #启用二进制日志后，保留日志的天数。服务器会自动清理指定天数前的日志文件，如果不设置则会导致服务器空间耗尽。一般设置为7～14天。
                                                                       #
default_storage_engine = InnoDB                                     　#新数据表的默认存储引擎(默认设置是MyISAM)。这项设置还可以通过–default-table-type选项来设置。
innodb_file_per_table = 1                                             #提供了更灵活的方式，它把每个数据库的信息保存在一个 .ibd 数据文件中。每个 .idb 文件代表它自己的表空间。通过这样的方式可以更快地完成类似 “TRUNCATE” 的数据库操作，当删除或截断一个数据库表时，你也可以回收未使用的空间。这样配置的另一个好处是你可以将某些数据库表放在一个单独的存储设备。这可以大大提升你磁盘的 I/O 负载。
innodb_data_home_dir = /data/mysql                             　　　　#InnoDB主目录，所有与InnoDB数据表有关的目录或文件路径都相对于这个路径。在默认的情况下，这个主目录就是MySQL的数据目录。
innodb_data_file_path = ibdata1:10M:autoextend     　　　　　　　　　　　#用来容纳InnoDB为数据表的表空间: 可能涉及一个以上的文件; 每一个表空间文件的最大长度都必须以字节(B)、兆字节(MB)或千兆字节(GB)为单位给出; 表空间文件的名字必须以分号隔开; 最后一个表空间文件还可以带一个autoextend属性和一个最大长度(max:n)。
innodb_log_group_home_dir = /data/mysql                     　　　　　　#用来存放InnoDB日志文件的目录路径(如ib_logfile0、ib_logfile1等)。在默认的情况下，InnoDB驱动程序将使用 MySQL数据目录作为自己保存日志文件的位置。
innodb_buffer_pool_size = 256M                                     　　#这个参数是InnoDB存储引擎的核心参数，默认为128KB，这个参数要设置为物理内存的60%～70%。
innodb_log_file_size = 64M                                            #事务日志文件写操作缓存区的最大长度(默认设置是1MB)。
innodb_log_buffer_size = 8M                                           #事务日志所使用的缓存区。InnoDB在写事务日志的时候，为了提高性能，先将信息写入Innodb Log Buffer中，当满足innodb_flush_log_trx_commit参数所设置的相应条件（或者日志缓冲区写满）时，再将日志写到文件（或者同步到磁盘）中。可以通过innodb_log_buffer_size参数设置其可以使用的最大内存空间。默认是8MB，一般为16～64MB即可。
innodb_flush_log_at_trx_commit = 1                             　　　　#这个选项决定着什么时候把日志信息写入日志文件以及什么时候把这些文件物理地写(术语称为”同步”)到硬盘上。设置值0的意思是每隔一秒写一次日 志并进行 同步，这可以减少硬盘写操作次数，但可能造成数据丢失; 设置值1(设置设置)的意思是在每执行完一条COMMIT命令就写一次日志并进行同步，这可以防止数据丢失，但硬盘写操作可能会很频繁; 设置值2是一般折衷的办法，即每执行完一条COMMIT命令写一次日志，每隔一秒进行一次同步。
innodb_lock_wait_timeout = 50                                         #如果某个事务在等待n秒(s)后还没有获得所需要的资源，就使用ROLLBACK命令放弃这个事务。这项设置对于发现和处理未能被InnoDB数据表驱动 程序识别出来的死锁条件有着重要的意义。这个选项的默认设置是50s。
                                                                      #
[mysqldump]                                                           #
quick                                                                 #
max_allowed_packet = 16M                                              #          
                                                                      #
[mysql]                                                               #
no-auto-rehash                                                        #
                                                                      #
[myisamchk]                                                           #
key_buffer_size = 64M                                                 #  
sort_buffer_size = 1M                                                 #  
read_buffer = 2M                                                      #
write_buffer = 2M                                                     #
                                                                      #
[mysqlhotcopy]                                                        #
interactive-timeout                                                   #
2、mysql 数据库索引案例（百万量级）
[client]
port    =3306                                  
socket    =/tmp/mysql.sock                     
 
 
 
[mysqld]                                                                             
port        = 3306                                                         
socket      = /tmp/mysql.sock                                   
user    = mysql  
server_id　　= 10
datadir　　= /data/mysql/
old_passwords　　= 1
lower_case_table_names　　= 1
character-set-server　　= utf8
default-storage-engine　　= MYISAM
log-bin　　= bin.log
log-error　　= error.log
pid-file　　= mysql.pid
long_query_time　　= 2
slow_query_time　　= 2
slow_query_log　
slow_query_log_file　　= slow.log
binlog_cache_size　　= 4MB
binlog_format　　= mixed
max_binlog_cache_size　　= 16MB
max_binlog_size　　= 1GB
expire_logs_days　　= 30
ft_min_word_len　　= 4
back_log　　= 512
max_allowed_packet　　= 64MB
max_connections　　= 4096
max_connect_errors　　= 100
join_buffer_size　　= 2MB
read_buffer_size　　= 2MB
read_rnd_buffer_size　　= 2MB
sort_buffer_size　　　　= 2MB
query_cache_size　　= 2MB
table_open_cache　　= 10000
thread_cache_size　　= 256
max_heap_table_size　　= 64MB
tmp_table_size　　= 64MB
thread_stack　　= 192KB
thread_concurrency　　= 24
local-infile　　= 0
skip-show-database
skip-name-resolve
skip-external-locking
connect_timeout　　= 600
interactive_timeout　　= 600
wait_timeout　　= 600
#MyISAM
key_buffer_size　　= 512MB
bulk_insert_buffer_size　　= 64MB
mysiam_sort_buffer_size　　= 64MB
mysiam_max_sort_file_size　　= 1GB
mysiam_repair_threads　　= 1
concurrent_insert　　= 2
myisam_recover
#INNODB
innodb_buffer_pool_size　　= 64G
innodb_additional_mem_pool_size　　= 32MB
innodb_data_file_path　　=　ibdata1:1G;ibdata2:1G:autoextend
innodb_read_io_threads　　= 8
innodb_write_io_threads 　　= 8
innodb_file_per_table　　= 1
innodb_flush_log_at_thx_commit　　= 2
innodb_lock_wait_timeout　　= 120
innodb_log_buffer_size　　= 8MB
innodb_log_file_size　　= 256MB
innodb_log_files_in_group　　= 3
innodb_max_dirty_pages_pct　　= 90
innodb_thread_concurrency　　= 16
innodb_open_files　　= 10000
#innodb_force_recovery　　= 4
#replication slave
read-only
#skip-salve-start
relay-log　　= relay.log
log-slave-updates
本文参考：
mariadb-mysql 配置文件 my-cnf 解读
MySQL 教程
《曝光：Linux 企业运维实战》
夜法之书 整理编辑 From: zhangxingeng
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Docker</tag>
        <tag>MySql</tag>
        <tag>Mariadb</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>Joplin 插件以及其 Markdown 语法。All in One!</title>
    <url>/posts/92d347d6/</url>
    <content><![CDATA[Joplin 是一个以 Markdown 为主要语法的笔记程序，发展到今天增加了许多插件，这些插件也大大增强了它的功能，今天我们就讲讲 Joplin 的各个插件的作用和使用方法。
首先我们打开 Joplin，依次点击工具 -&gt; 选项设置页面，然后点击 Markdown 选项卡，我们就可以看到如下界面

下面我们一个一个讲解一下每个插件的大概作用和用法，某些插件的详细使用方法可能需要我独立写一篇文章来介绍，这里我就先抛砖引玉大致介绍一下。
启动软中断插件
Joplin 默认使用的是硬中断方式，那么什么是软中断什么是硬中断呢？如果你刚开始使用 Markdown 撰写自己的笔记你可能会非常的不习惯，因为标准的 Markdown 语法里面换行需要两个回车符号，但是像 word 之类的编辑器都是一个回车，普通人会感觉很不习惯，所以 Joplin 默认采用了硬中断方式，这样你可以使用一个回车符实现换行。但是当我们启用软中断插件之后，我们就需要两个回车符来实现换行（准确说应该是分段），使用两个空格加一个回车来实现换行，前者的间距会比后者的大。启用软中断其实对于普通人来说不是很好用，很难适应，所以我不建议大家开启该插件！
启用 typographer 支持
这个插件的作用是用来申明我们的版权的，因为有时候我们可能需要将我们的笔记分享给别人，但是想要声明文章是我们写的，我们就可以启用该插件来声明我们的著作权，而且该插件会给我们渲染成指定的版权声明格式，讲讲怎么用：
我们启用插件之后，在我们想要声明著作权的地方键入：
(c)著作权所有人
然后 Joplin 就会给我们渲染为：

是不是很熟悉，很多网页的底部都会有这个声明！
启用数学表达式
这个是 Markdown 自带语法，Joplin 使用插件来实现的，其实就是大家在 Markdown 语法里面看到的行内公式使用，行间公式使用 $$…$$。需要说明的是 Joplin 使用的是 Katex 来解析数学符号，它的语法和 Latex 的数学公式写法差不多，我到现在还没有碰到很大的不同的地方！
启用高亮 ==Mark== 句法
这个其实就是一个语句高亮插件，中间的语句会被高亮显示，有助于我们对重要的内容进行强调，自己一试就一目了然了。

启用脚注
脚注的功能就是对文中的某一个特定的术语等进行解释补充说明，有点像是论文的参考文献，下面是一个简单的示例，相信大家一看就懂

根据图片你可能明白了脚注的使用方法：在我们想要使用脚注的地方使用 [^ 唯一标识符] 注明，然后在文章的最后使用响应的标识符进行说明即可，比如例子中的
[^lightzhan]:知乎搜索light zhan即可找到我了
注意那个冒号一定要是英文冒号，中文冒号可能无法被成功解析。
启用目录扩展
启用该扩展，我们就可以使用相应的语法在某个位置插入我们文章的目录，具体的语法为
[toc]
注意着是一个固定的符号，不需要改变什么，只需要在我们想要插入目录的地方放上 **[toc]** 即可，例如

上图最重要的就是坐上脚的 [toc] 指令，该指令自动生成了右边的整个目录！
启用下标 ~sub~ 和上标 ^sup^ 句法
一看到 sub 如果不小心就会认为这个是删除线，大错特错了，一定要明白两者的区别，删除线是左右都是两个波浪线，而这个只有一个波浪线，一定要搞清楚这个。下面我们看看这个插件的作用和用法。
这两个插件的作用其实很简单，就是下标和上标，看例子应该就明白的

启用术语表插件
对于这个插件得先知道什么是术语表。所谓的术语表其实可以理解为一个定义的列表，很多专业的书籍的前面都会有术语表，因为它需要给出书中所用术语的定义和解释。还不懂？我们在 Joplin 中启用该插件，然后新建一个笔记，输入如下文字：
Qdown

:   Qdown是由lightzhan开发的全功能软件下载程序，这里是程序的介绍页哦:http://lightzhan.xyz/index.php/qdown/ 

LightZhan

:   计算机爱好一名，爱折腾哎生活，*欢迎知乎关注lightzhan哦*

        可以嵌入一些代码

    定义第三段 
这些文字会被解析显示为：

对比一下发现了什么没有？术语表的每一项由两个部分组成，第一部分是术语，第二部分是该术语的解释，多个术语及其解释组合在一起就组成了表，这就是术语表！需要特别注意的是术语表的书写格式是固定的，如果你想要快速上手，建议你拷贝上面我提供的示例进行修改，修改两下你就懂格式到底是怎么回事了！
启用缩写句法
这个插件很有意思，也很有用。你是否记得有些程序的按钮，当你把鼠标放上去的时候它会显示按钮的作用。不记得了？不存在，我们也使用例子来说明。下面我们启用缩写句法插件，然后新建笔记，在笔记里面输入：
*[Qdown]: 由lightzhan开发
*[LightZhan]:  欢迎知乎关注我哦
Qdown 是由 LightZhan 开发的一款全协议下载器.
该文本会被 Joplin 显示为

这可能并不能完全显示出该插件的作用，因为截图的原因截不到，当我们把鼠标放在 Qdown 上面的时候，鼠标所在的位置处会弹出 “由 lightzhan” 开发的提示。不理解的可以拷贝上面的代码到 Joplin 感受一下，记得要开启该插件哦！需要注意的是该句中对应的缩写词前后都要有空格，负责你可能看不到上面的效果。
启用 Markdown emoji
该插件是用于在我们的笔记中插入表情的，这是一个简单的示例截图

详细的表情和表情的代码，可以参考这里。
启用 ++insert++ 句法
这个插件很好理解，一试便知道作用和用法了

说了那么多，就是在对应的文字下面显示一个下划线！
Markdown 是非常好用的笔记书写规范，记着，Markdown 不是某一个软件，而是一个通用的笔记书写规范，通过使用该规范进行写作，解析器会按照规定的样式将其渲染显示出来，说得直白点就是用于文字排版的。
Markdown 的排版语法
这里的讲解如果有不懂的可以参见下一节的示例：

标题。markdown 的标题使用 “#” 符号开头，一级标题一个”#”，二级标题两个 “#”（也就是 “##”），以此类推三级标题四级标题…….，不同级的标题会被渲染为不同的大小和样式（根据各个软件和相应的主题而定）；
粗体。markdown 的粗体字使用两个 “**” 包裹即可，比如 “你好” 解析后变为 “你好”；
斜体。markdown 的斜体使用 “*” 或者 “_” 包裹，比如 “你好” 解析显示为 “你好”；
引用。markdown 的引用使用 “&gt;” 开头，大部分软件要求 “&gt;” 要和引用内容之间有一个空格；
代码。对于程序员来说可能想要在文中插入代码，markdown 是支持插入代码的，行间代码使用一个 "`" 符号包裹，注意这个符号是键盘左上角 Esc 下面的那个键，不是我们所谓的英文上一撇；
数学公式。markdown 的数学解析一般使用 latex 语法，行内公式使用一个 $ 包裹即可，行间公式使用两个 $ 包裹；
markdown 的列表分为有序列表和无序列表。有序列表就是有序号，无序列表就是 无序号，有序列表就是在数字后面一个点，然后空一格写正文，比如：1. xxxxxxx，第二点需要新起一行 2. xxxxxx。无序列表是使用 “*” 或者 “-” 开始，后面跟一个空格写上正文。
markdown 的勾选框。markdown 的勾选框使用 - [ ]，注意字符之间都是有空格的。比如：第一行 - [ ] A, 第二行 - [ ] B。这样对应的渲染结果就是勾选框和对应的选项。注意字符之间的空格！
表格。markdown 的表格非常易于理解，请看下面的示例。

示例代码和渲染结果
下面的示例左边是书写文字，右边是渲染结果，注意书写文字里面的标识符和内容之间的空格：



需要说明的是上面的粗体显示为了橘红色的字体，这是我自己设置的格式，这个等大家熟悉了后可以使用 CSS 设计自己喜欢的样式。下面是表格的渲染结果 （其中左边的源代码不用那样对齐 ，横线的个数一处最少 3 个就行 ，右边是解析后的显示结果） ：

额～，左边左下角那个是鼠标光标，不是文字内容哈。需要说明的是不同的软件的不同的主题可能显示的结果会不一样，但是书写的语法是不变的。
启用 multimarkdown 表格扩展
这个插件说高深也不高深，看名字应该就能知道这是一个增强 Markdown 表格功能的插件，大家记得 Markdown 的表格是怎么使用的吗？如果忘记的话赶紧看看这篇文章回顾一下，不然下面的内容可能体会不会那么深！
好啦，我这里假设读者知道 markdown 的表格是怎么用的，然后我们开始讲解 multimarkdown 扩展。Markdown 自带的表格功能是非常有限的，如果你使用过的话就会发现它能做出来的表格一定是规整的，行和列一定是划分均匀整齐的，但是有时候我们需要的表格可能是这样的：

这种表格使用 Markdown 的表格是不可能做出来的，因为分组的效果和占用两个格子的效果是做不出来的，但是如果你启用了 MultiMarkdown 插件，你就可以使用下面的代码渲染出来：
|             |          分组                 ||
第一个表头     | 第二个表头     | 第三个表头      |
 ------------ | :-----------: | -----------:   |
内容          |          占用两个格子           ||
内容          |   **内容**     |         内容    |
新的一部分     |     更多       |         更多    |
更多          | 带有一个跳过的 '\|'              ||
[LightZhan制作]
你可以把上面的代码拷贝进 Joplin 编辑器研究一番就能理解 MultiMardown 表格扩展的用法了，下面我详细讲解一下。
MultiMarkdown 的表格扩展支持下面的功能：

使得元素占据多个列（上面的示例中有）
使得元素占据多个行
在表格上面或者下面对表头进行分组（上面的例子中有）
在表格的上面或者下面标注表格标题（上面的例子中有）
在表格中包含分块元素（列表、代码、段落等等）
表格不需要表头

上面标注了 “上面的例子中有” 的我这里就不在讲了，因为代码一研究或者修改修改就知道咋回事的，下面我们主要讲讲上面的例子中没有涉及到的。
1. 使得表格占据多行。这个其实很好用，但是有两种情况。第一种情况是一个项目占据两格。这种情况要占据多行的话，在我们对应列的起始行写上内容，然后接下来要合并的行直接写 “^^”。不明白不存在，我们来一个例子：

上面对应的代码是什么呢？看下面：
作者		| 信息			  | 信息		 |
----:		| --------------:         | ---------:	         |
LightZhan	| ligthzhan.xyz 				||
^^		| 更多Joplin教程           | Qdown下载器	         |
[LightZhan制作，允许规范转载]
把上面的代码拷贝进编辑器改改试试，很容易明白里面的玄机的！
第二种情况是我们添加块，看下面一点。
2.** 在表格中添加块元素。** 这个不用多说，直接在表格的格子里面用 Markdown 语法写作，渲染成对应的 Markdown 格式！比如加粗、斜体、代码块等等。下面来一个简单的例子，需要注意的是下面的例子当中我们的内容有几行！
|   Markdown   | 渲染结果       |
|--------------|---------------|
|    *斜体*    | *斜体*         | \
|              |               |
|    - 项目1   | - 项目1        | \
|    - 项目2   | - 项目2        |
|    ```python | ```python       \
|    .1 + .2   | .1 + .2         \
|    ```       | ```           |
[LightZhan制作，允许规范转载]
注意代码后面的”\”，这个符号是指定换行的，如果项目占据多行一定要写上。上面的代码复制黏贴进编辑器可以看到下面的渲染结果

**3. 表格不需要表头。** 这个也很简单，直接不写表头即可。拷贝下面的代码进编辑器
----:		| --------------: | ---------:	 |
LightZhan	| lightzhan.xyz 	        ||
^^		| 更多Joplin教程  | Qdown下载器	 |
[LightZhan制作，允许规范转载]
然后你就可以看到惊喜

启用 Fountain 语法支持
这个插件的目标人群非常少，Fountain 语法是用来写电影剧本的，而且要是要细讲的话估计又是一篇文章，因为使用的人非常少，所以我这里就不讲这个了。
Mermaid 插件的作用
Mermaid 是一个用于画流程图、时序图、类图、状态图、甘特图、饼图的 Markdown 扩展，其中状态图是最新 8.4 版本的新功能。如果你不知道这些图是干什么的，不存在，下面的教程里面我会每个都给出例子。
在 Joplin 里面使用 Mermaid
在 Joplin 里面如果想要使用 Mermaid，那么你需要使用代码块，并且代码的类型填写 mermaid，详细的格式如下：
```mermaid
graph TD
    Start --&gt; Stop
```
在渲染区我们就能得到如下的结果

Mermaid 流程图
下面我们讲解在 Mermaid 里面画流程图。上一节的示例便是流程图，我们把上一节的代码拿出来分析一下。首先我们看代码的第一行：graph TD，这一行代码有两个作用，graph 表示我们图的类型，graph 表示流程图，而第二个 TD 表示图的方向，可能的方向有如下几个

TB：自顶向下
 BT：自底向上
 RL：从右到左
 LR：从左到右
 TD：和 TB 一样

上面我们的例子使用的是 TD，如果你对其它的方向不明白，可以把代码拷贝到编辑器里面修改方向参数就可以理解各个方向的意义了。
上面的代码非常基础，因为如果要实现比较复杂的流程图，我们就需要使用一些比较高级的语法，比如定义节点。所谓的节点，你可以简单的理解为上面图片中的方框，但是如果我们要使用其它形状的节点怎么办呢？在上面的例子中我使用了默认的节点定义方法，也就是直接使用文本，这种方式定义节点的话 id 和显示文本是一样的，而且形状是固定的矩形。如果要定义不同的节点形状，或者使得 id 和显示文本不一样，可以使用下面的语法

定义矩形形状的节点：id [text]
 定义圆角矩形的节点：id (text)
 定义椭圆形的节点：id ([text])
 定义圆柱形的节点：id [(text)]
 定义圆形的节点：id ((text))
 定义非对称图形的节点：id&gt;text]
 定义菱形的节点：id {text}
 定义六角形的节点：id
 定义平行四边形的节点 (两个方向)：id [/text/] 或者 [\text]
 定义梯形的节点 (两个方向)：id [/text] 或者 di [\text/]

注意上面的 id 和 text 是需要我们自己定义替换的，如果同一个 id 有多个 text，取最后一次的定义值！
有了节点我们还需要将节点连接起来，也就是我们要使用线条或者箭头来进行节点的连接，Mermaid 支持下面的方式：

实线箭头：A–&gt;B
 实线无箭头：A–B
 无箭头实线上带文本：A–text–B
 实线箭头带文本：A–&gt;|text|B 或者 A–text–&gt;B
 虚线箭头：A-.-&gt;B
 虚线箭头带文本：A-.text.-&gt;B
 粗线箭头：A==&gt;B
 粗线箭头带箭头：Atext&gt;B

最好的办法就是把上面的代码拷贝进编辑器看看，一看你应该就能理解各个图形的形状！
上面我们讲解了节点和连线，下面我们说说图形的绘制。上面我使用的例子非常基础，下面来一个复杂点的例子供大家修改和研究
```mermaid
graph TD
    light[LightZhan]
    url[lightzhan.xyz]
    QdownUrl[访问LightZhan博客Qdown页面]
    Qdown((Qdown))
    function[功能]
    Qdown--&gt;|作者|light 
    light--个人主页--&gt;url
    Qdown--&gt;function
    Qdown--&gt;QdownUrl
    function1[极速下载]
    function2[磁链/BT下载]
    function3[迅雷下载]
    function5[下载体验]
    function4[Http/Https/FTP/SFTP]
    function-.功能1.-&gt;function1
    function-.功能2.-&gt;function2
    function-.功能3.-&gt;function3
    function-.功能4.-&gt;function4
    function-.更多功能.-&gt;function5
    annocement[本文首发于lightzhan.xyz,允许规范转载]

```
上面代码的渲染结果如下：

如果不清楚，可以把上面的代码拷贝到编辑器进行修改和摸索！
Mermaid 时序图
时序图是用于展示过程的方式和顺序的。举例来说，两个人之间的对话:
A 先问 B：Qdown 是啥？B 回答：Qdown 是全功能的下载软件！A 又问：哪里可以下载呀？B 回答： http://lightzhan.xyz/index.php/qdown/ 。我们使用 mermaid 绘制时序图来展示上面的对话过程：

这样是不是看上去清晰了很多了呢？希望通过这个例子能让你深切地感受到时序图是干什么用的！好了，放上上面的时序图的代码供大家研究：
```mermaid
sequenceDiagram
A-&gt;&gt;B:Qdown是啥？
B--&gt;&gt;A:Qdown是全功能的下载软件！
A-&gt;&gt;B:哪里可以下载呀？
B--&gt;&gt;A:http://lightzhan.xyz/index.php/qdown/
```
让我们来简单分析一下上面的代码。你可能注意到了第一行的 sequenceDiagram，这个就是告诉 mermaid 我们在这里绘制时序图，然后下面有箭头，在时序图里面，mermaid 支持下面类型的箭头和线段：

实线并且没有箭头：A-&gt;B:text
 虚线没有箭头：A–&gt;B:text
 实线带箭头：A-&gt;&gt;B:text
 虚线带箭头：A–&gt;&gt;B:text
 实线并且在终点带一个 x：A-xB:text
 虚线并且在终点带一个 x：A–xB:text

上面的 text 就是要显示在箭头或线段上的文本，在 mermaid 的时序图里面被称为消息，线段或箭头类型如果有不清楚的可以拷贝到编辑器里面看看，一目了然！
还记得上面我们在流程图里面的节点吗？在时序图里面不是定义节点，而是定义参与者，也就是上面的 A 和 B。上面的代码中我们定义参与者的方式采用的是默认方式，也就是不显示定义，有时候我们的参与者的名字太长的话可以使用显示定义来定义别名：
participant John
participant Alice
participant A as Alice
participant J as John
上面代码的第一二行仅仅是显式定义我们的参与者，第三四行给我们的参与者定义别名，定义了别名后我们在下面的使用中就可以直接使用 A 代替 Alice，使用 J 代替 John 了，这样输入会方便很多！
好了，时序图差不多就讲到这里，接下来的一些高级用法大部分我们都用不到，或者要使用的话不如使用专业的绘图软件使用插图的方式导入。
使用 Mermaid 绘制类图
类的定义
在讲解如何绘制类图之前我们先了解一下什么是类图！如果你是计算机专业或者会计算机编程的话应该就懂面向对象编程，对象是类的实例，而这里要绘制的类图就和面向对象编程里面的类相关。
对于编程人员来说，函数具有参数和返回值，属性具有变量类型，我们举一个例子来说一下：
class BankAccount{
  +String owner
  +BigDecimal balance
  +deposit(amount) bool
  +withdrawl(amount)
}
上面的代码的渲染结果为：

上面的代码是我直接从官方借鉴的，可以直观地看出对于银行账户（BankAccount），一共有两个属性和两个方法，属性都是具有对应的变量类型，而对于函数具有参数（amount），并且 deposit 函数还具有 bool 类型的返回值。你或许看到了前面的 + 号，这个是对应变量或属性的可见性，分别有：

+ public
– private
# protected
~ Package/Internal

如果我们想要定义的函数是抽象函数咋办呢？在括号的后面添加 * 即可：
someAbstractMethod()*
在渲染过后抽象函数会使用斜体进行显示，这里就不截图展示了。对于静态函数，将后面的 * 换为 $ 即可，在显示时静态函数会具有下划线。
类之间的关系
在编程中我们常常会用到的关系：



&lt;|–
继承（Inheritance）




*–
组成（Composition）


o–
聚集（Aggregation）


–&gt;
 关联（Association）


—
 实线（Link (Solid)）


…&gt;
 依赖（Dependency）


…|&gt;
 实现（Realization）


…
 虚线（Link (Dashed)）



下面我们举一个例子：“狗” 继承自 “动物” 类别
```mermaid
classDiagram
    class 动物{
        特点1：能动
        特点2：能叫
    }
    class 狗{
        特点1：4条腿
        特点2：会汪汪叫
        特点3：可爱至极
        汪汪叫(陌生人)
    }
    动物 &lt;|-- 狗
```
渲染结果为：

结合代码和展示结果应该很好理解，这就是一个狗继承自动物的简单例子，我们还可以对关系结果打标签：
```mermaid
classDiagram
    class 动物{
        特点1：能动
        特点2：能叫
    }
    class 狗{
        特点1：4条腿
        特点2：会汪汪叫
        特点3：可爱至极
        汪汪叫(陌生人)
    }
    动物 &lt;|-- 狗:属于（继承）
```
我们在关系指示后面加上冒号，然后后面加上关系说明，这样在渲染结果当中我们就可以看到箭头上出现了我们需要的标签说明：

好了，使用 mermaid 绘制类图就讲到这里，还有一些用法不是很常用，我就不讲了。
使用 mermaid 绘制饼图
绘制饼图的需求比较多，很多数据展示需要我们绘制饼图，幸运的是 mermaid 给我们提供了绘制饼图的功能，使用方法极其简单：
```mermaid
pie
    title LightZhan创作，允许规范转载（http://lightzhan.xyz）
    "Joplin" : 42.96
    "Qdown" : 50.05
    " 黑科技" : 10.01
    "其它" :  5

```
在上面的代码中，pie 关键字指定我们要绘制饼图，然后 tiltile 指定我们的标题，后面是数据分布，注意，mermaid 会将我们输入的数据进行计算，上面的数据加起来并不是 100，所以我们看到在下面的渲染结果中数据对应不上。

Joplin 插件非常丰富，你能找到各种各样的功能，这里推荐一些插件使用，见下面这篇文章， Joplin 插件推荐。
参考：

lightzhan.xyz

系列教程
笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

hexo 系列

hexo 独立博客搭建 [三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优化



 docker 环境
 hexo 使用入门
 hexo 基础配置
自定义修改
 hexo 部署
个性定义
性能优化
常见问题 



Hexo Markdown 以及各种插件功能测试



 markdown 各种其它语法插件
 latex 公式支持
 mermaid 图表
 plant uml 图表
 URL 卡片
 bilibili 卡片
 github 卡片
豆瓣卡片
插入音乐和视频
插入脑图


]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>note</tag>
        <tag>Joplin</tag>
        <tag>MarkDown</tag>
        <tag>Mermaid</tag>
      </tags>
  </entry>
  <entry>
    <title>为知笔记私有化 Docker 部署</title>
    <url>/posts/1802a8a7/</url>
    <content><![CDATA[登陆 NAS，打开套件中心，搜索 docker，并安装。
搜索 wiznote，找到 wiznote/wizserver，双击下载

在 NAS 中创建共享目录，用于存放笔记数据


启动 File Station


在 docker 目录下创建文件夹：
wiz


在 wiz 文件夹下创建文件夹：data



双击创建容器，启用资源限制，设置为内存限制 4096MB，官方介绍说需要 4G 内存



高级设置，启动自动重新启动


卷设置，使用刚才我们创建的 data 目录进行配置，装载路径 /wiz/storage，docker/wiz/config 装载路径 /wiz/app/wizserver/config



网络设置不动，端口设置添加映射：8888 映射 80 端口（8888 可以随便设置，跟访问地址有关）





设置环境变量

SEARCH=true TZ=Asia/Shanghai


直接应用，启动 docker，然后就静静的等待吧，可以看看镜像的日志，看到这些基本上就差不多启动好了（最新的镜像在 NAS 上首次启动非常慢，本人等了一个多小时才完全启动完毕，在本地安装速度非常快）


通过 http://NAS的IP:8888，进行访问，就可以看到已经启动完成




默认管理员账号：admin@wiz.cn，密码：123456
管理后台登陆地址：http://IP 地址：端口 /wapp/pages/admin

NAS 开启 SSH
首先在 NAS 上启动 SSH
登陆 NAS，打开控制面板-终端机和SNMP，在启动SSH功能前打上勾
打开命令行，输入
ssh NAS管理员账号@NAS的IP地址 ssh端口号默认是22
看到提示符，输入账号的密码，输入时不可见，输入完成按回车，看到命令行提示符变了，登陆成功。
进入容器
在命令行中输入
sudo docker ps
可能提示输入密码，就输入 NAS 管理员的密码即可，显示列表，查看到如下列表，找到其中运行了为知笔记的一行

复制为知笔记的 CONTAINER ID，然后再输入如下命令并回车：
sudo docker exec -it 粘贴刚复制好的ID号 /bin/bash
至此进入到容器中
修改配置文件
输入如下命令打开配置文件进行编辑：
vi /wiz/app/wizserver/config/default.json
vi 命令的具体使用方法请自行百度，保存好后退出，重启容器生效。
进入 docker，修改文件 /wiz/wizserver/app/config/default.json
"as": {
     "admin": ["admin@wiz.cn"],
     "share": {
       "admin": ["admin@wiz.cn"],
       "enableHttps": false,
       "enableSubDomain": false,
       "appShareUrl": "127.0.0.1:5001"
     },
其中 127.0.0.1:5001 修改为自己的服务器访问地址，可以给 docker 做个端口映射（因为群晖 NAS 占用了 5001 端口），譬如映射 8889 端口到容器的 5001 端口，则设置为 xxx.xxx.xxx.xxx:8889，分享后的链接即为该链接。
在 NAS 上可以用反向代理来解决二级域名的问题。
分享功能需要用户绑定手机，并完成认证，在 docker 中登陆数据库，并修改数据
mysql -u root -p
输入密码，密码在 docker 中 /wiz/wizserver/app/config/default.json 中查看
"mysql": {
  "as": {
   "host": "127.0.0.1",
   "user": "root",
   "password": "******************",
   "database": "wizasent",
   "connectionLimit": 50,
   "connectTimeout": 60000,
   "aquireTimeout": 60000,
   "waitForConnections": true
  },
其中 password 就是密码，进入 mysql 控制台后，执行以下命令：
use wizasent;
update wiz_user set MOBILE='你的手机号', MOBILE_VERIFY='1' where ID='1';
web 端登陆为知笔记，并修改默认账号后，修改后的账号无法登陆管理后台，需要做以下配置，修改文件 /wiz/wizserver/app/config/default.json，找到以下代码：
"as": {
  "admin": ["admin@wiz.cn"],
  "share": {
    "admin": ["admin@wiz.cn"],
    "enableHttps": false,
    "enableSubDomain": false,
    "appShareUrl": "127.0.0.1:5001"
  },
其中 admin@wiz.cn 修改为修改后的账号。
登陆 NAS，打开控制面板-应用程序门户-反向代理
点击新增，然后输入如下：

实际测试来源协议选择 https 时只有网页端可以登陆，客户端无法登陆，暂时还是选择 http 为好，也可以网页端通过 https 登陆，客户端通过 http 登陆，配置两个不同的端口（记得要在路由上配置端口映射）。
修改 default.json
{
  "debug": true,
  "enableHttps": true,
  "storage": {
     "__comments": "oss|local|s3|cos",
     "use": "local",
     "oss": {
       "bucket": "data_root",
       "region": "test",
       "accessKeyId": "test",
       "accessKeySecret": "test",
       "internal": false
     },
其中 enableHttps 配置成 true
重启服务
cd /wiz/app/wizserver
pm2 restart all
删除 /wiz/storage/index/.search 文件和 /wiz/storage/index/nodes 目录
重启容器
链接数据库，执行下列 SQL
update wizksent.wiz_kb_stat set index_new_status=4
进入容器，执行
cd /wiz/app/wizserver
pm2 start app.js --name="index2"  -f -- -c 1 -i 1 -t 2 -s index
pm2 start app.js --name="index2"  -f --  -s copy
查看日志
pm2 logs index2
下载官方插件，并安装到 Chrome 中
http://www.wiz.cn/downloads-webclipperchrome.html
在浏览器中输入 chrome://extensions/ 打开插件列表，开启开发者模式

看 ID 号，在浏览器中输入 chrome://inspect/#extensions 在打开的列表中找到 WizClipper，点击 inspect，开启调试窗口。
选择 Sources 标签，并打开文件 Scripts\wiz\WizConstant.js
在代码中查看 note.wiz.cn 和 api.wiz.cn 的网址全部替换成自己私有云的地址，实测，登陆没问题，保存失败。

管理功能


增加重建索引功能，以备不时之需


增加备份与恢复功能


增加 markdown 语法扩展：
flow（流程图）、sequence（时序图）、mermaid（流程图、时序图、甘特图）、LaTeX（公式）


增加手动配置分享链接


支持社交绑定的配置


支持对象存储或 webdav 存储


Web&amp;Mac 客户端


增加自定义模板


增加偏好设置，自定义快捷键（主要是编辑和预览切换的快捷键非常不适应）


增加同步预览模式，可以参考下 Typora，Bear 都不错


增加 https 访问方式


支持导出 jpg、png、docx 格式


浏览器插件

增加支持私有云登陆

【部署环境】
群晖 DS1517+（DSM6.2.2）
容器分配内存 4G，CPU*2 核
【出现的问题】


网页版上提示，自动保存失败，网络错误，请尽快保存（最后发现是时区不通道导致的，第 8 点解决了此问题）


所有社交平台账号无法绑定


mywiz 邮箱不可修改


绑定手机无法收到验证码，即无法绑定手机（通过修改数据库搞定）


存储设置功能多余（因为已经本地化部署了），改成数据备份 / 恢复就好了


支付信息是支付到为知去的，这个功能容易产生误解（如果多人使用的话）


docker 容器的时区与宿主机时区不同，添加环境变量解决，TZ=Asia/Shanghai


编辑整理 From： 大大木头 [为知社区]
系列教程
笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

hexo 系列

hexo 独立博客搭建 [三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优化



 docker 环境
 hexo 使用入门
 hexo 基础配置
自定义修改
 hexo 部署
个性定义
性能优化
常见问题 



Hexo Markdown 以及各种插件功能测试



 markdown 各种其它语法插件
 latex 公式支持
 mermaid 图表
 plant uml 图表
 URL 卡片
 bilibili 卡片
 github 卡片
豆瓣卡片
插入音乐和视频
插入脑图


]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>note</tag>
        <tag>wiz</tag>
        <tag>Docker</tag>
        <tag>linux</tag>
        <tag>Nas</tag>
        <tag>群晖</tag>
      </tags>
  </entry>
  <entry>
    <title>Joplin 入门指南 &amp; 实践方案</title>
    <url>/posts/e6086437/</url>
    <content><![CDATA[Evernote 笔记是我们常用的一个笔记服务，国内叫印象笔记，免费版本的 Evernote 笔记其实已经足够我们使用了，但是对于重度的笔记用户，Evernote 某些功能可能需要付费升级才可以使用，而且你的笔记是存放在 Evernote 的服务器上。
有些同学可能觉得放在 Evernote 服务器上的笔记会不安全，况且有些隐私性很强的笔记确实不适合放在公共的服务器上。此时，你需要一个可以保护个人隐私同时还可以与 Evernote 笔记功能相媲美的免费笔记服务：Joplin，它是一款免费开源的笔记软件。
Joplin 跨平台支持，包括 PC 桌面端，移动端，甚至提供了命令行版本，原生支持 markdown 格式，搜索速度快，可以通过其他第三方同步工具 (Dropbox/NextCloud/OneDrive/WebDAV/etc) 进行备份以及同步 ，支持浏览器 Web clipper 即网页剪贴。

Evernote 笔记该有的功能 Joplin 都有了，如果你不想掏钱购买 Evernote 付费版本，Joplin 将是最佳的替代品。更多的自建服务还有：

Chevereto 免费相册程序安装与使用 - 免费自建图床和公共图片相册
自建 RSS 阅读器 Tiny Tiny RSS 安装和配置自动更新，全文 RSS, 更换主题，手机 RSS 登录
放弃付费 1Password 改用免费开源的 bitwarden_rs 自建密码管理系统 - 安装，使用和备份

PS：更新记录

1、平时经常要校对文本，以及有大量的文件需要在电脑和移动硬盘同步，可以试试这些免费的同步对比工具：八大免费的文件对比同步工具 - 免费文件对比分析与复制同步备份软件。2021.3.24
2、对于 1Password 这类的密码管理软件重度依赖，但是苦于囊中羞涩的话，不防自建密码管理平台：Bitwarden 自建密码存储系统图文教程 - 开源免费的 bitwarden_rs 安装与使用。2020.10.10

一、Joplin 安装和使用
网站：

https://joplinapp.org/

直接到官网下载 Joplin 安装包，安装好了就可以启动 Joplin 了，以下是 Joplin 的软件界面，分成三栏，和我们平时熟悉的笔记软件是一样的。（点击放大）

这是 Joplin 的编辑器，支持 MarkDown，图片、数学公式、复选框等 MarkDown 语法。

不习惯 MarkDown，直接切换为可视编辑即可。

在 Joplin 的设置选项中还提供了非常多的 MarkDown 的插件，对于 MarkDown 深度用户来是一个福音。

二、Joplin 的特色功能
2.1 笔记历史版本
Joplin 提供了笔记历史版本，让你轻松地恢复任意时间的笔记版本。在 “工具” &gt; “选项” &gt; “笔记历史” 中启用，以及设置保留的笔记历史天数。要查看笔记的历史版本，点击编辑器上方的笔记属性图标，然后选择恢复：

2.2 E2EE 安全加密
在同步过程中，笔记本、笔记、标签等均以纯文本文件的方式同步，如果你还觉得不安全，你可以开启端到端加密（E2EE），把文件加密后同步到云端。由于 Joplin 的去中心化，密码必须手动在每个终端设置。

** 注意：不要在多个设备上同时启用加密，否则可能会造成加密密钥问题。特别提醒：** 加密之前，先将笔记导出 JEX 备份一份，以防万一。
2.3 Joplin 手机 APP
Joplin 可以直接在各大应用市场上下载，使用起来也很方便。

2.4 外部编辑器
Joplin 自带的编辑已经非常强大的，如果你想要使用自己的编辑器来编辑笔记也是可以的，包括 文本编辑器（如 Notepad++）、 Markdown 编辑器（如 Typora）等。

通过 Ctrl+E，或 Joplin 编辑器上方的图标（如下图）从外部编辑器打开笔记，从外部编辑器打开后，Joplin 将持续监控该文件，当你从外部编辑机保存后，Joplin 将自动同步最新变动。

你可以在 “工具” &gt; “选项” &gt; “通用选项” 中指定编辑器的路径。
三、Joplin 同步与备份
Joplin 与其它的笔记软件很大的不同就是没有存储功能，你需要将 Joplin 的笔记放在自己的主机或者网盘里，幸运的是 Joplin 支持多种方式的云同步：Nextcloud / Dropbox / OneDrive / File system / WebDAV。
3.1 Joplin 免费网盘同步
目前，Joplin 支持 Dropbox 、OneDrive 网盘同步，在同步选项中选择 OneDrive，然后就会打开认证。

同意验证。

与 OneDrive 同步时，Joplin 会在 OneDrive 中创建一个子目录：/Apps/Joplin，Joplin 仅有此目录的读写权限。如下图：

3.2 Joplin 使用 WebDAV 同步
WebDAV 可以自建，或使用支持 WebDAV 的云盘，另外 NAS（如群晖）通常也支持 WebDAV。

**Nextcloud：**Nextcloud 是一个开源的免费的自建个人云存储方案，要启用 Nextcloud 同步，你需要在 Nextcloud 中创建一个目录（比如：Joplin），在左下角的 “设置” 中获取 WebDAV 的 URL，在 Joplin 同步设置中，填入 WebDAV URL、用户名和密码。

有关于 Nextcloud 安装与使用教程，请参考：Oneinstack 安装 NextCloud 以及使用 Aria2 离线下载和 ocDownloader 插件配置。
** 坚果云：** 首次同步时会因为 WebDAV 短时间内的大量请求被坚果云临时限制，坚果云提示为 “Too many requests”，这个封锁会持续大约 6 小时。同步之前，在 Joplin 的 “工具” &gt; “选项” &gt; “同步” &gt; “高级选项” 中，将 “最大并发连接数” 改为 1 可以有效避免。

关于坚果云的使用方法，请参考：巧用又拍云 FTP 和坚果云 WebDAV - 打造个人文件备份和数据云存储。
四、Joplin 导入与导出
Joplin 可以很方便地支持从 Evernote（印象笔记）导入，方法如下：
从 Evernote（印象笔记）导入：

打开 Evernote，右击要导出的笔记本，选择 “导出笔记 “，导出 .enex 格式文件。
在 Joplin 中，选择 “文件” &gt; “导入” &gt; “ENEX – Evernote 导出文件（Markdown）” 即可导入。

从 Markdown 文件导入：

使用 Joplin 可以轻松导入 Markdown 文件或整个目录，选择 “文件” &gt; “导入” &gt; “MD – Markdown（文件 / 目录）” 导入即可。

从其他应用程序导入：

通常，很多应用程序都支持导入到 Evernote 中，所以从其他应用程序导入的思路是先导入 Evernote，再导出 .enex 文件，最后导入 Joplin 中。

如下图：

如果哪天你不想使用 Joplin 了，也可以很方便地导出。Joplin 支持多种导出格式，导出格式均为标准格式，可以在不依赖 Joplin 的情况下查看、编辑，部分格式支持无损 / 有损重新导入：

JEX：Joplin 的无损导出格式，包含所有的元数据如标签、更新时间等。JEX 是实际上是一个 tar 文件，可以直接解压出 MarkDown 文件。这种格式常用于备份，可以无损重新导入。
RAW：同 JEX 格式相似，只是数据会保存为目录，并且每个笔记都会导出为一个单独的文件。可以无损重新导入。
JSON：导出为 JSON 格式的文件。不支持重新导入。
MD：按照笔记本的分级结构导出为目录，每条笔记在对应的目录中导出为 Markdown 格式的文件，目录名和文件名与原笔记本对应，此种格式易于读取，但是导出的文件将丢失元数据。可以有损导入（丢失元数据）。
HTML：导出为网页文件，将 Markdown 格式转为 html 标签，带有样式。不支持导入。
PDF：将单个笔记导出为 PDF 格式的文件。不支持导入。

如下图：

五、总结
免费开源的笔记 Joplin 无论在功能上还是使用体验上基本上与 Evernote 印象笔记无异了，在隐私保护方面做得非常好，特别适合那些想要保存个人信息笔记的用户。
使用免费开源的笔记 Joplin 最大的问题就是找好同步的网盘或者云存储，另外强烈建议大家在对 Joplin 的设置进行调整时先备份一个，以免同步后删除了所有的笔记。
编辑整理 From：挖站否
系列教程
笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

hexo 系列

hexo 独立博客搭建 [三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优化



 docker 环境
 hexo 使用入门
 hexo 基础配置
自定义修改
 hexo 部署
个性定义
性能优化
常见问题 



Hexo Markdown 以及各种插件功能测试



 markdown 各种其它语法插件
 latex 公式支持
 mermaid 图表
 plant uml 图表
 URL 卡片
 bilibili 卡片
 github 卡片
豆瓣卡片
插入音乐和视频
插入脑图


]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>note</tag>
        <tag>Joplin</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Joplin 插件使用推荐</title>
    <url>/posts/e3ee7f8b/</url>
    <content><![CDATA[Joplin 插件推荐

Gif 图片加载较慢，请耐心等待！

persistent-text-folding-in-editor


Ctrl(or Cmd) + Alt + F to fold all
Ctrl(or Cmd) + Alt + U to unfold all

Plugin: Conflict Resolution

Joplin Kanban Plugin

Usage
To get started, you'll need a notebook which will contain all tasks that you want to see on the board. The plugin will only show tasks in a single notebook and it's sub-notebooks.
A kanban board is defined by a special type of note, which contains all of its configuration. Create a new note, and paste in the following:
```kanban
columns:
  - name: Backlog
    backlog: true
  - name: Work in progress
    tag: wip
  - name: Finished
    tag: done
```
It is important that the confiuration is surrounded by a code block (kanban ... ), otherwise it won't be detected.
joplin_plugin_nlr

 插件安装后会在工具菜单添加一项：NLR



 点击 NLR 打开新的 panel，即可在输入框输入书名或作者名称搜索小说



点击卡片右上方 INFO 打开新的小说目录，章节卡片右上 checkbox 选中即代表下载此 chapter，选中后，点击上方 DOWNLOAD 开始下载，在笔记列表中即可看到小说文本了。


joplin-outline

joplin-persistent-layout
Save editor layout (editor/split view/viewer/rich text) for each note separately.
To persist the layout for a note follow these steps:


Specify the tags for which a specific layout should be used.


To do this, go to the plugin's settings/options page and add the tags to the settings.


An example configuration could like this:





Make sure that the correct value is selected in View &gt; Layout button sequence.

To be able to use the layout switching correctly, this setting must be set accordingly. Otherwise the editor layout might not be switched to the expected one.
For example: If a tag is specified in option Tags for editor layout mode: Rendered Markdown viewer and least one note uses it, the setting must also contain Viewer.



Add the appropriate tags to the notes. If not already done.

When the selected note is changed, the editor layout is switched.
If none of the selected note's tags matches a specified layout tag, the default layout from the option Default editor layout is used.

If nothing is selected as default editor layout, the currently active editor layout will be kept.


If more than one tag is specified for a note, the first matching one is used.



Plugin: inline tags

joplin-plugin-note-overview

Create one or more notes with the following content:
&lt;!-- note-overview-plugin
search: -tag:*
fields: updated_time, title
alias: updated_time AS Last edit, title AS Title
sort: title DESC
--&gt;
Several of these blocks can be included in one note, also between text.
The note content is updated every x minutes (depending on your setting) or manualy by Tools &gt; Create Note overview.
joplin-plugin-embed-search
```search
your search query
```

Additional features

you can paste sort:asc or sort:desc to sort notes by title ascending or descending
A shorthand notebook:this, that narrows search to current notebook only.
Basic content embedding content:true (beta):


Spoilers




可使用 %% 遮盖部分文字。




格式：



%%扰流板、遮挡板%%



软件内呈现：






点击前
点击后



以及一个类似闪卡的可折叠块
格式：



:[

测试，标题

测试，内容

]:



软件内呈现：



点击前
点击后
Notes statistics



笔记内部的数据统计。



Note tabs



 像浏览器一样浏览文档，支持多个打开放置。






Quick links



使用 @@快速链接笔记文件。






Jira Issue

Homenotes

选择一个笔记作为每次打开软件时的首个笔记，可以把这个功能当作书签用。

Admonition
!!! note This is the admonition title
This is the admonition body
!!!

The following admonition types, supported by Docarys, are recognized by this plugin:



Type




note


abstract


info


tip


success


question


warning


failure


danger


bug


example


quote



Encrypted notes

字面意义，加密笔记，记住密码不得找回。

Favorites




收藏夹，支持笔记、标签笔记本的收纳（随取随用）



更改收藏夹中的笔记名不会更改原始笔记。



Highlight

打出 [h:colour:scope] 后，插件会自动识别成代码。




颜色
范围（自动选择的）




m = mark
e = empty


r = red
w = word


g = green
s = sentence


b = blue
l = line


y = yellow





其他插件：
官方插件下载地址及其介绍
系列教程
笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

hexo 系列

hexo 独立博客搭建 [三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优化



 docker 环境
 hexo 使用入门
 hexo 基础配置
自定义修改
 hexo 部署
个性定义
性能优化
常见问题 



Hexo Markdown 以及各种插件功能测试



 markdown 各种其它语法插件
 latex 公式支持
 mermaid 图表
 plant uml 图表
 URL 卡片
 bilibili 卡片
 github 卡片
豆瓣卡片
插入音乐和视频
插入脑图


]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>note</tag>
        <tag>Joplin</tag>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title>[三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优一站式完全教程</title>
    <url>/posts/40300608/</url>
    <content><![CDATA[
All in one 一站式 Hexo 配置优化教程！

本文很长，特别长，如果你遇到了什么问题，可以尝试搜索本文，你很可能有收获！ CtRL + F
欢迎光临博主的独立博客 夜法之书
本文就教你搭建一个美观实用的博客系统，步骤极尽详细！
本文中提到的大量特性，已经被博主提交到 matery 主题 develop 分支，提交记录见 Commit。所以下面很多特性已经不用自己修改了，可以直接使用。




最终效果如下图所示！

支持离线访问。
支持浅色 / 深色模式。
支持文章 RSS 订阅，并支持文章分类订阅。
支持新博文订阅通知，右下角小铃铛点击订阅！ chrome 用户可能由于网络原因链接不到 Google 的服务器而看不到这个小铃铛。edge 和 Firefox 用户可以正常订阅。






RSS Hub 和 TTRSS 私有部署实现订阅。
配合浏览器扩展 RSSHub Radar (opens new window) 和 移动端辅助 App RSSBud (opens new window)(iOS) 与 RSSAid (opens new window)(Android) 食用。

Hexo Docker 环境使用篇
Docker 简介：

Docker 是一种轻量级的虚拟机环境，可以隔离主机的运行环境，内核公用主机的，运行库和环境是 Docker 私有的。运行 Docker 程序只比主机直接运行程序性能损失微乎其微。使用 Docker 你可以同时运行各种各样运行库环境而不用担心搞乱你的主机运行库环境！
Docker 运行负载远小于 Vmware 这类虚拟机， Vmware 需要模拟对应的 CPU 指令，再虚机运行一个虚拟机自己的内核，再这个虚拟机内核之上，再运行虚拟机的运行库和程序。比 Docker 多了一个内核模拟和运行，Cpu 和内存开销大增！

Docker 版 hexo 环境一键部署

博主开源定制，推荐使用！省去您大量环境配置时间。
使用 Hexo Docker 之前需要 Docker 环境，请参阅后文 Docker 安装方法

docker-hub
Github-hexo



  



使用推荐 Docker 来搭配本文，阅读使用，将更省事，方便，快捷。hexo 环境一键搞定！
Docker 一键安装
docker create --name=hexo \
-e HEXO_SERVER_PORT=4000 \
-e GIT_USER="17lai" \
-e GIT_EMAIL="17lai@domain.tld" \
-v /mnt/blog.17lai.site:/app \
-p 4000:4000 \
bloodstar/hexo
hexo web 后台写作

基于 hexo-admin 实现，具体配置实现方法见后文。
最终效果如下图所示。 blog.17lai.fun 访问 blog， 添加后缀 admin 访问 hexo 后台。
使用前面提到的 hexo docker ，启动运行 hexo docker 后，非自动安装 hexo-admin 以及常用插件，你也可以自定义安装你虚幻的插件， vi /app/useRun.sh。



配置 hexo-admin 根目录下_config.yml:
admin:
  username: myfavoritename #用户名
  password_hash: be121740bf988b2225a313fa1f107ca1 #密码
  secret: a secret something # secret is used to make the cookies secure
  deployCommand: '/app/tools/cide.sh'  # 自定义的部署脚本，在 hexo admin 的 deploy 标签页 deploy 按钮点击调用
配置 post metadata 根目录下_config.yml:
# add and edit your own post metadata with the admin interface
metadata:
  author_id: defaultAuthorId
  language:
ssh key 部署
Docker 会自动随机生成 ssh key 在 /app/.ssh 目录下面。自动部署请把 ssh key 添加到 github 等平台。
Github 详细教程


将 SSH 公钥复制到剪贴板。 ...
 在任何页面的右上角，单击您的个人资料照片，然后单击 Settings（设置）。
在用户设置侧边栏中，单击 SSH and GPG keys（SSH 和 GPG 密钥）。
单击 New SSH key（新 SSH 密钥）或 Add SSH key（添加 SSH 密钥）。


SSH 进入 docker
docker exec -it hexo /bin/bash
然后就可以正常运行 hexo 的各种命令了，是不是非常简单？ 快来试试吧。
远程 SSH 访问 Docker

推荐使用 SecurtCRT 来远程访问你的 Docker。


自定义用户自动运行脚本

用户可以在这里添加自动配置，自动安装插件，等各种启动 docker 运行的命令。
它将在 Docker 启动完成后自动调用运行！

vi /app/useRun.sh
反向代理 Hexo Docker

Nginx (engine x) 是一个高性能的 HTTP 和反向代理 web 服务器，同时也提供了 IMAP/POP3/SMTP 服务。


一些测试可能需要 ssl 支持，那么用 nginx 来反向代理一下，就可以在本地愉快的测试 ssl 加密功能了。


访问 docker，需要 192.168.0.100:4000 这样数字 ip + 端口号的方式不觉得很丑陋，而且需要开大量的端口，使用 nginx 反向代理，可以直接使用域名访问。


如果你想使用 blog.17lai.fun 这样的域名访问你的 docker 里面运行的博客，请参考下文。



Nginx 也使用 docker 来运行，blog.17lai.fun 为本地域名，修改本地 hosts dns 信息来访问。
docker compose 配置
nginxweb:
  image: bloodstar/nginx-purge
  container_name: "nginxweb"
  hostname: nginxweb
  ports:
    - "80:80"
    - "443:443"
  restart: always
  volumes:
    # ${USERDIR}为你docker运行目录
    - ${USERDIR}/nginx/conf.d:/etc/nginx/conf.d:ro
    - ${USERDIR}/nginxproxy/certs:/etc/nginx/certs:ro
    - ${USERDIR}/nginx/nginx.conf:/etc/nginx/nginx.conf:ro

bloodstar/nginx-purge


  



nginx 配置
文件 blog.conf ，配置文件放到 ${USERDIR}/nginx/conf.d 目录中
upstream blog {
    server hexo:4000;
}

server {
    listen 80;
    listen 443 ssl http2;
    server_name  blog.17lai.fun;

    ssl_certificate /etc/nginx/certs/17lai.pem;
    ssl_certificate_key /etc/nginx/certs/17lai.key;

    ssl_session_cache shared:aria2SSL:10m;
    ssl_session_timeout  30m;
    #ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;
    ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;
    
    access_log /var/log/nginx/blog.17lai.fun_access.log combined;
    error_log  /var/log/nginx/blog.17lai.fun_error.log;
    
    keepalive_requests 10000;
    
    location / {
        #proxy_redirect off;
        proxy_pass http://blog;

        proxy_buffering off;
        
        add_header X-Cache-Status $upstream_cache_status;
        proxy_set_header Host $http_host;

        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header  X-Forwarded-Ssl     on;
        proxy_set_header  X-Forwarded-For     $proxy_add_x_forwarded_for;      
        proxy_set_header  X-Frame-Options     SAMEORIGIN;
        
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    } 
}

Windows DNS 修改
windows hosts 文件路径为： C:\Windows\System32\drivers\etc\HOSTS
管理员权限用文本编辑器打开这个文件并添加 192.168.0.100 blog.17lai.fun，然后，你就可以在本地浏览器中使用域名访问你的 blog 了！
Linux DNS 修改
Linux hosts 文件路径为： /etc/hosts
用文本编辑器或者命令行工具 vim 打开这个文件并添加 192.168.0.100 blog.17lai.fun，然后，你就可以在本地浏览器中使用域名访问你的 blog 了！
# root用户一条指令搞定
echo "192.168.0.100 blog.17lai.fun" &gt;&gt; /etc/hosts

#或者使用 vi 或者 vim
vi /etc/hosts
获取 SSL 证书


如果你购买了域名，可以在域名服务商获得免费的 ssl 证书。
自己生成私有证书，使用时需要给本地计算机，浏览器添加你自己的根证书，才能使你的 ssl 证书在你自己的浏览器中生效。



使用 Hexo Docker 之前需要 Docker 环境，下面是 Docker 环境安装方法。

Centos 安装 Docker
X86（一键安装脚本）：
curl -sSL https://get.docker.com/ | sh
Arm：
步骤 1
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
步骤 2
添加仓库
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
步骤 3
安装 Docker
sudo yum install docker-ce docker-ce-cli containerd.io

完成安装
步骤 4
启动 Docker
sudo systemctl start docker
QNAP 安装 Docker

在系统应用的 AppCenter 中找到 Container  Station，可以直接点击安装即可。


群晖 安装 Docker
首先要说的是，x86 平台的群晖才能用的上 Docker 套件，因此，ARM 架构平台的群晖只能说非常遗憾了。
　　打开套件中心，在 “所有套件” 中找到 Docker 并安装：

Hexo 入门篇
Hexo 通用简明教程
Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。
前提
安装 Hexo 相当简单，只需要先安装下列应用程序即可：

Node.js (Node.js 版本需不低于 8.10，建议使用 Node.js 10.0 及以上版本)
Git
nmp

安装
所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。
npm install -g hexo-cli
安装以后，可以使用以下两种方式执行 Hexo：

npx hexo
将 Hexo 所在的目录下的 node_modules 添加到环境变量之中即可直接使用： hexo

echo 'PATH="$PATH:./node_modules/.bin"' &gt;&gt; ~/.profile
升级
后期需要升级的化，进入 blog 目录，先检查更新:
$ npm outdated
Package                  Current  Wanted  Latest  Location
hexo                       3.9.0   3.9.0   4.2.0  hexo-site
hexo-deployer-git          1.0.0   1.0.0   2.1.0  hexo-site
hexo-generator-archive     0.1.5   0.1.5   1.0.0  hexo-site
hexo-generator-category    0.1.3   0.1.3   1.0.0  hexo-site
hexo-generator-feed        1.2.2   1.2.2   2.2.0  hexo-site
hexo-generator-index       0.2.1   0.2.1   1.0.0  hexo-site
hexo-generator-tag         0.2.0   0.2.0   1.0.0  hexo-site
hexo-renderer-ejs          0.3.1   0.3.1   1.0.0  hexo-site
hexo-renderer-marked       0.3.2   0.3.2   2.0.0  hexo-site
hexo-renderer-stylus       0.3.3   0.3.3   1.1.0  hexo-site
hexo-server                0.3.3   0.3.3   1.0.0  hexo-site
修改 package.json 文件，基于 Latest 列内容更新版本号，然后更新并检查版本号：
$ npm install --save

# 检查版本号
$ hexo -v
hexo: 4.2.0
hexo-cli: 3.1.0
......
建站
安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。
hexo init &lt;folder&gt;
cd &lt;folder&gt;
npm install
启动网页服务
此时，通过 hexo s 命令即可在本地启动您的博客站点了。
$ hexo s
INFO  Start processing
INFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.
接下来将安装主题，配置博客托管平台，实现一键发布并刷新 CDN 缓存。
npm 下载加速
安装淘宝镜像， 加 NPM
npm config set registry https://registry.npm.taobao.org
安装 CNPM
npm install -g cnpm --registry=https://registry.npm.taobao.org
Hexo 日常操作命令
# 进入hexo docker 环境。需要你已经安装了docker环境，并安装了上文提到的hexo docker
docker exec -it hexo /bin/bash
# 运行完这条命令后，你就发现命令提示符变了，你此时进入了一个独立于你的主机运行环境的新的 node + hexo 开发环境了。

# 生成新页面 404
hexo new page 404

# 新增新文章 2022-03-26-blog.17lai.site
hexo new post 2022-03-26-blog.17lai.site

# 清理上次生成的静态网页，可以不运行，但你修改了一些源码后，很可能有各种不生效或错误
hexo clean

# 生成静态网页
hexo g

# gulp调用gulpfile.js压缩静态网页相关代码，减小网页体积
gulp 

# 调用根目录中 _config.yml 文件的deploy配置的参数来部署你的静态网页
hexo d
hexo 目录结构说明
在执行过 Hexo deploy 命令之后，目录结构新增了.deploy_git，public，.gitignore，如下：
 $ tree -L 2
.
├── .deploy_git
├── node_modules
├── public
├── scaffolds
│   ├── draft.md
│   ├── page.md
│   └── post.md
├── source
│   ├── _posts
│   ├── _drafts
├── themes
├── _config.yml
├── db.json
├── package.json
└── package-lock.json
_config.yml
用来配置博客相关的参数，初始化时自动创建。具体参数设置，可参照 Hexo 配置 文档。
node_modules 和 package.json
都是在初始化时自动创建。

node_modules 用来存储已安装的各类依赖包。
package.json 用来查看 Hexo 的版本以及相关依赖包的版本。

Hexo 会默认安装：

hexo：主程序
 hexo-deployer-git：实现 git 部署方式
 hexo-generator-archive：存档页面生成器
 hexo-generator-category：分类页面生成器
 hexo-generator-index：index 生成器
 hexo-generator-tag：标签页面生成器
 hexo-renderer-ejs：支持 EJS 渲染
 hexo-renderer-marked：Markdown 引擎
 hexo-renderer-stylus：支持 stylus 渲染
 hexo-server：支持本地预览，默认地址 localhost:4000

新安装的依赖包，也会保存在 node_module 文件夹下。
scaffold
模板文件夹，初始化时自动创建。包含 page，post，draft 三种模板，分别对应 页面、要发布的文章、草稿。
themes
主题文件夹，初始化时自动创建。每一个主题，都有一个单独的文件夹。默认主题为 landscape。
source ， public 和 .deploy_git

source：资源文件夹。用来存放图片、Markdown 文档（文章、草稿）、各种页面（分类、关于页面等）。
public：将 source 文件夹里的 Markdown 文档，转换成 index.html。再结合主题进行渲染，就是我们最终看到的博客。
.deploy_git：将 public 文件夹的内容提交到 Github 后生成，内容与 public 文件夹基本一致。

这三者的关系大致是：source -&gt; public -&gt; .deploy_git

执行 hexo generate，根据 source，更新 public。
执行 hexo deploy，根据 public，更新 .deploy_git。

常用命令
指令说明

hexo server #启动本地服务器，用于预览主题。Hexo 会监视文件变动并自动更新，除修改站点配置文件外，无须重启服务器，直接刷新网页即可生效。
hexo server -s #以静态模式启动
hexo server -p 5000 #更改访问端口 (默认端口为 4000，’ctrl + c’关闭 server)
hexo server -i IP地址 #自定义 IP
hexo clean #清除缓存，网页正常情况下可以忽略此条命令，执行该指令后，会删掉站点根目录下的 public 文件夹
hexo g #生成静态网页 (执行 $ hexo g 后会在站点根目录下生成 public 文件夹，hexo 会将”/blog/source/“下面的.md 后缀的文件编译为.html 后缀的文件，存放在”/blog/public/ “ 路径下)
hexo d #自动生成网站静态文件，并将本地数据部署到设定的仓库 (如 github)
hexo init 文件夹名称 #初始化 XX 文件夹名称
npm update hexo -g#升级
npm install hexo -g #安装
node-v #查看 node.js 版本号
npm -v #查看 npm 版本号
git --version #查看 git 版本号
hexo -v #查看 hexo 版本号
 hexo new page "music" #新增页面 music
hexo new post "文章名称" #新增文章

简写指令
hexo n "我的第一篇文章"` 等价于 `hexo new "我的第一篇文章"` 还等价于 `hexo new post "我的第一篇文章"
hexo p` 等价于 `hexo publish
hexo g` 等价于 `hexo generate
hexo s`等价于 `hexo server
hexo d` 等价于 `hexo deploy
hexo g -d`等价于`hexo generate --deploy
注: hexo clean 没有 简写，git --version 没有简写
Hexo 基础配置篇
下载主题
hexo-theme-matery 是一个采用 Material Design 和响应式设计的 Hexo 博客主题，点击 这里 可以查看示例效果。点击 这里 下载 master 分支的最新稳定版的代码，解压缩后，将 hexo-theme-matery 的文件夹复制到 Hexo 的 themes 文件夹中即可。
Docker 环境命令
git clone https://github.com/blinkfox/hexo-theme-matery.git /app/themes/matery; 
切换主题
修改 Hexo 根目录下的 _config.yml 的 theme 的值：theme: hexo-theme-matery
_config.yml 文件的其它修改建议

请修改 _config.yml 的 url 的值为你的网站主 URL（如：http://xxx.github.io）。
建议修改两个 per_page 的分页条数值为 6 的倍数，如：12、18 等，这样文章列表在各个屏幕下都能较好的显示。
如果是中文用户，则建议修改 language 的值为 zh-CN。

新建主题必备 about、tags、404 等页面
新建分类 categories 页
categories 页是用来展示所有分类的页面，如果 source 目录下还没有 categories/index.md 文件，那么就需要新建一个，命令如下：
hexo new page "categories"
编辑你刚刚新建的页面文件 /source/categories/index.md，至少需要以下内容：
---
title: categories
date: 2018-09-30 17:25:30
type: "categories"
layout: "categories"
---
新建标签 tags 页
tags 页是用来展示所有标签的页面，如果 source 目录下还没有 tags/index.md 文件，那么就需要新建一个，命令如下：
hexo new page "tags"
编辑刚刚新建的页面文件 /source/tags/index.md，至少需要以下内容：
---
title: tags
date: 2018-09-30 18:23:38
type: "tags"
layout: "tags"
---
新建留言板 contact 页
contact 页是用来展示留言板信息的页面，如果在你的博客 source 目录下还没有 contact/index.md 文件，那么你就需要新建一个，命令如下：
hexo new page "contact"
编辑你刚刚新建的页面文件 /source/contact/index.md，至少需要以下内容：
---
title: contact
date: 2018-09-30 17:25:30
type: "contact"
layout: "contact"
---

注：本留言板功能依赖于第三方评论系统，请激活你的评论系统才有效果。并且在主题的 _config.yml 文件中，第 19 至 21 行的 “菜单” 配置，取消关于留言板的注释即可。

新建友情链接 friends 页
friends 页是用来展示友情链接信息的页面，如果在你的博客 source 目录下还没有 friends/index.md 文件，那么你就需要新建一个，命令如下：
hexo new page "friends"
编辑你刚刚新建的页面文件 /source/friends/index.md，至少需要以下内容：
---
title: friends
date: 2018-12-12 21:25:30
type: "friends"
layout: "friends"
---
同时，在你的博客 source 目录下新建 _data 目录，在 _data 目录中新建 friends.json 文件，文件内容如下所示：
[{
    "avatar": "https://blog.17lai.site/favicon.png",
    "name": "夜法之书的Blog",
    "introduction": "嵌入式，Linux Kernel&amp;Driver, PT, Docker, Nas等等",
    "url": "https://blog.17lai.site",
    "title": "前去学习"
},{
    "avatar": "http://image.luokangyuan.com/1_qq_27922023.jpg",
    "name": "码酱",
    "introduction": "我不是大佬，只是在追寻大佬的脚步",
    "url": "http://luokangyuan.com/",
    "title": "前去学习"
}, {
    "avatar": "http://image.luokangyuan.com/4027734.jpeg",
    "name": "闪烁之狐",
    "introduction": "编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬",
    "url": "https://blinkfox.github.io/",
    "title": "前去学习"
}, {
    "avatar": "http://image.luokangyuan.com/avatar.jpg",
    "name": "ja_rome",
    "introduction": "平凡的脚步也可以走出伟大的行程",
    "url": "https://me.csdn.net/jlh912008548",
    "title": "前去学习"
}]
新建关于我 about 页
about 页是用来展示关于我和我的博客信息的页面，如果 source 目录下还没有 about/index.md 文件，那么就需要新建一个，命令如下：
hexo new page "about"
编辑刚刚新建的页面文件 /source/about/index.md，至少需要以下内容：
---
title: about
date: 2018-09-30 17:25:30
type: "about"
layout: "about"
---
新建 404 页
新建一个 404.md 文件
在 hexo 的 souce 文件夹下创建一个 404.md，之后输入如下内容：
---
title: 404
date: 2019-11-23 21:10:10
type: "404"
layout: "404"
---

然后 hexo g 生成页面中就有 404。只是页面较丑。
404 页面美化

下载 404 特效
点击下载代码: 点我去代码出处

移植
放入 js 文件到主题中
将下载的压缩包解压，会发现里面有两个 js 文件和一个 html 页面，重要的就是 js 文件，将文件移植到主题的 source 文件的 libs 文件夹下，需要自己创建一个文件夹，我给文件夹取的名字叫做 404。

导入 404 js
因为该主题的 js 文件都是写_config.yml 文件里面的，为了规范，也需要将文件的路径写到该文件夹下
如下，之后导入 js 文件的时候就可以使用 404bodymovin 和 404data 来代替了

编辑 404.esj
&lt;style type="text/css"&gt;
    /* don't remove. */
    .page404-cover {
        /* height: 75vh; */
        height: 88vh;
    }
 
    #svgContainer {
      width: 100%;
      height: 100%;
      background-color: white;
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      margin: auto;
    }
&lt;/style&gt;
 
 
&lt;script src="&lt;%- theme.libs.js.my404bodymovin %&gt;"&gt;&lt;/script&gt;
&lt;script src="&lt;%- theme.libs.js.my404data %&gt;"&gt;&lt;/script&gt;
 
&lt;div class="bg-cover pd-header page404-cover"&gt;
    &lt;div id="svgContainer"&gt;&lt;/div&gt;
 
    &lt;script type="text/javascript"&gt;
        var svgContainer = document.getElementById('svgContainer');
        var animItem = bodymovin.loadAnimation({
          wrapper: svgContainer,
          animType: 'svg',
          loop: true,
          animationData: JSON.parse(animationData)
        });
    &lt;/script&gt;
&lt;/div&gt;
现在就移植成功了，使用下面命令上传，之后输入一个错误的页面就可以查看到了
hexo cl &amp;&amp; hexo g -d

Tips: 不要再本地试验，本地的时候输入错误的页面不会显示 404 页面的。

新建友情连接 friends 页（可选的）
friends 页是用来展示友情连接信息的页面，如果 source 目录下还没有 friends/index.md 文件，那么就需要新建一个，命令如下：
hexo new page "friends"
编辑刚刚新建的页面文件 /source/friends/index.md，至少需要以下内容：
---
title: friends
date: 2018-12-12 21:25:30
type: "friends"
layout: "friends"
---
同时，在 source 目录下新建 _data 目录，在 _data 目录中新建 friends.json 文件，文件内容如下所示：
[
  {
    "avatar": "https://www.lixl.cn/medias/avatar.jpg",
    "name": "悟尘记",
    "introduction": "人生就是一场修行，上善若水，厚德载物。",
    "url": "https://www.lixl.cn/",
    "title": "前去参观"
  },
  {
    "avatar": "https://wiki.hyperledger.org/download/attachments/2392069/fabric?version=1&amp;modificationDate=1540928132000&amp;api=v2",
    "name": "Fabric",
    "introduction": "A Blockchain Platform for the Enterprise",
    "url": "https://hyperledger-fabric.readthedocs.io/en/master/",
    "title": "前去学习"
  },
  {
    "avatar": "https://www.bootcdn.cn/assets/img/maoyun.svg",
    "name": "BootCDN",
    "introduction": "稳定、快速、免费的前端开源项目 CDN 加速服务。",
    "url": "https://www.bootcdn.cn/",
    "title": "前去加速"
  }
]
菜单导航配置
配置基本菜单导航的名称、路径 url 和图标 icon.

1. 菜单导航名称可以是中文也可以是英文 (如：Index 或主页)
2. 图标 icon 可以在 Font Awesome 中查找 

menu:
  Index:
    url: /
    icon: fas fa-home
  Tags:
    url: /tags
    icon: fas fa-tags
  Categories:
    url: /categories
    icon: fas fa-bookmark
  Archives:
    url: /archives
    icon: fas fa-archive
  About:
    url: /about
    icon: fas fa-user-circle
  Friends:
    url: /friends
    icon: fas fa-address-book
二级菜单配置方法
如果你需要二级菜单则可以在原基本菜单导航的基础上如下操作

在需要添加二级菜单的一级菜单下添加 children 关键字 (如:About 菜单下添加 children)
 在 children 下创建二级菜单的 名称 name, 路径 url 和图标 icon.
 注意每个二级菜单模块前要加 -.
 注意缩进格式 

menu:
  Index:
    url: /
    icon: fas fa-home
  Tags:
    url: /tags
    icon: fas fa-tags
  Categories:
    url: /categories
    icon: fas fa-bookmark
  Archives:
    url: /archives
    icon: fas fa-archive
  About:
    url: /about
    icon: fas fa-user-circle-o
  Friends:
    url: /friends
    icon: fas fa-address-book
  Medias:
    icon: fas fa-list
    children:
      - name: Music
        url: /music
        icon: fas fa-music
      - name: Movies
        url: /movies
        icon: fas fa-film
      - name: Books
        url: /books
        icon: fas fa-book
      - name: Galleries
        url: /galleries
        icon: fas fa-image
文章 Front-matter 介绍
Front-matter 选项详解
Front-matter 选项中的所有内容均为非必填的。但仍然建议至少填写 title 和 date 的值。



配置选项
默认值
描述




 title
Markdown 的文件标题
文章标题，强烈建议填写此选项


 date
 文件创建时的日期时间
发布时间，强烈建议填写此选项，且最好保证全局唯一


 author
 根 _config.yml 中的 author
文章作者


 img
featureImages 中的某个值
文章特征图，推荐使用图床 (腾讯云、七牛云、又拍云等) 来做图片的路径。如: http://xxx.com/xxx.jpg


top
true
推荐文章（文章是否置顶），如果 top 值为 true，则会作为首页推荐文章


 hide
false
隐藏文章，如果 hide 值为 true，则文章不会在首页显示


 cover
false
v1.0.2 版本新增，表示该文章是否需要加入到首页轮播封面中


 coverImg
 无
v1.0.2 版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片


 password
 无
文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 password 的值，该值必须是用 SHA256 加密后的密码，防止被他人识破。前提是在主题的 config.yml 中激活了 verifyPassword 选项


 toc
true
是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项


 mathjax
false
是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行


 summary
 无
文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要


 categories
 无
文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类


 tags
 无
文章标签，一篇文章可以多个标签


 keywords
 文章标题
文章关键字，SEO 时需要


 reprintPolicy
cc_by
 文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个




注意:

如果 img 属性不填写的话，文章特色图会根据文章标题的 hashcode 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图各有特色。
date 的值尽量保证每篇文章是唯一的，因为本主题中 Gitalk 和 Gitment 识别 id 是通过 date 的值来作为唯一标识的。
如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 _config.yml 中激活了配置。有些在线的 SHA256 加密的地址，可供使用：开源中国在线工具、chahuo、站长工具。


以下为文章的 Front-matter 示例。
最简示例
---
title: 基于Hexo的hexo-theme-matery主题搭建博客并优化
date: 2019-10-03 14:25:00
---
最全示例
---
title: 基于Hexo的hexo-theme-matery主题搭建博客并优化
date: 2019-12-30 09:25:00
author: 17lai.site
img: /medias/cover/hexo.jpg
top: true
cover: true
coverImg: /medias/cover/hexo.jpg
password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92
toc: false
mathjax: false
summary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要
categories: Hexo
keywords: Hexo GitHub blog
tags:
  - Hexo
  - Blog
  - GitHub
---
新建文章模板修改
首先为了新建文章方便，我们可以修改一下文章模板，建议将 /scaffolds/post.md 修改为如下代码：
---
title: {{ title }}
date: {{ date }}
author: 
img: 
coverImg: 
top: false
cover: false
toc: true
mathjax: false
password:
summary:
tags:
categories:
---
这样新建文章后 一些 Front-matter 参数不用你自己补充了，修改对应信息就可以了。
代码高亮
由于 Hexo 自带的代码高亮主题显示不好看，所以主题中使用到了 hexo-prism-plugin 的 Hexo 插件来做代码高亮，安装命令如下：
npm i -S hexo-prism-plugin
然后，修改 Hexo 根目录下 _config.yml 文件中 highlight.enable 的值为 false，并新增 prism 插件相关的配置，主要配置如下：
highlight:
  enable: false

prism_plugin:
  mode: "preprocess" # realtime/preprocess
  theme: "tomorrow"
  line_number: false # default false
  custom_css:
添加文章搜索功能



这个插件比广大教程提到的 hexo-generator-search 插件更加强大和好用！


matery 目前只支持 search.xml xml 格式的搜索文件！



本主题中还使用到了 hexo-generator-searchdb 的 Hexo 插件来做内容搜索，安装命令如下：
npm install hexo-generator-searchdb --save
在 Hexo 根目录下的 _config.yml 文件中，新增以下的配置项：
search:
  path: search.xml
  field: post
  content: true
  format: html
参数含义


path - file path. By default is search.xml. If the file extension is .json, the output format will be JSON. Otherwise XML format file will be exported.


field


the search scope you want to search, you can chose:


post (Default) - will only cover all the posts of your blog.


page - will only cover all the pages of your blog.


all - will cover all the posts and pages of your blog.




content - whether contains the whole content of each article. If false, the generated results only cover title and other meta info without mainbody. By default is true.


format


the form of the page contents, options are:


html (Default) - original html string being minified.


striptags - original html string being minified, and remove all the tags.


raw - markdown text of each posts or pages.




修改页脚
页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 /layout/_partial/footer.ejs 文件中，包括站点、使用的主题、访问量等。
修改社交链接
在主题的 _config.yml 文件中，默认支持 QQ、GitHub 和邮箱的配置，可以在主题文件的 /layout/_partial/social-link.ejs 文件中，新增、修改需要的社交链接地址，增加链接可参考如下代码：
&lt;a
  href="https://github.com/blinkfox"
  class="tooltipped"
  target="_blank"
  data-tooltip="访问我的GitHub"
  data-position="top"
  data-delay="50"
&gt;
  &lt;i class="fa fa-github"&gt;&lt;/i&gt;
&lt;/a&gt;
其中，社交图标（如：fa-github）可以在 Font Awesome 中搜索找到。以下是常用社交图标的标识，供参考：

Facebook: fa-facebook
Twitter: fa-twitter
Google-plus: fa-google-plus
Linkedin: fa-linkedin
Tumblr: fa-tumblr
Medium: fa-medium
Slack: fa-slack
新浪微博: fa-weibo
微信: fa-wechat
QQ: fa-qq

修改打赏的二维码图片
在主题文件的 source/medias/reward 文件中，可以替换成你的的微信和支付宝的打赏二维码图片。
配置文章基本信息
new_post_name: :title.md   # 新文章的文件名称
default_layout: post       # 预设布局
auto_spacing: false        # 在中文和英文之间加入空格
titlecase: false           # 把标题转换为 title case
external_link:             # 在新标签中打开链接
  enable: true             # 在新标签中打开链接
  field:                   # 对整个网站（site）生效或仅对文章（post）生效
  exclude:                 # 需要排除的域名。主域名和子域名如 www 需分别配置	[]
filename_case: 0           # 把文件名称转换为 (1) 小写或 (2) 大写
render_drafts: false       # 显示草稿，默认为：false
post_asset_folder: true    # 启动 Asset 文件夹
relative_link: false       # 把链接改为与根目录的相对位址
future: true               # 显示未来的文章
highlight:                 # 代码块的设置
  enable: false            # 开启代码块高亮
  line_number: false       # 显示行数
  auto_detect: false       # 如果未指定语言，则启用自动检测
  tab_replace:             # 用 n 个空格替换 tabs；如果值为空，则不会替换 tabs
配置代码高亮及样式
highlight:                      # 代码块的设置
  enable: false                 # 开启代码块高亮
  line_number: true             # 显示行数
  auto_detect: false            # 如果未指定语言，则启用自动检测
  tab_replace: ''               # 用 n 个空格替换 tabs；如果值为空，则不会替换 tabs
  wrap: true
  hljs: false
prismjs:
  enable: true
  preprocess: true
  line_number: true
  tab_replace: ''
配置代码的样式
code:
  lang: true     # 代码块是否显示名称
  copy: true     # 代码块是否可复制
  shrink: false  # 代码块是否可以收缩
  break: false   # 代码是否折行
配置是否启用转载限制模块
reprint:
  enable: false   #是否启用“转载规则限定模块”
  default: cc_by
文章转载规则，可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个
配置文章阅读密码功能
阅读文章的密码验证功能，如要使用此功能请激活该配置项，并在对应文章的 Front-matter 中写上 password 的键和加密后的密文即可。

请注意：为了保证密码原文不会被泄露到网页中，文章的密码必须是通过 SHA256 加密的，这样就不会被破解。

verifyPassword:
  enable: true
  promptMessage: 请输入访问本文章的密码
  errorMessage:  密码错误，将返回主页！
如何一键部署 hexo
通过 hexo-deployer-git 插件可以实现一键将博客同时部署到多个 git 仓库中。如同时发布到 github 及 gitee 提供的 pages 服务。安装：
npm install hexo-deployer-git --save
修改 Hexo 根目录下的 _config.yml 文件中的如下内容:
## Docs: https://hexo.io/docs/deployment.html
deploy:
  - type: git
    repo: https://github.com/lxl80/blog.git
    branch: gh-pages
    ignore_hidden: false
  - type: git
    repo: https://gitee.com/lxl80/lxl80.git
    branch: master
    ignore_hidden: false

也可以如本站一样，采用 hexo-deployer-cos-enhanced 插件将静态内容部署到腾讯云对象存储服务中，在 DNS 配置中将境内线路解析到腾讯云 CDN 地址，实现加速。部署完成后会自动刷新被更新文件的 CDN 缓存。

安装：
npm install hexo-deployer-cos-enhanced --save
_config.yml 配置如下:
deploy:
  - type: git
    repo: https://github.com/lxl80/blog.git
    branch: gh-pages
    ignore_hidden: false
  - type: cos
    bucket: lxl80-130****
    region: ap-beijing
    secretId: AKIDh9****F8FvL
    secretKey: Z3IGiur****QZR3PgjXmlVg
    cdnConfig:
      enable: true
      cdnUrl: https://static.lixl.cn
      bucket: static-130****
      region: ap-beijing
      folder: static
      secretId: AKIDh9****F8FvL
      secretKey: Z3IGiur****QZR3PgjXmlVg
然后通过 hexo g -d 即可实现一键发布，并更新 CDN 缓存。
文章链接转静态短地址（可选的）
如果文章名称是中文的，那么 Hexo 默认生成的永久链接也会有中文，这样不利于 SEO，且 gitment 评论对中文链接也不支持。我们可以用 hexo-permalink-pinyin Hexo 插件生成文章时生成中文拼音的永久链接，或者用 hexo-abbrlink 生成静态文章链接。以下结合 hexo-abbrlink 生成类似 /yyyy/mmdd+随机数.html 的文章链接地址。
安装命令如下：
npm install hexo-abbrlink --save



npm 下载太慢怎么办？ 修改国内淘宝源加速，戳



在 Hexo 根目录下的 _config.yml 文件中，修改 permalink: ，并在文件末尾新增 abbrlink: 配置项：
permalink: :year/:month:day:abbrlink.html

abbrlink:
  alg: crc16 #算法选项：crc16丨crc32
  rep: dec #输出进制：dec为十进制，hex为十六进制
添加 emoji 表情支持（可选的）
Matery 主题新增了对 emoji 表情的支持，使用到了 hexo-filter-github-emojis 的 Hexo 插件来支持 emoji 表情的生成，把对应的 markdown emoji 语法（::, 例如：:smile:）转变成会跳跃的 emoji 表情，安装命令如下
npm install hexo-filter-github-emojis --save


npm 下载太慢怎么办？ 修改国内淘宝源加速，戳


在 博客根目录下的 _config.yml 文件中，新增以下的配置项：
githubEmojis:
  enable: true
  className: github-emoji
  inject: true
  styles:
  customEmojis:
执行 hexo clean &amp;&amp; hexo g 重新生成博客文件，然后就可以在文章中对应位置看到你用 emoji 语法写的表情了。
文章字数统计插件
如果你想要在文章中显示文章字数、阅读时长信息，可以安装 hexo-wordcount 插件。
安装命令如下：
npm i --save hexo-wordcount
然后只需在本主题下的 _config.yml 文件中，激活以下配置项即可：
wordCount:
  enable: false # 将这个值设置为 true 即可.
  postWordCount: true
  min2read: true
  totalCount: true
添加 RSS 订阅支持
本主题中还使用到了 hexo-generator-feed 的 Hexo 插件来做 RSS，安装命令如下：
npm install hexo-generator-feed --save
在 Hexo 根目录下的 _config.yml 文件中，新增以下的配置项：
feed:
  type: atom
  path: atom.xml
  limit: 20
  hub:
  content:
  content_limit: 140
  content_limit_delim: " "
  order_by: -date
执行 hexo clean &amp;&amp; hexo g 重新生成博客文件，然后在 public 文件夹中即可看到 atom.xml 文件，说明已经安装成功了。
增加百度统计功能
首先注册百度统计站长版，登陆后点击 新增网站，然后直接输入你的博客地址例如： https://blog.17lai.site，网站域名 和 网站首页 都写这个，网站名称 可以填 我的博客，
行业类别： 博客 — 空间周边。
然后点击左侧菜单的 代码获取，找到
hm.src = "https://hm.baidu.com/hm.js?……"
问号后的这一段十六进制代码
复制下来，粘贴到 主题配置文件 中的 baidu_analytics: 后面，注意冒号和值之间要有一个空格，然后将该字段前面的 #号删除代表启用此功能。保存后即可
# Add baidu analytics configuration
# 添加 baidu Analytics 配置
baiduAnalytics:
  enable: false
  id: f614xxxxxxxxxxxxxxxx05d25e
Leancloud+Valine 打造 Hexo 个人博客极简评论系统
Leancloud 配置
首先访问 Leancloud 官网 https://leancloud.cn/
有 Github 账号的小伙伴可以用 Github 账号进行登陆然后绑定邮箱就可以啦！
进入之后点击创建应用

这样我们就创建好啦！

接着点击应用右上角的设置进入设置界面

选择应用 key，这样就可以看到我们接下来需要使用到的 key

接着进入应用中心绑定你的个人博客域名

Valine 配置
然后我们去主题配置文件中进行修改
主题配置文件路径：matery_config.yml
找到以下参数进行修改
# Valine.
# You can get your appid and appkey from https://leancloud.cn
# more info please open https://valine.js.org
valine:
  enable: true //打开valine评论功能
  appid: 你的leancloud appid 
  appkey: 你的leancloud appkey 
  notify: false //邮件提醒
  verify: true //评论时是否有验证码，需要在Leancloud 设置-&gt;安全中心 中打开
  placeholder: 说点什么吧！ //评论框默认显示
  avatar: hide //评论者的头像,我这里设置的不显示
  guest_info: nick # custom comment header
  pageSize: 10 # pagination size
PS：评论者头像可以进行如下设置

到此，一个极简评论系统就完成啦！
自定义修改篇
在本主题的 _config.yml 中可以修改部分自定义信息，有以下几个部分：

菜单
我的梦想
首页的音乐播放器和视频播放器配置
是否显示推荐文章名称和按钮配置
favicon 和 Logo
个人信息
 TOC 目录
文章打赏信息
复制文章内容时追加版权信息
 MathJax
 文章字数统计、阅读时长
点击页面的’爱心’效果
我的项目
我的技能
我的相册
Gitalk、Gitment、Valine 和 disqus 评论配置
不蒜子统计和谷歌分析（Google Analytics）
默认特色图的集合。当文章没有设置特色图时，本主题会根据文章标题的 hashcode 值取余，来选择展示对应的特色图

如果本主题中的诸多功能和主题色彩你不满意，可以在主题中自定义修改，很多更自由的功能和细节点的修改难以在主题的 _config.yml 中完成，需要修改源代码才来完成。以下列出了可能有用的地方：
更换字体
一般网站的 web 字体都可以直接从 Google-Font 获取资源，这样不用担心字体商业带来的法律问题。
常见的开源字体有：
思源黑体 、 文泉驿 、 文鼎开放字体 、 柳体 、 cwTeX 中文字体 、 濑户字体、江西拙楷体等。
1）创建 web 字体引用
@font-face{
    font-family: '引用的字体名称';
    src: url('谷歌字体路径（或者其他什么字体引用）');   
}
2）在网页合适的位置进行字体引用
①利用浏览器检查元素，获取需要定义字体的部分
②在主体的配置文件中 (hexo-theme-matery/layout/…) 找到对应的渲染 (.ejs) 文件，查找需要修改的部分
①演示一下利用浏览器获取定义字体的部分

对获取到的 id选择器：#artDetail 进行 css 渲染
#artDetail {
    font-family: '引用的web字体';
}
②利用主体的 ejs 渲染文件找出需要修饰的部分（加入自定义类）

/*使用我在文章内容详情定义的diyFnot类**/
.diyfont {
   font-family: '引用的web字体'; 
}

/*也可以使用自带的id*/
#artDetail {
    font-family: '引用的web字体'; 
}
网站全局化字体定义
@font-face{
    font-family: '引用的字体名称';
    src: url('谷歌字体路径（或者其他什么字体引用）');   
}

body {
    font-family: '引用的web字体名称'; 
}
引用本地的字体文件
当然有时候那个谷歌字体的网站可能登录不上去，需要科学上网，很烦人！我们也可以直接下载下字体文件，将他放在本地，进行直接引用！看下面操作👇
①在本地的 hexo 根目录的 source 文件下创立 diy-font 文件夹:/source/diy-font
在该文件下存放你的字体文件，比如：/source/diy-font/IBMPlexMono-Italic.ttf
②引用本地字体（仍然是在 my.css 文件中书写代码）
@font-face{
    font-family: 'hl';
    src: url('../diy-font/IBMPlexMono-Italic.ttf');
}

/** 表示全局使用，如果不想全局使用不要添加该段 */
body{
    font-family: 'hl';
}


/* 可以局部使用，建议添加 */
.diyFont{
    font-family: 'hl';
}
这样我们就可以实现引用本地的字体了，并且在 web 有效！
在你想要使用的元素的 class 里面加上 diyFont 即可。


直接使用
F12，找到对应的代码片段即可：


&lt;span class="logo-span diyFont"&gt;测试字体&lt;/span&gt;


模板使用
找到对应的模板 header.ejs 中的代码片段使用即可：


&lt;span class="logo-span diyFont"&gt;&lt;%= config.title %&gt;&lt;/span&gt;
修改主题颜色
在主题文件的 /source/css/matery.css 文件中，搜索 .bg-color 来修改背景颜色：
/* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */
.bg-color {
  background-image: linear-gradient(to right, #4cbf30 0%, #0f9d58 100%);
}

@-webkit-keyframes rainbow {
  /* 动态切换背景颜色. */
}

@keyframes rainbow {
  /* 动态切换背景颜色. */
}
修改 banner 图和文章特色图
可以直接在 /source/medias/banner 文件夹中更换喜欢的 banner 图片，主题代码中是每天动态切换一张，只需 7 张即可。如果会 JavaScript 代码，可以修改成自己喜欢切换逻辑，如：随机切换等，banner 切换的代码位置在 /layout/_partial/bg-cover-content.ejs 文件的 &lt;script&gt;&lt;/script&gt; 代码中：
$(".bg-cover").css("background-image", "url(/medias/banner/" + new Date().getDay() + ".jpg)");
在 /source/medias/featureimages 文件夹中默认有 24 张特色图片，你可以再增加或者减少，并需要在 _config.yml 做同步修改。
Hexo 跳过渲染
在 Hexo 部署时会默认渲染 source 下的所有 html 页面，但有时候想在 Hexo 博客上单独自定义 html 页面或 README.md 时，却不希望被 Hexo 渲染。因此对某个文件或者目录进行排除渲染是非常必要的。
方法一：font matter
Hexo 新建网站页面，然后将你的代码直接写入 index.md 中
在 Front matter 中添加 layout: false，此方法适用于单一的纯 HTML
CSS 页面。
---
title: tools
date: 2020-04-28 00:00:00
type: "tools"
layout: false
---
0x003 方法二：skip rende
在博客根目录下的 _config.yml，找到 skip_render，大概在 32 行左右，写入你想要的跳过渲染的路径，注意缩进和空格。
# 指定目录跳过hexo渲染
skip_render:
  - 'tools/*'
  - 'tools/**'

注释：tools/* 表示在目录 source/fireworks 下的文件全部跳过渲染，tools/** 表示在博客根目录 source/tools/ 文件夹下的文件全部跳过渲染（例如页面的 js、css 在另一个文件夹中）。

hexo 体积压缩


因为 hexo 生成的 html、css、js 等都有很多的空格或者换行，而空格和换行也是占用字节的，所以需要将空格换行去掉也就是我要进行的 “压缩”。减小体积，加快加载速度。
npm 下载太慢怎么办？ 修改国内淘宝源加速，戳


# 全局安装gulp模块
npm install gulp -g
# 安装各种小功能模块  执行这步的时候，可能会提示权限的问题，最好以管理员模式执行
npm install gulp gulp-htmlclean gulp-htmlmin gulp-minify-css gulp-uglify gulp-imagemin --save
# 额外的功能模块
npm install gulp-debug gulp-clean-css gulp-changed gulp-if gulp-plumber gulp-babel babel-preset-es2015 del @babel/core --save
 
或者使用yarn 
 
yarn global add gulp
yarn add  gulp gulp-htmlclean gulp-htmlmin gulp-minify-css gulp-uglify gulp-imagemin
yarn add  gulp-debug gulp-clean-css gulp-changed gulp-if gulp-plumber gulp-babel babel-preset-es2015 del @babel/core
然后，在根目录 (有_config.yml 文件，theme 目录的目录) 新增 gulpfile.js 文件，文件名必须是这个 :
var gulp = require("gulp");
var debug = require("gulp-debug");
var cleancss = require("gulp-clean-css"); //css压缩组件
var uglify = require("gulp-uglify"); //js压缩组件
var htmlmin = require("gulp-htmlmin"); //html压缩组件
var htmlclean = require("gulp-htmlclean"); //html清理组件
var imagemin = require("gulp-imagemin"); //图片压缩组件
var changed = require("gulp-changed"); //文件更改校验组件
var gulpif = require("gulp-if"); //任务 帮助调用组件
var plumber = require("gulp-plumber"); //容错组件（发生错误不跳出任务，并报出错误内容）
var isScriptAll = true; //是否处理所有文件，(true|处理所有文件)(false|只处理有更改的文件)
var isDebug = true; //是否调试显示 编译通过的文件
var gulpBabel = require("gulp-babel");
var es2015Preset = require("babel-preset-es2015");
var del = require("del");
var Hexo = require("hexo");
var hexo = new Hexo(process.cwd(), {}); // 初始化一个hexo对象

// 清除public文件夹
gulp.task("clean", function () {
    return del(["public/**/*"]);
});

// 下面几个跟hexo有关的操作，主要通过hexo.call()去执行，注意return
// 创建静态页面 （等同 hexo generate）
gulp.task("generate", function () {
    return hexo.init().then(function () {
        return hexo
            .call("generate", {
                watch: false
            })
            .then(function () {
                return hexo.exit();
            })
            .catch(function (err) {
                return hexo.exit(err);
            });
    });
});

// 启动Hexo服务器
gulp.task("server", function () {
    return hexo
        .init()
        .then(function () {
            return hexo.call("server", {});
        })
        .catch(function (err) {
            console.log(err);
        });
});

// 部署到服务器
gulp.task("deploy", function () {
    return hexo.init().then(function () {
        return hexo
            .call("deploy", {
                watch: false
            })
            .then(function () {
                return hexo.exit();
            })
            .catch(function (err) {
                return hexo.exit(err);
            });
    });
});

// 压缩public目录下的js文件
gulp.task("compressJs", function () {
    return gulp
        .src(["./public/**/*.js", "!./public/libs/**"]) //排除的js
        .pipe(gulpif(!isScriptAll, changed("./public")))
        .pipe(gulpif(isDebug, debug({ title: "Compress JS:" })))
        .pipe(plumber())
        .pipe(
            gulpBabel({
                presets: [es2015Preset] // es5检查机制
            })
        )
        .pipe(uglify()) //调用压缩组件方法uglify(),对合并的文件进行压缩
        .pipe(gulp.dest("./public")); //输出到目标目录
});

// 压缩public目录下的css文件
gulp.task("compressCss", function () {
    var option = {
        rebase: false,
        //advanced: true, //类型：Boolean 默认：true [是否开启高级优化（合并选择器等）]
        compatibility: "ie7" //保留ie7及以下兼容写法 类型：String 默认：''or'*' [启用兼容模式； 'ie7'：IE7兼容模式，'ie8'：IE8兼容模式，'*'：IE9+兼容模式]
        //keepBreaks: true, //类型：Boolean 默认：false [是否保留换行]
        //keepSpecialComments: '*' //保留所有特殊前缀 当你用autoprefixer生成的浏览器前缀，如果不加这个参数，有可能将会删除你的部分前缀
    };
    return gulp
        .src(["./public/**/*.css", "!./public/**/*.min.css"]) //排除的css
        .pipe(gulpif(!isScriptAll, changed("./public")))
        .pipe(gulpif(isDebug, debug({ title: "Compress CSS:" })))
        .pipe(plumber())
        .pipe(cleancss(option))
        .pipe(gulp.dest("./public"));
});

// 压缩public目录下的html文件
gulp.task("compressHtml", function () {
    var cleanOptions = {
        protect: /&lt;\!--%fooTemplate\b.*?%--&gt;/g, //忽略处理
        unprotect: /&lt;script [^&gt;]*\btype="text\/x-handlebars-template"[\s\S]+?&lt;\/script&gt;/gi //特殊处理
    };
    var minOption = {
        collapseWhitespace: true, //压缩HTML
        collapseBooleanAttributes: true, //省略布尔属性的值 &lt;input checked="true"/&gt; ==&gt; &lt;input /&gt;
        removeEmptyAttributes: true, //删除所有空格作属性值 &lt;input id="" /&gt; ==&gt; &lt;input /&gt;
        removeScriptTypeAttributes: true, //删除&lt;script&gt;的type="text/javascript"
        removeStyleLinkTypeAttributes: true, //删除&lt;style&gt;和&lt;link&gt;的type="text/css"
        removeComments: true, //清除HTML注释
        minifyJS: true, //压缩页面JS
        minifyCSS: true, //压缩页面CSS
        minifyURLs: true //替换页面URL
    };
    return gulp
        .src("./public/**/*.html")
        .pipe(gulpif(isDebug, debug({ title: "Compress HTML:" })))
        .pipe(plumber())
        .pipe(htmlclean(cleanOptions))
        .pipe(htmlmin(minOption))
        .pipe(gulp.dest("./public"));
});

// 压缩 public/medias 目录内图片
gulp.task("compressImage", function () {
    var option = {
        optimizationLevel: 5, //类型：Number 默认：3 取值范围：0-7（优化等级）
        progressive: true, //类型：Boolean 默认：false 无损压缩jpg图片
        interlaced: false, //类型：Boolean 默认：false 隔行扫描gif进行渲染
        multipass: false //类型：Boolean 默认：false 多次优化svg直到完全优化
    };
    return gulp
        .src("./public/medias/**/*.*")
        .pipe(gulpif(!isScriptAll, changed("./public/medias")))
        .pipe(gulpif(isDebug, debug({ title: "Compress Images:" })))
        .pipe(plumber())
        .pipe(imagemin(option))
        .pipe(gulp.dest("./public"));
});
// 执行顺序： 清除public目录 -&gt; 产生原始博客内容 -&gt; 执行压缩混淆 -&gt; 部署到服务器
gulp.task(
    "cicd",
    gulp.series(
        "clean",
        "generate",
        "compressHtml",
        "compressCss",
        "compressJs",
        "compressImage",
        gulp.parallel("deploy")
    )
);

// 默认任务
gulp.task(
    "ci",
    gulp.series(
        "clean",
        "generate",
        gulp.parallel("compressHtml", "compressCss", "compressJs","compressImage")
    )
);

// 默认任务
gulp.task(
    "default",
    gulp.series(
        gulp.parallel("compressHtml", "compressCss", "compressJs","compressImage")
    )
);
//Gulp4最大的一个改变就是gulp.task函数现在只支持两个参数，分别是任务名和运行任务的函数
运行：
hexo clean &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp;  hexo g
gulp 只执行压缩功能。直接在 Hexo 根目录执行  gulp ci ，这个命令相当于 hexo cl&amp;&amp;hexo g 并且再把代码和图片压缩。 在 Hexo 根目录执行 gulp cicd ，这个命令与前一个相比是：在最后又加了个 hexo d ，等于说生成、压缩文件后又帮你自动部署了
如果不想用图片压缩可以把文件中的 "compressImage" 去掉即可
博客中插入音乐
hexo-tag-aplayer
hexo-tag-aplayerAPlayer 播放器的 Hexo 标签插件（现已支持 MetingJS）。
安装
npm install --save hexo-tag-aplayer
使用方法 ——aplayer
{% aplayer title author url [picture_url, narrow, autoplay, width:xxx, lrc:xxx] %}

title : 曲目标题
author: 曲目作者
url: 音乐文件 URL 地址
picture_url: (可选) 音乐对应的图片地址
narrow: （可选）播放器袖珍风格
autoplay: (可选) 自动播放，移动端浏览器暂时不支持此功能
width:xxx: (可选) 播放器宽度 (默认: 100%)
lrc:xxx: （可选）歌词文件 URL 地址
例如：

{% aplayer "她的睫毛" "周杰伦" "http://home.ustc.edu.cn/~mmmwhy/%d6%dc%bd%dc%c2%d7%20-%20%cb%fd%b5%c4%bd%de%c3%ab.mp3"  "http://home.ustc.edu.cn/~mmmwhy/jay.jpg" %}
如果你觉得前面的方法不太好用，可以用下面的方法，使用 MetingJS。
使用方法 ——MetingJS
MetingJS 是基于 Meting API 的 APlayer 衍生播放器，支持对于 QQ 音乐、网易云音乐、虾米、酷狗、百度等平台的音乐播放。
第一步：修改_config.yml 配置
在 hexo 的配置文件_config.yml 中添加：
aplayer:
	meting: true
第二步：使用 MetingJS 播放器
&lt;!-- 简单示例 (id, server, type)  --&gt;
{% meting "571184509" "xiami" "playlist" %}
有关的选项列表如下:



选项
默认值
描述




 id
 必须值
歌曲 id / 播放列表 id / 相册 id / 搜索关键字


 server
 必须值
音乐平台: netease, tencent, kugou, xiami, baidu


type
 必须值
song, playlist, album, search, artist


fixed
false
开启固定模式


 mini
false
开启迷你模式


 loop
all
列表循环模式：all, one,none


order
list
列表播放模式： list, random


volume
0.7
 播放器音量


 lrctype
0
 歌词格式类型


 listfolded
false
指定音乐播放列表是否折叠


 storagename
metingjs
LocalStorage 中存储播放器设定的键名


 autoplay
true
自动播放，移动端浏览器暂时不支持此功能


 mutex
true
该选项开启时，如果同页面有其他 aplayer 播放，该播放器会暂停


 listmaxheight
340px
播放列表的最大长度


 preload
auto
音乐文件预载入模式，可选项： none, metadata, auto


theme
#ad7a86
播放器风格色彩设置



博客中插入视频
hexo-tag-dplayer
hexo-tag-dplayer 是 DPlayer 播放器的 Hexo 标签插件
安装
npm install --save hexo-tag-dplayer
使用
{% dplayer key=value ... %}
例：
{% dplayer "url=http://www.nenu.edu.cn/_upload/article/videos/03/5f/7c999eed42e3aadc413d7f851f0e/0f50b3eb-9285-41d2-ac4d-6cc363651aad_B.mp4"  "autoplay=true" "preload=metadata" "hotkey=true" %} 
有关的选项列表如下:



选项
默认值
描述




 url
 必须值
视频地址


 loop
false
视频循环播放


 volume
0.7
播放器音量


 hotkey
true
开启热键


 autoplay
true
自动播放，移动端浏览器暂时不支持此功能


 logo
-
在左上角展示一个 logo，你可以通过 CSS 调整它的大小和位置


 mutex
true
该选项开启时，如果同页面有其他播放，该播放器会暂停


 highlight
[]
自定义进度条提示点


 preload
auto
视频文件预载入模式，可选项： none, metadata, auto


theme
#ad7a86
播放器风格色彩设置



注：如果使用腾讯视频、优酷视频等在线视频网站的资源，需要先进行视频地址解析，如点量视频解析，获取到实际的视频地址。
其他使用方法
在使用优酷或者腾讯视频时可以直接复制分享代码到文章中，如：
&lt;iframe height=498 width=510 src='https://player.youku.com/embed/XMjk4ODAyMzIyOA==' frameborder=0 'allowfullscreen'&gt;&lt;/iframe&gt;
参考文献

hexo-tag-aplayer
hexo-tag-dplayer

网络优化篇
npm 下载速度加速

npm 下载太慢怎么办？ 修改国内淘宝源加速，戳

CDN 加速（强烈建议启用）

为什么强烈建议启用 CDN？


研究表明，用户最满意的打开网页时间，是在 2 秒以下。用户能够忍受的最长等待时间在 6～8 秒之间。就是说，8 秒是一个临界值，如果你的网站打开速度在 8 秒以上，那么你将失去大部分用户。研究显示，如果等待 12 秒以后，网页还是没有载入，那么 99% 以上的用户会选择关闭网页。
Google 做过一个试验，10 条搜索结果的页面载入时间需要 0.4 秒，显示 30 条搜索结果的页面载入时间需要 0.9 秒，结果后者使得 Google 总的流量和收入减少了 20%。Google 地图上线的时候，首页大小有 100KB，后来下降到 70~80KB。结果，流量在第一个星期上升了 10%，接下来的 3 个星期又再上升了 25%。Amazon 的统计也显示了相近的结果，首页打开时间每增加 100 毫秒，网站销售量会减少 1%。
以上数据说明了一个非常重要的问题，如果你的网站速度如果超过 2s 以上，那么你的客户可能在流失和离你而去了。这一点对于电商网站尤其重要，打开速度慢，那么将造成转化率降低，损失将会大量增加。

放在 Github 的资源在国内加载速度比较慢，因此需要使用 CDN 加速来优化网站打开速度，jsDelivr + Github 便是免费且好用的 CDN，非常适合博客网站使用。也可以选择主流云服务商提供的对象存储 + CDN 来获得更快速及稳定的访问效果，费用低到几乎可忽略。
用法：
https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径
例如：
https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2022/03/1120220311110247.webp
注意：版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源。

还可以配合 PicGo 图床上传工具的自定义域名前缀来上传图片，使用极其方便。具体使用方法可参见我的另一篇文章: 使用 Typora+iPic/PicGo 图床 + CDN 实现高效 Markdown 创作

Cloudflare CDN

配置最简单的 CDN 方式了。在 github  raw 链接地址前面加 https://images.weserv.nl/?url=, 就会自动使用 cloudflare cdn 来加速图片访问。使用发现无法加速 gif。

本 blog 主要使用这个方法，如下所示。

未加速图片地址 

https://raw.githubusercontent.com/appotry/cloudimg/main/data/2021/09/1020210910231815.png

Cloudflare 加速图片地址

# 使用了cloudflare partner 加速
https://cimg1.17lai.site/data/2021/09/1020210910231815.png
SEO 优化



搜索引擎优化，又称为 SEO，即 Search Engine Optimization，它是一种通过分析搜索引擎的排名规律，了解各种搜索引擎怎样进行搜索、怎样抓取互联网页面、怎样确定特定关键词的搜索结果排名的技术。Google 自动收录效果还不错，百度就差得远了（GitHub 不允许百度的 Spider 爬取 GitHub 上的内容）。


如果没有备案，百度 seo 是不会收录的！所以如果你有国内 vps，并且备案了，可以做百度 seo，如果没有，百度 seo 内容都不需要看了。



网域提交方式


自动提交
（分三种）

主动推送
自动推送
 sitemap（站点地图）



手动提交

即手动地将链接一次性提交给百度



一般自动提交比手动提交效果好一点，自动提交又从效率上来说：
主动推送 &gt; 自动推送 &gt; sitemap
自动提交的三种方式：

主动推送：最为快速的提交方式。将站点当天新产出链接通过此方式推送给百度，以保证新链接可以及时被百度收录。
自动推送：最为便捷的提交方式。将自动推送的 JS 代码部署在站点的每一个页面源代码中，当部署代码的页面在每次被浏览时，链接就会被自动推送给百度。可以与主动推送配合使用。
sitemap：您可以定期将网站链接放到 sitemap文件中，然后将 sitemap文件提交给百度。百度会周期性的抓取检查您提交的 sitemap，对其中的链接进行处理，但收录速度慢于主动推送。

使用 sitemap 方式推送
安装 sitemap 插件生成站点地图文件:
npm install hexo-generator-sitemap --save
npm install hexo-generator-baidu-sitemap --save  #百度专用
安装后直接执行 hexo cl&amp;&amp;hexo g -d 命令，就会在网站根目录生成 sitemap.xml 及 baidusitemap.xml 文件。

在博客目录的_config.yml 中添加如下代码

# 通用站点地图
sitemap:
  path: sitemap.xml

# 百度站点地图
baidusitemap:
  path: baidusitemap.xml
百度优化
登录百度搜索资源平台， 登录成功之后在 用户中心 –&gt; 站点管理 页面中点击添加网站，按提示操作。

添加网站

提示：由于百度的 spider 是爬取不到 GitHub 的内容的，所以在第三步验证网站的时候，建议选择 CNAME验证的方式。

经过以上步骤，百度已经知道有我们网站的存在了，但是百度还不知道我们的网站上有什么内容，所以要向百度推送我们的内容。点击 网站支持 –&gt; 数据引入 –&gt; 链接提交菜单，提交站点地图：

提交站点地图
另外，hexo-theme-matery 主题已经内置了 自动推送 的功能， 检查 themes/hexo-theme-matery/_config.yml 文件中如下配置:
# 百度搜索资源平台提交链接
baiduPush: true
自动推送的 JS 代码部署在站点的每一个页面源代码中，当页面在每次被浏览时，链接就会被自动推送给百度。
谷歌优化
登录 Google Search Console，点击添加资源，输入自己的域名，按提示操作。

添加资源

提示：需要进行 DNS 验证，进入 DNS 域名解析设置页面，按提示增加 TXT 记录，如下图:

DNS 验证内容填写示例

验证成功后，需要提交站点地图。参照下图提交，然后等待收录。

提交站点地图

注意：hexo 配置文件中的 url 一定要输入正确的域名，插件是根据 url 生成站点地图的。

其它搜索引擎


Bing 提交
神马站长


百度自动推送方式
只要每个需要被百度爬取的 HTML 页面中加入一段 JS 代码即可：
&lt;script&gt;
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
&lt;/script&gt;
我所使用的 matery 主题可以自动给每个页面加上这段代码，只需在主题配置文件中配置：
# 百度搜索资源平台提交链接
baiduPush: true
即可！
其他主题一般都有这个功能的实现，如果没有的话，想办法在每个页面加入以上 JS 代码即可，原理是一样。
百度主动推送 SEO 方式


配置文章自动推送到百度蜘蛛


获取百度推送密钥
在 百度资源 注册你的网址，验证完后可在站点管理-&gt;资源提交-&gt;链接提交-&gt;主动推送(实时) 中找到你的推送密钥，下面说明中的 token= 后的内容即为推送密钥。
推送接口
接口调用地址：http://data.zz.baidu.com/urls?site=https://ifibe.com&amp;token=xxxxxxxxxx
安装主动推送插件：hexo-baidu-url-submit
$ npm install hexo-baidu-url-submit --save
然后打开 hexo配置文件，在末尾加入以下配置：
# hexo-baidu-url-submit  百度主动推送
baidu_url_submit:
  count: 80 # 提交最新的一个链接
  host: https://blog.17lai.site # 在百度站长平台中注册的域名
  token: xxxxxxx # 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里!
  path: baidu_urls.txt # 文本文档的地址， 新链接会保存在此文本文档里
密匙的获取是在百度的自动提交的主动推送那里。

再加入新的 deploy：
deploy:
- type: baidu_url_submitter
如图：

这样每次执行 hexo d 的时候，新的链接就会被推送了。
$ hexo clean
$ hexo g
$ hexo d
推送成功时，会有如下终端提示！

各种不同的推送反馈字段说明点我查看，一般来说，推送失败基本都是地址不相符造成的，我们只需对比 baidu_url_submit 在 public 中生成的 baidu_urls.txt 的地址，与自己填写在 host 字段中的地址对比看是否一样即可。
Github Action 自动提交 SEO 方式
安装插件
npm i hexo-seo-autopush --save
配置
在 hexo 的 config.yml 里添加
hexo-seo-autopush 配置
# enable: 开启/关闭 推送
# count: 每次提交最新的10篇文章
# https://github.com/lete114/hexo-seo-autopush
hexo_seo_autopush:
  baidu:
    enable: true
    count: 100
  bing:
    enable: true
    count: 10
  google:
    enable: true
    count: 10
    google_file: google_service_account.json # 谷歌服务账户
添加 Google Push 配置和解决 push 后没有 GitHub Actions .github\workflows\AutoPush.yml 文件的问题
# Deployment
## Docs: https://hexo.io/docs/one-command-deployment
deploy:
   - type: git
     repo: https://github.com/lete114/Test.git
     branch: main
     ignore_hidden: false  # 忽略隐藏文件及文件夹(目录)
   - type: GooglePush # 谷歌提交
获取站长平台密钥
Baidu Key

打开百度站长平台，点击左侧的普通收录 https://ziyuan.baidu.com/


Bing Key

打开 Bing 站长平台，https://www.bing.com/webmasters/home
 点击右上角头像 旁边的齿轮，跟着下图操作


Google Key

Google Wiki， 使用参考。



打开 Google indexing API 官网


选择创建项目，点击继续


点击转到凭据页面


跟着如下图片步骤




json 文件内的内容
{
  "type": "service_account",
  "project_id": "elated-guild-298003",
  "private_key_id": "cf58d669c0e8c8e082b2c403ade5e2548078e384",
  "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDEAJw89yeylRrA\nB+bzOAfQQNgOCABIwEKCy5mMxWSaiXy2RktyCJWjMR2Pgz770NJgClQHPJjsFn0c\nukHufpnuiX3VPlimLANPCRFdU/qp+yiaw4quIhYF1UZJkhmhL30anghUcvi+r9hQ\nw+RwcKrgA4EUzqUJaPdvjtzSoo315PPGfR91ASD5S8gE02yVI8igtYMX7v2x1JYR\n7PwHJwOVemiM9lot8ilvoUbV4BU0vSlwFoxKMJAbEXTmJjEKQi9992rcMW0GzXO8\ncHldUUtURXkt3VFjYTH27KhHiTkTXw+uZRBu1rkubDJkS8lGIWN7Fc/r4HMMCVTu\nXPS6HbJ/AgMBAAECggEANSS7OBaFd3jRL3cVCiZLjA5A5pEJzq/+eKtOn2oYDISx\nwVRO+YTVWdGj47kg1zM4D11NikbGaeDxHFxuKwW9o/04lpyYebneTcw2Hpl6EiOs\nz0WssOlCEmPQ8nrAI0GWiKSHuqoPwtg37TIoGsqZsjKRCby759DDokZYnm3/0sc+\niEllT0ZyBZhGDzyguVLEdCIR2P02q/hQzLyd6ejWGGwZebImbGoILhmuOjVrco0p\nV0JbrrNskjM5Epe7w+CpGftEASJ7Dxa8oj0qIT6cyAipra2AZAGnG9jrLcWpJuhu\nvNeDIFnTfpNEac+khXZZE2++MIQfTX9wGJc8tox2vQKBgQD6yiNvAL7sxExiy6ER\ntLtFQ3bvmMpKRFGvFOyPOtMbmjZ3D1GEtNNKGH4v1TI+tncEy7Q5Dm7nWwpi8yvL\nbh8xKghelAc/CU1nw0xDEDCkMbAwpFg5A5ZDImy3LZsQh0kNXniIMy1vMSt5yLKS\n80gXQKGCxG8t3rP8Qd/2a55g1QKBgQDIExP1nG9sHJaigmitEUwr0Ow6Shqr56Me\nd7995gaV1oLWWCQzrXt/viWkb1W5ZGIxzcWNWz99m4CbvqfewRr598Eenald0csN\nVcIEk+0C+6KqA+jU9Tfs2zow/C7JuKULP2N++o0EoSz/ngokP7f1yLOYbr507v/R\n0cLElQBQAwKBgAbxDWYHKUG4dTzO0hiBXiWepm4fVooTtgcYlyunvywmapeFDwaT\nUr3cS7HbPtbJiiXR1Z02rw8sT+9JN88brzVXKoAjrMer5D6ZA0Vf71i8H1pZUi/R\nz5jwHP48/uvIMtdx4/gxInLPc5qdWYQDw90Q5ueNtF4aqfSzhhV2CR45AoGBAJN9\nPOF6iMjx6jmyWOf8MGK8iOgPaMoA4Ea9j/SHdaNPlvPb1hQid0AcNDObv14Dmj+M\nqW0jLxKxZ4VobufPAsvyz/J51zjKRx11cqldQwNH7QnYB/O1MZzxn1wtC3C5JTG9\ncONSYFJhXoKxRliigEI3ye089jnNVdifAS1ZiflxAoGBANTX1fEMEeNuYU0v3rtd\n5CkPZg4TNZ+y2MGl5xR1LdIgrJ8c9xKoW4rpp7SsOIvHpWX494f90D7o9uFEGSQ4\nyQK53jVzJ0ekGV5BdPF3n3/2j2VEqFLHi7LL4CJSxr6ci7OfBoHOGE8odhevQCCK\njnFzEin0QsBEgIC73fBh6XcH\n-----END PRIVATE KEY-----\n",
  "client_email": "googleindexing@elated-guild-298003.iam.gserviceaccount.com",
  "client_id": "103034240916368863393",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/googleindexing%40elated-guild-298003.iam.gserviceaccount.com"
}


打开谷歌站长平台




配置博客仓库


Name 必须是 baidu_token 和 bing_apikey(不区分大小写)


添加完成后



谷歌的一些问题
触发谷歌提交的命令是 hexo d
由于谷歌需要配合 Google indexing API 平台提供的 json 进行提交，而这个 json 格式不能泄露
为防止 json 泄露只能本地提交，将 json 放到 hexo 根目录可自定义重命名 (必须对应插件的配置)
如果你的使用Github Actions自动部署的话请把仓库设置为私有

提交成功返回状态码
以上步骤完成后即可 hexo d 部署了


看看 Github 仓库是否上传成功



点击 Actions 查看是否执行



点击 Auto Push—-&gt;build—–&gt; 点击第 2 步 自动提交
如图 43 行

// baidu返回的结果
{
	"remain": 2060,  // 表示当天剩余的可推送url条数
	"success": 47    // 成功推送的url条数
} 
// bing返回结果(错误)
{
	"ErrorCode": 2,  // 错误 
	"Message": "ERROR!!! Quota remaining for today: 2, Submitted: 47"
    // Message：表示 你目前只剩2个url推送，而你现在推送的是47条url
    // bing新用户开始每日只有10个推送额，据我了解连续推送10天(这我也不确定)
    // 如果出现这个错误的话，你就只能先手动添加等系统给你分配额了(分配9999)
}
// bing返回结果(成功)
{"d":null}


Google 返回状态码
成功返回
Google response:  {
  urlNotificationMetadata: {
    url: 'https://blog.lete114.top/article/hexo-seo-autopush.html',
    latestUpdate: {
      url: 'https://blog.lete114.top/article/hexo-seo-autopush.html',
      type: 'URL_UPDATED',
      notifyTime: '2020-12-08T02:31:32.871417693Z'
    }
  }
}
出现此错误需要：翻墙
FetchError: request to https://www.googleapis.com/oauth2/v4/token failed, reason: connect ETIMEDOUT 172.217.27.138:443
    at ClientRequest.&lt;anonymous&gt; (D:\Lete\GitHub\Hexo-Butterfly\node_modules\node-fetch\lib\index.js:1461:11)
    at ClientRequest.emit (events.js:321:20)
    at TLSSocket.socketErrorListener (_http_client.js:426:9)
    at TLSSocket.emit (events.js:321:20)
    at emitErrorNT (internal/streams/destroy.js:92:8)
    at emitErrorAndCloseNT (internal/streams/destroy.js:60:3)
    at processTicksAndRejections (internal/process/task_queues.js:84:21) {
  message: 'request to https://www.googleapis.com/oauth2/v4/token failed, reason: connect ETIMEDOUT 172.217.27.138:443',
  type: 'system',
  errno: 'ETIMEDOUT',
  code: 'ETIMEDOUT',
  config: {
    method: 'POST',
    url: 'https://www.googleapis.com/oauth2/v4/token',
    data: {
      grant_type: 'urn:ietf:params:oauth:grant-type:jwt-bearer',
      assertion: 'eyJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJnb29nbGVpbmRleGluZ0BzdGF0ZWx5LXRyYW5zaXQtMjk3NzE1LmlhbS5nc2VydmljZWFjY291bnQuY29tIiwic2NvcGUiOiJodHRwczovL3d3d


本地主动提交 SEO

hexo-url-submission
Wiki

安装方法

在终端中输入：

npm i hexo-url-submission

在 blog/_config.yml 文件中添加配置：

url_submission:
   enable: true
   type: 'latest' # latest or all( latest: modified pages; all: posts &amp; pages)
   channel: ['baidu', 'bing', 'google', 'shenma'] # Included channels are `baidu`, `google`, `bing`, `shenma`
   prefix: ['/post', '/wiki'] # URL prefix
   count: 10 # Submit limit
   proxy: '' # Set the proxy used to submit urls to Google
   urls_path: 'submit_url.txt' # URL list file path
   baidu_token: '' # Baidu private key
   bing_token: '' # Bing private key
   google_key: '' # Google key path (e.g. `google_key.json` or `data/google_key.json`)
   shenma_token: '' # ShenMa private key
   shenma_user: '' # Username used when registering
   sitemap: '' # Sitemap path(e.g. the url is like this https://abnerwei.com/baidusitemap.xml, you can fill in `baidusitemap.xml`)
更新方法
在站点根目录执行：
npm update hexo-url-submission
deploy
deploy:
  - type: us_baidu_deployer
  - type: us_bing_deployer
  - type: us_google_deployer
  - type: us_shenma_deployer
good job
Run:
hexo clean &amp;&amp; hexo g &amp;&amp; hexo d
enjoy it!
提交 robots.txt
robots.txt 是干嘛的？

robots.txt 是一种存放于网站根目录下的 ASCII 编码的文本文件，它的作用是告诉搜索引擎此网站中哪些内容是可以被爬取的，哪些是禁止爬取的。
robots.txt 要放在 Hexo根目录 下的 source 文件夹中。

每个人站点目录可能不太一样，可以参考下我的 robots.txt 文件，内容如下：
User-agent: *
Allow: /
Allow: /posts/
Disallow: /about/
Disallow: /archives/
Disallow: /js/
Disallow: /css/
Disallow: /contact/
Disallow: /fonts/
Disallow: /friends/
Disallow: /libs/
Disallow: /medias/
Disallow: /page/
Disallow: /tags/
Disallow: /categories/
更多关于 robots.txt 的写法参见 https://blog.csdn.net/fanghua_vip/article/details/79535639
编写完以上内容再重新部署一下，然后到百度资源平台的数据监控 -&gt;Robots 点击检测并更新 看能不能检测到。
配置 Nofollow

nofollow 是 HTML 页面中 a标签 的 属性值。
这个属性的作用是：告诉搜索引擎的爬虫不要追踪该链接，为了对抗博客垃圾留言信息

URL 优化
一般来说，SEO 搜索引擎优化认为，网站的最佳结构是 用户从首页点击三次就可以到达任何一个页面，但是我们使用 Hexo 编译的站点结构的 URL 是：域名/年/月/日/文章标题四层的结构，这样的 URL 结构很不利于 SEO，爬虫就会经常爬不到我们的文章，于是，我们需要优化一下网站文章的 URL
方案一：
直接改成域名/文章标题的形式，在 Hexo配置文件中修改 permalink 如下：
# URL
## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'
url: https://blog.sky03.cn
root: /
permalink: :title.html
permalink_defaults:
这个方式有个不好的地方：
直接以文章的标题作为 URL，而我们所写的文章的标题一般都是中文，但是 URL 只能用字母数字和标点符号表示，所以中文的 URL 只能被转义成一堆符号，而且还特别长。
方案二：
安装固定链接插件：hexo-abbrlink
插件作用：自动为每篇文章生成一串数字作每篇文章的 URI 地址。每篇文章的 Front-matter 中会自动增加一个配置项：abbrlink: xxxxx，该项的值就是当前文章的 URI 地址。


Hexo 根目录执行：
npm install hexo-abbrlink --save


Hexo配置文件末尾加入以下配置：
# hexo-abbrlink config 、固定文章地址插件
abbrlink:
  alg: crc16  #算法选项：crc16、crc32，区别见之前的文章，这里默认为crc16丨crc32比crc16复杂一点，长一点
  rep: dec    #输出进制：十进制和十六进制，默认为10进制。丨dec为十进制，hex为十六进制


Hexo配置文件中修改 permalink 如下：
# URL
## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'
url: https://blog.17lai.site
root: /
permalink: posts/:abbrlink.html
permalink_defaults:


这样站点结构就变成了：域名/posts/xxx.html
异步加载 JS
方法：将 JS 文件的引入，放到 HTML 的 body 结束标签的上方
例：
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;Hello World!&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        xxxxx....
        &lt;script src="xx/xx.js"&gt;&lt;/script&gt;
    &lt;/body&gt;
&lt;/html&gt;
原理：首先要明白，HTML 的加载是从上往下一行一行解释执行的，把 js 文件的引入放到下面，这样就会先把 HTML 页面展示出来，然后再加载 js。这样看起来的效果就是，大体的页面先出来，而 js 让它慢慢加载执行，如果你把 js 放到网页的上方，效果就是必须要加载完 js 才能继续展示网页，体验极差。
注意：原主题的 js 文件尽量不要动，我们只需将自己增加的一些 js 按照异步加载的方式做即可，比如一些音乐 js 插件、实时在线聊天 js 插件等放到最后即可！因为这些文件要加载的东西很多。
字蛛压缩字体

在上面我们介绍了如何在网站上引用自己喜欢的字体，但是这样会出现一个问题：字体文件太大！（尤其是中文，有时候为了几个字引入一个数十兆的字体文件，得不偿失），所有需要字体压缩！

官网  GitHub
使用场景
你的网站中需要自定义字体（额外添加一些普通电脑中没有的字体），但是一般字体是包含很多字符的，这就导致字体文件的体积很大
字蛛作用
字蛛就是自动检测网站的 CSS 与 HTML 文件中的自定义字体（额外加的字体），并将网站中用到的文字重新打包成一个新的字体文件，并自动引入；
而没用到的文字就会删除，从而达到压缩字体文件体积的作用。
安装
npm install font-spider -g
在 CSS 中使用 WebFont：
/*声明 WebFont*/
@font-face {
  font-family: 'pinghei';
  src: url('../font/pinghei.eot');
  src:
    url('../font/pinghei.eot?#font-spider') format('embedded-opentype'),
    url('../font/pinghei.woff') format('woff'),
    url('../font/pinghei.ttf') format('truetype'),
    url('../font/pinghei.svg') format('svg');
  font-weight: normal;
  font-style: normal;
}

/*使用选择器指定字体*/
.home h1, .demo &gt; .test {
    font-family: 'pinghei';
}


@font-face 中的 src 定义的 .ttf 文件必须存在，其余的格式将由工具自动生成
开发阶段请使用相对路径的 CSS 与 WebFont


运行 font-spider 命令：
font-spider ./demo/*.html

页面依赖的字体将会自动压缩好，原 .ttf 字体会备份

webp 图像大小优化

把所有图像都转换为 webp 格式，可以极大减小图片体积，加快加载速度。

gulp 体积压缩


减小体积，加快加载速度
因为 hexo 生成的 html、css、js 等都有很多的空格或者换行，而空格和换行也是占用字节的，所以需要将空格换行去掉也就是我要进行的 “压缩”。


npm install gulp -g
# 安装各种小功能模块  执行这步的时候，可能会提示权限的问题，最好以管理员模式执行
npm install gulp gulp-htmlclean gulp-htmlmin gulp-minify-css gulp-uglify gulp-imagemin --save
# 额外的功能模块
npm install gulp-debug gulp-clean-css gulp-changed gulp-if gulp-plumber gulp-babel babel-preset-es2015 del @babel/core --save
 
或者使用yarn 
 
yarn global add gulp
yarn add gulp gulp-htmlclean gulp-htmlmin gulp-minify-css gulp-uglify gulp-imagemin
yarn add gulp-debug gulp-clean-css gulp-changed gulp-if gulp-plumber gulp-babel babel-preset-es2015 del @babel/core


npm 下载太慢怎么办？ 修改国内淘宝源加速，戳


然后，在根目录新增 gulpfile.js :
var gulp = require("gulp");
var debug = require("gulp-debug");
var cleancss = require("gulp-clean-css"); //css压缩组件
var uglify = require("gulp-uglify"); //js压缩组件
var htmlmin = require("gulp-htmlmin"); //html压缩组件
var htmlclean = require("gulp-htmlclean"); //html清理组件
var imagemin = require("gulp-imagemin"); //图片压缩组件
var changed = require("gulp-changed"); //文件更改校验组件
var gulpif = require("gulp-if"); //任务 帮助调用组件
var plumber = require("gulp-plumber"); //容错组件（发生错误不跳出任务，并报出错误内容）
var isScriptAll = true; //是否处理所有文件，(true|处理所有文件)(false|只处理有更改的文件)
var isDebug = true; //是否调试显示 编译通过的文件
var gulpBabel = require("gulp-babel");
var es2015Preset = require("babel-preset-es2015");
var del = require("del");
var Hexo = require("hexo");
var hexo = new Hexo(process.cwd(), {}); // 初始化一个hexo对象

// 清除public文件夹
gulp.task("clean", function () {
    return del(["public/**/*"]);
});

// 下面几个跟hexo有关的操作，主要通过hexo.call()去执行，注意return
// 创建静态页面 （等同 hexo generate）
gulp.task("generate", function () {
    return hexo.init().then(function () {
        return hexo
            .call("generate", {
                watch: false
            })
            .then(function () {
                return hexo.exit();
            })
            .catch(function (err) {
                return hexo.exit(err);
            });
    });
});

// 启动Hexo服务器
gulp.task("server", function () {
    return hexo
        .init()
        .then(function () {
            return hexo.call("server", {});
        })
        .catch(function (err) {
            console.log(err);
        });
});

// 部署到服务器
gulp.task("deploy", function () {
    return hexo.init().then(function () {
        return hexo
            .call("deploy", {
                watch: false
            })
            .then(function () {
                return hexo.exit();
            })
            .catch(function (err) {
                return hexo.exit(err);
            });
    });
});

// 压缩public目录下的js文件
gulp.task("compressJs", function () {
    return gulp
        .src(["./public/**/*.js", "!./public/libs/**"]) //排除的js
        .pipe(gulpif(!isScriptAll, changed("./public")))
        .pipe(gulpif(isDebug, debug({ title: "Compress JS:" })))
        .pipe(plumber())
        .pipe(
            gulpBabel({
                presets: [es2015Preset] // es5检查机制
            })
        )
        .pipe(uglify()) //调用压缩组件方法uglify(),对合并的文件进行压缩
        .pipe(gulp.dest("./public")); //输出到目标目录
});

// 压缩public目录下的css文件
gulp.task("compressCss", function () {
    var option = {
        rebase: false,
        //advanced: true, //类型：Boolean 默认：true [是否开启高级优化（合并选择器等）]
        compatibility: "ie7" //保留ie7及以下兼容写法 类型：String 默认：''or'*' [启用兼容模式； 'ie7'：IE7兼容模式，'ie8'：IE8兼容模式，'*'：IE9+兼容模式]
        //keepBreaks: true, //类型：Boolean 默认：false [是否保留换行]
        //keepSpecialComments: '*' //保留所有特殊前缀 当你用autoprefixer生成的浏览器前缀，如果不加这个参数，有可能将会删除你的部分前缀
    };
    return gulp
        .src(["./public/**/*.css", "!./public/**/*.min.css"]) //排除的css
        .pipe(gulpif(!isScriptAll, changed("./public")))
        .pipe(gulpif(isDebug, debug({ title: "Compress CSS:" })))
        .pipe(plumber())
        .pipe(cleancss(option))
        .pipe(gulp.dest("./public"));
});

// 压缩public目录下的html文件
gulp.task("compressHtml", function () {
    var cleanOptions = {
        protect: /&lt;\!--%fooTemplate\b.*?%--&gt;/g, //忽略处理
        unprotect: /&lt;script [^&gt;]*\btype="text\/x-handlebars-template"[\s\S]+?&lt;\/script&gt;/gi //特殊处理
    };
    var minOption = {
        collapseWhitespace: true, //压缩HTML
        collapseBooleanAttributes: true, //省略布尔属性的值 &lt;input checked="true"/&gt; ==&gt; &lt;input /&gt;
        removeEmptyAttributes: true, //删除所有空格作属性值 &lt;input id="" /&gt; ==&gt; &lt;input /&gt;
        removeScriptTypeAttributes: true, //删除&lt;script&gt;的type="text/javascript"
        removeStyleLinkTypeAttributes: true, //删除&lt;style&gt;和&lt;link&gt;的type="text/css"
        removeComments: true, //清除HTML注释
        minifyJS: true, //压缩页面JS
        minifyCSS: true, //压缩页面CSS
        minifyURLs: true //替换页面URL
    };
    return gulp
        .src("./public/**/*.html")
        .pipe(gulpif(isDebug, debug({ title: "Compress HTML:" })))
        .pipe(plumber())
        .pipe(htmlclean(cleanOptions))
        .pipe(htmlmin(minOption))
        .pipe(gulp.dest("./public"));
});

// 压缩 public/medias 目录内图片
gulp.task("compressImage", function () {
    var option = {
        optimizationLevel: 5, //类型：Number 默认：3 取值范围：0-7（优化等级）
        progressive: true, //类型：Boolean 默认：false 无损压缩jpg图片
        interlaced: false, //类型：Boolean 默认：false 隔行扫描gif进行渲染
        multipass: false //类型：Boolean 默认：false 多次优化svg直到完全优化
    };
    return gulp
        .src("./public/medias/**/*.*")
        .pipe(gulpif(!isScriptAll, changed("./public/medias")))
        .pipe(gulpif(isDebug, debug({ title: "Compress Images:" })))
        .pipe(plumber())
        .pipe(imagemin(option))
        .pipe(gulp.dest("./public"));
});
// 执行顺序： 清除public目录 -&gt; 产生原始博客内容 -&gt; 执行压缩混淆 -&gt; 部署到服务器
gulp.task(
    "cicd",
    gulp.series(
        "clean",
        "generate",
        "compressHtml",
        "compressCss",
        "compressJs",
        "compressImage",
        gulp.parallel("deploy")
    )
);
gulp.task(
    "ci",
    gulp.series(
        "clean",
        "generate",
        gulp.parallel("compressHtml", "compressCss", "compressJs","compressImage")
    )
);
// 默认任务
gulp.task(
    "default",
    gulp.series(
        gulp.parallel("compressHtml", "compressCss", "compressJs","compressImage")
    )
);
//Gulp4最大的一个改变就是gulp.task函数现在只支持两个参数，分别是任务名和运行任务的函数
运行：
hexo clean &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp;  hexo g
直接在 Hexo 根目录执行 gulp ci，这个命令相当于 hexo cl&amp;&amp;hexo g 并且再把代码和图片压缩。 在 Hexo 根目录执行 gulp cicd ，这个命令与 gulp ci 相比是：在最后又加了个 hexo d ，等于说生成、压缩文件后又帮你自动部署了
如果不想用图片压缩可以把 "compressImage" 去掉即可
本地搜索优化
html、css 和 js 都压缩了，很开心。但是，还有一个大文件没有压缩，就是本地搜索的 DB 文件 search.xml。这个 search.xml 文件的大小为 7.5M，很大。
打开 search.xml 文件，发现里面不止包含文章内容，还包含 html 标签。参考 hexo-generator-searchdb，发现可以设置不生成标签。

修改 hexo/_config.yml 的 localsearch 配置为：

# local search
search:
  path: search.xml
  field: post
  format: striptags
  limit: 10000

重新生成 search.xml 文件



还可以给 search.xml 添加上 jsdelivr cdn 加速！


hexo 部署篇
Hexo Docker 本地部署
在最前面的篇章介绍了 Hexo Docker 环境的使用方法。具体使用方法见本文系列 [Hexo Docker 环境篇]。
优点：本地使用可定制化成都更高
缺点：必须要有 Docker 环境。异地使用麻烦，除非 ssh,vpn 等远程链接方法。
将 Hexo 部署到 vps，实现自动发布
搭建流程

服务器环境配置，安装 Git、Nginx 配置、创建 git 用户
本地 hexo 初始化
使用 Git 自动部署并发布博客

服务器环境搭建

安装 Git 和 NodeJS (Centos 环境)

yum install git
# 安装NodeJS 
curl --silent --location https://rpm.nodesource.com/setup_5.x | bash -

创建 git 账号 

adduser git
chmod 740 /etc/sudoers
vim /etc/sudoers

添加内容
找到

## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL

添加以下内容 

git     ALL=(ALL)     ALL

保存退出并改回权限 

chmod 400 /etc/sudoers

设置 git 账号密码 

sudo passwd git

使用 su git 切换到 git 用户，再执行下列操作：

# 切换到git用户目录
cd /home/git
# 创建.ssh文件夹
mkdir ~/.ssh
# 创建authorized_keys文件并编辑
vim ~/.ssh/authorized_keys
# 如果你还没有生成公钥，那么首先在本地电脑中执行 cat ~/.ssh/id_rsa.pub | pbcopy生成公钥
# 再将公钥复制粘贴到authorized_keys
# 保存关闭authorized_keys后，修改相应权限
chmod 600 ~/.ssh/authorized_keys
chmod 700 ~/.ssh

然后可以通过本地 Git Bash 执行 ssh 命令测试是否可以免密登录 

ssh -v git@服务器ip地址
这样 git 用户就添加好了。

Tips: 将公钥拷贝到服务器的～/.ssh/authorized_keys 文件中方法有如下几种：

将公钥通过 scp 拷贝到服务器上，然后追加到～/.ssh/authorized_keys 文件中，这种方式比较麻烦。scp -P 22 ~/.ssh/id_rsa.pub user@host:~/。
通过 ssh-copy-id 程序，就是我演示的方法，ssh-copyid user@host 即可
可以通过 cat ~/.ssh/id_rsa.pub | ssh -p 22 user@host ‘cat &gt;&gt; ~/.ssh/authorized_keys’，这个也是比较常用的方法，因为可以更改端口号。



安装 Nginx
 准备工作
首先由于 nginx 的一些模块依赖一些 lib 库，所以在安装 nginx 之前，必须先安装这些 lib 库，这些依赖库主要有 g++、gcc、openssl-devel、pcre-devel 和 zlib-devel 所以执行如下命令安装 

yum install gcc-c++
yum install pcre pcre-devel
yum install zlib zlib-devel
yum install openssl openssl--devel
Ubuntu 系统安装命令如下：
sudo apt-get install libpcre3 libpcre3-dev
sudo apt-get install zlib1g-dev
sudo apt-get install openssl libssl-dev

安装 Nginx
安装之前，最好检查一下是否已经安装有 nginx

find -name nginx
如果系统已经安装了 nginx，那么就先卸载
yum remove nginx
然后开始安装
首先进入 /usr/local 目录
cd /usr/local
从官网下载最新版的 nginx
wget -c https://nginx.org/download/nginx-1.14.2.tar.gz 
（注：版本号可更改，去官网查看最新版本号修改即可）
解压 nginx 压缩包
tar -zxvf nginx-1.14.2.tar.gz
会产生一个 nginx-1.14.2 目录，这时进入 nginx-1.14.2 目录
cd  nginx-1.14.2
接下来安装，使用–prefix 参数指定 nginx 安装的目录，make、make install 安装
./configure
（默认安装在 /usr/local/nginx，推荐使用默认设置）

make

make install

如果没有报错，顺利完成后，最好看一下 nginx 的安装目录
whereis nginx
（where 和 is 要连这些，中间没有空格）


启动和停止 nginx

cd /usr/local/nginx/sbin/
./nginx 
./nginx -s stop
./nginx -s quit
./nginx -s reload
./nginx -s quit: 此方式停止步骤是待nginx进程处理任务完毕进行停止。
./nginx -s stop: 此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。
查询 nginx 进程：
ps aux | grep nginx


重启 nginx


 先停止再启动（推荐）：
对 nginx 进行重启相当于先停止再启动，即先执行停止命令再执行启动命令。如下：

./nginx -s quit
./nginx

重新加载配置文件：
当 nginx 的配置文件 nginx.conf 修改后，要想让配置生效需要重启 nginx，使用 -s reload 不用先停止 nginx 再启动 nginx 即可将配置信息在 nginx 中生效，如下：

./nginx -s reload
启动成功后，在浏览器可以看到如下页面：


开机自启动

即在 rc.local 增加启动代码就可以了。
vim /etc/rc.local
增加一行
/usr/local/nginx/sbin/nginx
到这里，nginx 安装完毕，启动、停止、重启操作也都完成。
建立 git 裸库
# 回到git目录
cd /home/git
# 使用git用户创建git裸仓库，以blog.git为例
git init --bare blog.git
检查用户组权限
我们的 git 裸仓库已经建立好了，离成功又近了一步。为了以防万一，我们要检查一下之前的 blog.git、.ssh、blog 目录的用户组权限是否都为 git:git
# 还记得/var/www/吗？这是之前配置nginx时，我们自己选定的网站根目录，请依据你自己的设置更改，如果没有的话自己
ll -a /www/wwwroot/hexo
ll -a /home/git/
如果有哪个不是，执行下面相应的命令后再查看
sudo chown -R git:git /www/wwwroot/hexo
sudo chmod -R 755 /www/wwwroot/hexo
sudo chown git:git -R /home/git/blog.git
使用 git-hooks 同步网站根目录
简单来说，我们使用一个钩子文件：post-receive，每当 git 仓库接收到内容的时候，就会自动调用这个钩子，把内容同步到网站根目录。
在 git 用户下执行：
# 新建一个post-receive文件并编辑
vim ~/blog.git/hooks/post-receive
在里面输入以下内容，注意修改为自己的设置：
#!/bin/bash
set -e
GIT_REPO=/home/git/blog.git
TMP_GIT_CLONE=/tmp/blog
PUBLIC_WWW=/www/wwwroot/hexo
rm -rf ${TMP_GIT_CLONE}
git clone -b main $GIT_REPO $TMP_GIT_CLONE
cd $TMP_GIT_CLONE
#for b in `git branch -r | grep -v -- '-&gt;'`; do git branch --track ${b##origin/} $b; done
#git checkout main
rm -rf ${PUBLIC_WWW}/*
cp -rf ${TMP_GIT_CLONE}/* ${PUBLIC_WWW}
echo "update web done!"
#ls -al ${PUBLIC_WWW}
rm -rf ${TMP_GIT_CLONE}
保存退出后，执行以下赋予这个文件可执行权限。
chown -R git:git ~/blog.git/hooks/post-receive
chmod +x ~/blog.git/hooks/post-receive
好了，以上就是服务器端需要配置的内容。我们还差最后一步就可以完成整个部署了！
修改配置文件 nginx.conf
修改上面的配置文件：
vim /usr/local/nginx/conf/nginx_config
然后修改其中两个部分，如下所示：

然后重启nginx，方法见 nginx安装部分。
配置本地 Hexo 的_config.yml
非常简单，只需要找到本地 Hexo 博客的站点配置文件_config.yml，找到以下内容并修改：
deploy: 
  type: git
  repo: git@你的服务器IP:/home/git/blog.git
  branch: master
保存后，剩下的就是 Hexo 的日常操作了，这里就不赘述了，写完文章后，在你的本地博客根目录执行以下命令：
hexo c &amp;&amp; hexo g -d
就可以实现线上博客的自动更新了！一切搞定！
Rsync 同步部署静态文件方法

使用 rsync 同步

本地生成静态文件后 rsync 同步到 vps 网页目录，lnap 使用宝塔配置，这里只需要一个 nginx。
# rsync [options] from_dir to_dir
# 替换这里的ip为你的服务器ip
rsync -avzP  /home/17lai.blog  root@8.8.8.8:/www/wwwroot/hexo
Hexo Github Action 自动部署
准备

Hexo 博客源码的仓库，在 GitHub 上。
ssh 密钥，参考文章：Windows 下利用 Git 生成 SSH KEY 并配置到 GitHub

步骤

为需要部署的平台添加密钥
修改 _config.yml 中的 deploy 配置
在 GitHub 上设置 Secrets
创建 GitHub Action

为需要部署的平台添加密钥
按照之前的教程，只要你之前成功将 Hexo 的博客部署到 GitHub 上，那你电脑在 ~/.ssh 目录下一定有以下三个文件：

id_rsa：私钥
id_rsa.pub：公钥
known_hosts：记录对所有用户都可信赖的远程主机的公钥

将 id_rsa.pub（公钥）添加到不同平台中即可，参考文章：Windows 下利用 Git 生成 SSH KEY 并配置到 GitHub
下面是不同平台添加的地址：

GitHub
GitLab
Coding
Gitee

修改 _config.yml 中的 deploy 配置
请使用 ssh (即以 git@ 开头的 clone 链接) 的连接方式，根据直接的实际地址填写。
deploy:
  - type: git
    repo:
      github: git@github.com:Sitoi/Sitoi.github.io.git
      coding: git@e.coding.net:Sitoi/Sitoi.git
      gitee: git@gitee.com:sitoi/sitoi.git
      gitlab: git@gitlab.com:Sitoi/sitoi.gitlab.io.git
    branch: master
在 GitHub 上设置 Secrets


进入到你在 GitHub 上面的源码仓库


点击右上角的 Settings



Settings


点击左侧的 Secrets


点击右上角的 New secret



New secret

在 Name 中输入 HEXO_DEPLOY_PRI，在 Value 中填入 id_rsa（私钥）的全部内容


Add secret
创建 GitHub Action

点击项目上方的 Action 按钮


Action

点击 set up a workflow yourself 创建 Workflow


Workflow

修改 main.yaml 的内容


Create Workflow

根据实际情况修改成你自己的内容


Git 推送使用的用户名：git config –global user.name ‘sitoi’：
Git 推送使用的邮箱：git config –global user.email ‘133397418@qq.com‘
Hexo 的版本：npm i hexo@4.1.1 -g

name: Hexo CI

on:
  push:
    branches:
      - butterfly

jobs:
  butterfly-build:

    runs-on: ubuntu-latest

    strategy:
      matrix:
        node-version: [10.x]

    steps:
      - uses: actions/checkout@v1
      - name: Use Node.js 10.x
        uses: actions/setup-node@v1
        with:
          node-version: '10.x'
      - name: env prepare
        env:
          HEXO_DEPLOY_PRI: ${{ secrets.HEXO_DEPLOY_PRI }}
        run: |
          mkdir -p ~/.ssh/
          echo "$HEXO_DEPLOY_PRI" &gt; ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts
          ssh-keyscan gitlab.com &gt;&gt; ~/.ssh/known_hosts
          ssh-keyscan e.coding.net &gt;&gt; ~/.ssh/known_hosts
          ssh-keyscan gitee.com &gt;&gt; ~/.ssh/known_hosts
          git config --global user.name 'sito'
          git config --global user.email '133397418@qq.com'
          npm i
          npm i hexo@4.1.1 -g
      - name: gen
        run: |
          hexo clean
          hexo generate
          hexo deploy

将你的源码推送到 GitHub 上，你的博客一会就会自动更新了。

以 token 方式部署到 Github
deploy:
  type: git
  repo:
    github:
      url: &lt;repository url&gt;
      branch: [branch]
      token: ''
  message: [message]
  name: [git user]
  email: [git email]
  extend_dirs: [extend directory]
  ignore_hidden: false # default is true
  ignore_pattern: regexp  # whatever file that matches the 
travis 自动部署配置

travis 是第三方 CICD 服务，比 action 更加强大，下面只是参考，请查阅 travis 文档，并结合自己的环境修改！

sudo: false
language: node_js
node_js:
- 10.16.3
cache: npm
branches:
  only:
  - master # build master branch only

env:
  global:
  - GIT_USER: appotry
  - HEXO_BACKUP_REPO: github.com/appotry/hexo-backup.git
  - HEXO_THEME_REPO: github.com/appotry/hexo-theme-matery.git
  - GITHUB_PAGES_REPO: github.com/appotry/hexo.github.io.git
  - APPOTRY_REPO: github.com/appotry/hexo.git

before_install:
- export TZ='Asia/Shanghai'
- npm install hexo -g
- npm install gulp-cli -g

install:
- npm install

script:
- git clone https://${HEXO_THEME_REPO} themes/next
- git clone https://${GIT_USER}:${GITHUB_TOKEN}@${HEXO_BACKUP_REPO} hexo-backup
- mv hexo-backup/source .
- rm -rf source/private
- npm run build

after_success:
- git config --global user.name "appotry"
- git config --global user.email "email@qq.com"
- git clone https://${GIT_USER}:${GITHUB_TOKEN}@${GITHUB_PAGES_REPO} voidking
- unalias cp
- cp -rf public/. 17lai.blog
- cd 17lai.blog
- git add .
- git commit -m "Travis CI Auto Builder"
- git push --force --quiet "https://${GIT_USER}:${GITHUB_TOKEN}@${GITHUB_PAGES_REPO}" master:master
利用 GitLab 实现 Hexo 博客的 CI/CD
Portainer 提供了对服务在线更新的 WebHook，所以基于 GitLab 自带的 CI/CD 功能实现 Hexo 博客的持续部署，就非常轻松了。
CI/CD 其实本质上是一套流程，流程规则可以自行定义。在本文研究的主题下，流程分为三步：第一步是编译 Hexo 博客并生成静态文件；第二步是将静态文件打包成可提供 Web 服务的镜像；第三步则是通过 Portainer 的钩子触发服务更新。
.gitlab-ci.yml
stages:
  - compile
  - build
  - deploy

# CONTAINER_RELEASE_IMAGE 根据自己的仓库名修改
variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_DRIVER: overlay2
  CONTAINER_RELEASE_IMAGE: registry.gitlab.com/xxx/xxx:latest

compile:
  stage: compile
  image: node:lts-alpine
  script:
    - npm install
    - ./node_modules/hexo/bin/hexo generate
  artifacts:
    paths:
      - public/
    expire_in: 20 minutes

build:
  stage: build
  image: docker:stable
  services:
    - docker:dind
  script:
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN registry.gitlab.com
    - docker info
    - docker build -f ./Dockerfile -t $CONTAINER_RELEASE_IMAGE public
    - docker push $CONTAINER_RELEASE_IMAGE

# 根据自己的钩子修改下方的 URL
deploy:
  stage: deploy
  script:
    - curl https://xxx.xxx.xxx/api/webhooks/xxx -X POST

为了保证服务更新的成功率，可以在 deploy 环节加个错误判断和重试次数，具体的看 GitLab 官方文档即可。
下面给出我的 Dockerfile 文件，供参考。
FROM nginx:alpine

COPY . /usr/share/nginx/html

RUN chmod 777 /usr/share/nginx/html -R \
    &amp;&amp; sed -i 's/#error_page  404/error_page  404/' /etc/nginx/conf.d/default.conf
个性定制篇
多种主题美化
修改主题颜色
配色包括导航栏，底部栏，a 标签等，主题配色是绿色。
修改 themes\Matery\source\css\matery.css 样式
快捷键 ctrl+F 查找到 #4cbf30（浅绿色）和 #0f9d58（深绿色）还有首页字体颜色，修改为你喜欢的颜色
/* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */ 
.bg-color { 
	background-image: linear-gradient(to right, #4cbf30 0%, #0f9d58 100%); 
} 
/*如果想去掉banner图的颜色渐变效果，请将以下的css属性注释掉或者删除掉即可*/ 
@-webkit-keyframes rainbow { 
	/* 动态切换背景颜色. */ 
} 
@keyframes rainbow { 
	/* 动态切换背景颜色. */ 
}

背景樱花飘落效果
在 themes/matery/source/js 目录下新建 sakura.js 文件，打开这个网址传送门，将内容复制粘贴到 sakura.js 即可。
然后在 themes/matery/layout/layout.ejs 文件内添加下面的内容：
&lt;script type="text/javascript"&gt;
//只在桌面版网页启用特效
var windowWidth = $(window).width();
if (windowWidth &gt; 768) {
    document.write('&lt;script type="text/javascript" src="/js/sakura.js"&gt;&lt;\/script&gt;');
}
&lt;/script&gt;
修改花瓣的数量
因为普遍在使用的樱花背景效果花瓣数太多了，一些人不太喜欢。
于是按不同花瓣数量做了几个新的 js ，并提供如下 cdn 形式的引用：
https://cdn.jsdelivr.net/gh/fz6m/Private-web@1.2/js/sakura/sakura-small.js
以上为少量樱花效果，另提供几个不同数量的文件引用名：



文件名
说明




 sakura-small.js
 少量樱花


 sakura-half.js
 樱花相对原效果数量减半


 sakura-reduce.js
 樱花相对原效果减少 1/4


sakura-original.js
 樱花数量不变（原效果）



自定义鼠标样式
首先将鼠标样式下载到本地，推荐大家一个网站：https://zhutix.com/ico/ori-cursors/
以我的为例，我将鼠标指针样式放在了主题文件夹下的 medias 目录下，然后打开 themes\matery\source\css 下的 my.css 文件，添加内容如下：
*{
    cursor: url("/medias/imgs/zhengchang.ico"),auto!important;
}
:active{
    cursor: url("/medias/imgs/dianji.ico"),auto!important;
}
取消首页渐变颜色动画
在 themes\Matery\source\css\matery.css，ctrl+F 快捷键查找.bg-cover:after，注释掉即可。
/* .bg-cover:after {
    -webkit-animation: rainbow 60s infinite;
    animation: rainbow 60s infinite;
} */
优化目录栏，透明化
目录样式竟然在：themes\Matery\layout\_partial\post-detail-toc.ejs
.toc-widget {
    width: 345px;
    padding-left: 20px;
    background-color: rgb(255, 255, 255,0.7);
    border-radius: 10px;
    box-shadow: 0 10px 35px 2px rgba(0, 0, 0, .15), 0 5px 15px rgba(0, 0, 0, .07), 0 2px 5px -5px rgba(0, 0, 0, .1) !important;
}
增加点击跳转评论按钮
新建文件 themes\Matery\layout\_partial\back-comment.ejs, 粘贴如下代码
我这里评论是 valine，直接填写的 valine 的 id——href="#vcomments", 如果是其他评论，对应修改即可。
&lt;!-- 直达评论 --&gt;
&lt;div id="to_comment" class="comment-scroll"&gt;
    &lt;a class="btn-floating btn-large waves-effect waves-light" href="#vcomments" title="直达评论"&gt;
        &lt;i class="fas fa-comments"&gt;&lt;/i&gt;
    &lt;/a&gt;
&lt;/div&gt;
在 themes\Matery\layout\_partial\valine.ejs 文末添加一条，引用第一步的内容；
&lt;%- partial('_partial/back-comment.ejs') %&gt;
则只在 valine 存在的页面才显示直达评论，防止首页其他地方也出现按钮。其实还可以优化为浮动出现，有一点麻烦，我这里没有设置。
增加样式在 themes\Matery\source\css\matery.css 添加内容如下：
/*直达评论按钮样式*/
.comment-scroll {
    position: fixed;
    right: 15px;
    bottom: 135px;
    padding-top: 15px;
    margin-bottom: 0;
    z-index: 998;
}

.comment-scroll .btn-floating {
    background: linear-gradient(to bottom right, #FF9999 0%, #ff6666 100%);
    width: 48px;
    height: 48px;
}

.comment-scroll .btn-floating i {
    line-height: 48px;
    font-size: 1.8rem;
}

bottom: 135px; 是距离底部的高度，看看你是否需要修改。
修改滑动条
/* 滚动条 */
::-webkit-scrollbar-thumb {
    background-color: #FF2A68;
    background-image: -webkit-linear-gradient(45deg,rgba(255,255,255,.4) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.4) 50%,rgba(255,255,255,.4) 75%,transparent 75%,transparent);
    border-radius: 3em;
}
::-webkit-scrollbar-track {
    background-color: #ffcacaff;
    border-radius: 3em;
}
::-webkit-scrollbar {
    width: 8px;
    height: 15px;
}
添加博客看板娘	动漫人物挂件
方法如下：
安装插件：
npm install --save hexo-helper-live2d
安装喜欢的模型：
$ npm install packagename
#安装下载动画人物库, 动画人物有很多, 可以网上查询资料, 下面推荐几种.
npm install --save live2d-widget-model-shizuku #课桌女孩
npm install --save live2d-widget-model-hibiki  #御姐
npm install --save live2d-widget-model-wanko   #狗狗
npm install --save live2d-widget-model-haruto  #海军服女孩
npm install --save live2d-widget-model-miku    #萝莉
将 packagename 换成模型名字，如我使用的模型：
$ npm install live2d-widget-model-shizuku
然后打开博客根目录下的 _config.yml 文件，添加如下代码：
使用本地模型方式：
## 添加动画live2d模块  npm install --save hexo-helper-live2d
## 下载动画人物库 npm install live2d-widget-model-z16 -D
live2d:
  enable: true
  scriptFrom: local # 默认
  pluginRootPath: live2dw/ # 插件在站点上的根目录(相对路径)
  pluginJsPath: lib/ # 脚本文件相对与插件根目录路径
  pluginModelPath: assets/ # 模型文件相对与插件根目录路径
  tagMode: false # 标签模式, 是否仅替换 live2d tag标签而非插入到所有页面中
  debug: false # 调试, 是否在控制台输出日志
  model:
    use: live2d-widget-model-miku
  display:
    position: right #动画位置
    width: 150
    height: 190
    # 位置配置，这个在左侧边栏位置很居中
    hOffset: 50  # 调节水平位置
    vOffset: -5  # 调节垂直位置
  mobile:
    show: false # 是否在移动设备上显示
    scale: 0.5 # 移动设备上的缩放
  react:
    opacityDefault: 0.7
    opacityOnHover: 0.8
使用网络模型方式：
# Live2D
## https://github.com/EYHN/hexo-helper-live2d
live2d:
  enable: true
  # enable: false
  pluginRootPath: live2dw/ # Root path of plugin to be on the site (Relative)
  pluginJsPath: lib/ # JavaScript path related to plugin's root (Relative)
  pluginModelPath: assets/ # Relative model path related to plugin's root (Relative)
  scriptFrom: local # Default
  # scriptFrom: jsdelivr # jsdelivr CDN
  # scriptFrom: unpkg # unpkg CDN
  # scriptFrom: https://cdn.jsdelivr.net/npm/live2d-widget@3.x/lib/L2Dwidget.min.js # Your custom url
  tagMode: false # Whether only to replace live2d tag instead of inject to all pages
  log: false # Whether to show logs in console
  model:
    #use: live2d-widget-model-lwet # npm-module package name
    # use: wanko # folder name in (hexo base dir)/live2d_models/
    # use: ./wives/wanko # folder path relative to hexo base dir
    # 模型：https://huaji8.top/post/live2d-plugin-2.0/
    use: https://cdn.jsdelivr.net/npm/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json # Your custom url
  display:
    position: left
    width: 300
    height: 400
    hOffset: 50
    vOffset: 10
  mobile:
    show: false
效果见本 blog 左下角。
添加夜间模式切换



下面这个还远未完善，只是基本可用，很多显示细节还需要调整。


博主业余钻研 ccs 教程，慢慢修改完善中。



在主题目录下的 /layout/layout.ejs 文件添加夜间模式切换按钮:
&lt;!-- 切换夜间/白天模式按钮 --&gt;
&lt;a onclick="switchNightMode()" id="sma"&gt; &lt;i class="fa fa-moon-o" id="nightMode" aria-hidden="true"&gt;&lt;/i&gt; &lt;/a&gt;
在主题目录下的 /source/js/matery.js 文件添加 js 代码:
// 深色模式按钮设置
if (localStorage.getItem('dark') === '1') {
    document.body.classList.add('dark');
} else if (new Date().getHours() &gt;= 22 || new Date().getHours() &lt; 7) {
    /*定时开启暗色模式&lt;默认晚22点至早6点默认开启&gt;*/
    // document.body.classList.add('dark');
    // $("#nightMode").removeClass("fa-moon-o").addClass("fa-lightbulb");
} else if (matchMedia('(prefers-color-scheme: dark)').matches) {
    document.body.classList.add('dark');
}

// 深色模式设置
function switchNightMode() {
    var body = document.body;
    if (body.classList.contains('dark')) {
        document.body.classList.remove('dark');
        localStorage.setItem('dark', '0');
        $('#nightMode').removeClass("fa-lightbulb").addClass("fa-moon-o");
        return;
    } else {
        document.body.classList.add('dark');
        localStorage.setItem('dark', '1');
        $('#nightMode').removeClass("fa-moon-o").addClass("fa-lightbulb");
        return;
    }
}

/*提醒开启夜间模式功能*/
setTimeout(
    function () {
        if ((new Date().getHours() &gt;= 19 || new Date().getHours() &lt; 7) &amp;&amp; !$('body').hasClass('DarkMode')) {
            let toastHTML = '&lt;span style="color:#97b8b2;border-radius: 10px;&gt;'
                + '&lt;i class="fa fa-bell" aria-hidden="true"&gt;&lt;/i&gt;晚上使用深色模式阅读更好哦。(ﾟ▽ﾟ)/&lt;/span&gt;'
            M.toast({html: toastHTML})
        }
    }, 2200);
在主题目录下的 /source/css/matery.css 文件添加夜间模式切换的样式:
/******夜间模式切换样式 start*******/
/* 深色模式按钮设置 */
#sma {
    background: #000;
    width: 38px;
    height: 38px;
    display: block;
    position: fixed;
    border-radius: 50%;
    right: 15px;
    bottom: 170px;
    padding-top: 15px;
    margin-bottom: 0;
    z-index: 998;
    cursor: pointer;
}

#sma .fa-moon-o {
    position: absolute;
    right: 8px;
    bottom: 8px;
    font-size: 1.48rem !important;
}

#sma .fa-lightbulb {
    position: absolute;
    right: 13px;
    bottom: 8px;
    font-size: 1.5rem !important;
}

.fa-moon-o:before {
    content: "\f186";
}

.fa-comments:before {
    content: "\f086";
}

/* 深色模式设置 */ /* 字体颜色变灰白色 */
body.dark .fas,
body.dark .title,
body.dark .row .text,
body.dark article .article-content .summary,
body.dark .card .card-image .card-title,
body.dark .fa-moon-o:before,
body.dark .fa-lightbulb:before,
body.dark article .article-tags .chip,
body.dark .chip-container .tag-title,
body.dark div.jqcloud a,
body.dark .friends-container .tag-title,
body.dark .frind-ship .title h1,
body.dark .card .card-content p,
body.dark .v[data-class=v] .vcount,
body.dark .v[data-class=v] .vcount .vnum,
body.dark pre code,
body.dark h1,
body.dark h2,
body.dark h3, body.dark h4,
body.dark h5,
body.dark h6, body.dark li,
body.dark p,
body.dark header .side-nav .mobile-head .logo-name,
body.dark header .side-nav .mobile-head .logo-desc,
body.dark header .side-nav .menu-list a,
body.dark .bg-cover .post-title,
body.dark a {
    color: rgba(255, 255, 255, 0.6);
}

/* 背景颜色变灰色 */
body.dark .card,
body.dark .block-with-text:after {
    background-color: #282c34;
}

/* 背景颜色变黑色 */
body.dark,
body.dark .v[data-class=v] .vcount,
body.dark #rewardModal .modal-content,
body.dark .modal,
body.dark header .side-nav,
body.dark header .side-nav .menu-list .m-nav-show {
    background-color: #12121c;
   /**因为我的背景图导致部分页面无法全部切换成深色背景, 需要取消背景图片**/
    background-image: url(#); 
}

/* 改变透明度 */
body.dark .aplayer {
    background: #2f3742 !important;
}

body.dark img, body.dark strong {
    filter: brightness(.7);
}
/******夜间模式切换样式 end*******/
Tag 标签外挂使用方法
Tag标签外挂使用方法

{%r%}
紅色
{%endr%}
{%g%}
綠色
{%endg%}
{%y%}
黃色
{%endy%}
图片懒加载

图片懒加载是提升网站性能和用户体验的一个非常很好方式，并且几乎所有的大型网站都使用到了，比如微博，仅把用户可见的部分显示图片，其余的都暂时不加载，做法就是：让所有图片元素 src 指向一个小的站位图片比如 loading，并新增一个属性 (如 data-original) 存放真实图片地址。每当页面加载（或者滚动条滚动），使用 JS 脚本将可视区域内的图片 src 替换回真实地址，并做请求重新加载。

Don't worry about lazyload SEO problem, because Google supports it already.


那么，赶快用起来吧！
在站点根目录执行下面的命令：
npm install hexo-lazyload-image --save
#或者使用yarn
yarn add hexo-lazyload-image
之后在站点配置文件下添加下面的代码
lazyload:
  enable: true  # 是否开启图片懒加载
  onlypost: false  # 是否只对文章的图片做懒加载
  loadingImg: # eg ./images/loading.gif
  isSPA: false # optional. For performance considering, isSPA is added. If your theme is a SPA page, please set it as true
  preloadRatio: 3 # optional, default is 1
最后执行 hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 就可以看到效果了。
存在问题：
查看大图，发现全部为 loading 加载图，原因是因为懒加载插件与 lightgallery 插件冲突，解决办法如下：
修改主题文件下的 matery.js，在 108 行左右添加以下代码：
$(document).find('img[data-original]').each(function(){
        $(this).parent().attr("href", $(this).attr("data-original"));
});

specify no-lazy for specify image
we can also disable the lazy process if specify a attribute on img tag in both markdown or html
&lt;img no-lazy src="abc.png" /&gt;

外链跳转插件
使用 npm 或者 yarn 安装
## npm 安装
npm install hexo-external-link --save
## yarn 安装
yarn add hexo-external-link
之后在博客站点根目录下添加如下配置：
hexo_external_link:
  enable: true
  enable_base64_encode: true
  url_param_name: 'u'
  html_file_name: 'go.html'
  target_blank: true
  link_rel: 'external nofollow noopener noreferrer'
  domain: 'your_domain' # 如果开启了防盗链，填写你的域名
  safety_chain: true
添加天气小插件
首先去中国天气官网：，配置自己的插件，选择自定义插件 —&gt; 自定义样式 ——&gt; 生成代码，然后会生成一段代码，复制粘贴到 themes/matery/layout/layout.ejs 即可。
新增个人相册
新建相册目录
执行下面的命令：
hexo new page galleries
然后到站点根目录的 source 目录下找名称为 galleries 的目录，打开目录下的 **index.md ** 文档，在原有基础上添加一下配置：
type: "galleries"
layout: "galleries"
紧接着，在主题配置文件的 menu 属性添加关于相册的菜单
相册:
  url: /galleries 
  icon: fas fa-image
如果需要添加到二级菜单，添加格式为：
- name: 相册
  url: /galleries 
  icon: fas fa-image
添加 ejs 文件和 css 文件
首先新建 gallery.css，填写的代码内容如下：
.gallery-wrapper{
  padding-top: 30px;
}
.gallery-wrapper .gallery-box{
  padding: 5px !important;
}

.gallery-wrapper .gallery-item {
  display: block;
  overflow: hidden;
  background-color: #fff;
  padding: 5px;
  padding-bottom: 0;
  position: relative;
  -moz-box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.22);
  -webkit-box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.22);
  box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.22);
}

.gallery-cover-box{
  width: 100%;
  padding-top: 60%;
  text-align: center;
  overflow: hidden;
  position: relative;
  background: center center no-repeat;
  -webkit-background-size: cover;
  background-size: cover;
}

.gallery-cover-box .gallery-cover-img {
  display: inline-block;
  width: 100%;
  position: absolute;
  left: 50%;
  top: 50%;
  transform: translate(-50%,-50%);
}
.gallery-item .gallery-name{
  font-size: 14px;
  line-height: 24px;
  text-align: center;
  color: #666;
  margin: 0;
}

.waterfall {
  column-count: 3;
  column-gap: 1em;
}
.photo-wrapper{
  padding-top: 20px;
}
.photo-item {
  display: block;
  padding: 10px;
  padding-bottom: 0;
  margin-bottom: 14px;
  font-size: 0;
  -moz-page-break-inside: avoid;
  -webkit-column-break-inside: avoid;
  break-inside: avoid;
  background: white;
  -moz-box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.22);
  -webkit-box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.22);
  box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.22);
}
.photo-item img {
  width: 100%;
}
.photo-item .photo-name{
  font-size: 14px;
  line-height: 30px;
  text-align: center;
  margin-top: 10px;
  margin-bottom: 10px;
  border-top: 1px solid #dddddd;
}

/*适配移动端布局*/
@media only screen and (max-width: 601px) {
  .waterfall {
    column-count: 2;
    column-gap: 1em;
  }
}
然后保存，将此文件放在主题目录下，路径为 matery/source/css。
紧接着，新建 galleries.ejs 文件，添加以下代码：
&lt;link rel="stylesheet" href="/css/gallery.css"&gt;

&lt;%- partial('_partial/bg-cover') %&gt;

&lt;main class="content"&gt;
    &lt;div class="container"&gt;
        &lt;% if (site.data &amp;&amp; site.data.galleries) { %&gt;
        &lt;% var galleries = site.data.galleries; %&gt;
        &lt;div class="gallery-wrapper row"&gt;
            &lt;% for (var i = 0, len = galleries.length; i &lt; len; i++) { %&gt;
            &lt;% var gallery = galleries[i]; %&gt;
            &lt;div class="col s6 m4 l4 xl3 gallery-box"&gt;
                &lt;a href="./&lt;%- gallery.name %&gt;" class="gallery-item" data-aos="zoom-in-up"&gt;
                     &lt;div class="gallery-cover-box" style="background-image: url(&lt;%- theme.jsDelivr.url %&gt;&lt;%- gallery.cover%&gt;);"&gt;
                    &lt;/div&gt;
                    &lt;p class="gallery-name"&gt;
                        &lt;%- gallery.name %&gt;
                    &lt;/p&gt;
                &lt;/a&gt;
            &lt;/div&gt;
            &lt;% } %&gt;
        &lt;/div&gt;
        &lt;% } %&gt;
    &lt;/div&gt;
&lt;/main&gt;
将此文件放在 matery/layout 目录下，同时再此目录下接着新建 gallery.ejs 文件，添加以下代码：
&lt;link rel="stylesheet" href="/css/gallery.css"&gt;
&lt;link type="text/css" href="/libs/fancybox/jquery.fancybox.css" rel="stylesheet"&gt;
&lt;link type="text/css" href="/libs/justifiedGallery/justifiedGallery.min.css" rel="stylesheet"&gt;

&lt;%- partial('_partial/post-cover') %&gt;
&lt;%
let galleries = [];
if (site.data &amp;&amp; site.data.galleries) {
    galleries = site.data.galleries;
}
var pageTitle = page.title;
function getCurrentGallery(galleries, pageTitle) {
    for (let i = 0; i &lt; galleries.length; i++) {
        if (galleries[i]['name'] == pageTitle) {
            return galleries[i];
        }
    }
}
var currentGallery = getCurrentGallery(galleries, pageTitle)

var photos = currentGallery.photos;
var galleryImageStr = theme.jsDelivr.url ? theme.jsDelivr.url : '';

let imageStr = ''

for (var i = 0, len = photos.length; i &lt; len; i++) {
    var photo = photos[i];

    imageStr += "&lt;a href=\"" + galleryImageStr + photo + "\"" +
            "     class=\"photo-item\" rel=\"example_group\"" +
            "     data-fancybox=\"images\"&gt;" +
            "      &lt;img src=\"" + galleryImageStr + photo + "\"" +
            "       alt=" + photo + "&gt;\n" +
            "    &lt;/a&gt;"

}
%&gt;  

&lt;div class="container"&gt;
    &lt;div class="photo-wrapper"&gt;
        &lt;% if (page.password ) { %&gt;

            &lt;script src="/js/crypto-js.js"&gt;&lt;/script&gt;
            &lt;script src="/js/gallery-encrypt.js"&gt;&lt;/script&gt;
            &lt;div id="hbe-security"&gt;
                &lt;div class="hbe-input-container"&gt;
                    &lt;input type="password" class="hbe-form-control" id="pass"  placeholder="请输入密码查看内容"/&gt;
                    &lt;a href="javascript:;" class="btn-decrypt" id="btn_decrypt"&gt;解密&lt;/a&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div  id="mygallery"&gt;
                &lt;div class="waterfall" id="encrypt-blog" style="display:none"&gt;
                    &lt;%- aes(imageStr, page.password) %&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;% } else { %&gt;
            &lt;div class="waterfall" id="encrypt-blog"&gt;
                &lt;%- imageStr %&gt;
            &lt;/div&gt;
        &lt;% } %&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script src="/libs/fancybox/fancybox.js"&gt;&lt;/script&gt;
&lt;script src="/libs/justifiedGallery/justifiedGallery.min.js"&gt;&lt;/script&gt;
&lt;script&gt;

  $("a[rel=example_group]").fancybox();
  $("#encrypt-blog").justifiedGallery({margins: 5, rowHeight: 150});

&lt;/script&gt;
注意：

需要几个文件，我把文件地址放在下面，用浏览器打开链接，就会显示出代码，然后复制粘贴到文加中去就行。开头的是文件路径，如果没有的话，就新建一个就 OK 了。



libs/fancybox/jquery.fancybox.css：
https://blog.17lai.site/libs/fancybox/jquery.fancybox.css


libs/justifiedGallery/justifiedGallery.min.css：
https://blog.17lai.site/libs/justifiedGallery/justifiedGallery.min.css


matery/source/js/crypto-js.js：
https://blog.17lai.site/js/crypto-js.js


matery/source/js/gallery-encrypt.js：
https://blog.17lai.site/js/gallery-encrypt.js


libs/fancybox/fancybox.js：
https://blog.17lai.site/libs/fancybox/fancybox.js


libs/justifiedGallery/justifiedGallery.min.js：
https://blog.17lai.site/libs/justifiedGallery/justifiedGallery.min.js


添加相册 json 配置文件
在站点目录 source/_data/ 下新建一个 galleries.json 的文件，json 代码如下：
[
    {
      "name": "2020",
      "cover": "/medias_webp/images/01.webp",
      "description": "我的图床",
      "photos": [
        "/medias_webp/images/01.webp",
        "/medias_webp/images/02.webp",
        "/medias_webp/images/03.webp"
      ]
    },
    {
      "name": "2021",
      "cover": "/medias_webp/featureimages/1.webp",
      "description": "featureimages 图片展示",
      "photos": [
        "/medias_webp/featureimages/1.webp",
        "/medias_webp/featureimages/2.webp",
        "/medias_webp/featureimages/3.webp",
        "/medias_webp/featureimages/4.webp",
      ]
    },
    {
      "name": "2022",
      "cover": "/medias_webp/banner/0.webp",
      "description": "banner 图片展示",
      "photos": [
        "/medias_webp/banner/0.webp",
        "/medias_webp/banner/1.webp",
        "/medias_webp/banner/2.webp",
      ]
    }
]
字段含义：

name 是相册标题
cover 是封面图片
description 是相册介绍
photos 是图片列表

配置文件建好了之后还没完，只剩最后一个步骤了，在 galleries 目录下建立对应的相册名称目录和文件，比如我这个相册需要新建名称为 2020 目录，然后下面再分别新建 index.md 文件，2020/index.md 文件内容为：
---
title: 2020
date: 2021-10-13 10:51:50
type: "gallery"
layout: "gallery"
---
2021/index.md，2022/index.md 文件内容和上面一样，只是 title 修改不同而已
galleries 目录结构
galleries
├── 2020
│&nbsp;&nbsp; └── index.md
├── 2021
│&nbsp;&nbsp; └── index.md
├── 2022
│&nbsp;&nbsp; └── index.md
├── index.md
查看效果
完成以上步骤，执行命令，在本地查看效果：
hexo clean &amp;&amp; hexo g &amp;&amp; hexo s
我的效果

新增折叠功能

这里利用 hexo-sliding-spoiler 插件间接实现折叠功能，在 matery 主题中零修改源代码实现折叠功能。
另一种修改代码实现折叠效果，参考 Hexo next 博客添加折叠块功能添加折叠代码块。

安装插件
npm install hexo-sliding-spoiler --save
配置插件
根目录配置文件_config.yml 中添加
plugin:
- hexo-sliding-spoiler
到这里已经实现折叠功能了。
进一步完善美化
修改 node_modules_hexo-sliding-spoiler@1.2.1@hexo-sliding-spoiler\assets\spoiler.css
.spoiler {
    margin: 20px 0;
    padding: 15px;
    border: 1px solid #E5E5E5;
    background: #E5E5E5;
    position: relative;
    clear: both;
    border-radius: 3px;
    transition:all .6s
}

.spoiler .spoiler-title {
    margin: 0 -15px;
    padding: 5px 15px;
    color: #353535;
    font-weight: bold;
    font-size: 18px;
    display: block;
    cursor: pointer;
}

.spoiler.collapsed .spoiler-title:before {
    content: "▶ ";
}

.spoiler.expanded .spoiler-title:before {
    content: "▼ ";
}
使用方法
{% spoiler title %}
content
{% endspoiler %}
实例
{% spoiler 点击显/隐内容 %}

内容测试

{% endspoiler %}

{% spoiler 点击显/隐内容 %}

内容测试

{% endspoiler %}

让 Hexo 博客支持通知功能
安装插件
插件的 GitHub 仓库 hexo-web-push-notification
在你的博客站点目录执行下面的命令：
npm i hexo-web-push-notification --save
如果你安装了 cnpm 或者 yarn 等可执行下面的命令，安装依赖包的速度更快：
cnpm i hexo-web-push-notification --save #安装cnpm的执行这个命令
yarn add hexo-web-push-notification #安装yarn的执行这个命令
紧接着再你的博客站点目录下的配置文件，而不是主题配置文件，添加以下配置：
webPushNotification:
  webpushrKey: "your webpushr rest api key"
  webpushrAuthToken: "your webpushr authorize token"
  trackingCode: "AEGlpbdgvBCWXqXI6PtsUzobY7TLV9gwJU8bzMktrwfrSERg_xnLVbjpCw8x2GmFmi1ZcLTz0ni6OnX5MAwoM88"
其中 webpushrKey,webpushrAuthToken 和 trackingCode 的值在官网注册得到。
官网注册
点击右边的图标即可进入👉 ： 传送门
注册完之后，然后会让你重新登录，登录之后，然后填写相关的信息即可。

填写图中所显示的相关网站信息，填写完之后，点击下一步



Web push notications 仅支持 HTTPS 的网站，不支持 HTTP 的网站

根据网站类型，并根据网站指引进行操作，以 Hexo 为例


info， 其中将第二步中所指的代码复制粘贴到你的 footer.ejs 或者 layout.ejs，对于 hexo 用户，建议将其加入 index.ejs 即可。因为主题的不同，所以代码添加的位置不同，简单的说，就是放在网站的 &lt;/body&gt; 标签之前，根据你的主题而言，自己添加。

接着将以下代码插入到网页中就可以了。确保每一个你想要询问用户接受通知的页面都要包含以下代码。
其中，上图步骤二中的代码有 trackingCode 的值，如下图中所标明的一长串字母。

验证安装

部署之后可能会遇到无法正常发送通知的情况.
进入目录 node_modules/hexo-web-push-notification/index.js文件中第22行'summary': util.stripHTML(newPost.excerpt), 这里取值取的是 excerpt，改成 summary 即可。
修改前
var JSONFeed = {
        'title': newPost.title,
        'id': newPost.path,
        'date_published': newPost.date.format('L'),
        'summary': util.stripHTML(newPost.excerpt),
        'url': newPost.permalink,
        'tags': newPost.tags.data.map(function (v) { return v.name }),
        'categories': newPost.categories.data.map(function (v) { return v.name })
    }
var JSONFeed = {
        'title': newPost.title,
        'id': newPost.path,
        'date_published': newPost.date.format('L'),
        'summary': util.stripHTML(newPost.summary),
        'url': newPost.permalink,
        'tags': newPost.tags.data.map(function (v) { return v.name }),
        'categories': newPost.categories.data.map(function (v) { return v.name })
    }
客服聊天窗口
1、在官网注册账号
官网地址：点我去 crisp 官网注册
2、注册完成后设置
登录刚才注册的账户 —— 设置 —— 网站设置 —— 添加网站。
添加完成之后就多了一行网站信息。点网站整合，就有不同的站的整合方式。
比如：html 方式
就是复制 JS 代码片段到你的到 head 标签里。
&lt;script type="text/javascript"&gt;window.$crisp=[];window.CRISP_WEBSITE_ID="xxxxxxx-097e-402f-bb6b-xxxxxxx";(function(){d=document;s=d.createElement("script");s.src="https://client.crisp.chat/l.js";s.async=1;d.getElementsByTagName("head")[0].appendChild(s);})();&lt;/script&gt;
3、其他的设置也
登录刚才注册的账户 —— 设置 —— 网站设置。
网站信息行 —— 设置，自己根据需要设置即可，比如显示位置，颜色，自己的头像等。
整个使用非常简单的。
使用 Valine-Admin 管理评论和评论提醒
使用
首先其他的不错说了，在阅读本篇文章之前你最好已经整合了 Valine 留言。
由于我已经整合过了所以前面几个步骤的图片来源自 @Valine-Admin
首先登陆账号，找到云引擎在点击设置。

复制仓库地址：DesertsP/Valine-Admin


把 git 仓库地址房子代码库输入框中。
切换到部署标签页，分支使用 master，点击部署。

接下来输入分支为 master

部署完成之后就是设置环境变量
环境变量
点击设置，找到自定义环境变量点击新增变量


SITE_NAME : 网站名称。
SITE_URL : 网站地址，最后不要加 / 。
SMTP_USER : SMTP 服务用户名，一般为邮箱地址。
SMTP_PASS : SMTP 密码，一般为授权码，而不是邮箱的登陆密码，请自行查询对应邮件服务商的获取方式
SMTP_SERVICE : 邮件服务提供商，支持 QQ、163、126、Gmail、"Yahoo"、...... ，全部支持请参考 : Nodemailer Supported services。 — 如这里没有你使用的邮件提供商，请查看自定义邮件服务器
SENDER_NAME : 寄件人名称。
TO_EMAIL：这个是填收邮件提醒的邮箱地址，若没有这个字段，则将邮件发到 SMTP_USER。
TEMPLATE_NAME：设置提醒邮件的主题，目前内置了两款主题，分别为 default 与 rainbow。默认为 default

设置好以上变量之后 点击实例

然后重启项目，注意任何变动都要重启项目
然后看一下效果

还不错
自定义后台

首先需要设置管理员信息。访问管理员注册页面 https://云引擎域名/sign-up，注册管理员登录信息，如：https://deserts-io.avosapps.us/sign-up

点击设置然后点击 Web 主机域名找到自己的后台地址

然后在 Usee 表中增加账号， 只需要填写 email、password、username 其中邮箱必须设置为你的上面环境变量的邮箱
设置完之后登录就能在你的后台管理评论
更多设置
邮件通知模板
邮件通知模板在云引擎环境变量中设定，可自定义通知邮件标题及内容模板。



环境变量
示例
说明




 MAIL_SUBJECT
{SITE_NAME} 上的评论收到了回复
 [可选]@通知邮件主题（标题）模板


 MAIL_TEMPLATE
 见下文
 [可选]@通知邮件内容模板


 MAIL_SUBJECT_ADMIN
${SITE_NAME} 上有新评论了
 [可选] 博主邮件通知主题模板


 MAIL_TEMPLATE_ADMIN
 见下文
 [可选] 博主邮件通知内容模板



邮件通知包含两种，分别是被 @通知和博主通知，这两种模板都可以完全自定义。默认使用经典的蓝色风格模板（样式来源未知）。
默认被 @通知邮件内容模板如下：
&lt;div style="border-top:2px solid #12ADDB;box-shadow:0 1px 3px #AAAAAA;line-height:180%;padding:0 15px 12px;margin:50px auto;font-size:12px;"&gt;&lt;h2 style="border-bottom:1px solid #DDD;font-size:14px;font-weight:normal;padding:13px 0 10px 8px;"&gt;您在&lt;a style="text-decoration:none;color: #12ADDB;" href="${SITE_URL}" target="_blank"&gt;            ${SITE_NAME}&lt;/a&gt;上的评论有了新的回复&lt;/h2&gt; ${PARENT_NICK} 同学，您曾发表评论：&lt;div style="padding:0 12px 0 12px;margin-top:18px"&gt;&lt;div style="background-color: #f5f5f5;padding: 10px 15px;margin:18px 0;word-wrap:break-word;"&gt;            ${PARENT_COMMENT}&lt;/div&gt;&lt;p&gt;&lt;strong&gt;${NICK}&lt;/strong&gt;回复说：&lt;/p&gt;&lt;div style="background-color: #f5f5f5;padding: 10px 15px;margin:18px 0;word-wrap:break-word;"&gt; ${COMMENT}&lt;/div&gt;&lt;p&gt;您可以点击&lt;a style="text-decoration:none; color:#12addb" href="${POST_URL}" target="_blank"&gt;查看回复的完整內容&lt;/a&gt;，欢迎再次光临&lt;a style="text-decoration:none; color:#12addb" href="${SITE_URL}" target="_blank"&gt;${SITE_NAME}&lt;/a&gt;。&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;
效果如下图：

mail-blue-template
@通知模板中的可用变量如下（注，这是邮件模板变量，是指嵌入到 HTML 邮件模板中的变量，请勿与云引擎环境变量混淆）：



模板变量
说明




 SITE_NAME
 博客名称


 SITE_URL
 博客首页地址


 POST_URL
 文章地址（完整路径）


PARENT_NICK
 收件人昵称（被 @者，父级评论人）


PARENT_COMMENT
 父级评论内容


 NICK
 新评论者昵称


 COMMENT
 新评论内容



默认博主通知邮件内容模板如下：
&lt;div style="border-top:2px solid #12ADDB;box-shadow:0 1px 3px #AAAAAA;line-height:180%;padding:0 15px 12px;margin:50px auto;font-size:12px;"&gt;&lt;h2 style="border-bottom:1px solid #DDD;font-size:14px;font-weight:normal;padding:13px 0 10px 8px;"&gt;您在&lt;a style="text-decoration:none;color: #12ADDB;" href="${SITE_URL}" target="_blank"&gt;${SITE_NAME}&lt;/a&gt;上的文章有了新的评论&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;${NICK}&lt;/strong&gt;回复说：&lt;/p&gt;&lt;div style="background-color: #f5f5f5;padding: 10px 15px;margin:18px 0;word-wrap:break-word;"&gt; ${COMMENT}&lt;/div&gt;&lt;p&gt;您可以点击&lt;a style="text-decoration:none; color:#12addb" href="${POST_URL}" target="_blank"&gt;查看回复的完整內容&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;
博主通知邮件模板中的可用变量与 @通知中的基本一致，PARENT_NICK 和 PARENT_COMMENT 变量不再可用。
这里还提供一个彩虹风格的 @通知邮件模板代码：
&lt;div style="border-radius: 10px 10px 10px 10px;font-size:13px;    color: #555555;width: 666px;font-family:'Century Gothic','Trebuchet MS','Hiragino Sans GB',微软雅黑,'Microsoft Yahei',Tahoma,Helvetica,Arial,'SimSun',sans-serif;margin:50px auto;border:1px solid #eee;max-width:100%;background: #ffffff repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 1px 5px rgba(0, 0, 0, 0.15);"&gt;&lt;div style="width:100%;background:#49BDAD;color:#ffffff;border-radius: 10px 10px 0 0;background-image: -moz-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));background-image: -webkit-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));height: 66px;"&gt;&lt;p style="font-size:15px;word-break:break-all;padding: 23px 32px;margin:0;background-color: hsla(0,0%,100%,.4);border-radius: 10px 10px 0 0;"&gt;您在&lt;a style="text-decoration:none;color: #ffffff;" href="${SITE_URL}"&gt; ${SITE_NAME}&lt;/a&gt;上的留言有新回复啦！&lt;/p&gt;&lt;/div&gt;&lt;div style="margin:40px auto;width:90%"&gt;&lt;p&gt;${PARENT_NICK} 同学，您曾在文章上发表评论：&lt;/p&gt;&lt;div style="background: #fafafa repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 2px 5px rgba(0, 0, 0, 0.15);margin:20px 0px;padding:15px;border-radius:5px;font-size:14px;color:#555555;"&gt;${PARENT_COMMENT}&lt;/div&gt;&lt;p&gt;${NICK} 给您的回复如下：&lt;/p&gt;&lt;div style="background: #fafafa repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 2px 5px rgba(0, 0, 0, 0.15);margin:20px 0px;padding:15px;border-radius:5px;font-size:14px;color:#555555;"&gt;${COMMENT}&lt;/div&gt;&lt;p&gt;您可以点击&lt;a style="text-decoration:none; color:#12addb" href="${POST_URL}#comments"&gt;查看回复的完整內容&lt;/a&gt;，欢迎再次光临&lt;a style="text-decoration:none; color:#12addb"                href="${SITE_URL}"&gt; ${SITE_NAME}&lt;/a&gt;。&lt;/p&gt;&lt;style type="text/css"&gt;a:link{text-decoration:none}a:visited{text-decoration:none}a:hover{text-decoration:none}a:active{text-decoration:none}&lt;/style&gt;&lt;/div&gt;&lt;/div&gt;
效果如图：

彩虹模板
垃圾评论检测

Akismet (Automattic Kismet) 是应用广泛的一个垃圾留言过滤系统，其作者是大名鼎鼎的 WordPress 创始人 Matt Mullenweg，Akismet 也是 WordPress 默认安装的插件，其使用非常广泛，设计目标便是帮助博客网站来过滤留言 Spam。有了 Akismet 之后，基本上不用担心垃圾留言的烦恼了。 启用 Akismet 后，当博客再收到留言会自动将其提交到 Akismet 并与 Akismet 上的黑名单进行比对，如果名列该黑名单中，则该条留言会被标记为垃圾评论且不会发布。

如果还没有 Akismet Key，你可以去 AKISMET FOR DEVELOPERS 免费申请一个； 当 AKISMET_KEY 设为 MANUAL_REVIEW 时，开启人工审核模式； 如果你不需要反垃圾评论，Akismet Key 环境变量可以忽略。
为了实现较为精准的垃圾评论识别，采集的判据除了评论内容、邮件地址和网站地址外，还包括评论者的 IP 地址、浏览器信息等，但仅在云引擎后台使用这些数据，确保隐私和安全。
如果使用了本站最新的 Valine 和 Valine Admin，并设置了 Akismet Key，可以有效地拦截垃圾评论。被标为垃圾的评论可以在管理页面取消标注。



环境变量
示例
说明




 AKISMET_KEY
xxxxxxxxxxxx
[可选] Akismet Key 用于垃圾评论检测



手动配置邮件服务器

自定义邮件服务器地址和端口信息，删除 SMTP_SERVICE 环境变量，新增以下变量：




变量
示例
说明




 SMTP_HOST
smtp.qq.com
[可选] SMTP_SERVICE 留空时，自定义 SMTP 服务器地址


 SMTP_PORT
465
[可选] SMTP_SERVICE 留空时，自定义 SMTP 端口


 SMTP_SECURE
true
[可选] 使用 TLS



Troubleshooting


部署失败，请在评论中附图，或去 Github 发起 Issue


邮件发送失败，确保环境变量都没问题后，重启云引擎

重启云引擎


博主通知模板中不要出现 PARENT* 相关参数（请勿混用模板）


点击邮件中的链接跳转至相应评论，这一细节实现需要在 Web 前端添加一点额外的代码：


&lt;script&gt;
    if(window.location.hash){
        var checkExist = setInterval(function() {
           if ($(window.location.hash).length) {
              $('html, body').animate({scrollTop: $(window.location.hash).offset().top-90}, 1000);
              clearInterval(checkExist);
           }
        }, 100);
    }
&lt;/script&gt;

来自 small-rose 的模板

@邮件通知效果：
您在 [ {SITE_URL}) 上的留言有新回复啦！
${PARENT_NICK} 同学，您曾在文章上发表评论：
${PARENT_COMMENT}
${NICK} 给您的回复如下：
${COMMENT}
您可以点击查看回复的完整內容，欢迎再次光临 [ {SITE_URL})。
@邮件通知模板代码：
&lt;div style="border-radius: 10px 10px 10px 10px;font-size:13px; color: #555555;width: 666px;font-family:'Century Gothic','Trebuchet MS','Hiragino Sans GB',微软雅黑,'Microsoft Yahei',Tahoma,Helvetica,Arial,'SimSun',sans-serif;margin:50px auto;border:1px solid #eee;max-width:100%;background: #ffffff repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 1px 5px rgba(0, 0, 0, 0.15);"&gt;&lt;div style="width:100%;background:#49BDAD;color:#ffffff;border-radius: 10px 10px 0 0;background-image: -moz-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));background-image: -webkit-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));height: 66px;"&gt;&lt;p style="font-size:15px;word-break:break-all;padding: 23px 32px;margin:0;background-color: hsla(0,0%,100%,.4);border-radius: 10px 10px 0 0;"&gt;您在&lt;a style="text-decoration:none;color: #ffffff;" href="${SITE_URL}"&gt; ${SITE_NAME}&lt;/a&gt;上的留言有新回复啦！&lt;/p&gt;&lt;/div&gt;&lt;div style="margin:40px auto;width:90%"&gt;&lt;p&gt;${PARENT_NICK} 同学，您曾在文章上发表评论：&lt;/p&gt;&lt;div style="background: #fafafa repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 2px 5px rgba(0, 0, 0, 0.15);margin:20px 0px;padding:15px;border-radius:5px;font-size:14px;color:#555555;"&gt;${PARENT_COMMENT}&lt;/div&gt;&lt;p&gt;${NICK} 给您的回复如下：&lt;/p&gt;&lt;div style="background: #fafafa repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 2px 5px rgba(0, 0, 0, 0.15);margin:20px 0px;padding:15px;border-radius:5px;font-size:14px;color:#555555;"&gt;${COMMENT}&lt;/div&gt;&lt;p&gt;您可以点击&lt;a style="text-decoration:none; color:#12addb" href="${POST_URL}#comments"&gt;查看回复的完整內容&lt;/a&gt;，欢迎再次光临&lt;a style="text-decoration:none; color:#12addb" href="${SITE_URL}"&gt; ${SITE_NAME}&lt;/a&gt;。&lt;/p&gt;&lt;style type="text/css"&gt;a:link{text-decoration:none}a:visited{text-decoration:none}a:hover{text-decoration:none}a:active{text-decoration:none}&lt;/style&gt;&lt;/div&gt;&lt;div style="width:100%;background:#49BDAD;color:#ffffff;border-radius: 0 0 10px 10px;background-image: -moz-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));background-image: -webkit-linear-gradient(0deg,rgb(67, 198, 184), rgb(255, 209, 244));height: 66px;"&gt;&lt;/div&gt;&lt;/div&gt;
博主通知效果：
您在 [ {SITE_URL}) 上的文章有了新的评论！
${NICK} 同学，发表评论说：
${COMMENT}
您可以点击查看回复的完整內容。
&lt;div style="border-radius: 10px 10px 10px 10px;font-size:13px; color: #555555;width: 666px;font-family:'Century Gothic','Trebuchet MS','Hiragino Sans GB',微软雅黑,'Microsoft Yahei',Tahoma,Helvetica,Arial,'SimSun',sans-serif;margin:50px auto;border:1px solid #eee;max-width:100%;background: #ffffff repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 1px 5px rgba(0, 0, 0, 0.15);"&gt;&lt;div style="width:100%;background:#49BDAD;color:#ffffff;border-radius: 10px 10px 0 0;background-image: -moz-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));background-image: -webkit-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));height: 66px;"&gt;&lt;p style="font-size:15px;word-break:break-all;padding: 23px 32px;margin:0;background-color: hsla(0,0%,100%,.4);border-radius: 10px 10px 0 0;"&gt;您在&lt;a style="text-decoration:none;color: #ffffff;" href="${SITE_URL}"&gt; ${SITE_NAME}&lt;/a&gt;上的文章有了新的评论！&lt;/p&gt;&lt;/div&gt;&lt;div style="margin:40px auto;width:90%"&gt;&lt;p&gt;&lt;strong&gt;${NICK}&lt;/strong&gt; 同学，发表评论说：&lt;/p&gt;&lt;div style="background: #fafafa repeating-linear-gradient(-45deg,#fff,#fff 1.125rem,transparent 1.125rem,transparent 2.25rem);box-shadow: 0 2px 5px rgba(0, 0, 0, 0.15);margin:20px 0px;padding:15px;border-radius:5px;font-size:14px;color:#555555;"&gt;${COMMENT}&lt;/div&gt;&lt;p&gt;您可以点击&lt;a style="text-decoration:none; color:#12addb" href="${POST_URL}#comments"&gt;查看回复的完整內容&lt;/a&gt;。&lt;/p&gt;&lt;style type="text/css"&gt;a:link{text-decoration:none}a:visited{text-decoration:none}a:hover{text-decoration:none}a:active{text-decoration:none}&lt;/style&gt;&lt;/div&gt;&lt;div style="width:100%;background:#49BDAD;color:#ffffff;border-radius: 0 0 10px 10px ;background-image: -moz-linear-gradient(0deg, rgb(67, 198, 184), rgb(255, 209, 244));background-image: -webkit-linear-gradient(0deg,rgb(67, 198, 184), rgb(255, 209, 244));height: 66px;"&gt;&lt;/div&gt;&lt;/div&gt;
解决休眠
免费版的 LeanCloud 容器，是有强制性休眠策略的，不能 24 小时运行：

每天必须休眠 6 个小时
 30 分钟内没有外部请求，则休眠。
休眠后如果有新的外部请求实例则马上启动（但激活时此次发送邮件会失败）。

也就是如果服务器休眠了的话用户第一次评论是提醒不了的。
参考了 Valine-Admin 官网找到了解决办法。
首先在环境变量增加服务器地址，就是你的后台服务器地址

下面是你的服务器地址，可以自定义
同样登录后台
找到定时任务

然后点击创建任务，上面是我创建好的

选择 self_wake 函数，然后运行时间使用 cron 表达式

0 0/30 7-23 ? 表示每天 6 点到 11 点 每 30 分钟叫醒服务器一次

这样就完美的解决了服务器休眠的问题
那如果用户不在时间范围内发留言了怎么办？我们也可以创建一个捡漏的定时任务

创建捡漏定时任务
然后运行函数选择 resend_mails, 同样使用 cron 表达式

0 0 8 ?

表示每八个小时进行捡漏一次，这样如果有留言遗漏的话就能即使的提醒。
WakeLeanCloud
这个项目主要是用来解决 LeanCloud 通过定时任务唤醒机器时被流控的问题。
如何使用

Fork 此项目
添加一个名为 GITHUB_TOKEN 的 Token，并为赋予 repo，admin:repo_hook ， workflow 的权限
添加名为 SITE 的 Secrets，内容为自己管理后台地址。多个请用英文逗号分隔

详细教程请参考优雅解决 LeanCloud 流控问题
让 hexo 支持 pwa

pwa 中文叫渐进式网页应用，pwa 网站可以直接添加网址站到桌面，就相当于在系统中直接安装了一个 app，打开的效果也和 app 差不多，加载速度也很快，部分功能可以直接离线使用。Google 的 Workbox 标准，目前来看需要 Chrome 支持

hexo-pwa 很久没更新，看到资料都是支持 4.x 版本 hexo。
hexo-offline 亲自验证，支持最新 5.x 的 hexo。


安装 hexo-offline
npm install hexo-offline --save
关于这个插件的详细使用方法可以看下面这里
https://github.com/JLHwung/hexo-offline
配置 hexo-offline
之后我们在站点根目录_config.yml 如下配置
# offline config passed to sw-precache.
service_worker:
  maximumFileSizeToCacheInBytes: 5242880
  staticFileGlobs:
  - /**/*.{js,html,css,png,jpg,gif,svg,eot,ttf,woff,woff2}
  - /lib/**/*.js
  - /lib/**/*.css
  - /images/*
  - /js/src/**/*.js
  stripPrefix: public
  verbose: true
  runtimeCaching:
    - urlPattern: /*
      handler: cacheFirst
      options:
        origin: cdn.bootcss.com
注意哦不是主题的_config.yml 文件
之后生成 manifest.json 文件，可以在这个网站在线生成。
填入相关的参数，如下


Tips: 一定需要一个 512x512 的 icon！

之后点击 generate.zip 把配置都下载过来
把 manifest.json 和 images 文件夹直接复制到 hexo 下 source 文件夹中，最后我们编辑主题，在 head 里添加
&lt;link rel="manifest" href="/manifest.json"&gt;
如果使用的是 hexo next 主题，在
themes/next/layout/_partials/head/head.swig
如果使用的是 hexo matery 主题，在
themes/matery/layout/_partial/head.ejs

这个文件中添加上面这句话即可，最后直接重新生成站点，部署即可
验证和使用
需要 https 访问，看到这个齿轮

然后在浏览器地址栏可以看到应用标志

Tips: offline 需要 https 才能正常使用


点击打开，会看到如下结果，试一下？

valine 的使用与升级到 1.4
一、valine 启用
1、主要流程
valine 和 miniValine 使用基本类似。
（1）去 Leancloud 注册。
注意事项：
节点选择：华东节点、华北节点、国际版。
如果你的域名没有备案，建议选择国际版。 因为华东或华北节点在安装评论系统之后访问要求域名备案。
（2）在 “设置 “，” 应用 Keys”，找到你的 appid 和 appkey，配置到主题中 valine 配置的地方，启用 valine。
（3）在 “设置 “，” 安全中心”，”Web 安全域名”，添加自己的域名。
（4）在 “设置 “，” 安全中心”，” 服务开关”，数据存储要打开。
（5）在 “存储 “，” 用量统计”，”HTTP 状态码”，启用，方便后续报错查错误码。
（6）重新编译部署 hexo clean &amp; hexo g &amp; hexo d
2、遇到问题
搞这个东西采坑不少，有些坑都是自己不小心造成的。我在网上查了，交流群里也咨询请教了，没有人能解决这个问题，毕竟这个坑是自己造成的。
常见 Code 403 问题：
Code 403: 访问被api域名白名单拒绝，请检查你的安全域名设置.
网上多数的说法是在 web 安全域名中添加自己的域名。可是如果添加之后还是这个问题呢？
其实一般不会有这个问题，我有这个问题是我改了权限造成了。
官方给的解释：

应用在控制台中的相关服务选项未打开，如 Class 关闭了权限，或是 User 缺失了 session 信息等情况下，云端会统一地返回 403 错误码及不同的错误信息，代表当前请求因权限不够而被拒。例如：
信息 - Forbidden to read/write by class permissions
含义 - 操作被禁止，因为 Class 表没有打开「读」或者「写」的权限。进入 控制台 &gt; 存储，点击相应的 Class，从右侧选择 其他 下拉菜单，进入 权限管理 来调整。
信息 - The user cannot be altered by a client without the session.
含义 - 用户没有登录，无法修改用户信息。

解决：
（1）首次使用，添加一条评论，一般添加之后就会好了。
（2）后续使用，403，请检查 comment 表的 add_fields/create/find 权限开放。
（3）如果还是不行将_use 表的 add_fields/create/find 权限开放。
（4）如果还是不行，到 “存储 “，” 用量统计”，”HTTP 状态码” 处，检查你的错误码，然后去 LeanCloud 的错误找应用的错误码，排查原因吧。
二、valine 升级
1、引入 1.4 版的 js 文件
（1）修改主题配置文件
js:
  valine: https://unpkg.com/valine/dist/Valine.min.js #/libs/valine/Valine.min.js 
（2）将文件放你自己的仓库
下载我的 Valine.min.js 文件，直接替换你主题目录 /source/libs/valine/ 下的 Valine.min.js 文件。
注意，如果你担心替换有问题，可以先备份一下你自己的 Valine.min.js 文件。
2、增加 valine 的配置：
1.4 的版本有些属性调整了，主题下的_config.ymlvaline 属性如下：
valine:
  enable: true
  appId: iTxfqh5e9IaRfiiVOTbIWoKa-XXXXXX
  appKey: C5s5xGFErD1EtXXXXXXXX
  verify: true  # 是否启用防垃圾验证
  notify: true  # 是否开启邮件提醒(https://valine.js.org/notify.html)
  visitor: true
  avatar: monsterid  # 头像样式(https://valine.js.org/avatar.html) 
  pageSize: 10
  placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!' # Comment Box placeholder
  background: /medias/comment_bg.png #背景图
  count: true
  enableQQ: 970175021
  recordIP: true
  requiredFields: 
    - nick
    - mail
  guest_info: 
    - nick
    - mail
    - link
  master: 
    - 123abc508165c8eba9a77f872xxxx046  # md5加密后的博主邮箱
  metaPlaceholder:  # 输入框的背景文字
    nick: 昵称/QQ号(必填)
    mail: 邮箱(必填)
    link: 网址(https://)
  lang: zh-CN
  tagMeta: # The String Array of Words to show Flag.[Just Only xCss Style mode]
    - 博主
    - 小伙伴
    - 访客
  friends: # The MD5 String Array of friends Email to show friends Flag.[Just Only xCss Style mode]
    - c08508165c8eba9a77f8c2853xxxx09e
    - 901345d4c91ddfd8db0f175bbcfff0c8
    - 1512958e18378c98b498d5effe3e76ff
复制代码注意缩进对齐，不对齐可能会报错，请自行检查对齐。
3、修改 valine.ejs：
Matery 主题使用的 ejs 模板预编译，如果你使用了 pug 或者 swig 等其他的模板语言，请修改成对应语言语法即可。
原始的 valine.ejs
new Valine({
        el: '#vcomments',
        appId: '&lt;%- theme.valine.appId %&gt;',
        appKey: '&lt;%- theme.valine.appKey %&gt;',
        notify: '&lt;%- theme.valine.notify %&gt;' === 'true',
        verify: '&lt;%- theme.valine.verify %&gt;' === 'true',
        visitor: '&lt;%- theme.valine.visitor %&gt;' === 'true',
        avatar: '&lt;%- theme.valine.avatar %&gt;',
        pageSize: '&lt;%- theme.valine.pageSize %&gt;',
        lang: '&lt;% if (config.language == "zh-CN") {  %&gt;zh-cn&lt;% } else { %&gt;en&lt;% } %&gt;',
        placeholder: '&lt;%= theme.valine.placeholder %&gt;'
    });
升级后的 valine.ejs
let metaPlaceholder = &lt;%-  JSON.stringify(theme.valine.metaPlaceholder) %&gt; ;
//这里要换行
new Valine({
        el: '#vcomments',
        appId: '&lt;%- theme.valine.appId %&gt;',
        appKey: '&lt;%- theme.valine.appKey %&gt;',
        notify: '&lt;%- theme.valine.notify %&gt;' === 'true',
        verify: '&lt;%- theme.valine.verify %&gt;' === 'true',
        visitor: '&lt;%- theme.valine.visitor %&gt;' === 'true',
        avatar: '&lt;%- theme.valine.avatar %&gt;',
        pageSize: '&lt;%- theme.valine.pageSize %&gt;',
        lang: '&lt;%- theme.valine.lang %&gt;',
        placeholder: '&lt;%= theme.valine.placeholder %&gt;',
        meta: &lt;%- '["' + theme.valine.guest_info.join('", "') + '"]' %&gt;,
        recordIP: '&lt;%- theme.valine.recordIP %&gt;' === 'true',
        enableQQ: '&lt;%- theme.valine.avatar %&gt;',
        requiredFields: &lt;%- '["' + theme.valine.master.join('", "') + '"]' %&gt;,
        master: &lt;%- '["' + theme.valine.master.join('", "') + '"]' %&gt;,
        friends: &lt;%- '["' + theme.valine.friends.join('", "') + '"]' %&gt;,
        tagMeta: &lt;%- '["' + theme.valine.tagMeta.join('", "') + '"]' %&gt;,
        metaPlaceholder: metaPlaceholder,

    });
如果需要验证昵称和邮箱可以加上以下代码：
document.body.addEventListener('click', function(e) {
    if (e.target.classList.contains('vsubmit')) {
        const email = document.querySelector('input[type=email]');
        const nick = document.querySelector('input[name=nick]');
        const reg = /^[A-Za-z0-9_-\u4e00-\u9fa5]+@[a-zA-Z0-9_-]+(\.[a-zA-Z0-9_-]+)+$/;
        if (!email.value || !nick.value || !reg.test(email.value)) {
            const str = `&lt;div class="valert txt-center"&gt;&lt;div class="vtext"&gt;请填写正确的昵称和邮箱！&lt;/div&gt;&lt;/div&gt;`;
            const vmark = document.querySelector('.vmark');
            vmark.innerHTML = str;
            vmark.style.display = 'block';

            e.stopPropagation();

            setTimeout(function() {
                vmark.style.display = 'none';
                vmark.innerHTML = '';
            }, 2500);
        }
    }
    }, true);
说明：代码非原创，JS 正则验证本身也不难。
好了可以部署之后自己测试一下。
顺便说一下，填写昵称邮箱和网址的地方如果折行了就按我的样式改一下就好：
在 valine.ejs 是上面对着改一下就好了：
.v[data-class="v"] .vwrap .vheader .vinput {
  width: 32%;
  border-bottom: 1px dashed #dedede;
}
新建文章自动打开本地 Markdown 编辑器

写新文章时，需要控制台执行 hexo new “文章名字” 生成一篇新文章，但需要手动打开，挺麻烦，我们可以设置在生成之后自动打开

在站点根目录下新建 scripts 目录，然后在新建 auto_open.js，在文件填入一下内容
var spawn = require('child_process').exec;

// Hexo 2.x 用户复制这段
//hexo.on('new', function(path){
  //spawn('start  "markdown编辑器绝对路径.exe" ' + path);
//});

// Hexo 3 用户复制这段
hexo.on('new', function(data){
  spawn('start  "D:\Program Files\Typora\Typora.exe" ' + data.path);
});

其中”D:\Program Files\Typora\Typora.exe” 是我本地编辑器的路径，只需要改为你本地编辑器的路径即可，然后在执行 hexo cl &amp;&amp; hexo g -d，部署到 GitHub 即可，以后在新建文章就会自动打开编辑器。

常见问题篇
如何调试博客

需要一定的 web 开发知识才能做。
学会一些简单调试及基本 html 语言很容易，网上教程很多。
按 F12 进入调试模式，元素，网络，控制台，是常用的页面。



通过 hexo g -d 部署时报 Error: Spawn failed 错误:

这是由于 git 本地记录的提交版本号与 github 上不一致导致的，通过 git reset --hard commitCode 即可解决。


检查本地最近提交记录，获取最后一次提交记录的更新时间及标识，如 280a7fdd46fcfd7d34e652aec15523dcd247fac8

cd .deploy_git
cat .git/logs/HEAD

获取 github pages 服务所关联分支的最近一次提交记录，获取更新时间及标识。地址一般为：https://github.com/用户名/仓库名/commits/分支名，如 https://github.com/lxl80/blog/commits/gh-pages
如果发现提交最新的提交时间 / 标识不一致，通过以下命令即可解决:

git reset --hard f085038efdf79546c09641d37b2a2429c1ae8e60 #github上最新的提交标识
hexo docker 本地访问内容没有更新
可能是 node 内部 PM2 模块的缓存机制导致的。pm2 模块重启一下就可以了。
pm2 restart /hexo_run.js

fsevents 报错
npm ERR! code EBADPLATFORM npm ERR! notsup Unsupported platform for
fsevents@2.3.2: wanted {"os":"darwin","arch":"any"} (current:
{"os":"win32","arch":"x64"}) npm ERR! notsup Valid OS:    darwin npm
ERR! notsup Valid Arch:  any npm ERR! notsup Actual OS:   win32 npm
ERR! notsup Actual Arch: x64
解决方法：修改 package.json
"optionalDependencies": {
  "fsevents": "^2.3.2"
},
关于百度无法爬取 GitHub 内容解决方案


使用 coding 搭建一个可以被百度爬取到的代码托管平台
使用 vps 搭建一个 hexo 镜像访问，专门针对搜索引擎。



Tips: 博主用了第二种方法，2 个域名，前端域名用 dnspod，采用 cloudflare parter cname 接入。dnspos 有选路选择，针对搜索引擎进入 vps 搭建的 blog，对于其它线路到 cloudflare parter 加速过的 github pages  cname。后端域名用 cloudflare parter 以及免费版 cloudflare 管理。

既然百度无法爬取 GitHub，那么我们只需要找个可以被百度爬取到的代码托管平台即可（并且还提供 pages 服务），基本只有国内的平台了：Gitee 和 Coding！Gitee 自定义域名要花钱（九十多，都可以买服务器了），而 Coding 是可以免费自定义域名的。这里推介大家使用企业版的 Coding，因为企业版的 Coding 仓库服务器是在香港的，而普通版的服务器是在新加坡。地理原因，理论上企业版的更快一些！


将博客同时部署到两个仓库：GitHub 和 Coding
deploy:
- type: git
  repository: git@github.com:xxx/xxx.github.io.git
  branch: master

- type: git
  repository: git@e.coding.net:xxx/xxx.git
  branch: master


在域名那里，配置两个解析

线路类型作用：如果该值填 “国内”，国内的 IP 就会去访问此项对应的记录值地址
同理，如果该值填写 “国外”，国外的 IP 就会去访问 “国外” 对应的记录值地址


线路类型为百度或者国内，记录值为 Coding仓库的地址
线路类型为默认或者国外，记录值为 GitHub仓库地址




这样来自百度的spider 就会去爬国内Coding 的地址，而两个仓库的内容又都是一样的，如果请求 IP 来自国外，它又会去访问国外的GitHub，这样还有利于外国华侨和那些科学上网的用户访问，一石二鸟！（我真他妈天才！）


如果你只用 Coding 仓库，那就不需要这么麻烦了


测试百度 Spider 能不能爬你的域名


在任意目录下执行以下命令（将 “你的域名” 换成你的域名）
curl -A "Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)" -o example.html 你的域名


执行完命令，在该目录下会生成一个文件：example.html，打开它，如果显示


Moved Permanently，说明 301，被重定向了


Found，也就是爬到了


如果打开是你的首页，说明爬取到的内容就是你的首页 HTML 内容。


如果显示：

说明域名是解析到 GitHub 的，403Forbidden 访问禁止。






busuanzi 不蒜子计数显示异常，一闪就没



原因可能有两种 live2d 看板娘和 busuanzi 不蒜子计数冲突


busuanzi 不蒜子网络访问异常。





不在 leancloud 安全名单


不是正常域名访问


各种网络访问错误等等




近日安装了 live2d 看板娘插件，github 项目地址，安装后却意外发现 busuanzi 不蒜子计数失效了，在页面中不显示，但强制刷新后出现，再刷新又消失。经排查，未发现问题，但事实是网站源码出现了变化。

正常时

&lt;div id="busuanzi_container_page_pv" class="info-break-policy" style="display: inline;"&gt;
    &lt;i class="far fa-eye fa-fw"&gt;&lt;/i&gt;阅读次数:&amp;nbsp;&amp;nbsp;
    &lt;span id="busuanzi_value_page_pv"&gt;433&lt;/span&gt;

异常时

&lt;div id="busuanzi_container_page_pv" class="info-break-policy" style="display: none;"&gt;
    &lt;i class="far fa-eye fa-fw"&gt;&lt;/i&gt;阅读次数:&amp;nbsp;&amp;nbsp;
    &lt;span id="busuanzi_value_page_pv"&gt;434&lt;/span&gt;
对比发现出现了多余的 style="display: none;。
经过搜索主题源码，发现这个文件 themes\matery\source\libs\others\busuanzi.pure.mini.js 控制显示。
可以直接下载下面这个地址的 js 替换，来自个人 blog 的 js   busuanzi.pure.mini.js，直接下载这个 js 替换即可。下面源码经过了展开美化，原始文件是压缩去空格版本的。
注意： 这是一种破坏性修复，没有解决根本问题，临时修复方案。
var bszCaller, bszTag;
! function () {
    var c, d, e, a = !1,
        b = [];
    ready = function (c) {
        return a || "interactive" === document.readyState || "complete" === document.readyState ? c.call(document) :
            b.push(function () {
                return c.call(this)
            }), this
    }, d = function () {
        for (var a = 0, c = b.length; c &gt; a; a++) b[a].apply(document);
        b = []
    }, e = function () {
        a || (a = !0, d.call(window), document.removeEventListener ? document.removeEventListener(
            "DOMContentLoaded", e, !1) : document.attachEvent &amp;&amp; (document.detachEvent("onreadystatechange",
            e), window == window.top &amp;&amp; (clearInterval(c), c = null)))
    }, document.addEventListener ? document.addEventListener("DOMContentLoaded", e, !1) : document.attachEvent &amp;&amp; (
        document.attachEvent("onreadystatechange", function () {
            /loaded|complete/.test(document.readyState) &amp;&amp; e()
        }), window == window.top &amp;&amp; (c = setInterval(function () {
            try {
                a || document.documentElement.doScroll("left")
            } catch (b) {
                return
            }
            e()
        }, 5)))
}(), bszCaller = {
    fetch: function (a, b) {
        var c = "BusuanziCallback_" + Math.floor(1099511627776 * Math.random());
        window[c] = this.evalCall(b), a = a.replace("=BusuanziCallback", "=" + c), scriptTag = document.createElement(
                "SCRIPT"), scriptTag.type = "text/javascript", scriptTag.defer = !0, scriptTag.src = a,
            document.getElementsByTagName("HEAD")[0].appendChild(scriptTag)
    },
    evalCall: function (a) {
        return function (b) {
            ready(function () {
                try {
                    a(b), scriptTag.parentElement.removeChild(scriptTag)
                } catch (c) {
                    bszTag.hides()
                }
            })
        }
    }
}, bszCaller.fetch("//busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback", function (a) {
    bszTag.texts(a), bszTag.shows()
}), bszTag = {
    bszs: ["site_pv", "page_pv", "site_uv"],
    texts: function (a) {
        this.bszs.map(function (b) {
            var c = document.getElementById("busuanzi_value_" + b);
            c &amp;&amp; (c.innerHTML = a[b])
        })
    },
    hides: function () {
        this.bszs.map(function (a) {
            var b = document.getElementById("busuanzi_container_" + a);
            b &amp;&amp; (b.style.display = "")
        })
    },
    shows: function () {
        this.bszs.map(function (a) {
            var b = document.getElementById("busuanzi_container_" + a);
            b &amp;&amp; (b.style.display = "inline")
        })
    }
};
替换的人请操作其实就是把其中的 b.style.display="none" 中 none 去掉。
不蒜子 (busuanzi) 文章计数出错问题
出现这个原因，和 Chrome 85 版本 Referrer Policy 更改有关。什么是 Referrer，简单理解，就是请求 Web 服务器时，可以在 HTTP Request 的请求头 (header) 中加上当前页面的 URL，例如我们在浏览某个博客页面，需要加载一些图片，从服务器请求这些图片时，referrer 就是当前的博客页面 URL。从这里也可以看出，referrer 可能会暴露请求来源的某些信息或者隐私，有一定的隐私或安全风险。之前版本的 Chrome 浏览器，如果网站没有指定自己的 Referrer Policy，那么 Chrome 默认 policy 是 no-referrer-when-downgrade，在 Chrome 85 版本中，为了保护用户的隐私，默认的 Referrer Policy 则变成了 strict-origin-when-cross-origin。

no-referrer-when-downgrade: 当两个网站的 http 协议安全等级相当，或者目的网站安全协议等级高于当前网站 (HTTP –&gt; HTTP, HTTPS –&gt; HTTPS, HTTP –&gt; HTTPS)， referer 将会包含源网站的域名，路径，查询字符串；如果目的网站安全协议等级低于源网站 (HTTPS –&gt; HTTP)，将不会发送这些信息。
strict-origin-when-cross-origin： 只有当做同一域名请求时 (源网址和目标网址是同一域名），才发送域名，路径和请求字符串，当两个网站安全协议相当时，发送源网站的域名 (没有具体路径信息和查询字符串)，如果目标网站安全协议等级低于源网站，不发送 header 信息。

不蒜子统计博客文章访问量就是通过 referer 来计算的，通过上面的分析，如果 Referrer Policy 是 strict-origin-when-cross-origin，不蒜子接收到的只有博客的域名，没有文章的具体路径，所以具体某个文章的 PV 统计会出现错误。
修复方法：
在主题文件夹下 /layout/_partial/head.ejs 中添加
&lt;meta name="referrer" content="no-referrer-when-downgrade"&gt;
如何多个域名映射同一个 github pages
可能由于某种原因，换了一个域名，之前又有一些被搜索引擎收录，但是又不想让原来的链接失效，就需要让两个域名都映射到 github pages 中。本文介绍几种当前可能的方法。欢迎提出更多有效方法。
直接映射有什么问题？
你可能会想，两个域名都映射到 github pages 不就可以了？然而事实并非如此。首先当前 github 的 CNAME 中只支持一个域名。因此 CNAME 文件中只能有一个域名，而如果在域名映射中将两个域名都映射到 username.github.io，那么其中有一个会出现 404 错误。
前提
以下方法的前提是你已经明白如何为自己的 github pages 添加自定义域名。
需要注意什么？

需要给各大网站提交新的域名网址，重新被收录
域名变换前面网站的内容结构不能变，否则重定向也没有意义
当前单纯的域名没有办法进行备案
注意修改配置文件里的主域名为新的域名
由于更换了新的域名，导致原来 leancloud 统计的访问数据需要重新计算，也就是网站访问量被清零了，leancloud 也需要更新域名
新的 com 域名可申请免费的 SSL 证书，保证 https 可访问，而不会提示不安全
 301 重定向会将旧地址的权重转义到新地址上
百度收录速度较慢

方法一：域名托管平台重定向
有的域名服务商提供重定向功能，以阿里云为例，在域名映射添加记录的时候，可以选择显性 URL 或隐性 URL。但是自己在尝试这种方法的时候，会提示我 URL 备案异常。可能是由于这个时候已经用新的域名映射了博客地址，但是新的域名实际上是没有备案的。更无奈的是，目前貌似没有办法单独对域名进行备案。因此本人放弃了该方法。
如果你的博客也是部署在 github 上的，那么这种方法就不用尝试了，如果你的博客是部署在自己的服务器上的，那么网上都很多方法，这里就不介绍了。
方法二：部署两个仓库
我们注意到，除了 github pages，还有 coding.net 可用。它与 github 类似。原来的域名映射到这个地址就可以了。而在部署 hexo 的时候，是可以添加两个仓库地址的：
deploy:
- type: git
  repository: git@github.com:username/username.github.io.git
  branch: master
- type: git
  repository: git@git.coding.net:username/username.git
  branch: coding-pages
这两个仓库内容唯一的差别就是域名不一样，即 CNAME 中的记录值不一样。这样当访问两个不同的域名的时候，是访问不同的两个平台仓库。但是原来域名的权重不会转到新的域名中去。
方法三：新增项目重定向
假如你已经有 username.github.io 项目，新建一个名为 blog (名字自定义) 的项目，在项目的 setting 中，开启 github pages 服务，并且将旧的域名映射到 username.github.io。
实际上，github pages 并不是只能有一个，例如，你新创建的仓库访问地址为：username.github.io/blog。
由于旧的域名映射会导致 404 错误，那么在我们的新项目中增加一个 404.html，在页面中进行跳转即可：
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta charset="utf-8"&gt;
&lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
 &lt;script language="javascript"&gt;
var domain = "换成你自己的新域名";
var src = window.location.href;
var prtc = src.substring(0, src.indexOf(':'));
var target = src.substring(src.indexOf('/', src.indexOf(':') + 3));
window.location.href = prtc + "://" + domain + target;
location.href=prtc + "://" + domain + target;
&lt;/script&gt;
&lt;body&gt;
 &lt;h1&gt;&lt;/h1&gt;
&lt;/body&gt;
&lt;/html&gt;
另外，需要利用 google 的地址更改功能，使得旧网址的权重往新网址转移。
找到 search console 中的地址更改工具（设置按钮中找到）。
除了增加 404 页面外，还需要增加 CNAME 文件，里面的内容是你原先的域名。
参照

基于 Hexo 的 matery 主题搭建博客并深度优化 - 悟尘记
hexo 官方文档
闪烁之狐
hexo-theme-matery
Hexo 进阶之各种优化
Leancloud+Valine 打造 Hexo 个人博客极简评论系统
Hexo 进阶之各种优化
自动部署篇
Hexo 搭建 (VPS)
解决 live2d 看板娘和 busuanzi 不蒜子计数冲突
多个域名映射同一个 github pages
hexo 博客简单支持 PWA
Hexo 每天自动提交网站 url 到搜索引擎
Hexo 博客订阅文章通知功能
修改 matery 原有主题相册
Matery 主题新手常见问题
hexo-gitlab-cicd-conf
更改 hexo 的主题为 Matery, 并进行初步的优化
Hexo 之渲染绕过
使用 gulp 压缩图片
Hexo+Github 博客搭建完全教程 博客开源
Hexo 主题使用 Valine-Admin 管理评论和评论提醒
Hexo 博客进阶：图片懒加载与代码压缩
matery 主题个性化定制
crystalblog 三部曲  1 2 3
个人博客搭建 博客开源
PWA 踩坑记 - 从零到一让你的博客也能离线访问
Matery 主题添加暗色模式 黑夜模式 开源代码 hexo-themes-matery-pro
加载动画 (吃豆豆)  加载动画旋转方块
优化 search.xml 大小

系列教程
hexo 系列

hexo 独立博客搭建 [三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优化



 docker 环境
 hexo 使用入门
 hexo 基础配置
自定义修改
 hexo 部署
个性定义
性能优化
常见问题 



Hexo Markdown 以及各种插件功能测试



 markdown 各种其它语法插件
 latex 公式支持
 mermaid 图表
 plant uml 图表
 URL 卡片
 bilibili 卡片
 github 卡片
豆瓣卡片
插入音乐和视频
插入脑图


笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>Github</tag>
        <tag>hexo</tag>
        <tag>matery</tag>
        <tag>cdn</tag>
        <tag>seo</tag>
      </tags>
  </entry>
  <entry>
    <title>浏览器的渲染过程</title>
    <url>/posts/69a052c9/</url>
    <content><![CDATA[
通常，我们只需要编写 HTML，CSS，JavaScript，浏览器上就能呈现出漂亮的网页了，但是浏览器是如何使用我们的代码在屏幕上渲染像素的呢？

首先，请先看一张大图
浏览器将 HTML，CSS，JavaScript 代码转换成屏幕上所能呈现的实际像素，这期间所经历的一系列步骤，叫做关键渲染路径（Critical Rendering Path）。其中包含：

构建对象模型（DOM，CSSOM）
构建渲染树（RenderTree）
布局
渲染

在构建对象模型到构建渲染树的这一过程，还穿插着 JS 脚本的加载和执行。如下图所示：

1.DOMTree 的构建
浏览器的渲染从解析 HTML 文档开始，宏观上，可以分为下面几个步骤：


第一步（解析）：从网络或者磁盘下读取的 HTML 原始字节码，通过设置的 charset 编码，转换成相字符



第二步（token 化）：通过词法分析器，将字符串解析成 Token，Token 中会标注出当前的 Token 是开始标签，还是结束标签，或者文本标签等。



第三步（生成 Nodes 并构建 DOM 树）：浏览器会根据 Tokens 里记录的开始标签，结束标签，将 Tokens 之间相互串联起来_（带有结束标签的 Token 不会生成 Node）_。
Node 包含了这个节点的所有属性。例如 &lt;img src="xxx.png" &gt; 标签最终生成出的节点对象中会保存图片地址等信息。
事实上，在构建 DOM 树时，不是要等所有的 Tokens 都转换成 Nodes 后才开始，而是一边生成 Token 一边采取深度遍历算法消耗 Token 来生成 Node，如下图所示：
图中有颜色的小数字代表构建的具体步骤，可以看出，首先生成出 html Token, 并消耗 Token 创建出 html 节点对象，接着生成 head Token 并消耗 Token 创建出 head节点对象......，当所有的 Tokens 都消耗完了，紧接着 DOM 树也就构建完了。


这里抛出个小问题，为什么有时在 js 中访问 DOM 时浏览器会报错呢？
因为在上述的解析的过程中，如果碰到了script或者 link 标签，就会根据 src 对应的地址去加载资源，在script标签没有设置 async/defer 属性时，这个加载过程是下载并执行完全部的代码，此时，DOM 树还没有完全创建完毕，这个时候如果 js 企图访问 script 标签后面的 DOM 元素，浏览器就会抛出找不到该 DOM 元素的错误。
值得注意的是：从 bytes 到 Tokens 的这个过程，浏览器都可以交给其他单独的线程去处理，不会堵塞浏览器的渲染线程。但是后面的部分就都在渲染线程下进行了，也就是我们常说的 js 单线程环境。
2.CSSOMTree 的构建
DOM 会记录页面的内容，但是浏览器还需要知道这些内容该用什么样式去展示，所以还需要构建 CSSOMTree。CSSOM 的生成过程和 DOM 的生成过程十分相似，也是：1. 解析，2.Token 化，3. 生成 Nodes 并构建 CSSOMTree：
假设浏览器收到了下面这样一段 css:
body {font-size: 16px;}
p {font-weight: bold;}
p span {display:none;}
span {color: red;}
img {float: right;}
最终会生成如下的 CSSOMTree:

从图中可以看出，最开始 body 有一个样式规则是 font-size:16px，之后，在 body 这个样式基础上每个子节点还会添加自己单独的样式规则，比如 span 又添加了一个样式规则 color:red。正是因为样式这种类似于继承的特性，浏览器设定了一条规则：CSSOMTree 需要等到完全构建后才可以被使用，因为后面的属性可能会覆盖掉前面的设置。比如在上面的 css 代码基础上再添加一行代码 p {font-size:12px}，那么之前设置的 16px 将会被覆盖成 12px。
下面是官方给的一种解释：

未构建完的 CSSOMTree 是不准确的，浏览器必须等到 CSSOMTree 构建完毕后才能进入下一阶段。
所以，CSS 的加载速度与构建 CSSOMTree 的速度将直接影响首屏渲染速度，因此在默认情况下 CSS 被视为阻塞渲染的资源，需要将它尽早、尽快地下载到客户端，以便缩短首次渲染的时间。

那么回到上面生成 DOM 时提到的 JS 问题：在标签没有设置 async/defer 属性时，js 会阻塞 DOM 的生成。原因是 js 会改变 DOMTree 的内容，如果不阻塞，会出现一边生成 DOM 内容，一边修改 DOM 内容的情况，无法确保最终生成的 DOMTree 是确定唯一的。
同理，JS 也会可以修改 CSS 样式，影响 CSSOMTree 最终的结果。而我们前面提到，不完整的 CSSOMTree 是不可以被使用的，如果 JS 试图在浏览器还未完成 CSSOMTree 的下载和构建时去操作 CSS 样式，浏览器会暂停脚本的运行和 DOM 的构建，直至浏览器完成了 CSSOM 的下载和构建。也就是说，JS 脚本的出现会让 CSSOM 的构建阻塞 DOM 的构建。

平时谈及页面性能优化，经常会强调 css 文件应该放在 html 文档中的前面引入，js 文件应该放在后面引入，这么做的原因是什么呢？

举个例子：本来，DOM 构建和 CSSOM 构建是两个过程，井水不犯河水。假设 DOM 构建完成需要 1s，CSSOM 构建也需要 1s，在 DOM 构建了 0.2s 时发现了一个 link 标签，此时完成这个操作需要的时间大概是 1.2s，如下图所示：

而此时我们在 HTML 文档的中间插中入了一段 JS 代码，在 DOM 构建中间的过程中发现了这个script标签，假设这段 JS 代码只需要执行 0.0001s，那么完成这个操作需要的时间就会变成：

那如果我们把 css 放到前面，js 放到最后引入时，构建时间会变成：

由此可见，虽然只是插入了小小的一段只运行 0.0001s 的 js 代码，不同的引入时机也会严重影响 DOMTree 的构建速度。
简而言之，如果在 DOM，CSSOM 和 JavaScript 执行之间引入大量的依赖关系，可能会导致浏览器在处理渲染资源时出现大幅度延迟：

当浏览器遇到一个 script 标签时，DOMTree 的构建将被暂停，直至脚本执行完毕
 JavaScript 可以查询和修改 DOMTree 与 CSSOMTree
 直至 CSSOM 构建完毕，JavaScript 才会执行
脚本在文档中的位置很重要

3. 渲染树的构建
现在，我们已经拥有了完整的 DOM 树和 CSSOM 树。DOM 树上每一个节点对应着网页里每一个元素，CSSOM 树上每个节点对应着网页里每个元素的样式，并且此时浏览器也可以通过 JavaScript 操作 DOM/CSSOM 树，动态改变它的结构。但是 DOM/CSSOM 树本身并不能直接用于排版和渲染，浏览器还会生成另外一棵树：Render 树

接下来我们来谈几条概念


Render 树上的每一个节点被称为：RenderObject。


RenderObject 跟 DOM 节点几乎是一一对应的，当一个可见的 DOM 节点被添加到 DOM 树上时，内核就会为它生成对应的 RenderOject 添加到 Render 树上。


其中，可见的 DOM 节点不包括：


一些不会体现在渲染输出中的节点（&lt;html&gt;&lt;script&gt;&lt;link&gt;….），会直接被忽略掉。


通过 CSS 隐藏的节点。例如上图中的 span 节点，因为有一个 CSS 显式规则在该节点上设置了 display:none 属性，那么它在生成 RenderObject 时会被直接忽略掉。


Render 树是衔接浏览器排版引擎和渲染引擎之间的桥梁，它是排版引擎的输出，渲染引擎的输入。


此时的 Render 树上，已经包含了网页上所有可见元素的内容和位置信息 排版引擎会根据 Render 树的内容和结构，准确的计算出元素该在网页上的什么位置。到此，我们已经具备进入布局的一切准备条件，但是通过上面我们知道，布局后面还有一个渲染过程，那么_Render 树是衔接浏览器排版引擎和渲染引擎之间的桥梁，它是排版引擎的输出，渲染引擎的输入。_这句话是什么意思呢？
RenderObject and RenderLayer

浏览器渲染引擎并不是直接使用 Render 树进行绘制，为了方便处理 Positioning,Clipping,Overflow-scroll,CSS Transfrom/Opacrity/Animation/Filter,Mask or Reflection,Z-indexing 等属性，浏览器需要生成另外一棵树：Layer 树


浏览器会为一些特定的 RenderObject 生成对应的 RenderLayer，其中的规则是：

是否是页面的根节点 It’s the root object for the page
 是否有 css 的一些布局属性（relative absolute or a transform) It has explicit CSS position properties (relative, absolute or a transform)
 是否透明 It is transparent
 是否有溢出 Has overflow, an alpha mask or reflection
 是否有 css 滤镜 Has a CSS filter
 是否包含一个 canvas 元素使得节点拥有视图上下文 Corresponds to canvas element that has a 3D (WebGL) context or an accelerated 2D context
 是否包含一个 video 元素 Corresponds to a video element

当满足上面其中一个条件时，这个 RrenderObject 就会被浏览器选中生成对应的 RenderLayer。至于那些没有被命运选中的 RrenderObject，会从属与父节点的 RenderLayer。最终，每个 RrenderObject 都会直接或者间接的属于一个 RenderLayer。
浏览器渲染引擎在布局和渲染时会遍历整个 Layer 树，访问每一个 RenderLayer，再遍历从属于这个 RenderLayer 的 RrenderObject，将每一个 RenderObject 绘制出来。可以理解为：Layer 树决定了网页绘制的层次顺序，而从属于 RenderLayer 的 RrenderObject 决定了这个 Layer 的内容，所有的 RenderLayer 和 RrenderObject 一起就决定了网页在屏幕上最终呈现出来的内容。
4. 布局
到目前为止，浏览器计算出了哪些节点是可见的以及它的信息和样式，接下来就需要计算这些节点在设备视口内的确切位置和大小，这个过程我们称之为 “布局”。
布局最后的输出是一个 “盒模型”：将所有相对测量值都转换成屏幕上的绝对像素。

5. 渲染
最后，既然我们知道了哪些节点可见、它们的计算样式以及几何信息，我们终于可以将这些信息传递给最后一个阶段：将渲染树中的每个节点转换成屏幕上的实际像素：浏览器通过发出 “Paint Setup” 和 “Paint” 事件，将渲染树转换成屏幕上的像素。

至此，我们就能够在浏览器上看到漂亮的网页了

谈及页面性能优化，我们也常说要尽量减少浏览器的重排和重绘，浏览器重排和重绘时究竟做了哪些工作呢？

我们平时常说的重排，其实就是浏览器计算 render 树，布局到渲染的这个过程，而重绘就是计算 layer 树到渲染的这个过程，每当触发一次重绘和重排时，浏览器都需要重新经过一遍上述的计算。很显然，重排会产生比重绘更大的开销，但无论是重排还是重绘，都会给浏览器渲染线程造成很大的负担，所以，我们在实际生产中要严格注意减少重排和重绘的触发。至于如何减少重排和重绘的次数，这里就不多做展开了，详细请听下回分解～
总结：

经过：1. 构建对象模型（DOM，CSSOM），2. 构建渲染树（RenderTree），3. 布局，4. 渲染 这几个步骤后，我们就能在浏览器上看到漂亮的网页啦。
CSS 被视为阻塞渲染的资源，应放到代码的头部尽快加载。
同步的 JavaScript 会暂停 DOMTree 的构建，应放到代码的尾部最后加载，或者使用 async/defer属性异步加载 JavaScript。
重排和重绘会给浏览器渲染线程造成很大的负担，尽量减少重排和重绘的触发次数

参考文献：
https://developers.google.com/web/fundamentals/performance/critical-rendering-path/constructing-the-object-model?hl=zh-cn
https://developers.google.com/web/fundamentals/performance/critical-rendering-path/render-tree-construction?hl=zh-cn
https://developers.google.com/web/fundamentals/performance/critical-rendering-path/render-blocking-css?hl=zh-cn
https://mp.weixin.qq.com/s?__biz=MzA5NzkwNDk3MQ==&amp;mid=2650588806&amp;idx=1&amp;sn=408a54e7c8102fd6944c9a40b119015a&amp;scene=21#wechat_redirect
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>http</tag>
        <tag>css</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title>在浏览器输入 URL 回车之后发生了什么</title>
    <url>/posts/656a0abb/</url>
    <content><![CDATA[前言

这个问题已经是老生常谈了，更是经常被作为面试的压轴题出现，网上也有很多文章，但最近闲的无聊，然后就自己做了一篇笔记，感觉比之前理解更透彻了。
这篇笔记是我这两天看了数十篇文章总结出来的，所以相对全面一点，但由于我是做前端的，所以会比较重点分析浏览器渲染页面那一部分，至于其他部分我会罗列出关键词，感兴趣的可以自行查阅，
** 注意：** 本文的步骤是建立在，请求的是一个简单的 HTTP 请求，没有 HTTPS、HTTP2、最简单的 DNS、没有代理、并且服务器没有任何问题的基础上，尽管这是不切实际的。
大致流程

URL 解析
 DNS 查询
 TCP 连接
处理请求
接受响应
渲染页面

一、URL 解析
地址解析：
首先判断你输入的是一个合法的 URL 还是一个待搜索的关键词，并且根据你输入的内容进行自动完成、字符编码等操作。
HSTS
由于安全隐患，会使用 HSTS 强制客户端使用 HTTPS 访问页面。详见：你所不知道的 HSTS (opens new window)。
其他操作
浏览器还会进行一些额外的操作，比如安全检查、访问限制（之前国产浏览器限制 996.icu）。
检查缓存

二、DNS 查询
基本步骤

1. 浏览器缓存
浏览器会先检查是否在缓存中，没有则调用系统库函数进行查询。
2. 操作系统缓存
操作系统也有自己的 DNS 缓存，但在这之前，会向检查域名是否存在本地的 Hosts 文件里，没有则向 DNS 服务器发送查询请求。
3. 路由器缓存
路由器也有自己的缓存。
4. ISP DNS 缓存
ISP DNS 就是在客户端电脑上设置的首选 DNS 服务器，它们在大多数情况下都会有缓存。
根域名服务器查询
在前面所有步骤没有缓存的情况下，本地 DNS 服务器会将请求转发到互联网上的根域，下面这个图很好的诠释了整个流程：


根域名服务器：维基百科 (opens new window)

需要注意的点

递归方式：一路查下去中间不返回，得到最终结果才返回信息（浏览器到本地 DNS 服务器的过程）
迭代方式，就是本地 DNS 服务器到根域名服务器查询的方式。
什么是 DNS 劫持
前端 dns-prefetch 优化

三、TCP 连接
TCP/IP 分为四层，在发送数据时，每层都要对数据进行封装：

1. 应用层：发送 HTTP 请求
在前面的步骤我们已经得到服务器的 IP 地址，浏览器会开始构造一个 HTTP 报文，其中包括：

请求报头（Request Header）：请求方法、目标地址、遵循的协议等等
请求主体（其他参数）

其中需要注意的点：

浏览器只能发送 GET、POST 方法，而打开网页使用的是 GET 方法

2. 传输层：TCP 传输报文
传输层会发起一条到达服务器的 TCP 连接，为了方便传输，会对数据进行分割（以报文段为单位），并标记编号，方便服务器接受时能够准确地还原报文信息。
在建立连接前，会先进行 TCP 三次握手。

关于 TCP/IP 三次握手，网上已经有很多段子和图片生动地描述了。
相关知识点：

SYN 泛洪攻击


3. 网络层：IP 协议查询 Mac 地址
将数据段打包，并加入源及目标的 IP 地址，并且负责寻找传输路线。
判断目标地址是否与当前地址处于同一网络中，是的话直接根据 Mac 地址发送，否则使用路由表查找下一跳地址，以及使用 ARP 协议查询它的 Mac 地址。

注意：在 OSI 参考模型中 ARP 协议位于链路层，但在 TCP/IP 中，它位于网络层。

4. 链路层：以太网协议
以太网协议
根据以太网协议将数据分为以 “帧” 为单位的数据包，每一帧分为两个部分：

标头：数据包的发送者、接受者、数据类型
数据：数据包具体内容

Mac 地址
以太网规定了连入网络的所有设备都必须具备 “网卡” 接口，数据包都是从一块网卡传递到另一块网卡，网卡的地址就是 Mac 地址。每一个 Mac 地址都是独一无二的，具备了一对一的能力。
广播
发送数据的方法很原始，直接把数据通过 ARP 协议，向本网络的所有机器发送，接收方根据标头信息与自身 Mac 地址比较，一致就接受，否则丢弃。
注意：接收方回应是单播。

相关知识点：

ARP 攻击


服务器接受请求
接受过程就是把以上步骤逆转过来，参见上图。
四、服务器处理请求
大致流程

HTTPD
最常见的 HTTPD 有 Linux 上常用的 Apache 和 Nginx，以及 Windows 上的 IIS。
它会监听得到的请求，然后开启一个子进程去处理这个请求。
处理请求
接受 TCP 报文后，会对连接进行处理，对 HTTP 协议进行解析（请求方法、域名、路径等），并且进行一些验证：

验证是否配置虚拟主机
验证虚拟主机是否接受此方法
验证该用户可以使用该方法（根据 IP 地址、身份信息等）

重定向
假如服务器配置了 HTTP 重定向，就会返回一个 301 永久重定向响应，浏览器就会根据响应，重新发送 HTTP 请求（重新执行上面的过程）。

关于更多：详见这篇文章 (opens new window)

URL 重写
然后会查看 URL 重写规则，如果请求的文件是真实存在的，比如图片、html、css、js 文件等，则会直接把这个文件返回。
否则服务器会按照规则把请求重写到 一个 REST 风格的 URL 上。
然后根据动态语言的脚本，来决定调用什么类型的动态文件解释器来处理这个请求。
以 PHP 语言的 MVC 框架举例，它首先会初始化一些环境的参数，根据 URL 由上到下地去匹配路由，然后让路由所定义的方法去处理请求。
五、浏览器接受响应
浏览器接收到来自服务器的响应资源后，会对资源进行分析。
首先查看 Response header，根据不同状态码做不同的事（比如上面提到的重定向）。
如果响应资源进行了压缩（比如 gzip），还需要进行解压。
然后，对响应资源做缓存。
接下来，根据响应资源里的 MIME (opens new window) 类型去解析响应内容（比如 HTML、Image 各有不同的解析方式）。
六、渲染页面
浏览器内核

不同的浏览器内核，渲染过程也不完全相同，但大致流程都差不多。
基本流程

1. HTML 解析
首先要知道浏览器解析是从上往下一行一行地解析的。
解析的过程可以分为四个步骤：
1. 解码（encoding）
传输回来的其实都是一些二进制字节数据，浏览器需要根据文件指定编码（例如 UTF-8）转换成字符串，也就是 HTML 代码。
2. 预解析（pre-parsing）
预解析做的事情是提前加载资源，减少处理时间，它会识别一些会请求资源的属性，比如 img 标签的 src 属性，并将这个请求加到请求队列中。
3. 符号化（Tokenization）
符号化是词法分析的过程，将输入解析成符号，HTML 符号包括，开始标签、结束标签、属性名和属性值。
它通过一个状态机去识别符号的状态，比如遇到 &lt;，&gt; 状态都会产生变化。
4. 构建树（tree construction）

注意：符号化和构建树是并行操作的，也就是说只要解析到一个开始标签，就会创建一个 DOM 节点。

在上一步符号化中，解析器获得这些标记，然后以合适的方法创建 DOM 对象并把这些符号插入到 DOM 对象中。

浏览器容错进制
你从来没有在浏览器看过类似 "语法无效" 的错误，这是因为浏览器去纠正错误的语法，然后继续工作。
事件
当整个解析的过程完成以后，浏览器会通过 DOMContentLoaded 事件来通知 DOM 解析完成。
2. CSS 解析
一旦浏览器下载了 CSS，CSS 解析器就会处理它遇到的任何 CSS，根据语法规范 (opens new window) 解析出所有的 CSS 并进行标记化，然后我们得到一个规则表。
CSS 匹配规则
在匹配一个节点对应的 CSS 规则时，是按照从右到左的顺序的，例如：div p { font-size :14px } 会先寻找所有的 p 标签然后判断它的父元素是否为 div。
所以我们写 CSS 时，尽量用 id 和 class，千万不要过度层叠。
3. 渲染树
其实这就是一个 DOM 树和 CSS 规则树合并的过程。

注意：渲染树会忽略那些不需要渲染的节点，比如设置了 display:none 的节点。

计算
通过计算让任何尺寸值都减少到三个可能之一：auto、百分比、px，比如把 rem 转化为 px。
级联
浏览器需要一种方法来确定哪些样式才真正需要应用到对应元素，所以它使用一个叫做 specificity 的公式，这个公式会通过：

标签名、class、id
 是否内联样式
!important

然后得出一个权重值，取最高的那个。
渲染阻塞
当遇到一个script标签时，DOM 构建会被暂停，直至脚本完成执行，然后继续构建 DOM 树。
但如果 JS 依赖 CSS 样式，而它还没有被下载和构建时，浏览器就会延迟脚本执行，直至 CSS Rules 被构建。
所有我们知道：

CSS 会阻塞 JS 执行
 JS 会阻塞后面的 DOM 解析

为了避免这种情况，应该以下原则：

CSS 资源排在 JavaScript 资源前面
 JS 放在 HTML 最底部，也就是 &lt;/body&gt; 前

另外，如果要改变阻塞模式，可以使用 defer 与 async，详见：这篇文章 (opens new window)

 布局与绘制

确定渲染树种所有节点的几何属性，比如：位置、大小等等，最后输入一个盒子模型，它能精准地捕获到每个元素在屏幕内的准确位置与大小。
然后遍历渲染树，调用渲染器的 paint () 方法在屏幕上显示其内容。
5. 合并渲染层
把以上绘制的所有图片合并，最终输出一张图片。
6. 回流与重绘
回流 (reflow)
当浏览器发现某个部分发现变化影响了布局时，需要倒回去重新渲染，会从 html 标签开始递归往下，重新计算位置和大小。
reflow 基本是无法避免的，因为当你滑动一下鼠标、resize 窗口，页面就会产生变化。
重绘 (repaint)
改变了某个元素的背景色、文字颜色等等不会影响周围元素的位置变化时，就会发生重绘。
每次重绘后，浏览器还需要合并渲染层并输出到屏幕上。
回流的成本要比重绘高很多，所以我们应该尽量避免产生回流。
比如：

display:none 会触发回流，而 visibility:hidden 只会触发重绘。


JavaScript 编译执行

大致流程

可以分为三个阶段：
1. 词法分析
JS 脚本加载完毕后，会首先进入语法分析阶段，它首先会分析代码块的语法是否正确，不正确则抛出 “语法错误”，停止执行。
几个步骤：

分词，例如将 var a = 2，，分成 var、a、=、2 这样的词法单元。
解析，将词法单元转换成抽象语法树（AST）。
代码生成，将抽象语法树转换成机器指令。

2. 预编译
JS 有三种运行环境：

全局环境
函数环境
 eval

每进入一个不同的运行环境都会创建一个对应的执行上下文，根据不同的上下文环境，形成一个函数调用栈，栈底永远是全局执行上下文，栈顶则永远是当前执行上下文。
创建执行上下文
创建执行上下文的过程中，主要做了以下三件事：

创建变量对象

参数、函数、变量


建立作用域链

确认当前执行环境是否能访问变量


确定 This 指向

3. 执行
JS 线程

虽然 JS 是单线程的，但实际上参与工作的线程一共有四个：

其中三个只是协助，只有 JS 引擎线程是真正执行的


JS 引擎线程：也叫 JS 内核，负责解析执行 JS 脚本程序的主线程，例如 V8 引擎
事件触发线程：属于浏览器内核线程，主要用于控制事件，例如鼠标、键盘等，当事件被触发时，就会把事件的处理函数推进事件队列，等待 JS 引擎线程执行
定时器触发线程：主要控制 setInterval 和 setTimeout，用来计时，计时完毕后，则把定时器的处理函数推进事件队列中，等待 JS 引擎线程。
HTTP 异步请求线程：通过 XMLHttpRequest 连接后，通过浏览器新开的一个线程，监控 readyState 状态变更时，如果设置了该状态的回调函数，则将该状态的处理函数推进事件队列中，等待 JS 引擎线程执行。

注：浏览器对同一域名的并发连接数是有限的，通常为 6 个。
宏任务
分为：

同步任务：按照顺序执行，只有前一个任务完成后，才能执行后一个任务
异步任务：不直接执行，只有满足触发条件时，相关的线程将该异步任务推进任务队列中，等待 JS 引擎主线程上的任务执行完毕时才开始执行，例如异步 Ajax、DOM 事件，setTimeout 等。

微任务
微任务是 ES6 和 Node 环境下的，主要 API 有：Promise，process.nextTick。
微任务的执行在宏任务的同步任务之后，在异步任务之前。

代码例子
以上代码输出顺序为：1,3,5,4,2
参考文档

what-happens-when-zh_CN (opens new window)
Tags to DOM (opens new window)
彻底理解浏览器的缓存机制 (opens new window)
浏览器的工作原理：新式网络浏览器幕后揭秘 (opens new window)
深入浅出浏览器渲染原理 (opens new window)
js 引擎的执行过程（一） (opens new window)
 还有一些找不到了。。。。。

From: 4ark.me
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>自动曝光原理</title>
    <url>/posts/509c7bd3/</url>
    <content><![CDATA[自动曝光的原理
曝光是摄影中十分重要的一个环节，它决定了一张图片的明暗，如下图所示，第一张图片太暗，而第三种图片太亮。

曝光由什么来决定
使用过数码相机的人都知道曝光由光圈、曝光时间、ISO 三者共同决定，详细的关系就不赘述。
光圈：控制进光量；
曝光时间：光到达的时间长度；
ISO：增益；
但是对于手机以及其他电子产品使用的微型摄像头，光圈大小是固定的，所以手机拍照的曝光由曝光时间和 ** 增益 (ISO)** 来控制。
什么是自动曝光
数码相机中有一种手动模式，可手动设置光圈、曝光时间、ISO 来控制曝光，该模式的使用对摄影师的要求会比较高。另外 数码相机的全自动模式、光圈优先模式、快门优先模式以及手机等电子产品的曝光都属于自动曝光。
自动曝光就是相机代替人的操作，自动调节曝光时间、光圈、ISO 进行曝光，使得所摄物体亮度正常。这句话解释起来很简单，但是存在两个难点问题：第一，相机不如人眼这样可以直观的分辨图像明暗，如何判断这幅图像是否亮度合适；第二，如何调整曝光时间、光圈、ISO, 这三者调节的比例。
自动曝光的标准
在此之前需要了解物体的亮度与色彩是由物体对光线的反射率来决定的。例如纯黑色的放射率是 0，纯白色的反射率是 100%，处于中间的灰度的反射率是 18%，这就是 18% 中间灰度。

具有一定反射率的物体在最终的图像中被还原到了其相应的灰度级，这就意味着达到了正确的曝光。例如摄影师们通常在拍摄之前使用中性灰卡测试曝光是否正常。
但是相机在各种场景下无法识别物体的反射率，因此采用了一个简单粗暴而又行之有效的方法，统一将图像整体平均亮度设置为中性灰的亮度。该方法基于 ** 科学家认为自然界的平均反射率是 18%** 这一理论。当然，这个方法也不是走遍天下都不怕，比如拍摄雪景时需要增加曝光补偿，不然会偏暗，因为雪景的亮度远远大于中性灰度。这也就是摄影中的一句口诀的由来 “白增黑减”。
自动曝光算法
上面已经讲了自动曝光的标准，也就确立了曝光目标，要达到这一目标还要自动曝光算法来实现。
目前比较常见的算法有平均亮度法、权重均值法、亮度直方图等。其中最普遍的就是平均亮度法。平均亮度法就是对图像所以像素亮度求平均值，通过不断调整曝光参数最终达到目标亮度。而权重均值法是对图像不同区域设置不同权重来计算图像亮度，例如相机中的各种测光模式的选择就是改变不同区域的权重。亮度直方图法是通过为直方图中峰值分配不同权重来计算图像亮度。
自动曝光实现的过程：
第一步：对当前图像进行亮度统计；
第二步：根据当前图像亮度确定曝光值；
第三步：计算新的曝光参数，曝光时间、光圈、增益；
第四步：将新的曝光参数应用到相机；
第五步：重复步骤一到四，直到亮度满足要求。
曝光参数调整_曝光表
前面留下两个问题：“第一，相机不如人眼这样可以直观的分辨图像明暗，如何判断这幅图像是否亮度合适；第二，如何调整曝光时间、光圈、ISO, 这三者调节的比例。” 第一个问题在前面有过解释，第二个问题也就是自动曝光实现步骤的第三步，曝光值由光圈、曝光时间、增益沟通决定，当计算出一个曝光量，曝光三要素有很多种组合方式。一般情况下有曝光曲线，每个曝光量对应一组参数。手机中曝光曲线可以通过 Tuning 调整。
From: 积极的悲观主义者
]]></content>
      <categories>
        <category>image</category>
      </categories>
      <tags>
        <tag>3a</tag>
        <tag>ae</tag>
        <tag>image</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习之视频人脸识别系列</title>
    <url>/posts/a0f3c838/</url>
    <content><![CDATA[系列 1 简介
出品 | 磐创 AI 技术团队
【磐创 AI 导读】本文是深度学习之视频人脸识别系列的第一篇文章，介绍了人脸识别领域的一些基本概念，分析了深度学习在人脸识别的基本流程，并总结了近年来科研领域的研究进展，最后分析了静态数据与视频动态数据在人脸识别技术上的差异。欢迎大家点击上方篮子关注我们的公众号：磐创 AI。
一、基本概念
1. 人脸识别（face identification）
人脸识别是 1 对 n 的比对，给定一张人脸图片，如何在 n 张人脸图片中找到同一张人脸图片，相对于一个分类问题，将一张人脸划分到 n 张人脸中的一张。类似于管理人员进行的人脸识别门禁系统。
2. 人脸验证（face verification）
人脸验证的 1 对 1 的比对，给定两张人脸图片，判断这两张人脸是否为同一人，类似于手机的人脸解锁系统，事先在手机在录入自己的脸部信息，然后在开锁时比对摄像头捕捉到的人脸是否与手机上录入的人脸为同一个人。
3. 人脸检测（face detection）
人脸检测是在一张图片中把人脸检测出来，即在图片上把人脸用矩形框出来，并得到矩形的坐标，如下图所示。

4. 人脸关键点检测
根据输入的人脸图像，识别出面部关键特征点，如眼睛、鼻尖、嘴角点、眉毛以及人脸各部件轮廓点的坐标，如下图所示。

5. 人脸矫正（人脸对齐）
通过人脸关键点检测得到人脸的关键点坐标，然后根据人脸的关键点坐标调整人脸的角度，使人脸对齐，由于输入图像的尺寸是大小不一的，人脸区域大小也不相同，角度不一样，所以要通过坐标变换，对人脸图像进行归一化操作，如下图所示。

二、基于深度学习的人脸识别算法基本流程
随着神经网络的迅速发展和其对图像数据的强大的特征提取，深度学习运用于人脸识别也成为热点研究方向；2014 年的开山之作 DeepFace，第一个真正将大数据和深度学习结合应用于人脸识别与验证，确立人脸识别的常规流程：图片 -&gt; 人脸与关键点检测 -&gt; 人脸对齐 -&gt; 人脸表征（representation）-&gt; 分类。首先将图片中的人脸检测处理并通过关键点进行对齐，如何输入到神经网络，得到特征向量，通过分类训练过程，该向量即为人脸的特征向量。要求出两张人脸的相似度即计算两个特征的向量度量之差，方法包括：SVM、SiameseNetwork、JointBayesian、L1 距离、L2 距离、cos 距离等。
三、科研领域近期进展
科研领域近期进展主要集中于 loss 函数的研究，包括 DeepId2（Contrastive Loss）、FaceNet（Triplet loss）、L-Softmax、SphereFace（A-Softmax）、Center Loss、L2-Softmax、NormFace、CosFace（AM-Softmax）、ArcFace（AA-Softmax）等。
四、基于视频人脸识别和图片人脸识别的区别
（该小结部分参考于博客园 - 米罗西 http://www.cnblogs.com/zhehan54/p/6727631.html）
相对于图片数据，目前视频人脸识别有很多挑战，包括：（1）视频数据一般为户外，视频图像质量比较差；（2）人脸图像比较小且模糊；（3）视频人脸识别对实时性要求更高。
但是视频数据也有一些优越性，视频数据同时具有空间信息和时间信息，在时间和空间的联合空间中描述人脸和识别人脸会具有一定提升空间。在视频数据中人脸跟踪是一个提高识别的方法，首先检测出人脸，然后跟踪人脸特征随时间的变化。当捕捉到一帧比较好的图像时，再使用图片人脸识别算法进行识别。这类方法中跟踪和识别是单独进行的，时间信息只在跟踪阶段用到。
【总结】：本期文章主要介绍了基于深度学习的人脸识别算法的一些基本入门知识，下一期我给大家介绍人脸识别中获取神经网络输入的算法，即关于人脸检测、人脸关键点检测与人脸对齐的一些重要算法和相关论文解析。
系列 2 人脸检测与对齐
一、人脸检测与关键点检测
1. 问题描述：
人脸检测解决的问题为给定一张图片，输出图片中人脸的位置，即使用方框框住人脸，输出方框的左上角坐标和右下角坐标或者左上角坐标和长宽。算法难点包括：人脸大小差异、人脸遮挡、图片模糊、角度与姿态差异、表情差异等。而关键检测则是输出人脸关键点的坐标，如左眼（x1，y1）、右眼（x2，y2）、鼻子（x3，y3）、嘴巴左上角（x4，y4）、嘴巴右上角（x5，y5）等。
2. 深度学习相关算法：
（1）Cascade CNN
Cascade CNN 源于发表于 2015 年 CVPR 上的一篇论文 A Convolutional Neural Network Cascade for Face Detection【2】，作者提出了一种级连的 CNN 网络结构用于人脸检测。算法主体框架是基于 V-J 的瀑布流思想【1】，是传统技术和深度网络相结合的一个代表，Cascade CNN 包含了多个分类器，这些分类器使用级联结构进行组织，与 V-J 不同的地方在于 Cascade CNN 采用卷积网络作为每一级的分类器。整个网络的处理流程如下图所示：

整个处理流程里包含了六个网络：12-net、12-calibration-net、24-net、24-calibration-net、48-net、48-calibration-net，其中三个二分类网络用于分类其是否为人脸，另外三个 calibration 网络用于矫正人脸框边界。其中第二个网络之后、第四个网络之后、第五个网络之后使用 NMS 算法过滤掉冗余的框。
12-net，24-net 和 48-net 的网络结构如下图所示：

13-12-calibration-net，24-calibration-net，48-calibration-net 的结构如下图所示：

该算法结合了 V-J 框架构造了级连的 CNN 网络结构并设计边界矫正网络用来专门矫正人脸框边界，在 AFW 数据集上准确率达到 97.97%。

（2）Faceness-Net
Faceness-Net 源于论文 A convolutional neural network cascade for face detection【3】，该算法基于 DCNN 网络【5】的人脸局部特征分类器，算法首先进行人脸局部特征的检测，使用多个基于 DCNN 网络的 facial parts 分类器对人脸进行评估，然后根据每个部件的得分进行规则分析得到 Proposal 的人脸区域，然后从局部到整体得到人脸候选区域，再对人脸候选区域进行人脸识别和矩形框坐标回归，该过程分为两个步骤。
第一个步骤：每个人脸局部特征使用 attribute-aware 网络检测并生成人脸局部图，其中一共五个特征属性： 头发、眼睛、鼻子、嘴巴、胡子。然后通过人脸局部图根据评分构建人脸候选区域，具体如下图所示：

第二个步骤：训练一个多任务的卷积网络来完成人脸二分类和矩形框坐标回归，进一步提升其效果，具体如下图所示：

Faceness 从脸部特征的角度来解决人脸检测中的遮挡和姿态角度问题，其整体性能在当时是非常好的，在 AFW 数据集上准确率可以达到 98.05%。

（3）MTCNN
MTCNN 源于论文 Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks【6】，是基于多任务级联卷积神经网络来解决人脸检测和对齐问题，同时输出图片的人脸矩阵框和关键点坐标（左眼、右眼、鼻子、嘴巴左上角、嘴巴右上角）。MTCNN 为三阶的级联卷积神经网络，整体框架如下图所示：

输入阶段：为应对目标多尺度问题，将原始图像 resize 到不同尺寸，构建图像金字塔，作为三阶级联架构的输入，这样处理可以更好地检测大小不一的人脸。
第一阶段：通过一个全部由卷积层组成的 CNN，取名 P-Net，获取候选人脸框、关键点坐标和人脸分类（是人脸或不是），之后采用 NMS 过滤掉高重叠率的候选窗口。如下图所示：

第二阶段：第一阶段输出的候选人脸框作为更为复杂的 R-Net 网络的输入，R-Net 进一步筛除大量错误的候选人脸框，同样也通过 NMS 过滤掉高重叠率的候选窗口。如下图所示：

第三阶段：与第二阶段类似，最终网络输出人脸框坐标、关键点坐标和人脸分类（是人脸或不是）。如下图所示：

MTCNN 通过三级的级联卷积神经网络对任务进行从粗到细的处理，还提出在线困难样本生成策略（online hard sample mining ）可以进一步提升性能。兼并了速度与准确率，速度在 GPU 上可以达到 99FPS，在 FDDB 数据集上可以达到 95.04 准确率，具体如下图所示：

二、人脸对齐（部分参考于 GraceDD 的博客文章）
人脸对齐通过人脸关键点检测得到人脸的关键点坐标，然后根据人脸的关键点坐标调整人脸的角度，使人脸对齐，由于输入图像的尺寸是大小不一的，人脸区域大小也不相同，角度不一样，所以要通过坐标变换，对人脸图像进行归一化操作。人脸关键点检测有很多算法可以使用包括：ASM、AAM、DCNN 、TCDCN 、MTCNN 、TCNN、TCNN 等，这里就不详细介绍，主要说一下得到人脸关键点之后如何进行人脸对齐，是所有人脸达到归一化效果，该过程如下图所示：

该过程涉及到图像的仿射变换，简单来说，“仿射变换” 就是：“线性变换”+“平移”，即坐标的变换。假如我们希望人脸图片归一化为尺寸大小 600600，左眼位置在（180，200），右眼位置在（420，200）。 这样人脸中心在图像高度的 1/3 位置，并且两个眼睛保持水平，所以我们选择左眼角位置为 ( 0.3width, height / 3 )，右眼角位置为（0.7*width , height / 3） 。
利用这两个点计算图像的变换矩阵（similarity transform），该矩阵是一个 2*3 的矩阵，如下：

如果我们想对一个矩形进行变换，其中 x、y 方向的缩放因为分别为 sx，sy，同时旋转一个角度 ，然后再在 x 方向平移 tx, 在 y 方向平移 ty
利用 opencv 的 estimateRigidTransform 方法，可以获得这样的变换矩阵，但遗憾的是，estimateRigidTransform 至少需要三个点，所以我们需要构选第三个点，构造方法是用第三个点与已有的两个点构成等边三角形，这样第三个点的坐标为：

代码如下：

经过上一步的处理之后，所有的图像都变成一样大小，并且又三个关键点的位置是保持一致的，但因为除了三个点对齐了之外，其他点并没有对齐。所以根据得到的变换矩阵对剩下所有的点进行仿射变换，opencv 代码如下所示：

img 为输入图像；
warped 为变换后图像，类型与 src 一致；
M 为变换矩阵，需要通过其它函数获得，当然也可以手动输入；
Image_size 为输出图像的大小；
三、 总结
本期文章主要介绍了人脸检测与对齐的相关算法，下一期我给大家介绍一下人脸表征的相关算法，即通过深度学习提取人脸特征，通过比较人脸特征进行人脸识别与验证。
参考文献：

【1】 S.Z.Li, L.Zhu, Z.Q.Zhang, A.Blake, H.J.Zhang, H.Y.Shum. Statistical learning of multi-view face detection. In: Proceedings of the 7-th European Conference on Computer Vision. Copenhagen, Denmark: Springer, 2002.67-81.
【2】Li H, Lin Z, Shen X, et al. A convolutional neural network cascade for face detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 5325-5334.
【3】Yang S, Luo P, Loy C C, et al. Faceness-Net: Face detection through deep facial part responses[J]. IEEE transactions on pattern analysis and machine intelligence, 2017.
【4】Yang S, Luo P, Loy C C, et al. From facial parts responses to face detection: A deep learning approach[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 3676-3684.
【5】Sun Y, Wang X, Tang X. Deep convolutional network cascade for facial point detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2013: 3476-3483.
【6】Zhang K, Zhang Z, Li Z, et al. Joint face detection and alignment using multitask cascaded convolutional networks[J]. IEEE Signal Processing Letters, 2016, 23(10): 1499-1503.

系列 3：人脸表征
一、人脸表征
把人脸图像通过神经网络，得到一个特定维数的特征向量，该向量可以很好地表征人脸数据，使得不同人脸的两个特征向量距离尽可能大，同一张人脸的两个特征向量尽可能小，这样就可以通过特征向量来进行人脸识别。

二、论文综述
1. DeepFace：
2014 年论文 DeepFace: Closing the Gap toHuman-Level Performance in Face Verification 提出了 DeepFace 算法，第一个真正将大数据和深度学习神经网络结合应用于人脸识别与验证。在该人脸识别模型中分为四个阶段：人脸检测 =&gt; 人脸对齐 =&gt; 人脸表征 =&gt; 人脸分类，在 LFW 数据集中可以达到 97.00% 的准确率。
（1）人脸检测与对齐：该模型使用 3D 模型来将人脸对齐，该方法过于繁琐，在实际应用中很少使用，经过 3D 对齐以后，形成的图像都是 152×152 的图像，具体步骤如下图。

分为如下几步：
a. 人脸检测，使用 6 个基点  b. 二维剪切，将人脸部分裁剪出来  c. 67 个基点，然后 Delaunay 三角化，在轮廓处添加三角形来避免不连续  d. 将三角化后的人脸转换成 3D 形状  e. 三角化后的人脸变为有深度的 3D 三角网  f. 将三角网做偏转，使人脸的正面朝前。  g. 最后放正的人脸  h. 一个新角度的人脸（在论文中没有用到）
（2）人脸表征：人脸表征使用了 5 个卷积层和 1 个最大池化层、1 个全连接层，如下图所示。前三层的目的在于提取低层次的特征，为了网络保留更多图像信息只使用了一层池化层；后面三层都是使用参数不共享的卷积核，因为主要是因为人脸不同的区域的特征是不一样的，具有很大的区分性，比如鼻子和眼睛所表示的特征是不一样的，但是使用参数不共享的卷积核也增加了模型计算量以及需要更多的训练数据。最后输出的 4096 维向量进行 L2 归一化。

a. Conv：32 个 11×11×3 的卷积核
b. max-pooling: 3×3， stride=2
c. Conv: 16 个 9×9 的卷积核
d. Local-Conv: 16 个 9×9 的卷积核，Local 的意思是卷积核的参数不共享
e. Local-Conv: 16 个 7×7 的卷积核，参数不共享
f. Local-Conv: 16 个 5×5 的卷积核，参数不共享
g. Fully-connected: 4096 维
h. Softmax: 4030 维
（3）分类：论文介绍了两种方法进行分类，加权的卡方距离和使用 Siamese 网络结构，设 f1 和 f2 为特征向量，上一个步骤的输出，则有：
①加权卡方距离：计算公式如下，加权参数由线性 SVM 计算得到：

②Siamese 网络：网络结构是成对进行训练，得到的特征表示再使用如下公式进行计算距离：

2. DeepID1：
DeepID1 是 2014 年 Deep LearningFace Representation from Predicting 10,000 Classes 一文提出的，是 DeepID 三部曲的第一篇。DeepID1 使用 softmax 多分类训练，主要思想第一个是数据集的增大，包括训练集使用 celebface，包含 87628 张图片，5436 个人脸，增大了训练集；使用多尺寸输入，通过 5 个 landmarks 将每张人脸划分成 10regions，每张图片提取 60patches=10regions3scales2 (RGB orgray)，第二个是网络结构，DeepID 提取的人脸特征就是一个由连接第三层与第四层组成的全连接层特征，如下图所示，每个 patches 经过这个 cnn 网络，第四层的特征更加全局化（global），第三层的特征更加细节，因此 DeepID 连接了两者，以求同时包含全局，细节信息。

60 个 patches 使用 60 个 CNN, 每个 CNN 提取 2*160=320 维特征（与水平翻转一起输入），总网络模型如下图所示，最后分别使用联合贝叶斯算法与神经网络进行分类，并比较结果。

模型最终以 CelebFaces + 中 202,599 图像作为训练集， patch 数提升为 100（10r10s2） ，特征数提升为 1001602=32000 然后使用 PCA 降为 150 维 ，使用联合贝叶斯算法进行验证， 最终在 LFW 上达到 97.20% 的验证准确率。
3. DeepID2：
DeepID2 是 Deep Learning Face Representationby Joint Identification-Verification 一文提出的，对 DeepID1 进行了进一步的改进，提出了 contrastive loss，在分类任务，我们需要的是减少类内差距（同一人脸），增加类间差距（不同人脸），softmax loss 分类的监督信号可以增大类间差距，但是却对类内差距影响不大，所以 DeepID2 加入了另一个 loss，contrastive loss，从而增加验证的监督信号，就可以减少类内差距。
网络结构类似 DeepID1, 不同之处在于使用了两种不同的损失函数，网络结构如下图所示。

损失函数：
①分类信号，Softmax loss。

②验证信号，contrastiveloss，使用 l2 范数距离表示，m 为阈值不参与训练，括号内的 θve={m}，该损失函数可以让类间的距离给定一个限制 margin，即 m 大小的距离。


两 loss 的组合方式： 首先使用 2 个输入，计算 Softmax loss 和 contrastive loss, 总损失为二者通过 λ 加权求和，通过总损失来执行梯度下降更新卷积参数，通过 Softmax loss 来更新 softmax 层的参数。
整个模型使用 celebrate + 数据集训练，每张图片使用了 21 facial landmarks，分成 200patches（20regions5scales2RGB&amp;Gray)，水平翻转后变为 400patches，使用了 200 个卷积神经网络，提取 400（2002）个 Deepid2 特征，使用贪婪算法降为 25 个 Deepid2 特征，使用 PCA 将 25160Deepid2 特征降为 180 维，最后使用联合贝叶斯算法进行验证，最终在 LFW 上得到的最终准确率是 98.97%，使用 7 组 25 个 Deepid2 特征，SVM 融合可得到准确率为 99.15% 。DeepID2 在 2014 年是人脸领域非常有影响力的工作，也掀起了在人脸领域引进 MetricLearning 的浪潮。
4. DeepID2+：
DeepID2 + 源于论文 Deeply learned facerepresentations are sparse, selective, and robust，DeepID2 + 是对 DeepID2 的改进。①卷积层在原来基础上再增加 128 维，第四层全连接层从 160 增加到 512，训练数据增加了 CelebFaces+ dataset，WDRef 等，有 12000 个人脸的大约 290,000 张图片； ②每个卷积层的后面都加了一个 512 为的全连接层，并添加 contrastive loss 监督信号，而不仅在第四层全连接层上有 。网络结构如下图所示。

最终在 LFW 数据集上准确率为 99.47%。
5. DeepID3：
DeepID3 源于 2015 年的 Deepid3:Face recognition with very deep neural networks 论文，该论文探究了复杂神经网络对人脸识别的作用。论文研究 VGG 与 GoogleNet 用于人脸识别的效果，论文在 VGG 和 GooLeNet 的基础上进行构建合适的结构，使得方便人脸识别。结果发现 DeepID3 的结果和 DeepID2 + 相当，可能是由于数据集的瓶颈，需要更大的数据才能有更好的提升，两个网络结构如下图所示。

网络输出使用 PCA 降维到 300 维的向量，使用联合贝叶斯算法进行验证，最终在 LFW 上得到的最终准确率是 99.53%。
6. FaceNet：
FaceNet 由论文 Facenet: A unified embedding forface recognition and clustering 提出，这篇 2015 年来自 Google 的 论文同样具有非常大的影响力，不仅仅成功应用了 TripletLoss 在 benchmark 上取得 state-of-art 的结果，更因为他们提出了一个绝大部分人脸问题的统一解决框架，即：识别、验证、搜索等问题都可以放到特征空间里做，需要专注解决的仅仅是如何将人脸更好的映射到特征空间。FaceNet 在 DeepID 的基础上，将 ContrastiveLoss 改进为 Triplet Loss，去掉 softmaxloss。FaceNet 实验了 ZFNet 类型网络和 Inception 类型网络，最终 Inception 类型网络效果更好，网络结构如下图所示。

FaceNet 没有使用 PCA 降维，而是在网络中直接训练输出 128 维的向量，用全连接层来完成降维，最后的 128 维的向量经过 Triplet Loss。
Triplet Loss 输入不再是 Image Pair，而是三张图片（Triplet），分别为 Anchor Face（xa），Negative Face（xn）和 Positive Face（xp）。Anchor 与 Positive Face 为同一人，与 Negative Face 为不同人，在特征空间里 Anchor 与 Positive 的距离要小于 Anchor 与 Negative 的距离，且相差超过一个 Margin Alpha。
loss 的目标为：

总 loss 公式为：

Contrastive Loss 与 Triplet Loss 的比较， Contrastive Loss 目标是减少类内差距（两个蓝点），增加类间差距（蓝点与红点）；Triplet Loss 则是输入三张图片，Anchor 与 Positive 的距离要小于 Anchor 与 Negative 的距离，且相差超过一个 Margin Alpha，即 Triplet Loss 同时约束了两个距离。

最后 FaceNet 在 LFW 数据集上达到了 99.63% 的准确率。
基于 ContrastiveLoss 和 Triplet Loss 的 MetricLearning 符合人的认知规律，在实际应用中也取得了不错的效果，但同时也有很多问题，由于 ContrastiveLoss 和 Triplet Loss 的训练样本都基于 pair 或者 triplet 的，可能的样本数是 O (N2) 或者 O (N3) 的，所以模型需要很久的计算才能拟合并且训练集需要足够大。
三、总结
本期文章主要介绍人脸表征相关算法和论文综述，主要是 2014 年到 2016 年的研究成果， ContrastiveLoss 和 Triplet Loss 在实际应用中也取得了很好的效果，但是也有很多问题，由于 Contrastive Loss 和 Triplet Loss 的训练样本都基于 pair 或者 triplet 的，可能的样本数是 O (N2) 或者 O (N3) 的，所以模型需要很久的计算才能拟合并且训练集要足够大，所以在之后的人脸识别研究中，大部分在于 loss 函数的研究，这部分将会在下一期给大家介绍。
参考文献：

【1】 Taigman Y, Yang M, Ranzato M A, et al.Deepface: Closing the gap to human-level performance in faceverification[C]//Proceedings of the IEEE conference on computer vision andpattern recognition. 2014: 1701-1708.
【2】Sun Y, Wang X, Tang X. Deep learning facerepresentation from predicting 10,000 classes[C]//Proceedings of the IEEEconference on computer vision and pattern recognition. 2014: 1891-1898.
【3】Sun Y, Chen Y, Wang X, et al. Deeplearning face representation by joint identification-verification[C]//Advancesin neural information processing systems. 2014: 1988-1996.
【4】Sun Y, Liang D, Wang X, et al. Deepid3:Face recognition with very deep neural networks[J]. arXiv preprintarXiv:1502.00873, 2015.
【5】Simonyan K, Zisserman A. Very deepconvolutional networks for large-scale image recognition[J]. arXiv preprintarXiv:1409.1556, 2014.
【6】Szegedy C, Liu W, Jia Y, et al. Goingdeeper with convolutions[C]//Proceedings of the IEEE conference on computervision and pattern recognition. 2015: 1-9.
【7】Sun Y, Wang X, Tang X. Deeply learned facerepresentations are sparse, selective, and robust[C]//Proceedings of the IEEEconference on computer vision and pattern recognition. 2015: 2892-2900.
【8】Schroff F, Kalenichenko D, Philbin J.Facenet: A unified embedding for face recognition andclustering[C]//Proceedings of the IEEE conference on computer vision andpattern recognition. 2015: 815-823.

系列 4：人脸表征 - 续
一、人脸表征
把人脸图像通过神经网络，得到一个特定维数的特征向量，该向量可以很好地表征人脸数据，使得不同人脸的两个特征向量距离尽可能大，同一张人脸的两个特征向量尽可能小，这样就可以通过特征向量来进行人脸识别。

二、论文综述
1. L-Softmax：
Softmax Loss 函数被广泛应用于深度学习，较为简单实用，但是它并不能够明确引导神经网络学习区分性较高的特征。L-Softmax 能够有效地引导网络学习使得样本类内距离较小、类间距离较大的特征，L-Softmax 不但能够调节类间距离的间隔（margin）大小，而且能够防止过拟合。
L-Softmax 是对 softmax loss 的改进，softmax loss 公式如下所示：

其中 fj 表示最终全连接层的类别输出向量 f 的第 j 个元素，N 为训练样本的个数，则 fyi 可以表示为 fyi=WTyi xi，其中 0≤θj≤π，最终的损失函数可得：

softmax 的目的是使得 WT1x&gt;WT2x，即 ∥W1∥∥x∥cos (θ1)&gt;∥W2∥∥x∥cos (θ2)，从而得到输入 x（来自类别 1）输出正确的分类结果。L-Softmax 通过增加一个正整数变量 m，从而产生一个决策余量，能够更加严格地约束上述不等式，即：

其中 0≤θ1&lt;π/m。如果 W1 和 W2 能够满足∥W1∥∥x∥cos (mθ1)&gt;∥W2∥∥x∥cos (θ2)，那么就必然满足∥W1∥∥x∥cos (θ1)&gt;∥W2∥∥x∥cos (θ2)，这样的约束对学习 W1 和 W2 的过程提出了更高的要求，在训练学习过程中，类间要比之前多了一个 m 的间隔，从而使得 1 类和 2 类有了更宽的分类决策边界。这种 Margin Based Classification 使得学习更加的困难，从而使类间距离增加了一个 margin 距离，L-Softmax loss 的总公式如下：

当 m 越大时，分类的边界越大，学习难度当然就越高。
论文仅使用了 WebFace 数据集作为训练集和一个简单的卷积网络，就在 LFW 上达到了 98.71% 的正确率，证明了 L-Softmax loss 取得了比 softmax loss 更好的结果。
2. SphereFace :
SphereFace 在 MegaFace 数据集上识别率在 2017 年排名第一，提出 A-Softmax Loss 使人脸识别达到不错的效果。A-Softmax Loss 基于 softmax loss 和 L-Softmax loss，在二分类模型中，softmax loss 为：

如果 x 为类别一，则希望 p1&gt;p2, 则二分类的划分函数为：

权重归一化 ||w|| 为 1，b 为 0，此时特征上的点映射到单位超球面上，则二分类的划分函数为：

然后使用与 L-Softmax loss 相同的原理，使

则 A-Softmax Loss 最终为：

因此 A-Softmax Loss 是样本类别之间产生了角度距离，让决策函数更加严格并且更加具有可区分性。当 m 增大，角度距离也会增加。
A-Softmax 与 L-Softmax 的最大区别在于 A-Softmax 的权重归一化了，而 L-Softmax 则没有。A-Softmax 权重的归一化导致特征上的点映射到单位超球面上，A-Softmax 仅仅能从角度上划分类别，而 L-Softmax 是在角度与长度方向进行考量，两个方向如果划分不一就会收到干扰，导致精度下降。
SphereFace 使用的模型如下图所示：

训练与测试过程如下图所示，在测试过程中使用余弦计算相似度：

最终 SphereFace 在训练集较小的情况下，LFW 数据集上准确率为 99.42%。Sphereface 效果很好，但是它不优美。在测试阶段，Sphereface 通过特征间的余弦值来衡量相似性，即以角度为相似性的度量，在训练阶段，其实 Sphereface 的损失函数并不是在直接优化特征与类中心的角度，而是优化特征与类中心的角度在乘上一个特征的长度，这就造成了训练跟测试之间目标不一致。
3. Normface :
在优化人脸识别任务时，softmax 本身优化的是没有归一化的内积结果，但是最后在预测的时候使用的一般是 cosine 距离或者欧式距离，这会导致优化目标和最终的距离度量其实并不一致。 Normface 的核心思想是既然最后在特征对比的时候使用归一化的 cosine 距离，那么在训练的过程中把特征也做归一化处理，做了归一化之后，softmax 的优化就变成了直接优化 cosine 距离了，归一化过程如下，其中 e 是为了防止除 0 的较小正数：

相应的损失函数如下：

其中 W 是归一化的权重，f_i 是归一化的特征，参数 s 的引入是因为保证梯度大小的合理性，去掉 bias 是因为 softmax 之前的 fc 有 bias 的情况下会使得有些类别在角度上没有区分性但是通过 bias 可以区分，在这种情况下如果对 feature 做 normalize，会使得中间的那个小类别的 feature 变成一个单位球形并与其他的 feature 重叠在一起，所以在 feature normalize 的时候是不能加 bias 的。
Normface 使用了较小的模型使用多种 loss 训练，然后在 LFW 数据集上测试，证明了 feature normalize 的效果，结果如下：

4. CosFace :
Normface 用特征归一化解决了 Sphereface 训练和测试不一致的问题。但是却没有了 margin 的惩罚，腾讯 AI Lab 的 CosFace 或者 AM-softmax 是在 Normface 的基础上引入了 margin，损失函数为：

其中特征与权值都做了归一化：

分类决策为：

，比之前增加了 m 的 margin，m 是一个超参数，控制惩罚的力度，m 越大，惩罚越强。
CosFace 使用 mtcnn 进行人脸检测与对齐，人脸表征训练模型使用基于 residual units 64 层卷积网络的 Sphere Face，在 5M 的训练集上训练，在 LFW 数据集上测试，精度达到 99.73%。
5. ArcFace :
ArcFace 源于论文 Additive angular margin lossfor deep face recognition，也叫做 InsightFace，论文基本介绍了近期较为流行的人脸识别模型，loss 变化从 softmax 到 AM-softmax，然后提出 ArcFace，可以说起到了很好的综述作用，论文从三个方面探讨影响人脸识别模型精度的主要因素。
（1）数据：数据方面，论文探讨了各个数据集的数据质量和优缺点，并对 MS-Celeb-1M，MegaFace FaceScrub 做了清洗，清洗后的数据公开。
（2）网络：详细对比了不同的主流网络结构的性能，包括输入层尺寸大小、最后输出几层的不同结构、基本网络单元残差网络的不同结构、主干网络的不同模型。经过实验的证明，最后的网络结构：输入图片大小 112x112；第一层 convLayer 卷积核为 33 stride 1 时，网络输出 77；主干网络使用 ResNet100，并使用改进后的改进的残差网络结构，如下图；最后的几层输出层为最后一个卷积层后 + BN-Dropout-FC-BN 的结构。

（3）损失函数：与 AM-softmax 相比，区别在于 Arcface 引入 margin 的方式不同，损失函数为：

Arcface 的 m 是在余弦里面，AM-softmax 的在外面，ArcFace 更为直观并且在超球面维度上有更清晰的解释。Arcface 在 VGG2 和 MS-Celeb-1M 数据集上训练，在 LFW 数据集上精度达到 99.83%。
三、总结
本期文章主要介绍人脸表征相关算法和论文综述，人脸检测、对齐、特征提取等这些操作都可以在静态数据中完成，下一期将给大家介绍在视频数据中进行人脸识别的另一个重要的算法，视频人脸跟踪的概念与方法。
参考文献：

【1】 Liu W, Wen Y, Yu Z, et al. Large-MarginSoftmax Loss for Convolutional Neural Networks[C]//ICML. 2016: 507-516.1708.
【2】Liu W, Wen Y, Yu Z, et al. Sphereface:Deep hypersphere embedding for face recognition[C]//The IEEE Conference onComputer Vision and Pattern Recognition (CVPR). 2017, 1: 1.
【3】Wang F, Xiang X, Cheng J, et al. Normface:l 2 hypersphere embedding for face verification[C]//Proceedings of the 2017 ACMon Multimedia Conference. ACM, 2017: 1041-1049.
【4】Wang F, Cheng J, Liu W, et al. Additivemargin softmax for face verification[J]. IEEE Signal Processing Letters, 2018,25(7): 926-930.
【5】Wang H, Wang Y, Zhou Z, et al. CosFace:Large margin cosine loss for deep face recognition[J]. arXiv preprintarXiv:1801.09414, 2018.
【6】Deng J, Guo J, Zafeiriou S. Arcface:Additive angular margin loss for deep face recognition[J]. arXiv preprintarXiv:1801.07698, 2018.

From： https://cloud.tencent.com/developer/article/1160037?from=article.detail.1344438
出品 | 磐创 AI 技术团队
]]></content>
      <categories>
        <category>ai</category>
      </categories>
      <tags>
        <tag>ai</tag>
        <tag>face</tag>
      </tags>
  </entry>
  <entry>
    <title>1.5 万字 CSS 基础拾遗（核心知识、常见需求）</title>
    <url>/posts/448f849b/</url>
    <content><![CDATA[1.5 万字 CSS 基础拾遗（核心知识、常见需求）
本篇文章围绕了 CSS 的核心知识点和项目中常见的需求来展开。虽然行文偏长，但偏基础，适合初级中级前端阅读，阅读的时候请适当跳过已经掌握的部分。
这篇文章断断续续写了比较久，也参考了许多优秀的文章，但或许文章里还是存在不好或不对的地方，请多多指教，可以评论里直接提出来哈。
小 tip：后续内容更精彩哦。

核心概念和知识点
语法
CSS 的核心功能是将 CSS 属性设定为特定的值。一个属性与值的键值对被称为声明（declaration）。
color: red;  
而如果将一个或者多个声明用 {} 包裹起来后，那就组成了一个声明块（declaration block）。
{  
    color: red;  
    text-align: center;  
}  
声明块如果需要作用到对应的 HTML 元素，那还需要加上选择器。选择器和声明块组成了 CSS 规则集（CSS ruleset），常简称为 CSS 规则。

span {  
    color: red;  
    text-align: center;  
}  

“
规则集中最后一条声明可以省略分号，但是并不建议这么做，因为容易出错。

CSS 中的注释：
/* 单行注释 */

/*  
    多行  
    注释  
*/
在 CSS 文件中，除了注释、CSS 规则集以及 @规则 外，定义的一些别的东西都将被浏览器忽略。
@规则
CSS 规则是样式表的主体，通常样式表会包括大量的规则列表。但有时候也需要在样式表中包括其他的一些信息，比如字符集，导入其它的外部样式表，字体等，这些需要专门的语句表示。
而 @规则 就是这样的语句。CSS 里包含了以下 @规则：


@namespace 告诉 CSS 引擎必须考虑 XML 命名空间。


@media, 如果满足媒体查询的条件则条件规则组里的规则生效。


@page, 描述打印文档时布局的变化.


@font-face, 描述将下载的外部的字体。


@keyframes, 描述 CSS 动画的关键帧。


@document, 如果文档样式表满足给定条件则条件规则组里的规则生效。 (推延至 CSS Level 4 规范)


除了以上这几个之外，下面还将对几个比较生涩的 @规则 进行介绍。
@charset
@charset [1] 用于定义样式表使用的字符集。它必须是样式表中的第一个元素。如果有多个 @charset 被声明，只有第一个会被使用，而且不能在 HTML 元素或 HTML 页面的 &lt;style&gt; 元素内使用。
注意：值必须是双引号包裹，且和
@charset "UTF-8";  
平时写样式文件都没写 @charset 规则，那这个 CSS 文件到底是用的什么字符编码的呢？
某个样式表文件到底用的是什么字符编码，浏览器有一套识别顺序（优先级由高到低）：


文件开头的 Byte order mark [2] 字符值，不过一般编辑器并不能看到文件头里的 BOM 值；


HTTP 响应头里的 content-type 字段包含的 charset 所指定的值，比如：
Content-Type: text/css; charset=utf-8  
`


CSS 文件头里定义的 @charset 规则里指定的字符编码；


&lt;link&gt; 标签里的 charset 属性，该条已在 HTML5 中废除；


默认是 UTF-8。


@import
@import [3] 用于告诉 CSS 引擎引入一个外部样式表。
link 和 @import 都能导入一个样式文件，它们有什么区别嘛？


link 是 HTML 标签，除了能导入 CSS 外，还能导入别的资源，比如图片、脚本和字体等；而 @import 是 CSS 的语法，只能用来导入 CSS；


link 导入的样式会在页面加载时同时加载，@import 导入的样式需等页面加载完成后再加载；


link 没有兼容性问题，@import 不兼容 ie5 以下；


link 可以通过 JS 操作 DOM 动态引入样式表改变样式，而 @import 不可以。


@supports
@supports [4] 用于查询特定的 CSS 是否生效，可以结合 not、and 和 or 操作符进行后续的操作。
/* 如果支持自定义属性，则把 body 颜色设置为变量 varName 指定的颜色 */  
@supports (--foo: green) {  
    body {  
        color: var(--varName);  
    }  
}  
层叠性
层叠样式表，这里的层叠怎么理解呢？其实它是 CSS 中的核心特性之一，用于合并来自多个源的属性值的算法。比如说针对某个 HTML 标签，有许多的 CSS 声明都能作用到的时候，那最后谁应该起作用呢？层叠性说的大概就是这个。
针对不同源的样式，将按照如下的顺序进行层叠，越往下优先级越高：


用户代理样式表中的声明 (例如，浏览器的默认样式，在没有设置其他样式时使用)。


用户样式表中的常规声明 (由用户设置的自定义样式。由于 Chrome 在很早的时候就放弃了用户样式表的功能，所以这里将不再考虑它的排序。)。


作者样式表中的常规声明 (这些是我们 Web 开发人员设置的样式)。


作者样式表中的！important 声明。


用户样式表中的！important 声明 S。


理解层叠性的时候需要结合 CSS 选择器的优先级以及继承性来理解。比如针对同一个选择器，定义在后面的声明会覆盖前面的；作者定义的样式会比默认继承的样式优先级更高。
选择器
CSS 选择器无疑是其核心之一，对于基础选择器以及一些常用伪类必须掌握。下面列出了常用的选择器。 想要获取更多选择器的用法可以看 MDN CSS Selectors [5]。
基础选择器


标签选择器：h1


类选择器：.checked


ID 选择器：#picker


通配选择器：*


属性选择器


[attr]：指定属性的元素；


[attr=val]：属性等于指定值的元素；


[attr*=val]：属性包含指定值的元素；


[attr^=val] ：属性以指定值开头的元素；


[attr$=val]：属性以指定值结尾的元素；


[attr~=val]：属性包含指定值 (完整单词) 的元素 (不推荐使用)；


[attr|=val]：属性以指定值 (完整单词) 开头的元素 (不推荐使用)；


组合选择器


相邻兄弟选择器：A + B


普通兄弟选择器：A ~ B


子选择器：A &gt; B


后代选择器：A B


伪类
条件伪类


:lang()：基于元素语言来匹配页面元素；


:dir()：匹配特定文字书写方向的元素；


:has()：匹配包含指定元素的元素；


:is()：匹配指定选择器列表里的元素；


:not()：用来匹配不符合一组选择器的元素；


行为伪类


:active：鼠标激活的元素；


:hover： 鼠标悬浮的元素；


::selection：鼠标选中的元素；


状态伪类


:target：当前锚点的元素；


:link：未访问的链接元素；


:visited：已访问的链接元素；


:focus：输入聚焦的表单元素；


:required：输入必填的表单元素；


:valid：输入合法的表单元素；


:invalid：输入非法的表单元素；


:in-range：输入范围以内的表单元素；


:out-of-range：输入范围以外的表单元素；


:checked：选项选中的表单元素；


:optional：选项可选的表单元素；


:enabled：事件启用的表单元素；


:disabled：事件禁用的表单元素；


:read-only：只读的表单元素；


:read-write：可读可写的表单元素；


:blank：输入为空的表单元素；


:current()：浏览中的元素；


:past()：已浏览的元素；


:future()：未浏览的元素；


结构伪类


:root：文档的根元素；


:empty：无子元素的元素；


:first-letter：元素的首字母；


:first-line：元素的首行；


:nth-child(n)：元素中指定顺序索引的元素；


:nth-last-child(n)：元素中指定逆序索引的元素；；


:first-child：元素中为首的元素；


:last-child ：元素中为尾的元素；


:only-child：父元素仅有该元素的元素；


:nth-of-type(n)：标签中指定顺序索引的标签；


:nth-last-of-type(n)：标签中指定逆序索引的标签；


:first-of-type ：标签中为首的标签；


:last-of-type：标签中为尾标签；


:only-of-type：父元素仅有该标签的标签；


伪元素


::before：在元素前插入内容；


::after：在元素后插入内容；


优先级

优先级就是分配给指定的 CSS 声明的一个权重，它由匹配的选择器中的每一种选择器类型的数值决定。为了记忆，可以把权重分成如下几个等级，数值越大的权重越高：


10000：!important；


01000：内联样式；


00100：ID 选择器；


00010：类选择器、伪类选择器、属性选择器；


00001：元素选择器、伪元素选择器；


00000：通配选择器、后代选择器、兄弟选择器；


可以看到内联样式（通过元素中 style 属性定义的样式）的优先级大于任何选择器；而给属性值加上 !important 又可以把优先级提至最高，就是因为它的优先级最高，所以需要谨慎使用它，以下有些使用注意事项：


一定要优先考虑使用样式规则的优先级来解决问题而不是！important；


只有在需要覆盖全站或外部 CSS 的特定页面中使用！important；


永远不要在你的插件中使用！important；


永远不要在全站范围的 CSS 代码中使用！important；


继承性

在 CSS 中有一个很重要的特性就是子元素会继承父元素对应属性计算后的值。比如页面根元素 html 的文本颜色默认是黑色的，页面中的所有其他元素都将继承这个颜色，当申明了如下样式后，H1 文本将变成橙色。
body {  
    color: orange;  
}  
h1 {  
    color: inherit;  
}  
设想一下，如果 CSS 中不存在继承性，那么我们就需要为不同文本的标签都设置一下 color，这样一来的后果就是 CSS 的文件大小就会无限增大。
CSS 属性很多，但并不是所有的属性默认都是能继承父元素对应属性的，那哪些属性存在默认继承的行为呢？一定是那些不会影响到页面布局的属性，可以分为如下几类：


字体相关：font-family、font-style、font-size、font-weight 等；


文本相关：text-align、text-indent、text-decoration、text-shadow、letter-spacing、word-spacing、white-space、line-height、color 等；


列表相关：list-style、list-style-image、list-style-type、list-style-position 等；


其他属性：visibility、cursor 等；


对于其他默认不继承的属性也可以通过以下几个属性值来控制继承行为：


inherit：继承父元素对应属性的计算值；


initial：应用该属性的默认值，比如 color 的默认值是 #000；


unset：如果属性是默认可以继承的，则取 inherit 的效果，否则同 initial；


revert：效果等同于 unset，兼容性差。


文档流
在 CSS 的世界中，会把内容按照从左到右、从上到下的顺序进行排列显示。正常情况下会把页面分割成一行一行的显示，而每行又可能由多列组成，所以从视觉上看起来就是从上到下从左到右，而这就是 CSS 中的流式布局，又叫文档流。文档流就像水一样，能够自适应所在的容器，一般它有如下几个特性：


块级元素默认会占满整行，所以多个块级盒子之间是从上到下排列的；


内联元素默认会在一行里一列一列的排布，当一行放不下的时候，会自动切换到下一行继续按照列排布；


如何脱离文档流呢？
脱流文档流指节点脱流正常文档流后，在正常文档流中的其他节点将忽略该节点并填补其原先空间。文档一旦脱流，计算其父节点高度时不会将其高度纳入，脱流节点不占据空间。有两种方式可以让元素脱离文档流：浮动和定位。


使用浮动（float）会将元素脱离文档流，移动到容器左 / 右侧边界或者是另一个浮动元素旁边，该浮动元素之前占用的空间将被别的元素填补，另外浮动之后所占用的区域不会和别的元素之间发生重叠；


使用绝对定位（position: absolute;）或者固定定位（position: fixed;）也会使得元素脱离文档流，且空出来的位置将自动被后续节点填补。


盒模型
在 CSS 中任何元素都可以看成是一个盒子，而一个盒子是由 4 部分组成的：内容（content）、内边距（padding）、边框（border）和外边距（margin）。
盒模型有 2 种：标准盒模型和 IE 盒模型，本别是由 W3C 和 IExplore 制定的标准。
如果给某个元素设置如下样式：
.box {  
    width: 200px;  
    height: 200px;  
    padding: 10px;  
    border: 1px solid #eee;  
    margin: 10px;  
}  
标准盒模型认为：盒子的实际尺寸 = 内容（设置的宽 / 高） + 内边距 + 边框

所以 .box 元素内容的宽度就为 200px，而实际的宽度则是 width + padding-left + padding-right + border-left-width + border-right-width = 200 + 10 + 10 + 1 + 1 = 222。
IE 盒模型认为：盒子的实际尺寸 = 设置的宽 / 高 = 内容 + 内边距 + 边框

.box 元素所占用的实际宽度为 200px，而内容的真实宽度则是 width - padding-left - padding-right - border-left-width - border-right-width = 200 - 10 - 10 - 1 - 1 = 178。
现在高版本的浏览器基本上默认都是使用标准盒模型，而像 IE6 这种老古董才是默认使用 IE 盒模型的。
在  CSS3 中新增了一个属性 box-sizing，允许开发者来指定盒子使用什么标准，它有 2 个值：


content-box：标准盒模型；


border-box：IE 盒模型；


视觉格式化模型
视觉格式化模型（Visual formatting model）是用来处理和在视觉媒体上显示文档时使用的计算规则。CSS 中一切皆盒子，而视觉格式化模型简单来理解就是规定这些盒子应该怎么样放置到页面中去，这个模型在计算的时候会依赖到很多的因素，比如：盒子尺寸、盒子类型、定位方案（是浮动还是定位）、兄弟元素或者子元素以及一些别的因素。

Visual formatting model
从上图中可以看到视觉格式化模型涉及到的内容很多，有兴趣深入研究的可以结合上图看这个 W3C 的文档 Visual formatting model [6]。所以这里就简单介绍下盒子类型。

盒子类型由 display 决定，同时给一个元素设置 display 后，将会决定这个盒子的 2 个显示类型（display type）：


outer display type（对外显示）：决定了该元素本身是如何布局的，即参与何种格式化上下文；


inner display type（对内显示）：其实就相当于把该元素当成了容器，规定了其内部子元素是如何布局的，参与何种格式化上下文；


outer display type
对外显示方面，盒子类型可以分成 2 类：block-level box（块级盒子） 和 inline-level box（行内级盒子）。
依据上图可以列出都有哪些块级和行内级盒子：


块级盒子：display 为 block、list-item、table、flex、grid、flow-root 等；


行内级盒子：display 为 inline、inline-block、inline-table 等；


所有块级盒子都会参与 BFC，呈现垂直排列；而所有行内级盒子都参会 IFC，呈现水平排列。
除此之外，block、inline 和 inline-block 还有什么更具体的区别呢？
block


占满一行，默认继承父元素的宽度；多个块元素将从上到下进行排列；


设置 width/height 将会生效；


设置 padding 和 margin 将会生效；


inline


不会占满一行，宽度随着内容而变化；多个 inline 元素将按照从左到右的顺序在一行里排列显示，如果一行显示不下，则自动换行；


设置 width/height 将不会生效；


设置竖直方向上的 padding 和 margin 将不会生效；


inline-block


是行内块元素，不单独占满一行，可以看成是能够在一行里进行左右排列的块元素；


设置 width/height 将会生效；


设置 padding 和 margin 将会生效；


inner display type
对内方面，其实就是把元素当成了容器，里面包裹着文本或者其他子元素。container box 的类型依据 display 的值不同，分为 4 种：


block container：建立 BFC 或者 IFC；


flex container：建立 FFC；


grid container：建立 GFC;


ruby container：接触不多，不做介绍。


值得一提的是如果把 img 这种替换元素（replaced element）申明为 block 是不会产生 container box 的，因为替换元素比如 img 设计的初衷就仅仅是通过 src 把内容替换成图片，完全没考虑过会把它当成容器。
参考：


CSS 原理 - 你所不知道的 display [7]


格式化上下文 [8]


格式化上下文
格式化上下文（Formatting Context）是 CSS2.1 规范中的一个概念，大概说的是页面中的一块渲染区域，规定了渲染区域内部的子元素是如何排版以及相互作用的。
不同类型的盒子有不同格式化上下文，大概有这 4 类：


BFC (Block Formatting Context) 块级格式化上下文；


IFC (Inline Formatting Context) 行内格式化上下文；


FFC (Flex Formatting Context) 弹性格式化上下文；


GFC (Grid Formatting Context) 格栅格式化上下文；


其中 BFC 和 IFC 在 CSS 中扮演着非常重要的角色，因为它们直接影响了网页布局，所以需要深入理解其原理。
BFC
块格式化上下文，它是一个独立的渲染区域，只有块级盒子参与，它规定了内部的块级盒子如何布局，并且与这个区域外部毫不相干。

图来源于 yachen168
BFC 渲染规则


内部的盒子会在垂直方向，一个接一个地放置；


盒子垂直方向的距离由 margin 决定，属于同一个 BFC 的两个相邻盒子的 margin 会发生重叠；


每个元素的 margin 的左边，与包含块 border 的左边相接触 (对于从左往右的格式化，否则相反)，即使存在浮动也是如此；


BFC 的区域不会与 float 盒子重叠；


BFC 就是页面上的一个隔离的独立容器，容器里面的子元素不会影响到外面的元素。反之也如此。


计算 BFC 的高度时，浮动元素也参与计算。


如何创建 BFC？


根元素：html


非溢出的可见元素：overflow 不为 visible


设置浮动：float 属性不为 none


设置定位：position 为 absolute 或 fixed


定义成块级的非块级元素：display: inline-block/table-cell/table-caption/flex/inline-flex/grid/inline-grid


BFC 应用场景
1、 自适应两栏布局
应用原理：BFC 的区域不会和浮动区域重叠，所以就可以把侧边栏固定宽度且左浮动，而对右侧内容触发 BFC，使得它的宽度自适应该行剩余宽度。

&lt;div class="layout"&gt;  
    &lt;div class="aside"&gt;aside&lt;/div&gt;  
    &lt;div class="main"&gt;main&lt;/div&gt;  
&lt;/div&gt;  
.aside {  
    float: left;  
    width: 100px;  
}  
.main {  
    &lt;!-- 触发 BFC --&gt;  
    overflow: auto;  
}  
2、清除内部浮动
浮动造成的问题就是父元素高度坍塌，所以清除浮动需要解决的问题就是让父元素的高度恢复正常。而用     BFC 清除浮动的原理就是：计算 BFC 的高度时，浮动元素也参与计算。只要触发父元素的 BFC 即可。

.parent {
    overflow: hidden;
}
3、 防止垂直 margin 合并
BFC 渲染原理之一：同一个 BFC 下的垂直 margin 会发生合并。所以如果让 2 个元素不在同一个 BFC 中即可阻止垂直 margin 合并。那如何让 2 个相邻的兄弟元素不在同一个 BFC 中呢？可以给其中一个元素外面包裹一层，然后触发其包裹层的 BFC，这样一来 2 个元素就不会在同一个 BFC 中了。

&lt;div class="layout"&gt;  
	&lt;div class="a"&gt;a&lt;/div&gt;  
    &lt;div class="contain-b"&gt;  
        &lt;div class="b"&gt;b&lt;/div&gt;  
    &lt;/div&gt;  
&lt;/div&gt;  
.demo3 .a,  
.demo3 .b {  
    border: 1px solid #999;  
    margin: 10px;  
}  
.contain-b {  
    overflow: hidden;  
}  
针对以上 3 个 示例 ，可以结合这个 BFC 应用示例 配合观看更佳。
参考：CSS 原理 - Formatting Context [9]
IFC
IFC 的形成条件非常简单，块级元素中仅包含内联级别元素，需要注意的是当 IFC 中有块级元素插入时，会产生两个匿名块将父元素分割开来，产生两个 IFC。

IFC 渲染规则


子元素在水平方向上一个接一个排列，在垂直方向上将以容器顶部开始向下排列；


节点无法声明宽高，其中 margin 和 padding 在水平方向有效在垂直方向无效；


节点在垂直方向上以不同形式对齐；


能把在一行上的框都完全包含进去的一个矩形区域，被称为该行的线盒（line box）。线盒的宽度是由包含块（containing box）和与其中的浮动来决定；


IFC 中的 line box 一般左右边贴紧其包含块，但 float 元素会优先排列。


IFC 中的 line box 高度由 line-height 计算规则来确定，同个 IFC 下的多个 line box 高度可能会不同；


当内联级盒子的总宽度少于包含它们的 line box 时，其水平渲染规则由 text-align 属性值来决定；


当一个内联盒子超过父元素的宽度时，它会被分割成多盒子，这些盒子分布在多个 line box 中。如果子元素未设置强制换行的情况下，inline box 将不可被分割，将会溢出父元素。


针对如上的 IFC 渲染规则，你是不是可以分析下下面这段代码的 IFC 环境是怎么样的呢？
&lt;p&gt;It can get &lt;strong&gt;very complicated&lt;/storng&gt; once you start looking into it.&lt;/p&gt;   

对应上面这样一串 HTML 分析如下：


p 标签是一个 block container，对内将产生一个 IFC；


由于一行没办法显示完全，所以产生了 2 个线盒（line box）；线盒的宽度就继承了 p 的宽度；高度是由里面的内联盒子的 line-height 决定；


It can get：匿名的内联盒子；


very complicated：strong 标签产生的内联盒子；


once you start：匿名的内联盒子；


looking into it.：匿名的内联盒子。


参考：Inline formatting contexts [10]
IFC 应用场景


水平居中：当一个块要在环境中水平居中时，设置其为 inline-block 则会在外层产生 IFC，通过 text-align 则可以使其水平居中。


垂直居中：创建一个 IFC，用其中一个元素撑开父元素的高度，然后设置其 vertical-align: middle，其他行内元素则可以在此父元素下垂直居中。


偷个懒，demo 和图我就不做了。
层叠上下文
在电脑显示屏幕上的显示的页面其实是一个三维的空间，水平方向是 X 轴，竖直方向是 Y 轴，而屏幕到眼睛的方向可以看成是 Z 轴。众 HTML 元素依据自己定义的属性的优先级在 Z 轴上按照一定的顺序排开，而这其实就是层叠上下文所要描述的东西。

-w566
我们对层叠上下文的第一印象可能要来源于 z-index，认为它的值越大，距离屏幕观察者就越近，那么层叠等级就越高，事实确实是这样的，但层叠上下文的内容远非仅仅如此：


z-index 能够在层叠上下文中对元素的堆叠顺序其作用是必须配合定位才可以；


除了 z-index 之外，一个元素在 Z 轴上的显示顺序还受层叠等级和层叠顺序影响；


在看层叠等级和层叠顺序之前，我们先来看下如何产生一个层叠上下文，特定的 HTML 元素或者 CSS 属性产生层叠上下文，MDN 中给出了这么一个列表，符合以下任一条件的元素都会产生层叠上下文：


html 文档根元素


声明 position: absolute/relative 且 z-index 值不为 auto 的元素；


声明 position: fixed/sticky 的元素；


flex 容器的子元素，且 z-index 值不为 auto；


grid 容器的子元素，且 z-index 值不为 auto；


opacity 属性值小于 1 的元素；


mix-blend-mode 属性值不为 normal 的元素；


以下任意属性值不为 none 的元素：


transform


filter


perspective


clip-path


mask / mask-image / mask-border


isolation 属性值为 isolate 的元素；


-webkit-overflow-scrolling 属性值为 touch 的元素；


will-change 值设定了任一属性而该属性在 non-initial 值时会创建层叠上下文的元素；


contain 属性值为 layout、paint 或包含它们其中之一的合成值（比如 contain: strict、contain: content）的元素。


层叠等级
层叠等级指节点在三维空间 Z 轴上的上下顺序。它分两种情况：


在同一个层叠上下文中，它描述定义的是该层叠上下文中的层叠上下文元素在 Z 轴上的上下顺序；


在其他普通元素中，它描述定义的是这些普通元素在 Z 轴上的上下顺序；


普通节点的层叠等级优先由其所在的层叠上下文决定，层叠等级的比较只有在当前层叠上下文中才有意义，脱离当前层叠上下文的比较就变得无意义了。
层叠顺序
在同一个层叠上下文中如果有多个元素，那么他们之间的层叠顺序是怎么样的呢？

以下这个列表越往下层叠优先级越高，视觉上的效果就是越容易被用户看到（不会被其他元素覆盖）：


层叠上下文的 border 和 background


z-index &lt; 0 的子节点


标准流内块级非定位的子节点


浮动非定位的子节点


标准流内行内非定位的子节点


z-index: auto/0 的子节点


z-index &gt; 0 的子节点


如何比较两个元素的层叠等级？


在同一个层叠上下文中，比较两个元素就是按照上图的介绍的层叠顺序进行比较。


如果不在同一个层叠上下文中的时候，那就需要比较两个元素分别所处的层叠上下文的等级。


如果两个元素都在同一个层叠上下文，且层叠顺序相同，则在 HTML 中定义越后面的层叠等级越高。


参考：彻底搞懂 CSS 层叠上下文、层叠等级、层叠顺序、z-index [11]
值和单位
CSS 的声明是由属性和值组成的，而值的类型有许多种：


数值：长度值 ，用于指定例如元素 width、border-width、font-size 等属性的值；


百分比：可以用于指定尺寸或长度，例如取决于父容器的 width、height 或默认的 font-size；


颜色：用于指定 background-color、color 等；


坐标位置：以屏幕的左上角为坐标原点定位元素的位置，比如常见的 background-position、top、right、bottom 和 left 等属性；


函数：用于指定资源路径或背景图片的渐变，比如 url ()、linear-gradient () 等；


而还有些值是需要带单位的，比如 width: 100px，这里的 px 就是表示长度的单位，长度单位除了 px 外，比较常用的还有 em、rem、vw/vh 等。那他们有什么区别呢？又应该在什么时候使用它们呢？
px
屏幕分辨率是指在屏幕的横纵方向上的像素点数量，比如分辨率 1920×1080 意味着水平方向含有 1920 个像素数，垂直方向含有 1080 个像素数。

而 px 表示的是 CSS 中的像素，在 CSS 中它是绝对的长度单位，也是最基础的单位，其他长度单位会自动被浏览器换算成 px。但是对于设备而言，它其实又是相对的长度单位，比如宽高都为 2px，在正常的屏幕下，其实就是 4 个像素点，而在设备像素比 (devicePixelRatio) 为 2 的 Retina 屏幕下，它就有 16 个像素点。所以屏幕尺寸一致的情况下，屏幕分辨率越高，显示效果就越细腻。
讲到这里，还有一些相关的概念需要理清下：
设备像素（Device pixels）
设备屏幕的物理像素，表示的是屏幕的横纵有多少像素点；和屏幕分辨率是差不多的意思。
设备像素比（DPR）
设备像素比表示 1 个 CSS 像素等于几个物理像素。
计算公式：DPR = 物理像素数 / 逻辑像素数；
在浏览器中可以通过 window.devicePixelRatio 来获取当前屏幕的 DPR。
像素密度（DPI/PPI）
像素密度也叫显示密度或者屏幕密度，缩写为 DPI (Dots Per Inch) 或者 PPI (Pixel Per Inch)。从技术角度说，PPI 只存在于计算机显示领域，而 DPI 只出现于打印或印刷领域。
计算公式：像素密度 = 屏幕对角线的像素尺寸 / 物理尺寸
比如，对于分辨率为 750 * 1334 的 iPhone 6 来说，它的像素密度为：
Math.sqrt(750 * 750 + 1334 * 1334) / 4.7 = 326ppi   
设备独立像素（DIP）
DIP 是特别针对 Android 设备而衍生出来的，原因是安卓屏幕的尺寸繁多，因此为了显示能尽量和设备无关，而提出的这个概念。它是基于屏幕密度而计算的，认为当屏幕密度是 160 的时候，px = DIP。
计算公式：dip = px * 160 /dpi
em
em 是 CSS 中的相对长度单位中的一个。居然是相对的，那它到底是相对的谁呢？它有 2 层意思：


在 font-size 中使用是相对于父元素的 font-size 大小，比如父元素 font-size: 16px，当给子元素指定 font-size: 2em 的时候，经过计算后它的字体大小会是 32px；


在其他属性中使用是相对于自身的字体大小，如 width/height/padding/margin 等；


我们都知道每个浏览器都会给 HTML 根元素 html 设置一个默认的 font-size，而这个值通常是 16px。这也就是为什么 1em = 16px 的原因所在了。
em 在计算的时候是会层层计算的，比如：
&lt;div&gt;  
    &lt;p&gt;&lt;/p&gt;  
&lt;/div&gt;  
div { font-size: 2em; }  
p { font-size: 2em; }  
对于如上一个结构的 HTML，由于根元素 html 的字体大小是 16px，所以 p 标签最终计算出来后的字体大小会是 16 * 2 * 2 = 64px
rem
rem (root em) 和 em 一样，也是一个相对长度单位，不过 rem 相对的是 HTML 的根元素 html。
rem 由于是基于 html 的 font-size 来计算，所以通常用于自适应网站或者 H5 中。
比如在做 H5 的时候，前端通常会让 UI 给 750px 宽的设计图，而在开发的时候可以基于 iPhone X 的尺寸 375px * 812px 来写页面，这样一来的话，就可以用下面的 JS 依据当前页面的视口宽度自动计算出根元素 html 的基准 font-size 是多少。
(function (doc, win) {  
    var docEl = doc.documentElement,  
        resizeEvt = 'orientationchange' in window ? 'orientationchange' : 'resize',  
        psdWidth = 750,  // 设计图宽度  
        recalc = function () {  
            var clientWidth = docEl.clientWidth;  
            if ( !clientWidth ) return;  
            if ( clientWidth &gt;= 640 ) {  
                docEl.style.fontSize = 200 * ( 640 / psdWidth ) + 'px';  
            } else {  
                docEl.style.fontSize = 200 * ( clientWidth / psdWidth ) + 'px';  
            }  
        };

    if ( !doc.addEventListener ) return;  
    // 绑定事件的时候最好配合防抖函数  
    win.addEventListener( resizeEvt, debounce(recalc, 1000), false );  
    doc.addEventListener( 'DOMContentLoaded', recalc, false );

        function debounce(func, wait) {  
        var timeout;  
        return function () {  
            var context = this;  
            var args = arguments;  
            clearTimeout(timeout)  
            timeout = setTimeout(function(){  
                func.apply(context, args)  
            }, wait);  
        }  
    }  
})(document, window);

比如当视口是 375px 的时候，经过计算 html 的 font-size 会是 100px，这样有什么好处呢？好处就是方便写样式，比如从设计图量出来的 header 高度是 50px 的，那我们写样式的时候就可以直接写：
header {  
    height: 0.5rem;  
}  

每个从设计图量出来的尺寸只要除于 100 即可得到当前元素的 rem 值，都不用经过计算，非常方便。偷偷告诉你，如果你把上面那串计算 html 标签 font-size 的 JS 代码中的 200 替换成 2，那在计算 rem 的时候就不需要除于 100 了，从设计图量出多大 px，就直接写多少个 rem。
vw/vh
vw 和 vh 分别是相对于屏幕视口宽度和高度而言的长度单位：


1vw = 视口宽度均分成 100 份中 1 份的长度；


1vh = 视口高度均分成 100 份中 1 份的长度；


在 JS 中 100vw = window.innerWidth，100vh = window.innerHeight。

vw/vh 的出现使得多了一种写自适应布局的方案，开发者不再局限于 rem 了。
相对视口的单位，除了 vw/vh 外，还有 vmin 和 vmax：


vmin：取 vw 和 vh 中值较小的；


vmax：取 vw 和 vh 中值较大的；


颜色体系
CSS 中用于表示颜色的值种类繁多，足够构成一个体系，所以这里就专门拿出一个小节来讲解它。
根据 CSS 颜色草案 [12] 中提到的颜色值类型，大概可以把它们分为这几类：


颜色关键字


transparent 关键字


currentColor 关键字


RGB 颜色


HSL 颜色


颜色关键字
颜色关键字（color keywords）是不区分大小写的标识符，它表示一个具体的颜色，比如 white（白），黑（black）等；
可接受的关键字列表在 CSS 的演变过程中发生了改变：


CSS 标准 1 只接受 16 个基本颜色，称为 VGA 颜色，因为它们来源于 VGA 显卡所显示的颜色集合而被称为 VGA colors （视频图形阵列色彩）。


CSS 标准 2 增加了 orange 关键字。


从一开始，浏览器接受其它的颜色，由于一些早期浏览器是 X11 应用程序，这些颜色大多数是 X11 命名的颜色列表，虽然有一点不同。SVG 1.0 是首个正式定义这些关键字的标准；CSS 色彩标准 3 也正式定义了这些关键字。它们经常被称作扩展的颜色关键字， X11 颜色或 SVG 颜色 。


CSS 颜色标准 4 添加可 rebeccapurple 关键字来纪念 web 先锋 Eric Meyer。


如下这张图是 16 个基础色，又叫 VGA 颜色。截止到目前为止 CSS 颜色关键字总共有 146 个，这里可以查看 完整的色彩关键字列表 [13]。

VGA 颜色
需要注意的是如果声明的时候的颜色关键字是错误的，浏览器会忽略它。
transparent 关键字
transparent 关键字表示一个完全透明的颜色，即该颜色看上去将是背景色。从技术上说，它是带有 alpha 通道为最小值的黑色，是 rgba (0,0,0,0) 的简写。
透明关键字有什么应用场景呢？
实现三角形
下面这个图是用 4 条边框填充的正方形，看懂了它你大概就知道该如何用 CSS 写三角形了。

div {  
    border-top-color: #ffc107;  
    border-right-color: #00bcd4;  
    border-bottom-color: #e26b6b;  
    border-left-color: #cc7cda;  
    border-width: 50px;  
    border-style: solid;  
}  
用 transparent 实现三角形的原理：


首先宽高必须是 0px，通过边框的粗细来填充内容；


那条边需要就要加上颜色，而不需要的边则用 transparent；


想要什么样姿势的三角形，完全由上下左右 4 条边的中有颜色的边和透明的边的位置决定；


等腰三角形：设置一条边有颜色，然后紧挨着的 2 边是透明，且宽度是有颜色边的一半；直角三角形：设置一条边有颜色，然后紧挨着的任何一边透明即可。


看下示例：

增大点击区域
常常在移动端的时候点击的按钮的区域特别小，但是由于现实效果又不太好把它做大，所以常用的一个手段就是通过透明的边框来增大按钮的点击区域：
.btn {  
    border: 5px solid transparent;  
}  
currentColor 关键字
currentColor 会取当前元素继承父级元素的文本颜色值或声明的文本颜色值，即 computed 后的 color 值。
比如，对于如下 CSS，该元素的边框颜色会是 red：
.btn {  
    color: red;  
    border: 1px solid currentColor;  
}  
RGB [A] 颜色
RGB [A] 颜色是由 R (red)-G (green)-B (blue)-A (alpha) 组成的色彩空间。

在 CSS 中，它有两种表示形式：


十六进制符号；


函数符；


十六进制符号
RGB 中的每种颜色的值范围是 00~ff，值越大表示颜色越深。所以一个颜色正常是 6 个十六进制字符加上 # 组成，比如红色就是 #ff0000。
如果 RGB 颜色需要加上不透明度，那就需要加上 alpha 通道的值，它的范围也是 00~ff，比如一个带不透明度为 67% 的红色可以这样写 #ff0000aa。
使用十六进制符号表示颜色的时候，都是用 2 个十六进制表示一个颜色，如果这 2 个字符相同，还可以缩减成只写 1 个，比如，红色 #f00；带 67% 不透明度的红色 #f00a。
函数符
当 RGB 用函数表示的时候，每个值的范围是 0~255 或者 0%~100%，所以红色是 rgb (255, 0, 0)， 或者 rgb (100%, 0, 0)。
如果需要使用函数来表示带不透明度的颜色值，值的范围是 0~1 及其之间的小数或者 0%~100%，比如带 67% 不透明度的红色是 rgba (255, 0, 0, 0.67) 或者 rgba (100%, 0%, 0%, 67%)

“
需要注意的是 RGB 这 3 个颜色值需要保持一致的写法，要嘛用数字要嘛用百分比，而不透明度的值的可以不用和 RGB 保持一致写法。比如 rgb (100%, 0, 0) 这个写法是无效的；而 rgb (100%, 0%, 0%, 0.67) 是有效的。

在第 4 代 CSS 颜色标准中，新增了一种新的函数写法，即可以把 RGB 中值的分隔逗号改成空格，而把 RGB 和 alpha 中的逗号改成 /，比如带 67% 不透明度的红色可以这样写 rgba (255 0 0 / 0.67)。另外还把 rgba 的写法合并到 rgb 函数中了，即 rgb 可以直接写带不透明度的颜色。
HSL [A] 颜色
HSL [A] 颜色是由色相 (hue)- 饱和度 (saturation)- 亮度 (lightness)- 不透明度组成的颜色体系。



色相（H）是色彩的基本属性，值范围是 0~360 或者 0deg~360deg， 0 (或 360) 为红色，120 为绿色，240 为蓝色；


饱和度（S）是指色彩的纯度，越高色彩越纯，低则逐渐变灰，取 0~100% 的数值；0% 为灰色， 100% 全色；


亮度（L），取 0~100%，0% 为暗，100% 为白；


不透明度（A），取 0100%，或者 01 及之间的小数；


写法上可以参考 RGB 的写法，只是参数的值不一样。
给一个按钮设置不透明度为 67% 的红色的 color 的写法，以下全部写法效果一致：
button {  
    color: #ff0000aa;  
    color: #f00a;  
    color: rgba(255, 0, 0, 0.67);  
    color: rgb(100% 0% 0% / 67%);  
    color: hsla(0, 100%, 50%, 67%);  
    color: hsl(0deg 100% 50% / 67%);  
}  
小提示：在 Chrome DevTools 中可以按住 shift + 鼠标左键可以切换颜色的表示方式。

媒体查询
媒体查询是指针对不同的设备、特定的设备特征或者参数进行定制化的修改网站的样式。
你可以通过给 &lt;link&gt; 加上 media 属性来指定该样式文件只能对什么设备生效，不指定的话默认是 all，即对所有设备都生效：
&lt;link rel="stylesheet" src="styles.css" media="screen" /&gt;  
&lt;link rel="stylesheet" src="styles.css" media="print" /&gt;  
都支持哪些设备类型？


all：适用于所有设备；


print：适用于在打印预览模式下在屏幕上查看的分页材料和文档；


screen：主要用于屏幕；


speech：主要用于语音合成器。



需要注意的是：通过 media 指定的  资源尽管不匹配它的设备类型，但是浏览器依然会加载它。


除了通过 &lt;link&gt; 让指定设备生效外，还可以通过 @media 让 CSS 规则在特定的条件下才能生效。响应式页面就是使用了 @media 才让一个页面能够同时适配 PC、Pad 和手机端。
@media (min-width: 1000px) {}  
媒体查询支持逻辑操作符：


and：查询条件都满足的时候才生效；


not：查询条件取反；


only：整个查询匹配的时候才生效，常用语兼容旧浏览器，使用时候必须指定媒体类型；


逗号或者 or：查询条件满足一项即可匹配；


媒体查询还支持众多的媒体特性 [14]，使得它可以写出很复杂的查询条件：
/* 用户设备的最小高度为680px或为纵向模式的屏幕设备 */  
@media (min-height: 680px), screen and (orientation: portrait) {}  
常见需求
自定义属性
之前我们通常是在预处理器里才可以使用变量，而现在 CSS 里也支持了变量的用法。通过自定义属性就可以在想要使用的地方引用它。
自定义属性也和普通属性一样具有级联性，申明在 :root 下的时候，在全文档范围内可用，而如果是在某个元素下申明自定义属性，则只能在它及它的子元素下才可以使用。
自定义属性必须通过 --x 的格式申明，比如：--theme-color: red; 使用自定义属性的时候，需要用 var 函数。比如：
&lt;!-- 定义自定义属性 --&gt;  
:root {  
    --theme-color: red;  
}

&lt;!-- 使用变量 --&gt;  
h1 {  
    color: var(--theme-color);  
}


上图这个是使用 CSS 自定义属性配合 JS 实现的动态调整元素的 box-shadow，具体可以看这个 codepen demo。
1px 边框解决方案
Retina 显示屏比普通的屏幕有着更高的分辨率，所以在移动端的 1px 边框就会看起来比较粗，为了美观通常需要把这个线条细化处理。这里有篇文章列举了 7 中方案可以参考一下：7 种方法解决移动端 Retina 屏幕 1px 边框问题 [15]
而这里附上最后一种通过伪类和 transform 实现的相对完美的解决方案：
只设置单条底部边框：
.scale-1px-bottom {  
    position: relative;  
    border:none;  
}  
.scale-1px-bottom::after {  
    content: '';  
    position: absolute;  
    left: 0;  
    bottom: 0;  
    background: #000;  
    width: 100%;  
    height: 1px;  
    -webkit-transform: scaleY(0.5);  
    transform: scaleY(0.5);  
    -webkit-transform-origin: 0 0;  
    transform-origin: 0 0;  
}  
同时设置 4 条边框：
.scale-1px {  
    position: relative;  
    margin-bottom: 20px;  
    border:none;  
}  
.scale-1px::after {  
    content: '';  
    position: absolute;  
    top: 0;  
    left: 0;  
    border: 1px solid #000;  
    -webkit-box-sizing: border-box;  
    box-sizing: border-box;  
    width: 200%;  
    height: 200%;  
    -webkit-transform: scale(0.5);  
    transform: scale(0.5);  
    -webkit-transform-origin: left top;  
    transform-origin: left top;  
}  
清除浮动
什么是浮动：浮动元素会脱离文档流并向左 / 向右浮动，直到碰到父元素或者另一个浮动元素。
为什么要清楚浮动，它造成了什么问题？
因为浮动元素会脱离正常的文档流，并不会占据文档流的位置，所以如果一个父元素下面都是浮动元素，那么这个父元素就无法被浮动元素所撑开，这样一来父元素就丢失了高度，这就是所谓的浮动造成的父元素高度坍塌问题。
父元素高度一旦坍塌将对后面的元素布局造成影响，为了解决这个问题，所以需要清除浮动，让父元素恢复高度，那该如何做呢？
这里介绍两种方法：通过 BFC 来清除、通过 clear 来清除。
BFC 清除浮动
前面介绍 BFC 的时候提到过，计算 BFC 高度的时候浮动子元素的高度也将计算在内，利用这条规则就可以清楚浮动。
假设一个父元素 parent 内部只有 2 个子元素 child，且它们都是左浮动的，这个时候 parent 如果没有设置高度的话，因为浮动造成了高度坍塌，所以 parent 的高度会是 0，此时只要给 parent 创造一个 BFC，那它的高度就能恢复了。
而产生 BFC 的方式很多，我们可以给父元素设置 overflow: auto 来简单的实现 BFC 清除浮动，但是为了兼容 IE 最好用 overflow: hidden。
.parent {  
    overflow: hidden;  
}  
通过 overflow: hidden 来清除浮动并不完美，当元素有阴影或存在下拉菜单的时候会被截断，所以该方法使用比较局限。
通过 clear 清除浮动
我先把结论贴出来：
.clearfix {  
    zoom: 1;  
}  
.clearfix::after {  
    content: "";  
    display: block;  
    clear: both;  
}  
这种写法的核心原理就是通过 ::after 伪元素为在父元素的最后一个子元素后面生成一个内容为空的块级元素，然后通过 clear 将这个伪元素移动到所有它之前的浮动元素的后面，画个图来理解一下。

可以结合这个 codepen demo 一起理解上图的 clear 清楚浮动原理。
上面这个 demo 或者图里为了展示需要所以给伪元素的内容设置为了 ::after，实际使用的时候需要设置为空字符串，让它的高度为 0，从而父元素的高度都是由实际的子元素撑开。
该方式基本上是现在人人都在用的清除浮动的方案，非常通用。
参考：CSS 中的浮动和清除浮动，梳理一下 [16]
消除浏览器默认样式
针对同一个类型的 HTML 标签，不同的浏览器往往有不同的表现，所以在网站制作的时候，开发者通常都是需要将这些浏览器的默认样式清除，让网页在不同的浏览器上能够保持一致。
针对清除浏览器默认样式这件事，在很早之前 CSS 大师 Eric A. Meyer 就干过。它就是写一堆通用的样式用来重置浏览器默认样式，这些样式通常会放到一个命名为 reset.css 文件中。比如大师的 reset.css [17] 是这么写的：
html, body, div, span, applet, object, iframe,  
h1, h2, h3, h4, h5, h6, p, blockquote, pre,  
a, abbr, acronym, address, big, cite, code,  
del, dfn, em, img, ins, kbd, q, s, samp,  
small, strike, strong, sub, sup, tt, var,  
b, u, i, center,  
dl, dt, dd, ol, ul, li,  
fieldset, form, label, legend,  
table, caption, tbody, tfoot, thead, tr, th, td,  
article, aside, canvas, details, embed,   
figure, figcaption, footer, header, hgroup,   
menu, nav, output, ruby, section, summary,  
time, mark, audio, video {  
    margin: 0;  
    padding: 0;  
    border: 0;  
    font-size: 100%;  
    font: inherit;  
    vertical-align: baseline;  
}  
/* HTML5 display-role reset for older browsers */  
article, aside, details, figcaption, figure,   
footer, header, hgroup, menu, nav, section {  
    display: block;  
}  
body {  
    line-height: 1;  
}  
ol, ul {  
    list-style: none;  
}  
blockquote, q {  
    quotes: none;  
}  
blockquote:before, blockquote:after,  
q:before, q:after {  
    content: '';  
    content: none;  
}  
table {  
    border-collapse: collapse;  
    border-spacing: 0;  
}  
他的这份 reset.css 据说是被使用最广泛的重设样式的方案了。
除了 reset.css 外，后来又出现了 Normalize.css [18] 。关于 Normalize.css, 其作者 necolas 专门写了一篇文章介绍了它，并谈到了它和 reset.css 的区别。这个是他写那篇文章的翻译版：让我们谈一谈 Normalize.css [19]。
文章介绍到：Normalize.css 只是一个很小的 CSS 文件，但它在默认的 HTML 元素样式上提供了跨浏览器的高度一致性。相比于传统的 CSS reset，Normalize.css 是一种现代的、为 HTML5 准备的优质替代方案，现在已经有很多知名的框架和网站在使用它了。
Normalize.css 的具体样式可以看这里 Normalize.css
区别于 reset.css，Normalize.css 有如下特点：


reset.css 几乎为所有标签都设置了默认样式，而 Normalize.css 则是有选择性的保护了部分有价值的默认值；


修复了很多浏览器的 bug，而这是 reset.css 没做到的；


不会让你的调试工具变的杂乱，相反 reset.css 由于设置了很多默认值，所以在浏览器调试工具中往往会看到一大堆的继承样式，显得很杂乱；


Normalize.css 是模块化的，所以可以选择性的去掉永远不会用到的部分，比如表单的一般化；


Normalize.css 有详细的说明文档；


长文本处理
默认：字符太长溢出了容器

字符超出部分换行

字符超出位置使用连字符

单行文本超出省略

多行文本超出省略

查看以上这些方案的示例： codepen demo
有意思的是刚好前两天看到 chokcoco 针对文本溢出也写了一篇文章，主要突出的是对整块的文本溢出处理。啥叫整块文本？比如，下面这种技术标签就是属于整块文本：

另外他还对 iOS/Safari 做了兼容处理，感兴趣的可以去阅读下：CSS 整块文本溢出省略特性探究 [20]。
水平垂直居中
让元素在父元素中呈现出水平垂直居中的形态，无非就 2 种情况：


单行的文本、inline 或者 inline-block 元素；


固定宽高的块级盒子；


不固定宽高的块级盒子；


以下列到的所有水平垂直居中方案这里写了个 codepen demo，配合示例阅读效果更佳。
单行的文本、inline 或 inline-block 元素
水平居中
此类元素需要水平居中，则父级元素必须是块级元素 (block level)，且父级元素上需要这样设置样式：
.parent {  
    text-align: center;  
}  
垂直居中
方法一：通过设置上下内间距一致达到垂直居中的效果：
.single-line {  
    padding-top: 10px;  
    padding-bottom: 10px;  
}  
方法二：通过设置 height 和 line-height 一致达到垂直居中：
.single-line {  
    height: 100px;  
    line-height: 100px;  
}  
固定宽高的块级盒子
方法一：absolute + 负 margin

方法二：absolute + margin auto

方法三：absolute + calc

不固定宽高的块级盒子
这里列了 6 种方法，参考了颜海镜 写的文章 ，其中的两种 line-height 和 writing-mode 方案看后让我惊呼：还有这种操作？学到了学到了。
方法一：absolute + transform

方法二：line-height + vertical-align

方法三：writing-mode

方法四：table-cell

方法五：flex

方法六：grid

常用布局
两栏布局（边栏定宽主栏自适应）
针对以下这些方案写了几个示例： codepen demo
方法一：float + overflow（BFC 原理）

方法二：float + margin

方法三：flex

方法四：grid

三栏布局（两侧栏定宽主栏自适应）
针对以下这些方案写了几个示例： codepen demo
方法一：圣杯布局

方法二：双飞翼布局

方法三：float + overflow（BFC 原理）

方法四：flex

方法五：grid

多列等高布局
结合示例阅读更佳：codepen demo
方法一：padding + 负 margin

方法二：设置父级背景图片

三行布局（头尾定高主栏自适应）
列了 4 种方法，都是基于如下的 HTML 和 CSS 的，结合示例阅读效果更佳：codepen demo
&lt;div class="layout"&gt;  
    &lt;header&gt;&lt;/header&gt;  
    &lt;main&gt;  
        &lt;div class="inner"&gt;&lt;/div&gt;  
    &lt;/main&gt;  
    &lt;footer&gt;&lt;/footer&gt;  
&lt;/div&gt;  
html,  
body,  
.layout {  
    height: 100%;  
}  
body {  
    margin: 0;  
}  
header,   
footer {  
    height: 50px;  
}  
main {  
    overflow-y: auto;  
}  
方法一：calc

方法二：absolute

方法三：flex

方法四：grid

结了个尾
这是我断断续续写了 2 周完成的文章，算是自己对 CSS 的一个总结，虽然写得很长，但不足以覆盖所有 CSS 的知识，比如动画和一些 CSS3 的新特性就完全没涉及，因为这要写下来估计得有大几万字（其实就是懒 😝 ）。
码字作图不易，如果喜欢或者对你有丝毫帮助的话，帮忙点个👍 哈，点赞就是我的动力。同时也希望自己能坚持认真的写下去，因为在总结提升自己的同时如果也能帮助更多的前端 er，那将会让我感觉很开心。
参考资料
[1]@charset: https://developer.mozilla.org/zh-CN/docs/Web/CSS/@charset
[2]Byte order mark: https://en.wikipedia.org/wiki/Byte_order_mark
[3]@import: https://developer.mozilla.org/zh-CN/docs/Web/CSS/@import
[4]@supports: https://developer.mozilla.org/zh-CN/docs/Web/CSS/@supports
[5]MDN CSS Selectors: https://developer.mozilla.org/zh-CN/docs/Web/CSS/CSS_Selectors
[6]Visual formatting model: https://www.w3.org/TR/CSS2/visuren.html
[7] CSS 原理 - 你所不知道的 display: https://yachen168.github.io/article/display.html
[8] 格式化上下文: https://ithelp.ithome.com.tw/articles/10223896?sc=pt
[9] CSS 原理 - Formatting Context: https://yachen168.github.io/article/Formatting-context.html
[10]Inline formatting contexts: https://www.w3.org/TR/CSS2/visuren.html#inline-formatting
[11] 彻底搞懂 CSS 层叠上下文、层叠等级、层叠顺序、z-index: https://juejin.cn/post/6844903667175260174
[12] CSS 颜色草案: https://drafts.csswg.org/css-color-3/
[13] 完整的色彩关键字列表: https://codepen.io/bulandent/pen/gOLovwL
[14] 众多的媒体特性: https://developer.mozilla.org/zh-CN/docs/Web/Guide/CSS/Media_queries#%E5%AA%92%E4%BD%93%E7%89%B9%E6%80%A7
[15] 7 种方法解决移动端 Retina 屏幕 1px 边框问题: https://www.jianshu.com/p/7e63f5a32636
[16] CSS 中的浮动和清除浮动，梳理一下: https://www.jianshu.com/p/09bd5873bed4
[17]reset.css: https://meyerweb.com/eric/tools/css/reset/
[18]Normalize.css: https://github.com/necolas/normalize.css
[19] 让我们谈一谈 Normalize.css: https://jerryzou.com/posts/aboutNormalizeCss/
[20] CSS 整块文本溢出省略特性探究: https://juejin.cn/post/6938583040469762055
From https://mp.weixin.qq.com/s/UtYENocSsl0R10h8fww7Iw
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>http</tag>
        <tag>ccs</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim IDE Docker 以及中文指南</title>
    <url>/posts/647e6265/</url>
    <content><![CDATA[
Docker Vim IDE 由博主定制，加入中文环境配置，支持 CJK。并升级到最新版本！

Vim Docker

docker pull bloodstar/vim
alias edit='docker run -ti --rm -v $(pwd):/home/developer/workspace bloodstar/vim' 
edit some.file 
alias edit_update="docker pull bloodstar/vim:latest"
Vim IDE Docker

What's inside:

Alpine Linux
Vim + a ton of awesome plugins see bloodstar/vim:latest
Good support of Golang development with bloodstar/go-tools container
tmux
powerline
Mosh
OpenSSH, Bash, OMF, Python, etc.

how to start the daemon(and all containers)
docker create -v '/usr/lib/go' --name go-tools \
'bloodstar/go-tools' '/bin/true'

docker run -v $('pwd'):/home/developer/workspace \
--volumes-from go-tools \
-v ~/.ssh/pub_rsa:/etc/ssh_keys:ro \
-v /etc/localtime:/etc/localtime:ro \
-d -p 80:80 -p 8080:8080 -p 62222:62222 -p 60001:60001/udp \
--name drop-in bloodstar/drop-in
-v /etc/localtime:/etc/localtime:ro - makes tmux display local time
how to connect:
mosh --ssh="ssh -p 62222" -- developer@$&lt;ip&gt; tmux -u
or without host identity check:
mosh --ssh="ssh -o StrictHostKeyChecking=no -p 62222" -- developer@$&lt;ip&gt; tmux -u
Useful Bash scripts
Connect
#!/bin/bash
ip=$(docker inspect --format '{{ .NetworkSettings.IPAddress }}' drop-in)
mosh --ssh="ssh -p 62222" -- developer@$ip tmux -u
start the daemon(and all containers)
#!/bin/bash
dtc_id=$(docker ps -a -q --filter 'name=vim-go-tools')
if [[ -z "${dtc_id}" ]]; then
 echo 'vim-go-tools container not found. Creating...'
 docker create -v '/usr/lib/go' --name 'vim-go-tools' \
   'bloodstar/go-tools' '/bin/true'
 echo 'Done!'
fi
echo 'starting daemon...'
docker run -v $('pwd'):/home/developer/workspace \
  --volumes-from vim-go-tools \
  -v ~/.ssh/pub_rsa:/etc/ssh_keys:ro \
  -v /etc/localtime:/etc/localtime:ro \
  -e "GEMAIL=&lt;github email&gt;" \
  -e "GNAME=&lt;github name&gt;" \
  -d -p 80:80 -p 8080:8080 -p 62222:62222 -p 60001:60001/udp \
  --name drop-in bloodstar/drop-in
echo 'Done!'
Vim 中文快查表   &lt;= 戳这里

Tips: 在网页上端导航栏，[快查] =&gt; [更多快查表]，有更多快查表！
快去看看吧。

Vim

]]></content>
      <categories>
        <category>ide</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vim</tag>
        <tag>ide</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>从文学的角度，分析韩红的《天亮了》</title>
    <url>/posts/cb623532/</url>
    <content><![CDATA[现场 MV
.bbplayer{width: 100%; max-width: 850px; margin: auto} document.getElementById("mmedia-hHgHpSBSLLuzeRxJ").style.height=document.getElementById("mmedia-hHgHpSBSLLuzeRxJ").scrollWidth*0.76+"px";
    window.onresize = function(){
      document.getElementById("mmedia-hHgHpSBSLLuzeRxJ").style.height=document.getElementById("mmedia-hHgHpSBSLLuzeRxJ").scrollWidth*0.76+"px";
    }; 

精品分析： 原作：石晶兰 短文吧
再做个传送门： 天亮了，听歌时，关灯，准备纸巾。

先分析结构。
看歌词。
那是一个秋天，风儿那么缠绵，
让我想起他们那双无助的眼。
就在那美丽风景相伴的地方，
我听到一声巨响震彻山谷。
就是那个秋天，再看不到爸爸的脸。
他用他的双肩，托起我重生的起点。
黑暗中泪水沾满了双眼，
不要离开不要伤害。
共八行，等于两个四行。
两个四行一一对应，前三行，旋律基本是相同的。只有最后一行，为了与后面衔接，所以不同。
两个四行的布置，等于是一种重复。
这样的重要，在文学结构上，常见于起承。
但歌，相当于诗。囿于篇幅，在结构上，通常会有所缺失。起承两者，一般缺失的，都是起。那样的做法，也就是直接叙事，存在让受众猝不及防的弊病。
然后，《天亮了》并不是。
“那是一个秋天，风儿那么缠绵” 和 “就是那个秋天” 分明是起。
所以，《天亮了》并没有进行文学结构上的省略。
“那是一个秋天，风儿那么缠绵” 是起，接紧着的三行歌词，自然就是承了。
那么，第五行 “就是那个秋天” 怎么又来一个起呢？
自然是因为篇幅太短，叙事不够（前面承得不够），所以，还需要再承一下。
不能够不要第五行的起，直接往下写吗？
真要说的话，其实也能。不过，再加四行承，真的就能把事情说清楚吗？
显然，韩红想要表达的东西很多，她认为，不能。
仅靠精练语言，明显是不够的，还需要换角度陈述。
第五行的再起，实际上，就是为后面的换角度承，打基础的。
这种写法，也是有先例的。请看邓丽君《相见在明天》歌词：
记得我俩初相见，
风吹花儿飞满天。
你说我的笑容像花朵，
比那花儿更娇艳。
我还记得那一天，
送你送到小河边。
手牵着手呀心里有千言，
相对却无言。
跟《天亮了》一样，《相见在明天》也是两个四行，也是起承起承。
并且，两起两承，还跟诗词的押韵一样，其重复，不仅有加深印象的作用，更有共鸣回旋的作用，正是唐陈子昂所说的 “音情顿挫” 的顿挫，极大的提升了作品的美感，让受众的接受度大大提高，
继续看《天亮了》歌词：
我看到爸爸妈妈就这么走远，
留下我在这陌生的人世间。
不知道未来还会有什么风险。
我想要紧紧抓住他的手。
妈妈告诉我希望还会有。
看到太阳出来妈妈笑了。
天亮了。
六行都是转。具体在这里，自然不是转折，而是高那个潮。
此处值得一说的是合，只有三个字 “天亮了”。
这三个字，正好也是这首歌的歌名。
但是这三个字表达的，到底是什么意思、什么情感呢？
题都城南庄 / 唐 / 崔护
去年今日此门中，人面桃花相映红。
人面不知何处去，桃花依旧笑春风。
不难看出，最后一句 “桃花依旧笑春风” 跟前面三句的叙述，是接不上的。
去年这儿，有人面有桃花。今年这儿人面没有了，接下来说的通常是：还真是让人怀念啊。
俗吗？的确俗。并且，还不仅仅是俗，还存在因为什么而怀念那个姑娘的严重问题。
动机不纯的话，写出来就会玷污那个姑娘。动机纯粹，只是单纯的对美好事物的欣赏，写出来的话，又有自夸之嫌。
还真是不好写啊。
不好写，干脆就不写，另起一笔：“桃花依旧笑春风”。究竟表达的是什么样的滋味，让受众自己去想。
《天亮了》末尾的合 “天亮了”，就是 “桃花依旧笑春风” 这种表现手法。太多的感情，千言万语，加总在一起，实在难以挽上疙瘩。于是，就另起一行，来了句看似关系不大的 “天亮了”，让一切，尽在无言中。
不同的受众，会有不同的感受。因而这种让受众自己去想的结尾，总是余味无穷。
文学结构分析，就到这儿。第二段的结构跟第一段相同，就不讲了。
下面进行逐句评讲。
“那是一个秋天，风儿那么缠绵，” 没毛病。“那是” 开头，虽然不出彩，但是很自然，容易被人接受，接着往下听。
“让我想起他们那双无助的眼。” 这里，“他们” 是两个人；“那双” 眼睛虽然是复数，但落实到人，却是单数。因此，这是一个小错误。
很显然，用相同性质的词语直接替换是不行的，譬如 “四只”。四，数量较多，会分散受众的注意力，让受众去思考为什么是四。因而，如果硬要改的话，只能用其它性质的词语去替换，譬如 “彷徨”。
但 “彷徨无助”，又稍显生僻，会影响听者的接受速度，形成不怎么大的接受障碍。而如果也用 “无” 的话，无什么呢？无神？听上去，岂不是比 “彷徨无助” 更不容易分辨。
所以，实在要改，就只能把 “他们” 二字挪到这儿。
那样一来，“让我想起” 就要掺进两个水字了，譬如 “风儿让我想起”。
是不是太水了？
于是，我最终感觉，还是不改为好。
小错误嘛，存在也无妨。这就像文豪写书法一样，多一点少一点，多一笔少一笑，根本不算错误，关键是，那个字不能被错认为是别的字。
“那双无助的眼” 也一样，虽然存在小错误，但由于不影响表达内容，听者一听，就知道是怎么回事。由于没有影响信息传递，所以不改也是行的。
“就在那美丽风景相伴的地方，我听到一声巨响震彻山谷。” 这两小句，没有基础毛病。
值得注意的是，这两小句，存在一个对比：一个美丽的地方，一件悲惨的事。颇有一种把美好的事情撕烂了给读者看的悲剧色彩。
“就是那个秋天，再看不到爸爸的脸。”
为什么提到爸爸没提到妈妈？爸爸妈妈，可以一起提，也可以先后提。这里，实际上是先后提。先提爸爸，后面会提到妈妈。
先提爸爸，又比先提妈妈要好。这是因为，时至今日，最不令人怀疑的，是父女情。虽然背景事件中，那是个儿子，但韩红是女的，唱出来的声音又带有明显的女性特征。女声，提到爸爸，无形中，就相当于女儿提到爸爸。其中的感情，就往父女情的方向靠近了那么一点，让听者一下就能接受，丝毫没有怀疑。
“他用他的双肩，托起我重生的起点。”
背景事件的具体经过，可能生还的当事人都已经记不清楚了。这一句，属于带有归纳性、比拟性的描述。因而不需要因为 “用”“双肩托起”，去询问是不是父亲从洪水中救起了儿子那样的细节。
“黑暗中泪水沾满了双眼，”
“黑暗中” 很妙。只描述了环境，没有指明时间。那其实表达的是，若干个 “黑暗中”。包括当时，也包括事后。并且，“黑暗” 有天然的，也有人为的。天然的，譬如天黑加停电；人为的，譬如钻进被窝里。这些，都被包括了进去。
“不要离开、不要伤害。” 这句，就有些难度了。
“不要离开” 好理解。可以是儿子对父母的呼唤。但 “不要伤害” 呢？
“不要伤害”，到底是谁对谁发出的呐喊，后面再讲。
“我看到爸爸妈妈就这么走远，留下我在这陌生的人世间。不知道未来还会有什么风险。”
三小句，基础上没毛病。直接看上去，字面意思表达能力似乎稍弱。真是不是，后面再说。
“我想要紧紧抓住他的手” 中的 “他”，指父亲，也可以指母亲。
“妈妈告诉我希望还会有。看到太阳出来妈妈笑了。” 这是绝望中的回忆。这一家人，以前也是经受过苦难的。在曾经难熬的岁月中，妈妈曾经多次鼓励过儿子。鼓励的时候，有直述 “告诉我希望还会有”，也有以身作则 “看到太阳出来，妈妈笑了”。
“天亮了。” 尽在不言中，就不再讲了。
“这是一个夜晚天上宿星点点，我在梦里看见我的妈妈。”
继 “那是” 之后，此处出现了 “这是”。表示已经是事后，灾难之后。
“一个人在世上要学会坚强”，很明显，这不是儿子对父母能够说出的话。
结合前一小句 “我在梦里看见我的妈妈”，可以发现，这是妈妈对儿子说的话。并且还是死去之后的妈妈对儿子所说的话。
“我在梦里看见我的妈妈。一个人在世上要学会坚强” 紧接着的两句，主语变了。前一句是 “我”，后一句是 “妈妈”。同时，又因为死去的人继续说话这一违反科学常理的设定，使得后一句主语 “妈妈” 变得有些难以理解。
其实，受众的心，也是强大的。多听两遍，也还是能够理解的。
这两句主语的变化，从玄学的角度看，简单。但从文学的角度看，跳跃就非常大了。
唐 / 李白有句：“千里江陵一日还”。“千里江陵” 说的是千里之外的江陵。站在什么地方能够说出此话，自然是白帝城。“还”，指回来，站在什么地方能够说 “还”，当然只能是江陵。就这么一句，视角就从白帝城跳到了江陵。
《天亮了》中，这两句紧挨着的歌词的主语跳跃，其实跟 “千里江陵一日还” 的视角跳跃，是相似的类型。
“你不要离开不要伤害” 上一段出现过，就不讲了。
“我看到爸爸妈妈就这么走远，留下我在这陌生的人世间。我愿为他建造一个美丽的花园。”
比较上一段，区别的，是第三小句。此处的第三小句，从陈述中跳脱出来了，相当于插入了一个事后的心愿。
“我想要紧紧抓住他的手。妈妈告诉我希望还会有，看到太阳出来、天亮了。”
比较上一段，区别的仍然是第三小句。“妈妈笑了” 变成 “天亮了”。但此处的 “天亮了”，跟前面不一样，并不是起承转合的合，不是收尾，而就是一个简单的陈述，其实质，就相当于 “妈妈笑了”。
“我看到爸爸妈妈就这么走远，留下我在这陌生的人世间。我愿为他建造一个美丽的花园。
“我想要紧紧抓住他的手。妈妈告诉我希望还会有。看到太阳出来，他们笑了。”
重复，强调，加倍。略有不同的，就是 “妈妈笑了” 变成 “他们笑了”。由 “妈妈” 变成 “他们”，实际上也在告诉受众，马上就要收尾了。
以什么收尾，收到哪里呢？依然还是 “天亮了”，尽在不言中，让受众自己去想，
不知道是哪年哪天了，无意中，我就这么偶然听到了这首歌。
一听，就感受很好听。
一听，就听出来了，里面讲述了一场事故。因为有 “我听到一声巨响震彻山谷”、“再看不到爸爸的脸”。
另外，还听出了事故中，父母对孩子的救助。因为有 “他用他的双肩托起我重生的起点”。
很明显，事故是悲惨的，事故中的父母是可歌可泣的，事故之后的儿子或女儿（从歌词中听不出孩子的性别）是可怜的。
但是，就这么算了么？
这么好听的歌，最后一句 “天亮了” 到底表述的是怎样的感情？
没弄清楚，怎么能算完。
生活中，有各种各样的事故。最常见的，恐怕应该是车祸。
车祸事故，几乎每天都能够在地方新闻上看到。
看到车祸事故的新闻，心中有什么感受？
悲伤么？自然没有。
一般来说，亲人，才会悲伤。陌生人，通常只是略带同情、怜悯。
此处说的是，同样的事，因为自身角度的不同，感受大不相同。
那么，《天亮了》应该站在什么样的角度去欣赏呢？
最容易想到的角度，有两个。
一是生还的儿子或女儿。但是，站在这个角度欣赏，“我看到爸爸妈妈就这么走远，留下我在这陌生的人世间，不知道未来还会有什么风险。” 真的弱爆了。
另一个角度，则是富有同情心的旁观善良人士。这个角度的存在，是因为韩红。因为，就这么看过去，韩红，对于此次事故，似乎就是富有同情心的旁观善良人士。
但这个角度还是不行。“黑暗中泪水沾满了双眼”，没什么感觉。
于是乎，就剩下了不常见的角度 —— 死去父母的角度！
我试着想象了这样的角度，再听《天亮了》，眼泪一下子就出来了。
我是在这之后，才搜索得知了《天亮了》的创作背景。
是的，韩红，把自己当作那个孩子的父母，并且还把自己当作了孩子死去的父母。《天亮了》这首歌，表达的是死者对生者的寄托！
重新再看歌词。“黑暗中泪水沾满了双眼”，所指的，就不仅仅是事后孩子多次在被窝里痛哭，并且还指死去的父母在地狱中带泪含悲。
“不要离开”，只是孩子对父母的呼唤么？已然不是。以父母为参照物，生存的孩子，又何尝不是一种离开。
当然不是说想要孩子一起死，否则就不会用双肩托起重生的起点了。
“不要伤害” 的答案，此时就出来了。那就是死去的父母发出的呐喊。呐喊的对象是天地 —— 老天爷，不要伤害我们的孩子！
“一个人在世上要学会坚强” 不再是父母对自己的叮嘱，而是自己，对自己幸存的子女的叮嘱。
于是乎，最后一句合中的 “天亮了”，就表达了深深的无奈。
天亮了，通常指清晨，代表的是希望。但是，对于死者来说，天亮了，就代表魂魄状态的死者必须离开。
这是自然规律，死者必须离开。不想离开，也必须离开。因为 —— 天亮了。
难怪韩红唱这三个字的时候，泣不成声。
题外话又冒出来了。
我曾经进行过无数次评论。有那么一个人，曾经对于我的少部分评论非常不服。那就是，关于李白的诗的评论。
他认为，一件事物，可以从好坏两方面去说。他认为，李白的诗，就像打油诗，水平并不高。只是因为我的评论，才变得水平绝高了。
具体的说法就是，我先假定李诗水平绝高，然后往去往绝高的方向分析。
我的确也是这样做的。
但是，别人的诗，也可以假定为水平绝高啊，难道说真的就能分析出水平绝高来吗？
譬如杜甫的 “三顾频烦天下计”。“顾频烦” 三字的 “页” 旁，看不见吗？不擅书法，才会视而不见，所以杜甫不擅书法。是 “频烦天下计” 么？明明就只烦了一次。次数相对较多的，反而是 “顾”，顾了三次。于是这句应该读成 “三顾频、烦天下计”。这水平还怎么绝高呢？
相似的例子还有很多。无论是谁的作品，都能事先假定为水平绝高。但只有李白的诗，才会真的分析出水平绝高的答案出来。
所以，李诗的水平，是真的绝高。
这番题外话，表达的是，前面关于《天亮了》的评论，或许韩红自己并没那么想，或者韩红没想那么多，或许《天亮了》就仅仅是韩红的偶然之得。
我要说的是，《天亮了》既然已经成为作品，那么它就脱离了作者韩红，变成了一种独立的存在。不能因为韩红的文学水平不够高，而去否认《天亮了》的文学成就。
我的确是抱着欣赏的态度，先假定《天亮了》文学水平很高，然后真往极高文学水平的方向去分析的。但是很幸运，我得出了《天亮了》文学水平果然很高的结论。
换首别的歌，行吗？
谁说行，谁上。
最后，我还要说的是，文学水平，所指的，并不仅仅是文字方面的能力。
在打基础的时候，在斟酌字词句，在训练表达力、说服力的阶段，的确单指文字方面。
但是，在跨入感染力阶段之后，就不是了。
更多的，是提高心性。
心性高了，视角就不同了，感受也随之不同了，不管是写出来的作品，还是唱出来的歌，那都是不同的。
很多人说邓丽君的演唱水平并不高，那是不对的。应该说，邓丽君的演唱水平，其实很多人都达到过。个别的，譬如韩红，偶尔还超越过。
但是，为什么邓丽君流传下来的歌曲就那么多呢？其他歌者流传下来的歌就那么少呢？
就是因为心性。
心性与感染力关系，最容易明白的例子，就是翻唱。
《何日君在来》、《船歌》在邓丽君翻唱之前，并不好听，结果邓丽君一唱，就化腐朽为神奇了。
恰好，韩红也有过化腐朽为神奇的表现，譬如《妹妹找哥泪花流》、《天之大》（可搜）。
心性如此之高的韩红，偶得《天亮了》极高文学水准的作品，就是正常的了。
（全文完）
]]></content>
      <categories>
        <category>music</category>
      </categories>
      <tags>
        <tag>music</tag>
        <tag>韩红</tag>
      </tags>
  </entry>
  <entry>
    <title>解决 Thinkpad 笔记本喇叭破音问题！</title>
    <url>/posts/c945eae1/</url>
    <content><![CDATA[问题
主力笔记本笔记本播放音乐再次出现破音，换了几首音乐后问题依旧，前后对比强烈。
分析
从几年前上一次维修经验来看，应该是喇叭老化破裂了！拆机查看，发现的确事喇叭破裂。
解决方案
如是，网购了一个新喇叭，拆机，换上，完美解决问题！
喇叭施压后，能明显看到断裂痕迹。这样的喇叭音色就会出现明显的破音！如下图所示。



这已经是这台笔记本第二次出现喇叭破裂问题了！  感觉喇叭材料或者工艺有问题。
型号：Thinkpad T4X0S

]]></content>
      <categories>
        <category>notebook</category>
      </categories>
      <tags>
        <tag>thinkpad</tag>
        <tag>sound</tag>
        <tag>speaker</tag>
      </tags>
  </entry>
  <entry>
    <title>http 错误代码表</title>
    <url>/posts/80906b88/</url>
    <content><![CDATA[所有 HTTP 状态代码及其定义。
　代码&nbsp;&nbsp;指示&nbsp;&nbsp;
2xx&nbsp;&nbsp;成功&nbsp;&nbsp;
200&nbsp;&nbsp;正常；请求已完成。&nbsp;&nbsp;
201&nbsp;&nbsp;正常；紧接 POST 命令。&nbsp;&nbsp;
202&nbsp;&nbsp;正常；已接受用于处理，但处理尚未完成。&nbsp;&nbsp;
203&nbsp;&nbsp;正常；部分信息 — 返回的信息只是一部分。&nbsp;&nbsp;
204&nbsp;&nbsp;正常；无响应 — 已接收请求，但不存在要回送的信息。&nbsp;&nbsp;
3xx&nbsp;&nbsp;重定向&nbsp;&nbsp;
301&nbsp;&nbsp;已移动 — 请求的数据具有新的位置且更改是永久的。&nbsp;&nbsp;
302&nbsp;&nbsp;已找到 — 请求的数据临时具有不同 URI。&nbsp;&nbsp;
303&nbsp;&nbsp;请参阅其它 — 可在另一 URI 下找到对请求的响应，且应使用 GET 方法检索此响应。&nbsp;&nbsp;
304&nbsp;&nbsp;未修改 — 未按预期修改文档。&nbsp;&nbsp;
305&nbsp;&nbsp;使用代理 — 必须通过位置字段中提供的代理来访问请求的资源。&nbsp;&nbsp;
306&nbsp;&nbsp;未使用 — 不再使用；保留此代码以便将来使用。&nbsp;&nbsp;
4xx&nbsp;&nbsp;客户机中出现的错误&nbsp;&nbsp;
400&nbsp;&nbsp;错误请求 — 请求中有语法问题，或不能满足请求。&nbsp;&nbsp;
401&nbsp;&nbsp;未授权 — 未授权客户机访问数据。&nbsp;&nbsp;
402&nbsp;&nbsp;需要付款 — 表示计费系统已有效。&nbsp;&nbsp;
403&nbsp;&nbsp;禁止 — 即使有授权也不需要访问。&nbsp;&nbsp;
404&nbsp;&nbsp;找不到 — 服务器找不到给定的资源；文档不存在。&nbsp;&nbsp;
407&nbsp;&nbsp;代理认证请求 — 客户机首先必须使用代理认证自身。&nbsp;&nbsp;
415&nbsp;&nbsp;介质类型不受支持 — 服务器拒绝服务请求，因为不支持请求实体的格式。&nbsp;&nbsp;
5xx&nbsp;&nbsp;服务器中出现的错误&nbsp;&nbsp;
500&nbsp;&nbsp;内部错误 — 因为意外情况，服务器不能完成请求。&nbsp;&nbsp;
501&nbsp;&nbsp;未执行 — 服务器不支持请求的工具。&nbsp;&nbsp;
502&nbsp;&nbsp;错误网关 — 服务器接收到来自上游服务器的无效响应。&nbsp;&nbsp;
503&nbsp;&nbsp;无法获得服务 — 由于临时过载或维护，服务器无法处理请求。

HTTP&nbsp;400&nbsp;-&nbsp;请求无效&nbsp;
HTTP&nbsp;401.1&nbsp;-&nbsp;未授权：登录失败&nbsp;
HTTP&nbsp;401.2&nbsp;-&nbsp;未授权：服务器配置问题导致登录失败&nbsp;
HTTP&nbsp;401.3&nbsp;-&nbsp;ACL&nbsp;禁止访问资源&nbsp;
HTTP&nbsp;401.4&nbsp;-&nbsp;未授权：授权被筛选器拒绝&nbsp;
HTTP&nbsp;401.5&nbsp;-&nbsp;未授权：ISAPI&nbsp;或&nbsp;CGI&nbsp;授权失败&nbsp;&nbsp;
HTTP&nbsp;403&nbsp;-&nbsp;禁止访问&nbsp;
HTTP&nbsp;403&nbsp;-&nbsp;对&nbsp;Internet&nbsp;服务管理器&nbsp;(HTML)&nbsp;的访问仅限于&nbsp;Localhost&nbsp;
HTTP&nbsp;403.1&nbsp;禁止访问：禁止可执行访问&nbsp;
HTTP&nbsp;403.2&nbsp;-&nbsp;禁止访问：禁止读访问&nbsp;
HTTP&nbsp;403.3&nbsp;-&nbsp;禁止访问：禁止写访问&nbsp;
HTTP&nbsp;403.4&nbsp;-&nbsp;禁止访问：要求&nbsp;SSL&nbsp;
HTTP&nbsp;403.5&nbsp;-&nbsp;禁止访问：要求&nbsp;SSL&nbsp;128&nbsp;
HTTP&nbsp;403.6&nbsp;-&nbsp;禁止访问：IP&nbsp;地址被拒绝&nbsp;
HTTP&nbsp;403.7&nbsp;-&nbsp;禁止访问：要求客户证书&nbsp;
HTTP&nbsp;403.8&nbsp;-&nbsp;禁止访问：禁止站点访问&nbsp;
HTTP&nbsp;403.9&nbsp;-&nbsp;禁止访问：连接的用户过多&nbsp;
HTTP&nbsp;403.10&nbsp;-&nbsp;禁止访问：配置无效&nbsp;
HTTP&nbsp;403.11&nbsp;-&nbsp;禁止访问：密码更改&nbsp;
HTTP&nbsp;403.12&nbsp;-&nbsp;禁止访问：映射器拒绝访问&nbsp;
HTTP&nbsp;403.13&nbsp;-&nbsp;禁止访问：客户证书已被吊销&nbsp;
HTTP&nbsp;403.15&nbsp;-&nbsp;禁止访问：客户访问许可过多&nbsp;
HTTP&nbsp;403.16&nbsp;-&nbsp;禁止访问：客户证书不可信或者无效&nbsp;
HTTP&nbsp;403.17&nbsp;-&nbsp;禁止访问：客户证书已经到期或者尚未生效&nbsp;
HTTP&nbsp;404.1&nbsp;-&nbsp;无法找到&nbsp;Web&nbsp;站点&nbsp;
HTTP&nbsp;404&nbsp;-&nbsp;无法找到文件&nbsp;
HTTP&nbsp;405&nbsp;-&nbsp;资源被禁止&nbsp;
HTTP&nbsp;406&nbsp;-&nbsp;无法接受&nbsp;
HTTP&nbsp;407&nbsp;-&nbsp;要求代理身份验证&nbsp;
HTTP&nbsp;410&nbsp;-&nbsp;永远不可用&nbsp;
HTTP&nbsp;412&nbsp;-&nbsp;先决条件失败&nbsp;
HTTP&nbsp;414&nbsp;-&nbsp;请求&nbsp;-&nbsp;URI&nbsp;太长&nbsp;
HTTP&nbsp;500&nbsp;-&nbsp;内部服务器错误&nbsp;
HTTP&nbsp;500.100&nbsp;-&nbsp;内部服务器错误&nbsp;-&nbsp;ASP&nbsp;错误&nbsp;
HTTP&nbsp;500-11&nbsp;服务器关闭&nbsp;
HTTP&nbsp;500-12&nbsp;应用程序重新启动&nbsp;
HTTP&nbsp;500-13&nbsp;-&nbsp;服务器太忙&nbsp;
HTTP&nbsp;500-14&nbsp;-&nbsp;应用程序无效&nbsp;
HTTP&nbsp;500-15&nbsp;-&nbsp;不允许请求&nbsp;global.asa&nbsp;
Error&nbsp;501&nbsp;-&nbsp;未实现&nbsp;
HTTP&nbsp;502&nbsp;-&nbsp;网关错误
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用 media Go,MusicBrainz,Mp3tag 工具刮削音乐 整理音乐资料库</title>
    <url>/posts/3847ad58/</url>
    <content><![CDATA[背景
动画、电影、剧集可使用 TinyMediaManager 生成 nfo 元数据文件，多媒体软件解析生成海报墙展示丰富的影片信息。
而音乐文件则是将歌名、歌手、专辑、发行时间、歌词、封面图等信息写入文件标签，称为 ID3 Tag 。桌面软件、多媒体管理软件（Foobar2000/Plex/Emby/Jellyfin 等）都能解析展现歌曲信息。ID3 标签是 MP3 音乐档案中的歌曲附加讯息，它能够在 MP3 中附加曲子的演出者、作者以及其它类别资讯，方便众多乐曲的管理。缺少 ID3 标签并不会影响 MP3 的播放，但若没有的话，管理音乐文件也会相当的麻烦。
刮削效果
Foobar2000 读取效果：

Jellyfin 读取效果：

Mp3tag

纯手工修改，开源工具。


Media Go

不要使用最新版！老版本才有我们最需要的功能。


添加媒体库


自动获取属性

歌曲属性修改

MusicBrainz


MusicBrainz 官网：https://musicbrainz.org/
MusicBrainz Picard 下载地址：https://picard.musicbrainz.org/



MusicBrainz Picard 可以修改音乐的 Tag 标签信息，根据标签重命名文件。它的数据来源于非营利互联网音乐专辑数据库 MusicBrainz 项目，歌曲资源非常丰富。尤其它能根据声纹（音频指纹）识别 Mp3 文件进行匹配取信息，匹配率极高。不管是英文、中文歌曲，还是录音室版本、演唱会版本，都能很好地匹配出来。
支持 MP3、FLAC、OGG、M4A、WMA、WAV 等主流的音频格式，wav,ape 格式不支持，需要要转换成支持的格式。
写入前后对比：

MusicBrainz Picard 使用教程：
将音乐文件 / 文件夹拖入左侧窗口，点上方 “查询 “按钮，在 MusicBrainz 数据库里搜索对应音乐。

如果搜索不到，点击” 扫描 “，使用声纹匹配，准确度更高。

如果以上两种方法都搜索不到，或者添加的文件名变成乱码，右击” 查找相似的音轨 “

手动输入歌曲名字，搜索，选择正确的歌曲信息，载入 Picard。

右侧窗口载入专辑信息。展开列表，绿色方块的就是匹配成功的音乐。底部窗口展示文件原始标签信息和 MusicBrainz 网站上的信息对照。

如果匹配的不是正确的专辑信息，右击” 查找相似的音轨 “，选择正确的专辑信息载入 Picard。
如果搜索出了多张专辑，可点击错误的专辑拖动到目标专辑上完成匹配，省的一个一个文件的修改。

最后点 “保存”，将标签信息写入音乐文件。

如何重命名文件：
菜单栏 - 选项 - 勾选 “重命名文件”，保存的时候会同时写入信息 + 重命名。

默认设置是：序号 歌名.mp3，适合一个专辑一个文件夹使用。
如果是单文件的话要去创建命名规则，选项 - 正在重命名文件 - 保存时重命名文件，填写命名规则。

参考：

使用 MusicBrainz Picard 刮削音乐 整理音乐资料库

]]></content>
      <categories>
        <category>music</category>
      </categories>
      <tags>
        <tag>music</tag>
        <tag>刮削</tag>
        <tag>MusicBrainz</tag>
        <tag>mp3tag</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用 tinyMediaManager 刮削电影和电视剧，动画，并自动下载字幕</title>
    <url>/posts/e6d40157/</url>
    <content><![CDATA[
注意使用 V3 版本，V4 版本收费！
所以升级 V3 版本即可，不要升级到 V4 版本！不要升级到 V4 版本！不要升级到 V4 版本！


Plex 是一款很好用的个人媒体中心软件，但是因为国内网络的原因，使用默认的 TMDB 刮削器挂出来的效果并不好，要么就是影片信息不正确，要么就是海报不正常显示，实在让人头疼。
tinyMediaManager 是一款电影信息刮削和整理的软件，正好可以和 plex 配合，完美的解决这一问题。tinyMediaManager 在刮削影片的过程中会把影片的海报、演员表、背景图片等等都保存到影片所在文件夹，自动生成电影的 nfo 信息文件，并对文件和文件夹进行重新命名的操作。在 plex 设置刮削代理的时候，需要用一款插件可以直接读取 nfo 的信息，完成刮削，下面把使用方法分享给大家，

下载和安装 tinyMediaManager
官网下载地址：https://www.tinymediamanager.org/download/

tmm 下载
下载后直接解压文件夹
客户端需要 java 支持，先在电脑安装 java
客户端下载后是一个压缩包，解压之后就可以用

解压之后打开 tinyMediaManager.exe

TMM 设置
TMM 代理设置

重要：很多源都需要代理才能访问。这里正确的配置才能正确的刮削！
可以调整这里使用的内存，大内存可以极大加速刮削速度。


电影刮削设置
进行相关设置。Tmm 可以对电影和电视剧的刮削进行分别设置，打开设置后选择电影选项，可以选择分级标准、自动重命名等选项。

电影信息选项
点击侧边栏媒体库目录，添加电影目录
刮削器设置

选择电影刮削器

刮削器选项

nfo 选项，建议选择生成两种命名放视的 nfo
图片刮削器选择全选，图片文件名建议两边都选上，会分别生成两组命名格式不同的图片，为了保证 plex 能读取

图片命名选项
Tmm 还可以自动下载预告片，字幕。字幕下载时可以输入 opensubtitles 账户

字幕下载选项
重命名规则
这里重点讲一下重命名规则，刮削完后可以选择对电影文件和文件夹进行重命名，可能对于 pt 用户重命名可能会影响资源上传，可以不进行重命名操作。
一般情况下电影刮削出来的信息，title 是电影的中文标题名称，originaltitle 是电影的原标题名称，一般是英文名称。软件默认的设置是文件和文件夹都命名成 title，也就是中文标题，但是我发现这样在后期使用的时候有弊端。英文电影在检索字幕时会用文件名来检索，而用中文名称很多情况下检索不出来，所以这里把文件的命名规则改一下，改成 originaltitle，并去掉年份信息的括号，中间连接符改成点，文件名设置成{- ,edition,}.{videoFormat}.${audioCodec} 的格式。

电影文件重命名选项

刮削完的文件夹内文件信息

刮削完的电影文件夹目录
电视节目刮削设置类似，如果挂不出来可以用 the tvdb 来刮削。
tmm 有时候会出现网络不稳定，刮不到的情况，可以修改 host 解决
改 host 在 host 文件最后加一行 13.224.161.90 http://api.themoviedb.org
退出设置，开始刮削

更新电影源

选中要刮削的电影自动匹配
电影手动刮削


电视剧 &amp; 动画手动刮削
电视剧元数据刮削


季和集元数据刮削前整理

刮削季元素
整理好正确的季和集之后，才能正确的刮削季元素

TMM 整理完效果

这里用海贼王做展示，一个季和集都特别多的剧。


TMM 目录重命名整理

刮削完后，可以重命名视频文件，并进行目录整理。

方法 1

方法 2

等所有电影的信息刮削完后，选择重命名和清理，这样就完成了刮削的操作。以后下载了新电影，直接打开 tmm, 更新源之后直接选择搜索未刮削过的电影完成刮削。刮削出来的信息 kodi，emby 等软件也都能用。
Plex 设置
plex 插件的安装和设置
下载 plex 的插件
插件 XBMCnfoMoviesImporter 和 XBMCnfoTVImporter 分别是刮削电影和电视剧的插件
下载地址：https://github.com/gboudreau/XBMCnfoMoviesImporter.bundle
如果不能下载的话可以联系我获取，还有几个很好用的 plex 插件
下载完插件后就需要把插件解压到 plex 的插件目录：C:\Users\ 用户名 \AppData\Local\Plex Media Server\Plug-ins

plex 插件目录
注意解压后要把文件夹名后边的 master 去掉。
plex 代理设置
Plex 的代理设置就是选择刮削电影所用的刮削器及优先级。
装好插件后重启 plex，进行 plex 的设置。在代理设置中选择 XBMCnfoMoviesImporter，把它的优先级调到最高，第二个可以设置成字幕插件。

设置电影资料库的刮削器代理
点击设置界面下方管理里边的资料库，选择电影资料夹的高级设置，设置如下


plex 代理设置

刷新电影源数据资料
设置完成后就可以在 plex 主页对电影文件夹刷新元数据了。等待刷新完后就可以载入所有的电影信息了。

管理资料库 - 刷新电影元数据

更新后的电影信息
采用类似的设置，电视剧信息也能刮削。

电视剧更新后的信息
Emby 设置

Emby 内置刮削工具，但是速度较慢。下面设置基于外部刮削工具 TMM，所以没有勾选 Emby 刮削源！

最终效果演示


开始设置

新增媒体库

已有媒体库属性设置





Emby 字幕设置
字幕下载设置，字幕下载工具见后面的 [字幕下载] 章节

字幕下载
想要较好的自动下载字幕，最好用前面介绍的 tmm 刮削改名之后再使用下面工具。
subfinder 自动下载字幕

Docker： superng6/subfinder

下载完成，刮削后的目录，挂载到 subfinder 的 media 目录，就会自动下载字幕。
字幕下载对电影，英文剧集支持较好。对于一些 tv，动画手动下载字幕会更好一些。
注意：官方的配置文件有问题，时效问题。修改 URL 到最新即可。
chinesesubfinder

Docker： allanpk716/chinesesubfinder
 新开发的中文字幕查找工具，上面那个很久没更新了，这个刚出来。使用 nfo 里面刮削出来的文件名来匹配字幕。所以就原理来说，这个字幕匹配更准确。

bazarr

Docker：linuxserver/bazarr
 字幕下载管理，配合 sonarr, radarr 使用效果更好。对于英文剧集命名规范的支持较好，比如 [name]S01E01

参考

利用 tinyMediaManager 刮削影片，解决家用 nas 软件 plex 电影墙的问题

]]></content>
      <categories>
        <category>video</category>
      </categories>
      <tags>
        <tag>刮削</tag>
        <tag>tmm</tag>
        <tag>字幕</tag>
        <tag>emby</tag>
        <tag>plex</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 IPV6 访问 Qnap NAS 中 Docker 的服务</title>
    <url>/posts/462f1e5c/</url>
    <content><![CDATA[环境
系统：QTS 4.3.6
网络：IPV4 &amp; IPV6
Docker: 由 Container Station 提供
问题
通过 ipv6 地址可以打开 NAS 的管理页面，但是无法访问 Docker 对应端口的服务。
排查
QTS 中 Docker 使用的虚拟交换机网络没有启动 IPV6，且无法在虚拟交换机设置中手动启动。
这样一来，Docker 只监听了 tcp4 的端口，对于主机上 tcp6 的端口的访问无法映射到 docker 容器上。
解决方案
在主机上开一个 tcp6 的端口，将其转发到主机上与 docker 关联的 tcp4 端口。
即：
docker(tcp4)–&gt;host(tcp4)–&gt;host(tcp6)

在 qts 上安装包管理器：Entware. https://github.com/Entware/Entware/wiki/Install-on-QNAP-NAS
 执行 opkg update, 更新
安装端口转发工具，这里使用 socat：opkg install socat
 设置转发 host (tcp6)–&gt;host (tcp4):(socat TCP6-LISTEN:6880,reuseaddr,fork TCP4:127.0.0.1:7880 &amp;)
 大功告成

]]></content>
      <categories>
        <category>nas</category>
      </categories>
      <tags>
        <tag>nas</tag>
        <tag>docker</tag>
        <tag>qnap</tag>
        <tag>ipv6</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake 快速入门教程</title>
    <url>/posts/495db4d3/</url>
    <content><![CDATA[1.cmake 简介
cmake 是跨平台的 makefile 文件生成工具，是为了解决各个平台下面 make 工具不同造成的 makefile 文件格式不同的问题。也就是 cmake 是用来解决跨平台编译问题的。常见的还有 autotool 工具集，该工具集用于 GNU 软件协议的 makefile 文件生成，方便 GNU 包的编译和安装。
2.cmake 文件编辑规则

1) 命令不区分大小写，但是变量区分大小写。
2) 注释使用 #符号
 3) 命令如果有多个参数，互相之间用空格隔开

3.cmake 保留变量
cmake 里面有很多的预定义变量，是程序环境固有的，比如 CUDA_NVCC_FLAGS, 不同的变量有固定的作用，比如 CUDA_NVCC_FLAGS 是 nvcc 的参数 list, 变量可以使用 set 命令和 list 命令进行赋值和追加值，要注意的是变量可能可以有多个值，值与值之间用分号分开，可以使用 set (var a b c) 给 var 赋值 a b c, 还可以使用 list 命令给 var 追加删除插入值等，不同的变量有不同的值域，需要查阅手册
4.cmake 变量引用
cmake 里面变量的取值引用要使用 ${var} 的形式，但是在赋值的时候是不需要的，和 shell 命令有点相似.
5.cmake 指定 Debug 和 Release 版本
指定 Debug 和 Release 一共有三种方法：
1. 使用 ADD_COMPILE_OPTIONS () 加入 - g 指定 Debug 版本.
2. 使用 SET (CMAKE_BUILD_TYPE Debug/Rrelease) 指定 Debug
在下面加入：
SET(CMAKE_CXX_FLAGS_DEBUG "$ENV{CXXFLAGS} -O0 -Wall -g2 -ggdb")
SET(CMAKE_CXX_FLAGS_RELEASE "$ENV{CXXFLAGS} -O3 -Wall")
上面的设置 C++ 编译选项，对于 C 语言，设置 CMAKE_C_FLAGS_DEBUG、CMAKE_._FLAGS_RELEASE 变量，一般来说最好两个都设置原因是 CMake 中有一个变量 CMAKE_BUILD_TYPE , 可以的取值是 Debug Release 等。当这个变量值为 Debug 的时候，CMake 会使用变量 CMAKE_CXX_FLAGS_DEBUG 和 CMAKE_C_FLAGS_DEBUG 中的字符串作为编译选项生成 Makefile
编译动态库 or 静态库时，最好通过修改 CXXFLAGS 和 CFLAGS，以支持 - fPIC，这个选项有时是默认开启，有时默认关闭，但为了以后的应用，库文件最好都使用 - fPIC 编译

在使用 cmake 命令时加上 - DCMAKE_BUILD_TYPE=Debug/Release

5.cmake 指定生成文件
CUDA_ADD_LIBRARY () 指明目标文件是库文件，CUDA_ADD_EXECUTABLE () 指明生成的文件为可执行文件
6. 配置模板
通常我们要在工程目录下面创建 include、src 文件夹，include 文件夹里面存放头文件，src 文件夹里面存放源代码，注意这时候的源代码里面包含头文件的路径应该是 “../include/xx.h”，然后在工程根目录下面创建 CMakeLists.txt 文件，里面写入命令。在编译的时候为了不搞乱工程目录，在工程根目录下面创建 build 文件夹，在里面使用 “cmake ..” 命令创建 CMakefile, 再 make 即可。
#指定cmake最低版本号
cmake_minimum_required(VERSION 3.2)

#指定项目名称
PROJECT(Liner_Struct)

#指定头文件目录，不同目录用空格隔开,目录中有空格可用引号
#如果是相对路径，相对于CMakeLists.txt文件
INCLUDE_DIRECTORIES(include)

#指定源文件目录，DIR_SRCS值自定义变量，下面的命令对其进行了赋值
AUX_SOURCE_DIRECTORY(src DIR_SRCS)

#设置变量用于存放所有的编译文件，
#TEST_LINER_STRUCT是自定义变量，使用SET给其赋值
SET(TEST_LINER_STRUCT ${DIR_SRCS})

#增加编译选项
#判断是否为gcc编译器，如果是，增加编译选项
#c99是c语言的标准，常用的还有c++标准c++11
#下面的命令判断是否编译器是gcc
#message命令是输出信息,例如下面的输出“optional:-std=c99”
if(CMAKE_COMPILER_IS_GNUCXX)
    ADD_COMPILE_OPTIONS(-std=c99)
    message(STATUS "optional:-std=c99")
endif(CMAKE_COMPILER_IS_GNUCXX)

#配置生成文件
#${PROJECT_NAME}是cmake自带变量，其值和PROJECT()命令指定的一样
#${TEST_LINER_STRUCT}是自定义变量，上文赋值的
ADD_EXECUTABLE(${PROJECT_NAME} ${TEST_LINER_STRUCT})
7.if-else 语句
cmake 中的 if-else 语句
if(exp)
     cmdA
     cmdB
elseif(exp)
      cmdC
endif(exp)
最简单得到一个应用
if(ARM)
   #ARM平台
else()
  #非ARM平台 
endif()
使用 cmake -DARM=1 .. 时编译 ARM 代码，使用 cmake -DAMR=0 .. 编译非 ARM 代码
8. 与平台编译器的结合
8.1windows
在 windows 上运行 cmake 可以生成对应的 VS 的工程文件，然后使用相应的 VS 打开工程就可以进行编译。要注意的是如果使用 VS2010 及其以前的版本，C 不支持 C99，也就是变量的命名必须放在函数或者域的最前面，不能放在中间，特别麻烦。VS2015 在安装后可能还需要打开 VS，新建工程时选择 VC 可能相关组件还没有安装，如果这时候使用 cmake 会提示找不到 C、C 编译器（类似 yuNo CMAKE_CXX_COMPILER could be found）的错误。安装了相关的组件后 cmake 即不会有错误。
8.2 为 VS2015 生成的项目
打开工程文件后可以看到有 3 个项目，其中只有一个和我们有直接关系，就是我们在 CMakeLists.txt 里面定义的 PROJECT_NAME, 剩下的两个是 ALL_BUILD 和 ZERO_CHECK.
ZERO_CHECK
该目标会检查生成工程的 CMake 配置文件（ CMakeLists.txt ）是否更新。如更新，将运行 CMake 重新生成工程文件。
如果确信 CMakeLists.txt 不会被更新，或者希望手工运行 CMake 重新生成工程文件，可以在 CMakeLists.txt 配置文件中添加 set (CMAKE_SUPPRESS_REGENERATION FALSE) 命令， ZERO_CHECK 目标将不会生成。
ALL_BUILD
该目标会导致工程中所有项目被构建，类似 Visual Studio 的 Build All 或者 make 的 make all 命令。
转载 CMake 快速入门教程
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cmake</tag>
        <tag>develop</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用 Traefik V2 在 Ubuntu20.04 上面来做 Dockers Containers 的反向代理</title>
    <url>/posts/465d2738/</url>
    <content><![CDATA[How To Use Traefik v2 as a Reverse Proxy for Docker Containers on Ubuntu 20.04

Traefik 适合配合 Dockers swarm 做服务， Dockers portainer 做管理，ELK 集群做监控日志。


traefik 与 nginx 一样，是一款优秀的反向代理工具，或者叫 Edge Router。至于使用它的原因则基于以下几点

无须重启即可更新配置
自动的服务发现与负载均衡
与 docker 完美集成，基于 container label 的配置
漂亮的 dashboard 界面
metrics 的支持，支持对 prometheus 和 k8s 集成

Introduction
Docker can be an efficient way to run web applications in production, but you may want to run multiple applications on the same Docker host. In this situation, you’ll need to set up a reverse proxy. This is because you only want to expose ports 80 and 443 to the rest of the world.
Traefik is a Docker-aware reverse proxy that includes a monitoring dashboard. Traefik v1 has been widely used for a while, and you can follow this earlier tutorial to install Traefik v1). But in this tutorial, you’ll install and configure Traefik v2, which includes quite a few differences.
The biggest difference between Traefik v1 and v2 is that frontends and backends were removed and their combined functionality spread out across routers, middlewares, and services. Previously a backend did the job of making modifications to requests and getting that request to whatever was supposed to handle it. Traefik v2 provides more separation of concerns by introducing middlewares that can modify requests before sending them to a service. Middlewares make it easier to specify a single modification step that might be used by a lot of different routes so that they can be reused (such as HTTP Basic Auth, which you’ll see later). A router can also use many different middlewares.
In this tutorial you’ll configure Traefik v2 to route requests to two different web application containers: a Wordpress container and an Adminer container, each talking to a MySQL database. You’ll configure Traefik to serve everything over HTTPS using Let’s Encrypt.
Prerequisites
To complete this tutorial, you will need the following:

One Ubuntu 20.04 server with a sudo non-root user and a firewall. You can set this up by following our Ubuntu 20.04 initial server setup guide.
Docker installed on your server, which you can accomplish by following Steps 1 and 2 of How to Install and Use Docker on Ubuntu 20.04.
Docker Compose installed using the instructions from Step 1 of How to Install Docker Compose on Ubuntu 20.04.
A domain and three A records, db-admin.your_domain, blog.your_domain and monitor.your_domain. Each should point to the IP address of your server. You can learn how to point domains to DigitalOcean Droplets by reading through DigitalOcean’s Domains and DNS documentation. Throughout this tutorial, substitute your domain for your_domain in the configuration files and examples.

Step 1 — Configuring and Running Traefik
The Traefik project has an official Docker image, so you will use that to run Traefik in a Docker container.
But before you get your Traefik container up and running, you need to create a configuration file and set up an encrypted password so you can access the monitoring dashboard.
You’ll use the htpasswd utility to create this encrypted password. First, install the utility, which is included in the apache2-utils package:
sudo apt-get install apache2-utils
Then generate the password with htpasswd. Substitute secure_password with the password you’d like to use for the Traefik admin user:
htpasswd -nb admin secure_password
The output from the program will look like this:
Outputadmin:$apr1$ruca84Hq$mbjdMZBAG.KWn7vfN/SNK/
You’ll use this output in the Traefik configuration file to set up HTTP Basic Authentication for the Traefik health check and monitoring dashboard. Copy the entire output line so you can paste it later.
To configure the Traefik server, you’ll create two new configuration files called traefik.toml and traefik_dynamic.toml using the TOML format. TOML is a configuration language similar to INI files, but standardized. These files let us configure the Traefik server and various integrations, or providers, that you want to use. In this tutorial, you will use three of Traefik’s available providers: api, docker, and acme. The last of these, acme, supports TLS certificates using Let’s Encrypt.
Create and open traefik.toml using nano or your preferred text editor:
nano traefik.toml
First, you want to specify the ports that Traefik should listen on using the entryPoints section of your config file. You want two because you want to listen on port 80 and 443. Let’s call these web (port 80) and websecure (port 443).
Add the following configurations:
traefik.toml
[entryPoints]
  [entryPoints.web]
    address = ":80"
    [entryPoints.web.http.redirections.entryPoint]
      to = "websecure"
      scheme = "https"

  [entryPoints.websecure]
    address = ":443"
Note that you are also automatically redirecting traffic to be handled over TLS.
Next, configure the Traefik api, which gives you access to both the API and your dashboard interface. The heading of [api] is all that you need because the dashboard is then enabled by default, but you’ll be explicit for the time being.
Add the following code:
traefik.toml
...
[api]
  dashboard = true
To finish securing your web requests you want to use Let’s Encrypt to generate valid TLS certificates. Traefik v2 supports Let’s Encrypt out of the box and you can configure it by creating a certificates resolver of the type acme.
Let’s configure your certificates resolver now using the name lets-encrypt:
traefik.toml
...
[certificatesResolvers.lets-encrypt.acme]
  email = "your_email@your_domain"
  storage = "acme.json"
  [certificatesResolvers.lets-encrypt.acme.tlsChallenge]
This section is called acme because ACME is the name of the protocol used to communicate with Let’s Encrypt to manage certificates. The Let’s Encrypt service requires registration with a valid email address, so to have Traefik generate certificates for your hosts, set the email key to your email address. You then specify that you will store the information that you will receive from Let’s Encrypt in a JSON file called acme.json.
The acme.tlsChallenge section allows us to specify how Let’s Encrypt can verify that the certificate. You’re configuring it to serve a file as part of the challenge over port 443.
Finally, you need to configure Traefik to work with Docker.
Add the following configurations:
traefik.toml
...
[providers.docker]
  watch = true
  network = "web"
The docker provider enables Traefik to act as a proxy in front of Docker containers. You’ve configured the provider to watch for new containers on the web network, which you’ll create soon.
Our final configuration uses the file provider. With Traefik v2, static and dynamic configurations can’t be mixed and matched. To get around this, you will use traefik.toml to define your static configurations and then keep your dynamic configurations in another file, which you will call traefik_dynamic.toml. Here you are using the file provider to tell Traefik that it should read in dynamic configurations from a different file.
Add the following file provider:
traefik.toml
[providers.file]
  filename = "traefik_dynamic.toml"
Your completed traefik.toml will look like this:
traefik.toml
[entryPoints]
  [entryPoints.web]
    address = ":80"
    [entryPoints.web.http.redirections.entryPoint]
      to = "websecure"
      scheme = "https"

  [entryPoints.websecure]
    address = ":443"

[api]
  dashboard = true

[certificatesResolvers.lets-encrypt.acme]
  email = "your_email@your_domain"
  storage = "acme.json"
  [certificatesResolvers.lets-encrypt.acme.tlsChallenge]

[providers.docker]
  watch = true
  network = "web"

[providers.file]
  filename = "traefik_dynamic.toml"
Save and close the file.
Now let’s create traefik_dynamic.toml.
The dynamic configuration values that you need to keep in their own file are the middlewares and the routers. To put your dashboard behind a password you need to customize the API’s router and configure a middleware to handle HTTP basic authentication. Let’s start by setting up the middleware.
The middleware is configured on a per-protocol basis and since you’re working with HTTP you’ll specify it as a section chained off of http.middlewares. Next comes the name of your middleware so that you can reference it later, followed by the type of middleware that it is, which will be basicAuth in this case. Let’s call your middleware simpleAuth.
Create and open a new file called traefik_dynamic.toml:
nano traefik_dynamic.toml
Add the following code. This is where you’ll paste the output from the htpasswd command:
traefik_dynamic.toml
[http.middlewares.simpleAuth.basicAuth]
  users = [
    "admin:$apr1$ruca84Hq$mbjdMZBAG.KWn7vfN/SNK/"
  ]
To configure the router for the api you’ll once again be chaining off of the protocol name, but instead of using http.middlewares, you’ll use http.routers followed by the name of the router. In this case, the api provides its own named router that you can configure by using the [http.routers.api] section. You’ll configure the domain that you plan on using with your dashboard also by setting the rule key using a host match, the entrypoint to use websecure, and the middlewares to include simpleAuth.
Add the following configurations:
traefik_dynamic.toml
...
[http.routers.api]
  rule = "Host(`monitor.your_domain`)"
  entrypoints = ["websecure"]
  middlewares = ["simpleAuth"]
  service = "api@internal"
  [http.routers.api.tls]
    certResolver = "lets-encrypt"
The web entry point handles port 80, while the websecure entry point uses port 443 for TLS/SSL. You automatically redirect all of the traffic on port 80 to the websecure entry point to force secure connections for all requests.
Notice the last three lines here configure a service, enable tls, and configure certResolver to "lets-encrypt". Services are the final step to determining where a request is finally handled. The api@internal service is a built-in service that sits behind the API that you expose. Just like routers and middlewares, services can be configured in this file, but you won’t need to do that to achieve your desired result.
Your completed traefik_dynamic.toml file will look like this:
traefik_dynamic.toml
[http.middlewares.simpleAuth.basicAuth]
  users = [
    "admin:$apr1$ruca84Hq$mbjdMZBAG.KWn7vfN/SNK/"
  ]

[http.routers.api]
  rule = "Host(`monitor.your_domain`)"
  entrypoints = ["websecure"]
  middlewares = ["simpleAuth"]
  service = "api@internal"
  [http.routers.api.tls]
    certResolver = "lets-encrypt"
Save the file and exit the editor.
With these configurations in place, you will now start Traefik.
Step 2 – Running the Traefik Container
In this step you will create a Docker network for the proxy to share with containers. You will then access the Traefik dashboard. The Docker network is necessary so that you can use it with applications that are run using Docker Compose.
Create a new Docker network called web:
docker network create web
When the Traefik container starts, you will add it to this network. Then you can add additional containers to this network later for Traefik to proxy to.
Next, create an empty file that will hold your Let’s Encrypt information. You’ll share this into the container so Traefik can use it:
touch acme.json
Traefik will only be able to use this file if the root user inside of the container has unique read and write access to it. To do this, lock down the permissions on acme.json so that only the owner of the file has read and write permission.
chmod 600 acme.json
Once the file gets passed to Docker, the owner will automatically change to the root user inside the container.
Finally, create the Traefik container with this command:
docker run -d \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v $PWD/traefik.toml:/traefik.toml \
  -v $PWD/traefik_dynamic.toml:/traefik_dynamic.toml \
  -v $PWD/acme.json:/acme.json \
  -p 80:80 \
  -p 443:443 \
  --network web \
  --name traefik \
  traefik:v2.2
This command is a little long. Let’s break it down.
You use the -d flag to run the container in the background as a daemon. You then share your docker.sock file into the container so that the Traefik process can listen for changes to containers. You also share the traefik.toml and traefik_dynamic.toml configuration files into the container, as well as acme.json.
Next, you map ports :80 and :443 of your Docker host to the same ports in the Traefik container so Traefik receives all HTTP and HTTPS traffic to the server.
You set the network of the container to web, and you name the container traefik.
Finally, you use the traefik:v2.2 image for this container so that you can guarantee that you’re not running a completely different version than this tutorial is written for.
A Docker image’s ENTRYPOINT is a command that always runs when a container is created from the image. In this case, the command is the traefik binary within the container. You can pass additional arguments to that command when you launch the container, but you’ve configured all of your settings in the traefik.toml file.
With the container started, you now have a dashboard you can access to see the health of your containers. You can also use this dashboard to visualize the routers, services, and middlewares that Traefik has registered. You can try to access the monitoring dashboard by pointing your browser to https://monitor.your_domain/dashboard/ (the trailing / is required).
You will be prompted for your username and password, which are admin and the password you configured in Step 1.
Once logged in, you’ll see the Traefik interface:

You will notice that there are already some routers and services registered, but those are the ones that come with Traefik and the router configuration that you wrote for the API.
You now have your Traefik proxy running, and you’ve configured it to work with Docker and monitor other containers. In the next step you will start some containers for Traefik to proxy.
Step 3 — Registering Containers with Traefik
With the Traefik container running, you’re ready to run applications behind it. Let’s launch the following containers behind Traefik:

A blog using the official WordPress image.
A database management server using the official Adminer image.

You’ll manage both of these applications with Docker Compose using a docker-compose.yml file.
Create and open the docker-compose.yml file in your editor:
nano docker-compose.yml
Add the following lines to the file to specify the version and the networks you’ll use:
docker-compose.yml
version: "3"

networks:
  web:
    external: true
  internal:
    external: false
You use Docker Compose version 3 because it’s the newest major version of the Compose file format.
For Traefik to recognize your applications, they must be part of the same network, and since you created the network manually, you pull it in by specifying the network name of web and setting external to true. Then you define another network so that you can connect your exposed containers to a database container that you won’t expose through Traefik. You’ll call this network internal.
Next, you’ll define each of your services, one at a time. Let’s start with the blog container, which you’ll base on the official WordPress image. Add this configuration to the bottom of the file:
docker-compose.yml
...

services:
  blog:
    image: wordpress:4.9.8-apache
    environment:
      WORDPRESS_DB_PASSWORD:
    labels:
      - traefik.http.routers.blog.rule=Host(`blog.your_domain`)
      - traefik.http.routers.blog.tls=true
      - traefik.http.routers.blog.tls.certresolver=lets-encrypt
      - traefik.port=80
    networks:
      - internal
      - web
    depends_on:
      - mysql
The environment key lets you specify environment variables that will be set inside of the container. By not setting a value for WORDPRESS_DB_PASSWORD, you’re telling Docker Compose to get the value from your shell and pass it through when you create the container. You will define this environment variable in your shell before starting the containers. This way you don’t hard-code passwords into the configuration file.
The labels section is where you specify configuration values for Traefik. Docker labels don’t do anything by themselves, but Traefik reads these so it knows how to treat containers. Here’s what each of these labels does:

traefik.http.routers.adminer.rule=Host(`````blog.your_domain`````) creates a new router for your container and then specifies the routing rule used to determine if a request matches this container.
traefik.routers.custom_name.tls=true specifies that this router should use TLS.
traefik.routers.custom_name.tls.certResolver=lets-encrypt specifies that the certificates resolver that you created earlier called lets-encrypt should be used to get a certificate for this route.
traefik.port specifies the exposed port that Traefik should use to route traffic to this container.

With this configuration, all traffic sent to your Docker host on port 80 or 443 with the domain of blog.your_domain will be routed to the blog container.
You assign this container to two different networks so that Traefik can find it via the web network and it can communicate with the database container through the internal network.
Lastly, the depends_on key tells Docker Compose that this container needs to start after its dependencies are running. Since WordPress needs a database to run, you must run your mysql container before starting your blog container.
Next, configure the MySQL service:
docker-compose.yml
services:
...
  mysql:
    image: mysql:5.7
    environment:
      MYSQL_ROOT_PASSWORD:
    networks:
      - internal
    labels:
      - traefik.enable=false
You’re using the official MySQL 5.7 image for this container. You’ll notice that you’re once again using an environment item without a value. The MYSQL_ROOT_PASSWORD and WORDPRESS_DB_PASSWORD variables will need to be set to the same value to make sure that your WordPress container can communicate with the MySQL. You don’t want to expose the mysql container to Traefik or the outside world, so you’re only assigning this container to the internal network. Since Traefik has access to the Docker socket, the process will still expose a router for the mysql container by default, so you’ll add the label traefik.enable=false to specify that Traefik should not expose this container.
Finally, define the Adminer container:
docker-compose.yml
services:
...
  adminer:
    image: adminer:4.6.3-standalone
    labels:
      - traefik.http.routers.adminer.rule=Host(`db-admin.your_domain`)
      - traefik.http.routers.adminer.tls=true
      - traefik.http.routers.adminer.tls.certresolver=lets-encrypt
      - traefik.port=8080
    networks:
      - internal
      - web
    depends_on:
      - mysql
This container is based on the official Adminer image. The network and depends_on configuration for this container exactly match what you’re using for the blog container.
The line traefik.http.routers.adminer.rule=Host(`````db-admin.your_domain`````) tells Traefik to examine the host requested. If it matches the pattern of db-admin.your_domain, Traefik will route the traffic to the adminer container over port 8080.
Your completed docker-compose.yml file will look like this:
docker-compose.yml
version: "3"

networks:
  web:
    external: true
  internal:
    external: false

services:
  blog:
    image: wordpress:4.9.8-apache
    environment:
      WORDPRESS_DB_PASSWORD:
    labels:
      - traefik.http.routers.blog.rule=Host(`blog.your_domain`)
      - traefik.http.routers.blog.tls=true
      - traefik.http.routers.blog.tls.certresolver=lets-encrypt
      - traefik.port=80
    networks:
      - internal
      - web
    depends_on:
      - mysql

  mysql:
    image: mysql:5.7
    environment:
      MYSQL_ROOT_PASSWORD:
    networks:
      - internal
    labels:
      - traefik.enable=false

  adminer:
    image: adminer:4.6.3-standalone
    labels:
    labels:
      - traefik.http.routers.adminer.rule=Host(`db-admin.your_domain`)
      - traefik.http.routers.adminer.tls=true
      - traefik.http.routers.adminer.tls.certresolver=lets-encrypt
      - traefik.port=8080
    networks:
      - internal
      - web
    depends_on:
      - mysql
Save the file and exit the text editor.
Next, set values in your shell for the WORDPRESS_DB_PASSWORD and MYSQL_ROOT_PASSWORD variables:
export WORDPRESS_DB_PASSWORD=secure_database_password
export MYSQL_ROOT_PASSWORD=secure_database_password
Substitute secure_database_password with your desired database password. Remember to use the same password for both WORDPRESS_DB_PASSWORD and MYSQL_ROOT_PASSWORD.
With these variables set, run the containers using docker-compose:
docker-compose up -d
Now watch the Traefik admin dashboard while it populates.

If you explore the Routers section you will find routers for adminer and blog configured with TLS:

Navigate to blog.your_domain, substituting your_domain with your domain. You’ll be redirected to a TLS connection and you can now complete the WordPress setup:

Now access Adminer by visiting db-admin.your_domain in your browser, again substituting your_domain with your domain. The mysql container isn’t exposed to the outside world, but the adminer container has access to it through the internal Docker network that they share using the mysql container name as a hostname.
On the Adminer login screen, enter root for Username, enter mysql for Server, and enter the value you set for MYSQL_ROOT_PASSWORD for the Password. Leave Database empty. Now press Login.
Once logged in, you’ll see the Adminer user interface.

Both sites are now working, and you can use the dashboard at monitor.your_domain to keep an eye on your applications.
Conclusion
In this tutorial, you configured Traefik v2 to proxy requests to other applications in Docker containers.
Traefik’s declarative configuration at the application container level makes it easy to configure more services, and there’s no need to restart the traefik container when you add new applications to proxy traffic to since Traefik notices the changes immediately through the Docker socket file it’s monitoring.
To learn more about what you can do with Traefik v2, head over to the official Traefik documentation.
服务集群

k8s 太重了，虽然也有 k3s 之类的轻量级 k8s 解决方案，不过我还是选择了原生的 docker swarm。VPS 安装好 Docker 之后，不需要额外安装软件，就可以马上建立集群。

# 集群初始化，节点成为 manager 节点
docker swarm init --advertise-addr=x.x.x.x

# 集群丢失 Leader 时，强制重建集群
docker swarm init --advertise-addr=x.x.x.x --force-new-cluster

# 获取作为 worker 节点加入集群的命令
docker swarm join-token worker

# 获取作为 manager 节点加入集群的命令
docker swarm join-token manager

# 加入集群
docker swarm join --token xxx x.x.x.x:xxx --advertise-addr=x.x.x.x

参考：

digitalocean
shanyue

]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>traefik</tag>
        <tag>proxy</tag>
        <tag>swarm</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>第一次使用 VS CODE 时你应该指导的一切配置</title>
    <url>/posts/44557ab0/</url>
    <content><![CDATA[前言

文章标题：《第一次使用 VS Code 时你应该知道的一切配置》。本文的最新内容，更新于 2021-10-09。大家完全不用担心这篇文章会过时，因为随着 VS Code 的版本更新和插件更新，本文也会随之更新。


本文的最新内容，也会在 GitHub 上同步更新，欢迎 star。

VS Code 软件实在是太酷、太好用了，越来越多的新生代互联网民工正在使用它。
前端男神尤雨溪大大这样评价 VS Code：

有一点你可能会感到惊讶：VS Code 这款软件本身，是用 JavaScript 语言编写的（具体请自行查阅基于 JS 的 PC 客户端开发框架 Electron）。Jeff Atwood 在 2007 年提出了著名的 Atwood 定律：

任何能够用 JavaScript 实现的应用系统，最终都必将用 JavaScript 实现。

Jeff Atwood 这个人是谁不重要（他是 Stack Overflow 网站的联合创始人），重要的是这条定律。
前端目前是处在春秋战国时代，各路英雄豪杰成为后浪，各种框架工具层出不穷，VS Code 软件无疑是大前端时代最骄傲的工具。
如果你是做前端开发（JavaScript 编程语言为主），则完全可以将 VS Code 作为「主力开发工具」。这款软件是为前端同学量身定制的，开箱即用。
如果你是做其他语言方向的开发，并且不需要太复杂的集成开发环境，那么，你可以把 VS Code 作为「代码编辑器」来使用，纵享丝滑。
甚至是一些写文档、写作的同学，也经常把 VS Code 作为 markdown 写作工具，毫无违和感。
退而求其次，即便你不属于以上任何范畴，你还可以把 VS Code 当作最简单的文本编辑器来使用，完胜 Windows 系统自带的记事本。
写下这篇文章，是顺势而为。
一、惊艳登场：VS Code 的介绍
VS Code 的全称是 Visual Studio Code，是一款开源的、免费的、跨平台的、高性能的、轻量级的代码编辑器。它在性能、语言支持、开源社区方面，都做得很不错。
微软有两种软件：一种是 VS Code，一种是其他软件。
在 2015 年 4 月 29 日的微软 Build 开发者大会上，微软宣布推出 VS Code 之后，这个轻量级的编辑器成为全球无数开发者们最喜爱的开发工具。VS Code 基于开源且跨平台的理念，每月都会进行迭代，并提供每天发布的 insider 版本（insider 是微软的一种公测计划，类似于国内软件所说的内测版）。它拥有至少几万个插件，生态极为活跃和丰富。
IDE 与 编辑器的对比
IDE 和编辑器是有区别的：


IDE（Integrated Development Environment，集成开发环境）：对代码有较好的智能提示和相互跳转，同时侧重于工程项目，对项目的开发、调试工作有较好的图像化界面的支持，因此比较笨重。比如 Eclipse 的定位就是 IDE。


编辑器：要相对轻量许多，侧重于文本的编辑。比如 Sublime Text 的定位就是编辑器。再比如 Windows 系统自带的「记事本」就是最简单的编辑器。


需要注意的是，VS Code 的定位是编辑器，而非 IDE ，但 VS Code 又比一般的编辑器的功能要丰富许多。可以这样理解：VS Code 的体量是介于编辑器和 IDE 之间。VS Code 的使命，是让开发者在编辑器里拥有 IDE 那样的开发体验。
VS Code 流行起来之后，使用 Sublime Text、Atom 这类编辑器软件的人，自然就越来越少了。
VS Code 的特点

跨平台：支持 MacOS、Windows 和 Linux 等多个平台。在这多种平台下，拥有一致的用户界面和开发体验。
开源：VS Code 的源代码以 MIT 协议开源。不仅代码开源，而且整个产品的开发计划和发布管理也都是开源的。VS Code 团队每年都会在 GitHub 的 Wiki 上发布 Roadmap，列出一整年的规划图。VS Code 软件的官方文档也托管在了 GitHub 上。
自带终端、图形化的调试工具、Git 版本控制。
插件扩展：支持第三方插件，功能强大。既有中心化的插件市场，也可以直接在 VS Code 里搜索你想要的插件。
生态：社区生态活跃且丰富，社区氛围浓厚。
自带  emmet：支持代码自动补全，快速生成简单的语法结构。要知道，这个功能在 Sublime Text 中，得先安装插件才行。
语法支持：VS Code 自带了 JavaScript、TypeScript 和 Node.js 的语法支持，包括：语法高亮、代码智能提示和补全、括号匹配、颜色区分、代码片段提示等。也就是说，你在书写 JS 和 TS 时，这些语法支持都是自带的。其他的一些语言，你需要先安装相应的扩展包插件，就出现语法支持。
在修改配置方面，既有图形化的配置界面，也有 基于 JSON 文件的配置方式，满足不同人群的使用习惯。

前端利器之争： VS Code 与 WebStorm
前端小白最喜欢问的一个问题是：哪个编辑器 / IDE 好用？是 VS Code 还是 WebStorm （WebStorm 其实是 IntelliJ IDEA 的定制版）？我来做个对比：


哪个更酷：显然 VS Code 更酷。


内存占用情况：根据我的观察，VS Code 是很占内存的（尤其是当你打开多个窗口的时候），但如果你的内存条够用，使用起来是不会有任何卡顿的感觉的。相比之下，IntelliJ IDEA 不仅非常占内存，而且还非常卡顿。如果你想换个既轻量级、又不占内存的编辑器，最好还是使用「Sublime Text」编辑器。


使用比例：当然是 VS Code 更胜一筹。先不说别的，我就拿数据说话，我目前所在的研发团队有 200 人左右（120 个后台、80 个前端），他们绝大部分人都在用 VS Code 编码，妥妥的。


所以，如果你以后还问这个问题，那就真有些掉底了。
VS Code 的技术栈、核心组件
了解 VS Code 的技术栈和核心组件，可以让我们对 VS Code 有更深入的认识。此小段，了解即可。

开发框架：Electron。Electron 可以使用 Node.js + JS 这样的技术栈开发桌面 GUI 应用程序。
编辑器：Monaco Editor。Monaco Editor 是一款开源的在线代码编辑器，是 VS Code 浏览器版本的最核心组件。#
编程语言：TypeScript。TypeScript 是  JavaScript 的严格超集。TS 在 JS 的基础上添加了许多功能，引入了声明文件，而且支持类型扩展。TS 适合长期的、多人开发的大型项目开发。
让编辑器支持语言功能：Language Server Protocol （LSP） 语言服务协议。LSP 是编辑器 / IDE 与语言服务器之间的一种协议，通过 JSON-PRC 传输消息，可以让编辑器嵌入并支持各种编程语言。开发者可以在编辑器中使用各种语言来编写程序。
让编辑器支持调试功能：Debug Adapter Protocol（DAP）。DAP 是基于 JSON 的协议，它抽象了开发工具与调试工具质检的通信。
集成终端：Xterm.js。VS Code 的集成终端是基于开源项目 Xterm.js 进行开发的。Xterm.js 是一个使用 TS 开发的终端组件。另外，Xterm.js 并不是直接下来下来就能用的终端应用，它只是一个前端组件，可以与 bash 这样的进程进行连接，然后让用户通过  Xterm.js 进行交互。

VS Code 的安装

VS Code 官网：https://code.visualstudio.com

VS Code 的安装很简单，直接去官网下载安装包，然后双击安装即可。

上图中，直接点击 download，一键下载安装即可。
VS Code 支持以下平台：

安装完成后的界面如下：

VS  Code 被分为以下五个区域：

编辑器
侧边栏
状态栏
活动栏
面板

VS Code 在功能上非常克制，只包含了大多数开发流程中所需要的基础模块，包括：编辑器、文件管理、窗口管理、首选项设置、终端等。
你需要根据具体需要安装额外的组件或者插件。比如说，如果开发 TS 项目，则需要安装 TS 编译器、ESLint、TSLint 等编译工具。如果开发 C 语言项目，则需要安装 gcc、Clang 等编辑工具。
二、崭露锋芒：VS Code 快捷键
VS Code 用得熟不熟，首先就看你是否会用快捷键。以下列出的内容，都是常用快捷键，而加粗部分的快捷键，使用频率则非常高。
任何工具，掌握 20% 的技能，足矣应对 80% 的工作。既然如此，你可能会问：那就只保留 20% 的特性，不久可以满足 80% 的用户了吗？
但我想说的是：那从来都不是同样的 20%，每个人都会用到不同的功能。
掌握下面这些高频核心快捷键，你和你的工具，足矣露出锋芒。
1、工作区快捷键



Mac 快捷键
 Win 快捷键
作用
备注




 Cmd + Shift + P
Ctrl + Shift + P，F1
 显示命令面板



 Cmd + B
Ctrl + B
 显示 / 隐藏侧边栏
很实用


Cmd + \
Ctrl + \
拆分为多个编辑器
【重要】抄代码利器


 Cmd + 1、2
Ctrl + 1、2
 聚焦到第 1、第 2 个编辑器
同上重要


 Cmd + +、Cmd + -
ctrl + +、ctrl + -
 将工作区放大 / 缩小（包括代码字体、左侧导航栏）
在投影仪场景经常用到


 Cmd + J
Ctrl + J
 显示 / 隐藏控制台



 Cmd + Shift + N
Ctrl + Shift + N
 重新开一个软件的窗口
很常用


 Cmd + Shift + W
Ctrl + Shift + W
 关闭软件的当前窗口



 Cmd + N
Ctrl + N
 新建文件



 Cmd + W
Ctrl + W
 关闭当前文件




2、跳转操作



Mac 快捷键
 Win 快捷键
作用
备注




 Cmd + `
 没有
在同一个软件的多个工作区之间切换
使用很频繁


 Cmd + Option + 左右方向键
 Ctrl + Pagedown/Pageup
 在已经打开的多个文件之间进行切换
非常实用


 Ctrl + Tab
Ctrl + Tab
 在已经打开的多个文件之间进行跳转
不如上面的快捷键快


 Cmd + Shift + O
Ctrl + shift + O
 在当前文件的各种方法之间（符号：Symbol）进行跳转



 Cmd + T
Ctrl + T
 在当前工作区的各种方法之间（符号：Symbol）进行跳转



 Ctrl + G
Ctrl + G
 跳转到指定行



Cmd+Shift+\
Ctrl+Shift+\
跳转到匹配的括号




3、移动光标



Mac 快捷键
 Win 快捷键
作用
备注




方向键
方向键
在单个字符之间移动光标
大家都知道


 option + 左右方向键
 Ctrl + 左右方向键
在单词之间移动光标
很常用


 Cmd + 左右方向键
 Fn + 左右方向键（或 Win + 左右方向键）
将光标定位到当前行的最左侧、最右侧（在整行之间移动光标）
很常用


 Option + Alt + 左右方向键
 Alt + Shift + 左右方向键
左右扩大 / 缩小选中的范围
很酷，极为高效


 Cmd + ↑
Ctrl + Home
 将光标定位到文件的第一行



 Cmd + ↓
Ctrl + End
 将光标定位到文件的最后一行



 Cmd + Shift + \

 在代码块之间移动光标




4、编辑操作



Mac 快捷键
 Win 快捷键
作用
备注




 Cmd + C
Ctrl + C
 复制



 Cmd + X
Ctrl + X
 剪切



 Cmd + C
Ctrl + V
 粘贴



 Cmd + Enter
Ctrl + Enter
 在当前行的下方新增一行，然后跳至该行
即使光标不在行尾，也能快速向下插入一行


 Cmd+Shift+Enter
Ctrl+Shift+Enter
 在当前行的上方新增一行，然后跳至该行
即使光标不在行尾，也能快速向上插入一行


 Option + ↑
Alt + ↑
将代码向上移动
很常用


 Option + ↓
Alt + ↓
将代码向下移动
很常用


 Option + Shift + ↑
Alt + Shift + ↑
将代码向上复制一行



 Option + Shift + ↓
Alt + Shift + ↓
将代码向下复制一行
写重复代码的利器



另外再补充一点：将光标点击到某一行的任意位置时，默认就已经是选中全行了，此时可以直接复制或剪切，无需点击鼠标。这个非常实用，是所有的编辑操作中，使用得最频繁的。它可以有以下使用场景：

场景 1：假设光标现在处于第 5 行的任意位置，那么，直接依次按下 Cmd + C 和 Cmd + V，就会把这行代码复制到第 6 行。继续按 Cmd + C 和 Cmd + V，就会把这行代码复制到第 7 行。copy 代码 so easy。
场景 2：假设光标现在处于第 5 行，那么，先按下 Cmd + C，然后按两下↑ 方向键，此时光标处于第 3 行；紧接着，继续按下 Cmd + V，就会把刚刚那行代码复制到第 3 行，原本处于第 3 行的代码会整体下移。

你看到了没？上面的两个场景，我全程没有使用鼠标，只通过简单的复制粘贴和方向键，就做到了如此迅速的 copy 代码。你说是不是很高效？
5、删除操作



Mac 快捷键
 Win 快捷键
作用
备注




 Cmd + shift + K
Ctrl + Shift + K
 删除整行
「Cmd + X」的作用是剪切，但也可以删除整行


 option + Backspace
Ctrl + Backspace
 删除光标之前的一个单词
英文有效，很常用


 option + delete
Ctrl + delete
 删除光标之后的一个单词



 Cmd + Backspace

 删除光标之前的整行内容
很常用


 Cmd + delete

 删除光标之后的整行内容




备注：上面所讲到的移动光标、编辑操作、删除操作的快捷键，在其他编辑器里，大部分都适用。
6、多光标选择 / 多光标编辑
多光标选择在编程的提效方面可谓立下了汗马功劳。因为比较难记住，所以你要时不时回来复习这一段。



Mac 快捷键
 Win 快捷键
作用
备注




 Option + 鼠标连续点击任意位置
 Alt + 鼠标连续点击任意位置
在任意位置，同时出现多个光标
很容易记住


 Cmd + D
Ctrl + D
 将光标放在某个单词的位置（或者先选中某个单词），然后反复按下「 Cmd + D 」键， 即可将下一个相同的词逐一加入选择。
较常用


 Cmd + Shift + L
Ctrl + Shift + L
 将光标放在某个单词的位置（或者先选中某个单词），然后按下快捷键，则所有的相同内容处，都会出现光标。
很常用。比如变量重命名的时候，就经常用到



7、多列选择 / 多列编辑
多列选择是更高效的多光标选择，所以单独列成一小段。



Mac 快捷键
 Win 快捷键
作用
备注




 Cmd + Option + 上下键
 Ctrl + Alt + 上下键
在连续的多列上，同时出现多个光标
较常用


 Option + Shift + 鼠标拖动
 Alt + Shift + 鼠标拖动
按住快捷键，然后把鼠标从区域的左上角拖至右下角，即可在选中区域的每一行末尾，出现光标。
很神奇的操作，较常用


 Option + Shift + i
Alt + Shift + I
 选中一堆文本后，按下快捷键，既可在每一行的末尾都出现一个光标。
很常用



8、编程语言相关



Mac 快捷键
 Win 快捷键
作用
备注




 Cmd + /
Ctrl + /
 添加单行注释
很常用


 Option + Shift + F
Alt + shift + F
 代码格式化
很常用


 F2
F2
 以重构的方式进行重命名
改代码备


 Ctrl + J

 将多行代码合并为一行
 Win 用户可在命令面板搜索” 合并行 “


Cmd +





Cmd + U
Ctrl + U
 将光标的移动回退到上一个位置
撤销光标的移动和选择



9、搜索相关



Mac 快捷键
 Win 快捷键
作用
备注




 Cmd + Shift + F
Ctrl + Shift +F
 全局搜索代码
很常用


 Cmd + P
Ctrl + P
 在当前的项目工程里，全局搜索文件名



 Cmd + F
Ctrl + F
 在当前文件中搜索代码，光标在搜索框里



 Cmd + G
F3
 在当前文件中搜索代码，光标仍停留在编辑器里
很巧妙



10、自定义快捷键
按住快捷键「Cmd + Shift + P」，弹出命令面板，在命令面板中输入 “快捷键”，可以进入快捷键的设置。
当然，你也可以选择菜单栏「偏好设置 --&gt; 键盘快捷方式」，进入快捷键的设置：

11、快捷键列表
你可以点击 VS Code 左下角的齿轮按钮，效果如下：

上图中，在展开的菜单中选择「键盘快捷方式」，就可以查看和修改所有的快捷键列表了：

快捷键参考表（官方）
VS Code 官网提供了 PDF 版本的键盘快捷键参考表，转需：

Windows 版本：https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf
Mac 版本：https://code.visualstudio.com/shortcuts/keyboard-shortcuts-macos.pdf
Linux 版本：https://code.visualstudio.com/shortcuts/keyboard-shortcuts-linux.pdf

我们在 VS  Code 软件里通过菜单栏「帮助 --&gt; 键盘快捷方式参考」也可以打开相应平台的快捷键大全（PDF 版本）。
三、高端访问：命令面板的使用
Mac 用户按住快捷键 Cmd+Shift+P （Windows 用户按住快捷键 Ctrl+Shift+P），可以打开快速命令面板。效果如下：

命令面板的作用是希望解放开发者的鼠标，让一些操作和配置可以直接通过键盘进行。如果让开发者记住所有的配置项在菜单的哪个位置是不现实的，而且有些命令并不在菜单中。
有了命令面板之后，如果你需要修改一些设置项，或者进行一些快捷操作，则可以通过「命令面板」来操作，效率会更高。接下来列举一些。
1、VS Code 设置为中文语言
Mac 用户按住快捷键 Cmd+Shift+P （Windows 用户按住快捷键 Ctrl+Shift+P），打开命令面板。
在命令面板中，输入 Configure Display Language，选择 Install additional languages，然后安装插件 Chinese (Simplified) Language Pack for Visual Studio Code 即可。
或者，我们可以直接安装插件 Chinese (Simplified) Language Pack for Visual Studio Code，是一样的。
安装完成后，重启 VS Code。
2、设置字体大小
在命令面板输入 “字体”，可以进行字体的设置，效果如下：

当然，你也可以在菜单栏，选择「首选项 - 设置 - 常用设置」，在这个设置项里修改字体大小。
3、快捷键设置
在命令面板输入 “快捷键”，就可以进入快捷键的设置。
4、大小写转换
选中文本后，在命令面板中输入 transfrom，就可以修改文本的大小写了。

5、使用命令行启动 VS Code
（1）输入快捷键「Cmd + Shift + P 」，选择 install code command：

（2）使用命令行：

code 命令：启动 VS Code 软件
code pathName/fileName 命令：通过 VS Code 软件打开指定目录 / 指定文件。

备注：这种方法快捷简单，但是在电脑重启之后就失效了。稍后在第五段，我会介绍更常见的方法。
6、修改特定编程语言的设置项
输入快捷键「Cmd + Shift + P 」打开命令面板，然后输入并执行 Configure Language Specific Settings 即可。

四、私人订制：VS Code 的常见配置
0、设置项介绍
在修改 VS Code 配置之前，我们需要知道，在哪里可以找到设置项的入口。
方式 1：Mac 用户选择菜单栏「Code--&gt; 首选项 --&gt; 设置」，即可打开配置项：

方式 2：点击软件右下角的设置图标：


如上图所示，VS Code 提供两种不同范围的设置：

用户设置：全局生效。
工作区设置：只针对当前项目生效。工作区设置会覆盖用户设置。适用于团队协作场景。工作区的设置文件是保存在当前项目根目录的.vscode/settings.json 中，可以被提交到 Git 仓库，方便共享给项目组的其他成员。

操作技巧：
（1）我们可以在设置面板的顶部搜索框，输入关键词，就能迅速定位到你想要的设置项。
（2）上图中，点击右上角的 icon，可以通过 json 文件的形式修改设置项。
1、修改主题
1）修改颜色主题：
选择菜单栏「Code --&gt; 首选项 --&gt; 颜色主题」：

在弹出的对话框中，挑选你一个你喜欢的的颜色主题吧，或者安装其他颜色的主题：

或者在设置项里搜索 Workbench: Color Theme，进行修改。
2）修改文件图标的主题：
选择菜单栏「Code --&gt; 首选项 --&gt; 文件图标主题」：

在弹出的对话框中，挑选你一个你喜欢的的主题吧，或者安装其他的主题：

或者在设置项里搜索 Workbench: Icon Theme，进行修改。
2、面包屑（Breadcrumb）导航
打开 VS Code 的设置项，选择「用户设置 -&gt; 工作台 -&gt; 导航路径」，如下图所示：

上图中，将红框部分打钩即可。
设置成功后，我们就可以查看到当前文件的「层级结构」，非常方便。如下图所示：

有了这个面包屑导航，我们可以点击它，在任意目录、任意文件之间随意跳转。使用频繁非常高。
3、是否显示代码的行号
VS Code 默认显示代码的行号。你可以在设置项里搜索 editor.lineNumbers 修改设置，配置项如下：

我建议保留这个设置项，无需修改。
4、右侧是否显示代码的缩略图
如果某个文件的代码量很大，缩略图就很有用了，可以预览全局，并在当前文件中快速跳转。
VS Code 会在代码的右侧，默认显示缩略图。你可以在设置项里搜索 editor.minimap 进行设置，配置项如下：

上面这张图，你仔细琢磨下会发现，中文翻译十分精准。
5、将当前行代码高亮显示（更改光标所在行的背景色）
当我们把光标放在某一行时，这一行的背景色并没有发生变化。如果想高亮显示当前行的代码，需要设置两步：
（1）在设置项里搜索 editor.renderLineHighlight，将选项值设置为 all 或者 line。
（2）在设置项里增加如下内容：
"workbench.colorCustomizations": {
    "editor.lineHighlightBackground": "#00000090",
    "editor.lineHighlightBorder": "#ffffff30"
}
上方代码，第一行代码的意思是：修改光标所在行的背景色（背景色设置为全黑，不透明度 90%）；第二行代码的意思是：修改光标所在行的边框色。
6、改完代码后立即自动保存
方式一：
改完代码后，默认不会自动保存。你可以在设置项里搜索 files.autoSave，修改参数值为 afterDelay  ，即可自动保存。如下：

files.autoSave 的参数值有以下几种：

off（默认值）：不自动保存。
afterDelay（建议配置）：文件修改超过一定时间（默认 1 秒）后，就自动保存。
onFocusChange：当前编辑器失去焦点时，则自动保存。如果我们将配置项修改为 onFocusChange 之后，那么，当光标离开该文件后，这个文件就会自动保存了。
onWindowChange：VS  Code 软件失去焦点时，则自动保存。

方式二：
当然，你也可以直接在菜单栏选择「文件 - 自动保存」。勾选后，当你写完代码后，文件会立即实时保存。
7、热退出
当 VS Code 退出后，它可以记住未保存的文件。如果你希望达到这种效果，那么，你需要先将设置项 files.hotExit 的值改为 onExitAndWindowClose。这个配置项要不要改，看你个人需要。比如我自己平时设置的值是 onExit。

8、保存代码后，是否立即格式化
保存代码后，默认不会立即进行代码的格式化。你可以在设置项里搜索 editor.formatOnSave 查看该配置项：

我觉得这个配置项保持默认就好，不用打钩。
9、自动格式化粘贴的内容
在设置项里搜索 editor.formatOnPaste，将设置项改为 true：

10、设置字体大小
在设置项里搜索 fontSize，然后根据需要设置各种模块的字体大小：

11、空格 or 制表符
VS Code 会根据你所打开的文件来决定该使用空格还是制表。也就是说，如果你的项目中使用的都是制表符，那么，当你在写新的代码时，按下 tab 键后，编辑器就会识别成制表符。
（1）建议的设置项如下：

editor.detectIndentation：自动检测（默认开启）。建议把这个配置项修改为 false，截图如下：


这样做，是为了取消系统的自动缩进，建议自己手动格式化比较好。 参考链接：https://www.yisu.com/zixun/327399.html

editor.insertSpaces：按 Tab 键时插入空格（默认值为 true）。截图如下：



editor.tabSize：一个制表符默认等于四个空格。截图如下：


（2）状态栏也会显示当前的缩进值。点击状态栏，可以直接修改 tabSize 缩进值：

（3）另外，我们还可以安装 prettier 插件，设置代码在格式化时默认缩进值。prettier 是做代码格式化的最常见工具。

（4）去掉每一行末尾的空格。在设置项里搜索空格或者 "files.trimTrailingWhitespace"，将值设置为 true：

一般来说，每一行代码末尾的空格是多余的，所以建议去掉。
12、直观地显示代码里的空格和缩进 ✨
代码里如果有缩进或者空格，肉眼是看不出来的，但是我们可以修改配置项，把它揪出来。
在配置项里搜索 editor.renderWhitespace，修改为 all：

修改之后，代码里的空格、缩进的展示效果如下：

看到了没？哪里有空格、哪里是缩进，全都一目了然。
13、新建文件后的默认文件类型
当我们按下快捷键「Cmd + N」新建文件时，VS Code 默认无法识别这个文件到底是什么类型的，因此也就无法识别相应的语法高亮。
如果你想修改默认的文件类型，可以在设置项里搜索 files.defaultLanguage，设置项如下：

上图中的红框部分，填入你期望的默认文件类型。我填的是 html 类型，你也可以填写成 javascript 或者 markdown，或者其他的语言类型。
14、删除文件时，是否弹出确认框
当我们在 VS Code 中删除文件时，默认会弹出确认框。如果你想修改设置，可以在设置项里搜索 xplorer.confirmDelete。截图如下：

我建议这个设置项保持默认的打钩就好，不用修改。删除文件前的弹窗提示，也是为了安全考虑，万一手贱不小心删了呢？
15、在新窗口打开文件 / 文件夹
通过 window.openFoldersInNewWindow（默认值为 off）和 window.openFilesInNewWindow（默认值为 default），可以配置在打开文件夹、打开文件时，是否开启一个新的窗口。我个人建议，把这两个配置项都设置为 on，避免旧的窗口被覆盖：

补充知识 —— window.restoreWindows 可以用来配置 如何恢复之前的会话窗口。涉及到的场景是：你把 VS Code 关闭了，然后又打开了，是否要展示之前打开过的文件、文件夹？参数值有以下几种：

one（默认配置）：只会重新打开上一次回话中最后操作的那一个窗口。
none：打开一个空的窗口，不包含任何文件、文件夹。
all（建议配置）：恢复上一次会话中的所有窗口。
folders：恢复上一次会话中包含文件夹的窗口。



接下来，我们来讲一些更高级的操作。

五、纵享丝滑：常见操作和使用技巧
1、快速生成 HTML 骨架
先新建一个空的 html 文件，然后通过以下方式，可以快速生成 html 骨架。
方式 1：输入 !，然后按下 enter 键，即可生成 html 骨架。如下图：

方式 2：输入 html:5，然后按住 Tab 键，即可生成 html 骨架。
生成的骨架，内容如下：
&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;title&gt;Document&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;/body&gt;
&lt;/html&gt;
有了上面的 html 骨架之后，我们就可以快乐地在里面插入 CSS 代码和 JS 代码。
2、并排编辑：左右（上下）显示多个编辑器窗口（copy 代码利器）

并排编辑是所有的编辑操作中最常用的一个技巧，十分有用。比如我们在开发一个项目时，可能需要同时打开 HTML 文件和 CSS 文件，很常见。

Mac 用户按住快捷键 Cmd + \， Windows 用户按住快捷键 Ctrl + \，即可同时打开多个编辑器窗口，进行并排编辑。效果如下：

按快捷键「Cmd + 1 」切换到左边的窗口，按快捷键「Cmd + 2 」切换到右边的窗口，以此类推。随时随地，想切就切。
学会了这一招，以后 copy 代码的时候，leader 再也不用担心我抄得慢了，一天工资到手。

当然，使用快捷键 Cmd + \ 只是其中一种方式，我们还有很多种方式打开并行编辑。我们来做一个汇总。
如果你已经打开了一个编辑器，那么可以通过以下几种方式在另一侧打开另一个编辑器：（按照使用频率，从高到低排序）

使用快捷键 Cmd + \ 将编辑器一分为二。
使用快捷键 Cmd + P 调出文件列表，选择要打开的文件，然后按下 Cmd + Enter 快捷键。【重要】
按住 Option 键的同时，单击资源管理器的文件（Windows 用户是按 Alt 键）。
点击编辑器右上角的 Split Editor 按钮。
选择菜单栏「查看 --&gt; 编辑器布局」，然后选择你具体想要的布局，如下图所示：



通过拖拽，把当前文件移动到任意一侧。

补充知识：通过配置项 worbench.editor.OpenSideBySideDirection 可以控制编辑器在并排打开时出现的默认位置（默认值为 right，你也可以根据需要改为 down）。如下图所示：

3、从终端 code 命令启动 VS Code（Mac 电脑）
在终端输入 code 或者输入 code + 指定项目的目录，就可以启动 VS  Code，十分便捷。即：

code 命令：启动 VS Code 软件。
code pathName/fileName 命令：通过 VS Code 软件打开指定目录 / 指定文件。

为了达到目的，我们需要先将 VS Code 的软件安装路径添加到环境变量，一劳永逸。具体操作如下：
（1）打开 bash_profile 文件：
cd ~
vim ./bash_profile
（2）在 bash_profile 中添加如下内容：
# 从终端启动VS Code，并设置vscode启动的命令别名
alias code="/Applications/Visual\ Studio\ Code.app/Contents/Resources/app/bin/code"
注意，由于 Visual Studio Code.app 这个路径里有空格，所以需要在空格前面加上反斜杠 \。
（3）重启环境变量的配置：
# 重启
source ~/.bash_profile
大功告成。
改完之后，如果没生效，那你把  bash_profile 文件 换成 zshrc 文件试试。
参考链接：

mac 通过终端 code 命令打开 vscode

3、从终端 code 命令启动 VS Code（Windows 电脑）
在终端输入 code 或者输入 code + 指定项目的目录，就可以启动 VS  Code，十分便捷。即：

code 命令：启动 VS Code 软件。
code pathName/fileName 命令：通过 VS Code 软件打开指定目录 / 指定文件。

为了达到目的，我们需要先将 VS Code 的软件安装路径添加到环境变量，一劳永逸。具体操作如下：
（1）打开 VS Code 的安装位置，进入 bin 文件夹，复制路径。比如：D:\Microsoft VS Code\bin。
（2）回到桌面，右键我的电脑 --&gt; 高级系统设置 --&gt; 环境变量 --&gt; 编辑 path 值，在原来的 path 后面，追加内容 ;D:\Microsoft VS Code\bin（即英文的分号 + VS  Code 的 bin 路径)
（3）重启电脑，大功告成。
改完之后，如果没生效，那八成是因为你填的 path 值有问题。
参考链接：

windows 使用 code . 命令打开 vscode

4、在当前文件中搜索
在上面的快捷键列表中，我们已经知道如下快捷键：


Cmd + F（Win 用户是 Ctrl + F）：在当前文件中搜索，光标在搜索框里


Cmd + G（Win 用户是 F3）：在当前文件中搜索，光标仍停留在编辑器里


多个搜索结果出来之后，按下 Enter 键之后跳转到下一个搜索结果，按下 Shift + Enter 键之后跳转到上一个搜索结果。
另外，你可能会注意到，搜索框里有很多按钮，每个按钮都对应着不同的功能，如下图所示：

上图中，你可以通过「Tab」键和「Shift + Tab」键在输入框和替换框之间进行切换。
「在选定内容中查找」这个功能还是比较实用的。你也可以在设置项里搜索 editor.find.autoFindInSelection，勾选该设置项后，那么，当你选中指定内容后，然后按住「Cmd + F」，就可以自动只在这些内容里进行查找。该设置项如下图所示：

5、全局搜索
在上面的快捷键列表中，我们已经知道如下快捷键：

Cmd + Shift + F（Win 用户是 Ctrl + Shift +F）：在全局的文件夹中进行搜索。效果如下：


上图中，你可以点击红框部分，展开更多的配置项。然后点击红圈部分，进行过滤搜索。注意，第二个红圈那里会经常用到，它可以在搜索时过滤掉  .git、.node_modules 等忽略文件。
上图中，我们还可以点击 “在编辑器中打开”，在一个单独的文件中聚合展示搜索结果：

6、文件名 / 文件夹的搜索
前面的快捷键那一段我们讲过，通过 「Cmd + P」可以快速搜索并打开文件 / 文件夹。这种方式，一般用于快速打开最近编辑过的文件。
其实还有一种很巧妙的方式，可以在整个项目里，既能搜到文件，也能搜到文件夹。这种方式，常用于过滤项目的目录。操作方法很简单：

直接在文件资源管理器输入关键字就行。搜索结果会自动出现；使用方向键进行上下移动，可以在搜索的文件和文件夹之间进行跳转。
另外，右上角会看到一个过滤器，点击下图中的红圈部分，则只显示匹配的文件和文件夹。


当然，这招也有一点不足：不能搜中文。
7、大纲视图
如下图所示，大纲视图可以展示当前代码的方法结构、文件的目录结构：


8、文件对比
VS Code 默认支持对比两个文件的内容。选中两个文件，然后右键选择「将已选项进行比较」即可，效果如下：

VS Code 自带的对比功能并不够强大，我们可以安装插件 compareit，进行更丰富的对比。比如说，安装完插件 compareit 之后，我们可以将「当前文件」与「剪切板」里的内容进行对比：

如果你安装了 GitLens 插件，还可以将两个 git 分支的代码进行比对，非常完美。
9、查找某个函数在哪些地方被调用了
比如我已经在 a.js 文件里调用了 foo() 函数。那么，如果我想知道 foo() 函数在其他文件中是否也被调用了，该怎么做呢？
做法如下：在 a.js 文件里，选中 foo() 函数（或者将光标放置在 foo() 函数上），然后按住快捷键「Shift + F12」，就能看到 foo() 函数在哪些地方被调用了，比较实用。
10、鼠标操作


在当前行的位置，鼠标三击，可以选中当前行。


用鼠标单击文件的行号，可以选中当前行。


在某个行号的位置，上下移动鼠标，可以选中多行。


11、重构
重构分很多种，我们来举几个例子。
命名重构：
当我们尝试去修改某个函数（或者变量名）时，我们可以把光标放在上面，然后按下「F2」键，那么，这个函数（或者变量名）出现的地方都会被修改。
方法重构：
选中某一段代码，这个时候，代码的左侧会出现一个「灯泡图标」，点击这个图标，就可以把这段代码提取为一个单独的函数。
12：终端配置
VS Code 软件自带了终端，但我个人认为不是很好用，而且 VS Code 软件关了之后，终端也没了。建议大家使用其他的终端软件，专业的事情交给专业的人做。

Windows 平台的终端：推荐 PowerShell 软件。远程终端推荐 xshell 软件。
Mac 平台的终端：推荐 iTerm2 。 iTerm2 是 Mac 平台最好用的终端软件，没有之一。

右键行为：

在终端上，单击右键所产生的行为在不同的系统里是不同的。


Windows：如果有选定文本，则复制当前文本；如果没有选定文本，则粘贴。
macOS：选中光标所在位置的单词，并显示右键菜单。
Linux：显示右键菜单。

13、Git 版本管理
在 VS Code 中使用 Git 之前，需要你先安装 Git 环境。
VS Code 自带了 Git 版本管理的功能，如下图所示：

上图中，我们可以在这里进行常见的 git 命令操作。如果你还不熟悉 Git 版本管理，可以先去补补课。
我自己用的最多的功能是 diff 代码和合并冲突，自从用上了  VS Code 的这两个功能，简直离不开它。
我们先来看看 diff 代码的效果：

上图中，点击右上角的...，然后点击内联视图，则可以换一种视图 diff 代码：

Git 状态栏：

在 VS Code 的左下角会显示 Git 状态栏。如果当前代码仓库配置了远程仓库，那么 “同步更改” 会显示以下信息：

左边的数字：表示远程分支比本地分支多了 XX 个 Git commit。
右边的数字：表示本地分支比远程分支多了 XX 个 Git commit。

点击 “同步更改” 按钮，会拉取（pull）远程分支到本地分支，并推送（push）本地的 Git commit 到远程分支。
如果当前代码仓库没有配置远程仓库，则会显示 “发布更改” 的按钮。点击 “发布更改” 按钮，会把当前分支 push 到远程仓库。

另外，我建议安装插件 GitLens 搭配使用，它是 VS Code 中我最推荐的一个插件，简直是 Git 神器，码农必备。
我还要补充一句：
有人说，高手都是直接用命令行操作 Git。然而，根据我多年的经验来看，如果你的代码仓库需要管理的分支特别多，与团队的其他成员需要经常协作，那么，我建议你优先使用 GUI 图形化工具来操作 Git，避免出错。
我推荐的 GUI 版的 Git 工具有：

Tower
Sourcetree
GitKraken

14、将工作区放大 / 缩小
我们在上面的设置项里修改字体大小后，仅仅只是修改了代码的字体大小。
如果你想要缩放整个工作区（包括代码的字体、左侧导航栏的字体等），可以按下快捷键「cmd +/-」。windows 用户是按下「ctrl +/-」
当我们在投影仪上给别人演示代码的时候，这一招十分管用。
如果你想恢复默认的工作区大小，可以在命令面板输入重置缩放（英文是 reset zoom）
f### 11、创建多层子文件夹
我们可以在新建文件夹的时候，如果直接输入 aa/bb/cc，比如：

那么，就可以创建多层子文件夹，效果如下：

15、.vscode 文件夹的作用
为了统一团队的 vscode 配置，我们可以在项目的根目录下建立.vscode 目录，在里面放置一些配置内容，比如：


settings.json：工作空间设置、代码格式化配置、插件配置。


sftp.json：ftp 文件传输的配置。


.vscode 目录里的配置只针对当前项目范围内生效。将.vscode 提交到代码仓库，大家统一配置时，会非常方便。
16、自带终端
我们可以按下「Ctrl + `」打开 VS Code 自带的终端。我认为内置终端并没有那么好用，我更建议你使用第三方的终端 item2。
17、markdown 语法支持
VS Code 自带 markdown 语法高亮。也就是说，如果你是用 markdown 格式写文章，则完全可以用 VS Code 进行写作。
写完 md 文件之后，你可以点击右上角的按钮进行预览，如下图所示：

我一般是安装「Markdown Preview Github Styling」插件，以 GitHub 风格预览 Markdown 样式。样式十分简洁美观。
你也可以在控制面板输入 Markdown: 打开预览，直接全屏预览 markdown 文件。
18、Emmet in VS Code
Emmet 可以极大的提高 html 和 css 的编写效率，它提供了一种非常简练的语法规则。
举个例子，我们在编辑器中输入缩写代码：ul&gt;li*6 ，然后按下 Tab 键，即可得到如下代码片段：
&lt;ul&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
VS Code 默认支持 Emmet。更多 Emmet 语法规则，可以自行查阅。
19、修改字体，使用「Fira Code」字体
这款字体很漂亮，很适合用来写代码：

安装步骤如下：
（1）进入 https://github.com/tonsky/FiraCode 网站，下载并安装「Fira Code」字体。
（2）打开 VS Code 的「设置」，搜索 font，修改相关配置为如下内容：
"editor.fontFamily": "'Fira Code',Menlo, Monaco, 'Courier New', monospace", // 设置字体显示
"editor.fontLigatures": false,//控制是否启用字体连字，true启用，false不启用
上方的第二行配置，取决于个人习惯，我是直接设置为 "editor.fontLigatures": null，因为我不太习惯连字。
20、代码格式化
VS Code 默认对 JavaScript、TypeScript、JSON、HTML 提供了开箱即用的代码格式化支持。其他语言则需要先安装相应的插件才能支持。
另外，我们还可以安装 Prettier 插件进行更精细的代码格式化。下一段将插件的时候，会讲解。
21、智能提示 IntelliSense
VS Code 默认对 JavaScript、TypeScript、JSON、HTML、CSS、SCSS、Less 这 7 种语言（文件）提供了智能提示的支持。其他编程语言则需要先安装相应的插件才能支持。
在 VS Code 插件职场中，下图是最受欢迎的 8 种编程语言插件：

智能提示的功能很强大， 包括函数介绍、代码自动补全等等。
22、调试与运行
VS Code 内置了对 Node.js 运行时的调试支持，可以直接调试  JavaScript 和 TypeScript。其他编程语言的调试，则需要先安装相应的插件才能支持。
在 VS Code 插件市场中，下图是最受欢迎的几种调试插件：

23、文件传输：sftp
如果你需要将本地文件通过 ftp 的形式上传到局域网的服务器（需要先把服务端的配置搭建好），可以安装 sftp 这个插件，很好用。在公司会经常用到。
步骤如下：
（1）安装插件 sftp。
（2）配置 sftp.json 文件。 插件安装完成后，输入快捷键「cmd+shift+P」弹出命令面板，然后输入 sftp:config，回车，当前工程的.vscode 文件夹下就会自动生成一个 sftp.json 文件，我们需要在这个文件里配置的内容可以是：


host：服务器的 IP 地址


username：用户名


privateKeyPath：存放在本地的已配置好的用于登录工作站的密钥文件（也可以是 ppk 文件）


remotePath：工作站上与本地工程同步的文件夹路径，需要和本地工程文件根目录同名，且在使用 sftp 上传文件之前，要手动在工作站上 mkdir 生成这个根目录


ignore：指定在使用 sftp: sync to remote 的时候忽略的文件及文件夹，注意每一行后面有逗号，最后一行没有逗号


举例如下：(注意，其中的注释需要去掉)
{
  "host": "192.168.xxx.xxx", //服务器ip
  "port": 22, //端口，sftp模式是22
  "username": "", //用户名
  "password": "", //密码
  "protocol": "sftp", //模式
  "agent": null,
  "privateKeyPath": null,
  "passphrase": null,
  "passive": false,
  "interactiveAuth": false,
  "remotePath": "/root/node/build/", //服务器上的文件地址
  "context": "./server/build", //本地的文件地址

  "uploadOnSave": true, //监听保存并上传
  "syncMode": "update",
  "watcher": {
    //监听外部文件
    "files": false, //外部文件的绝对路径
    "autoUpload": false,
    "autoDelete": false
  },
  "ignore": [
    //忽略项
    "**/.vscode/**",
    "**/.git/**",
    "**/.DS_Store"
  ]
}
（3）在 VS Code 的当前文件里，选择「右键 -&gt; upload」，就可以将本地的代码上传到 指定的 ftp 服务器上（也就是在上方 host 中配置的服务器 ip）。
我们还可以选择「右键 -&gt; Diff with Remote」，就可以将本地的代码和 ftp 服务器上的代码做对比，非常方便。
24、沉浸模式 / 禅模式
程序员写代码需要专注，有时需要进入一种心流。VS Code 给我们提供了一种全屏下的沉浸模式，周围的面板都会被隐藏起来，只显示编辑器部分。
操作方法：菜单栏选择「查看 - 外观 - 禅模式」即可；或者按下快捷键 Cmd + K，放手，再按 Z 也可以达到目的。
正则表达式批量删除字符串
需求：将文本中的字符串 axxxxb，批量替换为 ab。其中，开头字符 a 和 结尾字符 b 固定，中间 xxx 长度不确定。
解决：传统查找替换无法胜任。可以使用 VScode 正则表达式功能，查找 a.*?b 替换为 ab 即可。其中 ? 是禁止贪婪匹配，否则会误删很多内容。

拓展需求：需求 —— 将文本中的字符串 axxxx，批量替换为 a。其中，开头字符 a 固定，后面的 xxx 长度不确定。
解决：传统查找替换无法胜任。可以使用 VScode 正则表达式功能，查找 a.*?\n 替换为 a\n 即可。
六、三头六臂：VS Code 插件介绍 &amp; 插件推荐
VS Code 有一个很强大的功能就是支持插件扩展，让你的编辑器仿佛拥有了三头六臂。
安装插件

上图中，点击红框部分，即可在顶部输入框里，查找你想要的插件名，然后进行安装。
插件安装完成后，记得重启软件（或者点击插件位置的 “重新加载”），插件才会生效。
另外，我们还可以访问官网的插件市场来安装插件：

VS Code 插件市场（官方）：https://marketplace.visualstudio.com/vscode

插件的安装目录：

Windows：：%USERPROFILE%\.vscode\extensions
macOS：~/.vscode/extensions
macOS：~/.vscode/extensions

插件的类型

插件市场的首页有四个模块，可以作为重要的信息来源：

Featured：由  VS Code 团队精心推荐的插件。
Trending：近期热门插件。
Most Popular：按总安装量排序的插件。
Recently Added：最新发布的插件。



插件市场至少有 17 种类型的插件：（按照数量排序）

Themes：主题插件
 Programming Languages：编程语言插件
 Snippets：代码片段
 Extension Packs：插件包，里面包括多个插件
 Formatters：代码格式化
 Linters：静态检查
 Debuggers：调试器
 Keymaps：快捷键映射
 Visualization：可视化
 Language Packs：各国的语言插件
 Azure：Azure 云计算
 Data Science：数据科学
 SCM Providers：源代码控制管理器（source control manager）
Notebooks
Education：教育
 Testing：测试相关
 Machine Learning：机器学习
 Others：其他

插件的过滤显示
在 VS  Code 中打开插件管理视图，可以针对已安装的插件，进行过滤展示。
1）点击插件视图右上角的... 按钮，可以展示不同状态的插件：

2）在搜索框输入字符 @，会展示出不同类型的过滤器：

常见的过滤器如下：
1）按大类搜：

@builtin：显示 VS Code 内置的插件
@disabled：显示被禁用的插件
@enabled：显示已启用的插件
@installed：显示已安装的插件
@outdated：显示待更新的插件

2）精准搜索：

@id：按 id 显示插件
@tag：根据标签显示插件。

3）对插件进行排序：

@sort:installs：根据插件的安装量排序
@sourt:rating：根据插件的评分排序
@sort:name：根据插件名字的字母顺序排序

4）组合搜索：（举例）

@installed @category:themes：显示已安装的主题插件。
@sort:installs java：对 Java 相关的插件按照安装量排序。

下面的内容，我来列举一些常见的插件，这些插件都很实用，小伙伴们可以按需安装。注意：每一类插件里，顺序越靠前，越实用。
1、基本插件
Chinese (Simplified) Language Pack for Visual Studio Code
让软件显示为简体中文语言。
2、Git 相关插件
GitLens 【荐】
我强烈建议你安装插件 GitLens，它是 VS Code 中我最推荐的一个插件，简直是 Git 神器，码农必备。如果你不知道，那真是 out 了。
GitLens 在 Git 管理上有很多强大的功能，比如：

将光标放置在代码的当前行，可以看到这样代码的提交者是谁，以及提交时间。这一点，是 GitLens 最便捷的功能。
查看某个 commit 的代码改动记录
查看不同的分支
可以将两个 commit 进行代码对比
甚至可以将两个 branch 分支进行整体的代码对比。这一点，简直是 GitLens 最强大的功能。当我们在不同分支 review 代码的时候，就可以用到这一招。

打开你的 Git 仓库，未安装  GitLens 时是这样的：

安装了  GitLens 之后是这样的：

上图中，红框部分就是  GitLens 的功能，诸君可以自由发挥。
补充一个有意思的趣事：Python 插件、Ruby 插件、GitLens 插件、Vetur 插件，这四个插件的开发者先后加入了微软。
Git History
有些同学习惯使用编辑器中的 Git 管理工具，而不太喜欢要打开另外一个 Git UI 工具的同学，这一款插件满足你查询所有 Git 记录的需求。
Local History 【荐】
维护文件的本地历史记录。代码意外丢失时，有时可以救命。

3、代码智能提示插件
Vetur
Vue 多功能集成插件，包括：语法高亮，智能提示，emmet，错误提示，格式化，自动补全，debugger。VS Code 官方钦定 Vue 插件，Vue 开发者必备。
ES7 React/Redux/GraphQL/React-Native snippets
React/Redux/react-router 的语法智能提示。
JavaScript(ES6) code snippets
ES6 语法智能提示，支持快速输入。
javascript console utils：快速打印 log 日志【荐】
安装这个插件后，当我们按住快捷键「Cmd + Shift + L」后，即可自动出现日志 console.log()。简直是日志党福音。
当我们选中某个变量 name，然后按住快捷键「Cmd + Shift + L」，即可自动出现这个变量的日志 console.log(name)。
其他的同类插件还有：Turbo Console Log。
不过，生产环境的代码，还是尽量少打日志比较好，避免出现一些异常。
编程有三等境界：


第三等境界是打日志，这是最简单、便捷的方式，略显低级，一般新手或资深程序员偷懒时会用。


第二等境界是断点调试，在前端、Java、PHP、iOS 开发时非常常用，通过断点调试可以很直观地跟踪代码执行逻辑、调用栈、变量等，是非常实用的技巧。


第一等境界是测试驱动开发，在写代码之前先写测试。与第二等的断点调试刚好相反，大部分人不是很习惯这种方式，但在国外开发者或者敏捷爱好者看来，这是最高效的开发方式，在保证代码质量、重构等方面非常有帮助，是现代编程开发必不可少的一部分。


Code Spell Checker：单词拼写错误检查
这个拼写检查程序的目标是帮助捕获常见的单词拼写错误，可以检测驼峰命名。从此告别 Chinglish.
Auto Close Tag、Auto Rename Tag
自动闭合配对的标签、自动重命名配对的标签。
4、代码显示增强插件
Bracket Pair Colorizer 2：突出显示成对的括号【荐】
Bracket Pair Colorizer 2 插件：以不同颜色显示成对的括号，并用连线标注括号范围。简称彩虹括号。
另外，还有个 Rainbow Brackets 插件，也可以突出显示成对的括号。
highlight-icemode：选中相同的代码时，让高亮显示更加明显【荐】
VSCode 自带的高亮显示，实在是不够显眼。用插件支持一下吧。
所用了这个插件之后，VS Code 自带的高亮就可以关掉了：
在用户设置里添加 "editor.selectionHighlight": false 即可。
参考链接：vscode 选中后相同内容高亮插件推荐
vscode-icons
vscode-icons 会根据文件的后缀名来显示不同的图标，让你更直观地知道每种文件是什么类型的。
indent-rainbow：突出显示代码缩进
indent-rainbow 插件：突出显示代码缩进。
安装完成后，效果如下图所示：

TODO Highlight
写代码过程中，突然发现一个 Bug，但是又不想停下来手中的活，以免打断思路，怎么办？按照代码规范，我们一般是在代码中加个 TODO 注释。比如：（注意，一定要写成大写 TODO，而不是小写的 todo）
//TODO:这里有个bug，我一会儿再收拾你
或者：
//FIXME:我也不知道为啥， but it works only that way.
安装了插件 TODO Highlight 之后，按住「Cmd + Shift + P」打开命令面板，输入「Todohighlist」，选择相关的命令，我们就可以看到一个 todoList 的清单。
Better Comments
为注释添加更醒目、带分类的色彩。
5、代码格式化插件
Prettier：代码格式化
Prettier 是一个代码格式化工具，只关注格式化，但不具备校验功能。在一个多人协同开发的团队中，统一的代码编写规范非常重要。一套规范可以让我们编写的代码达到一致的风格，提高代码的可读性和统一性。自然维护性也会有所提高，代码的展示也会更加美观。
步骤如下：
（1）安装插件 Prettier。
（2）在项目的根路径下，新建文件.prettierrc，并在文件中添加如下内容：
{
  "printWidth": 150,
  "tabWidth": 4,
  "semi": true,
  "singleQuote": true,
  "trailingComma": "es5",
  "tslintIntegration": true,
  "insertSpaceBeforeFunctionParenthesis": false
}
上面的内容，是我自己的配置，你可以参考。更多配置，可见官方文档：https://prettier.io/docs/en/options.html
（3）Mac 用户按快捷键「Option + Shift + F」，Win 用户按快捷键「Alt + shift + F」，即可完成代码的格式化。如果你的 VS Code 设置的是自动格式化代码，那么这一步可以忽略。
ESLint：代码格式的校验
日常开发中，建议用 Prettier 做代码格式化，然后用 eslint 做格式校验。很多人把这两个插件的功能弄混了。
一般做法是：格式化建议是由程序员手动触发，格式校验由系统强制校验。通过 Prettier 手动触发格式化，是为了让用户有感知；通过 eslint 做强制校验之后，如果代码的格式不符合要求，系统就禁止你提交代码。
Beautify
代码格式化工具。
备注：相比之下，Prettier 是当前最流行的代码格式化工具，比 Beautify 用得更多。
Paste JSON as Code
此插件可以将剪贴板中的 JSON 字符串转换成工作代码。支持多种语言。
JS-CSS-HTML Formatter【荐】
保存文件时，自动格式化 HTML、CSS、JS 代码。
6、图片相关插件
Polacode-2020：生成代码截图 【荐】
可以把代码片段保存成美观的图片，主题不同，代码的配色方案也不同，也也可以自定义设置图片的边框颜色、大小、阴影。
尤其是在我们做 PPT 分享时需要用到代码片段时，或者需要在网络上优雅地分享代码片段时，这一招很有用。
生成的效果如下：

其他同类插件：CodeSnap。我们也可以通过 https://carbon.now.sh/ 这个网站生成代码图片
有人可能会说：直接用 QQ 截图不行吗？可以是可以，但不够美观、不够干净。
Image Preview 【荐】
图片预览。鼠标移动到图片 url 上的时候，会自动显示图片的预览和图片尺寸。
7、CSS 相关插件
CSS Peek
增强 HTML 和 CSS 之间的关联，快速查看该元素上的 CSS 样式。
Vue CSS Peek
CSS Peek 对 Vue 没有支持，该插件提供了对 Vue 文件的支持。
Color Info
这个便捷的插件，将为你提供你在 CSS 中使用颜色的相关信息。你只需在颜色上悬停光标，就可以预览色块中色彩模型的（HEX、 RGB、HSL 和 CMYK）相关信息了。
8、Mardown 相关插件
Markdown Preview Github Styling 【荐】
以 GitHub 风格预览 Markdown 样式，十分简洁优雅。就像下面这样，左侧书写 Markdown 文本，右侧预览 Markdown 的渲染效果：

Markdown Preview Enhanced
预览 Markdown 样式。
Markdown All in One
这个插件将帮助你更高效地在 Markdown 中编写文档。
9、通用工具类插件
sftp：文件传输 【荐】
如果你需要将本地文件通过 ftp 的形式上传到局域网的服务器，可以安装 sftp 这个插件，很好用。在公司会经常用到。
详细配置已经在上面讲过。
Live Server 【荐】
在本地启动一个服务器，代码写完后可以实现「热更新」，实时地在网页中看到运行效果。就不需要每次都得手动刷新页面了。
使用方式：安装插件后，开始写代码；代码写完后，右键选择「Open with Live Server」。
open in browser
安装 open in browser 插件后，在 HTML 文件中「右键选择 --&gt; Open in Default Browser」，即可在浏览器中预览网页。
Project Manager
工作中，我们经常会来回切换多个项目，每次都要找到对应项目的目录再打开，比较麻烦。Project Manager 插件可以解决这样的烦恼，它提供了专门的视图来展示你的项目，我们可以把常用的项目保存在这里，需要时一键切换，十分方便。
WakaTime 【荐】
统计在 VS Code 里写代码的时间。统计效果如下：

Code Time
Code Time 插件：记录编程时间，统计代码行数。
安装该插件后，VS Code 底部的状态栏右下角可以看到时间统计。点击那个位置之后，选择「Code Time Dashboard」，即可查看统计结果。
备注：团长试了一下这个 code time 插件，发现统计结果不是很准。
File Tree to Text Generator：快速生成文件的目录树
如题。
Settings Sync


地址：https://github.com/shanalikhan/code-settings-sync


作用：多台设备之间，同步 VS Code 配置。通过登录 GitHub 账号来使用这个同步工具。


同步的详细操作，下一段会讲。
另外，北京时间的 2020 年 8 月 14 日，微软发布 Visual Studio Code 1.48 稳定版。此版本原生支持用户同步 VS Code 的配置，只需要登录微软账号或者 GitHub 账号即可。
vscode-syncing


地址：https://github.com/nonoroazoro/vscode-syncing


作用：多台设备之间，同步 VS Code 配置。


minapp：小程序支持
小程序开发必备插件。
Search node_modules
node_modules 模块里面的文件夹和模块实在是太多了，根本不好找。好在安装 Search node_modules 这个插件后，输入快捷键「Cmd + Shift + P」，然后输入 node_modules，在弹出的选项中选择 Search node_modules，即可搜索 node_modules 里的模块。

RemoteHub
不要惊讶，RemoteHub 和 GitLens 是同一个作者开发出来的。
RemoteHub 插件的作用是：可以在本地查看 GitHub 网站上的代码，而不需要将代码下载到本地。

这个插件目前使用的人还不多，赶紧安装起来尝尝鲜吧。
Live Share：实时编码分享
Live Share 这个神奇的插件是由微软官方出品，它的作用是：实时编码分享。也就是说，它可以实现你和你的同伴一起写代码。这绝对就是结对编程的神器啊。
安装方式：
打开插件管理，搜索 “live share”，安装。安装后重启 VS Code，在左侧会多出一个按钮：

上图中，点击红框部分，登录后就可以分享你的工作空间了。

Import Cost
在项目开发过程中，我们会引入很多 npm 包，有时候可能只用到了某个包里的一个方法，却引入了整个包，导致代码体积增大很多。Import Cost 插件可以在代码中友好的提示我们，当前引入的包会增加多少体积，这很有助于帮我们优化代码的体积。
10、主题插件
给你的 VS Code 换个皮肤吧，免费的那种。


Dracula Theme


Material Theme


Nebula Theme


One Dark Pro


One Monokai Theme


Monokai Pro


Ayu


Snazzy Plus


Dainty


SynthWave '84


GitHub Plus Theme：白色主题


Horizon Theme：红色主题


七、无缝切换：VS Code 配置云同步
我们可以将配置云同步，这样的话，当我们换个电脑时，即可将配置一键同步到本地，就不需要重新安装插件了，也不需要重新配置软件。
下面讲的两个同步方法，都可以，看你自己需要。方法 1 是 VS Code 自带的同步功能，操作简单。方法 2 需要安装插件，支持更多的自定义配置。
方法 1：使用 VS Code 自带的同步功能
1、配置同步：
（1）在菜单栏选择「 Code --&gt; 首选项 --&gt; 打开设置同步」：

（2）选择需要同步的配置：

（3）通过 Microsoft 或者 GitHub 账号登录。 上图中，点击 “登录并打开”，然后弹出如下界面：

上图中，使用  微软账号或者 GitHub 账号登录：

（4）同步完成后，菜单栏会显示 “首先项同步已打开”，最左侧也会多出一个同步图标，如下图所示：

2、管理同步：
（1）点击菜单栏「Code --&gt; 首选项 --&gt; 设置同步已打开」，会弹出如下界面，进行相应的同步管理即可：

（2）换另外一个电脑时，登录相同的账号，即可完成同步。
参考链接：

VS Code 原生的配置同步功能 ——Settings Sync

方法 2：使用插件 settings-sync
使用方法 2，我们还可以把配置分享其他用户，也可以把其他用户的配置给自己用。
1、配置同步：（将自己本地的配置云同步到 GitHub）
（1）安装插件 settings-sync。
（2）安装完插件后，在插件里使用 GitHub 账号登录。
（3）登录后在 vscode 的界面中，可以选择一个别人的 gist；也可以忽略掉，然后创建一个属于自己的 gist。
（4）使用快捷键 「Command + Shift + P」，在弹出的命令框中输入 sync，并选择「更新 / 上传配置」，这样就可以把最新的配置上传到 GitHub。
2、管理同步：（换另外一个电脑时，从云端同步配置到本地）
（1）当我们换另外一台电脑时，可以先在 VS Code 中安装 settings-sync 插件。
（2）安装完插件后，在插件里使用 GitHub 账号登录。
（3）登录之后，插件的界面上，会自动出现之前的同步记录：

上图中，我们点击最新的那条记录，就可将云端的最新配置同步到本地：

如果你远程的配置没有成功同步到本地，那可能是网络的问题，此时，可以使用快捷键 「Command + Shift + P」，在弹出的命令框中输入 sync，并选择「下载配置」，多试几次。
使用其他人的配置：
如果我们想使用别人的配置，首先需要对方提供给你 gist。具体步骤如下：
（1）安装插件 settings-sync。
（2）使用快捷键 「Command + Shift + P」，在弹出的命令框中输入 sync，并选择「下载配置」
（3）在弹出的界面中，选择「Download Public Gist」，然后输入别人分享给你的 gist。注意，这一步不需要登录 GitHub 账号。
最后一段
如果你还有什么推荐的 VS Code 插件，欢迎留言。
大家完全不用担心这篇文章会过时，随着 VS Code 的版本更新和插件更新，本文也会随之更新。关于 VS Code 内容的后续更新，你可以关注我在 GitHub 上的前端入门项目，项目地址是：

https://github.com/qianguyihao/Web

一个超级详细和真诚的前端入门项目。
todo

issues 84

参考链接
2021 年

中文版 Awesome VS Code：https://github.com/formulahendry/awesome-vscode-cn

2020 年

VSCode 插件大全｜ VSCode 高级玩家之第二篇
http://www.supuwoerc.xyz/tools/vscode/plugins.html
如何让 VS Code 更好用 10 倍？这里有一份 VS Code 新手指南
那些你应该考虑卸载的 VSCode 扩展
VS Code 折腾记 - (16) 推荐一波实用的插件集
VSCode 前端必备插件，有可能你装了却不知道如何使用？
能让你开发效率翻倍的 VSCode 插件配置（上）
https://segmentfault.com/a/1190000012811886
「Vscode」打造类 sublime 的高颜值编辑器
Mac Vscode 快捷键
使用 VSCode 的一些技巧
转载来源，[GitHub](https://github.com/qianguyihao/Web/blob/master/00 - 前端工具 / 01-VS Code 的使用.md) 推荐关注 star！


]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>vscode</tag>
        <tag>插件</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo Markdown 以及各种插件功能测试</title>
    <url>/posts/cf0f47fd/</url>
    <content><![CDATA[Markdown 插件

markdown-it-abbr
markdown-it-container
markdown-it-deflist
markdown-it-emoji
markdown-it-footnote
markdown-it-imsize
markdown-it-ins
markdown-it-mark
markdown-it-regexp
markdown-it-sub
markdown-it-sup
markdown-it-task-checkbox

常用标记
- 29^th^ =&gt; `29&lt;sup&gt;th&lt;/sup&gt;`
- H~2~0 =&gt; `H&lt;sub&gt;2&lt;/sub&gt;O`
- ==marked== =&gt; `&lt;mark&gt;inserted&lt;/mark&gt;`
- ++inserted++ =&gt; `&lt;ins&gt;inserted&lt;/ins&gt;`

29th =&gt; 29&lt;sup&gt;th&lt;/sup&gt;
H20 =&gt; H&lt;sub&gt;2&lt;/sub&gt;O
marked =&gt; &lt;mark&gt;inserted&lt;/mark&gt;
inserted =&gt; &lt;ins&gt;inserted&lt;/ins&gt;

markdown-it-task-checkbox

和主题某些 css 冲突，停用

- [x] item 1
    - [x] item 1-1
    - [ ] item 1-2
    - [ ] item 1-3
    - [ ] item 1-4
- [ ] item 2
    - [ ] item 2-1
    - [ ] item 2-2
    - [ ] item 2-3
    - [ ] item 2-4

[x] item 1

[x] item 1-1
[ ] item 1-2
[ ] item 1-3
[ ] item 1-4


[ ] item 2

[ ] item 2-1
[ ] item 2-2
[ ] item 2-3
[ ] item 2-4



markdown-it-multimd-table

目前仅支持多列合并

| 标题1        | 标题2        |
| ------------ | ------------ |
| 合并第一行                ||
| 第二行第一列 | 第二行第二列 |



标题 1
 标题 2




 合并第一行



第二行第一列
第二行第二列



colspan &gt; or empty cell:



a
b




&gt;
1


2




rowspan ‘^’



a
b




1
2


^^
4



|   Markdown   | Rendered HTML |
|--------------|---------------|
|    *Italic*  | *Italic*      | \
|              |               |
|    - Item 1  | - Item 1      | \
|    - Item 2  | - Item 2      |
|    ```python | ```python       \
|    .1 + .2   | .1 + .2         \
|    ```       | ```           |



Markdown
Rendered HTML





Italic
Italic
\







- Item 1
- Item 1
\


- Item 2
- Item 2



```python
```python \



.1 + .2
.1 + .2 \



```
```




| Task           | Time required | Assigned to   | Current Status | Finished | 
|----------------|---------------|---------------|----------------|-----------|
| Calendar Cache | &gt; 5 hours  | @georgehrke | in progress | - [x] ok?
| Object Cache   | &gt; 5 hours  | @georgehrke | in progress | [x] item1&lt;br/&gt;[ ] item2
| Object Cache   | &gt; 5 hours  | @georgehrke | in progress | &lt;ul&gt;&lt;li&gt;- [x] item1&lt;/li&gt;&lt;li&gt;- [ ] item2&lt;/li&gt;&lt;/ul&gt;
| Object Cache   | &gt; 5 hours  | @georgehrke | in progress | &lt;ul&gt;&lt;li&gt;[x] item1&lt;/li&gt;&lt;li&gt;[ ] item2&lt;/li&gt;&lt;/ul&gt;


- [x] works
- [x] works too



Task
Time required
Assigned to
Current Status
Finished




Calendar Cache
&gt; 5 hours
@georgehrke
in progress
- [x] ok?


Object Cache
&gt; 5 hours
@georgehrke
in progress
[x] item1 [ ] item2


Object Cache
&gt; 5 hours
@georgehrke
in progress
- [x] item1- [ ] item2


Object Cache
&gt; 5 hours
@georgehrke
in progress
[x] item1[ ] item2




[x] works
[x] works too

Function | MySQL / MariaDB | PostgreSQL | SQLite
:------------ | :-------------| :-------------| :-------------
substr | :heavy_check_mark: |  :white_check_mark: | :heavy_check_mark:



Function
MySQL / MariaDB
PostgreSQL
SQLite




substr
✔️
✅
✔️



emoji
:smile::smirk::sunny:
😄😏☀️
markdown-it-abbr
*[HTML]: Hyper Text Markup Language
*[W3C]:  World Wide Web Consortium
The HTML specification
is maintained by the W3C.
The HTML specification
is maintained by the W3C.
markdown-it-container
::: warning
*here be dragons*
:::
here be dragons
footnote
Here is a footnote reference,[^1] and another.[^longnote]

[^1]: Here is the footnote.

[^longnote]: Here's one with multiple blocks.

    Subsequent paragraphs are indented to show that they
belong to the previous footnote.
Here is a footnote reference,[1] and another.[2]
belong to the previous footnote.
markdown-it-imsize
![test](https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/10/1220211012022352.png)
![test](https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/10/1220211012022352.png =100x200)


公式测试

采用 **markdown-it-latex2img**

Demo
1 数学公式
1.1 内联公式
开头的 $ 必须在其右边紧跟一个非空格字符，而结尾的 $ 必须在其左边紧接一个非空格字符，并且不能紧跟一个数字。

勾股定理: 
等差数列求和公式: 
牛顿 - 莱布尼茨公式: 
二项分布: 

1.2 块公式
正态分布:
斐波那契数列, 前后两项的比值逐渐收敛到黄金分割比例
因式分解
狄利克雷函数
高斯公式
范德蒙行列式
线性方程组
2 物理公式

牛顿第一定律: 
牛顿第二定律: 
牛顿第三定律: 
质能守恒: 

万有引力定律: 
基尔霍夫定律
热力学第二定律
3 化学公式
离子反应与沉淀: 
氮气氢气合成氨
化学平衡常数:
4 生物公式
光合作用
5 语法参考
MathJax basic tutorial and quick reference
长公式



小括号测试
$\alpha\beta$

$\alpha_\beta$

$\alpha_\beta = \gamma_\delta$

(abctest)

\(abctest\)

\\(abctest\\)



(abctest)
(abctest)
\(abctest\)
下划线测试
w^{(l)}*{ij} = w^{(l)}*{ij} - \eta\frac{\partial E(W, b)}{\partial w^{(l)}_{ij}}

CSS 测试
文字增加背景色块 站点配置文件 ,
主题配置文件
&lt;span id="inline-blue"&gt;站点配置文件&lt;/span&gt;, 
&lt;span id="inline-purple"&gt;主题配置文件&lt;/span&gt;
引用边框变色
如果没有安装成功，那可能就是墙的原因。建议下载 `Node.js` 直接安装. 
关于更多基本操作和基础知识，请查阅 [Hexo](https://hexo.io/zh-cn/) 与 [NexT](http://theme-next.iissnan.com/) 官方文档.  
&lt;p id="div-border-left-red"&gt;如果没有安装成功, 那可能就是墙的原因. 建议下载 `Node.js` 直接安装. &lt;/p&gt;
&lt;p id="div-border-top-blue"&gt;关于更多基本操作和基础知识, 请查阅 [Hexo](https://hexo.io/zh-cn/) 与 [NexT](http://theme-next.iissnan.com/) 官方文档.&lt;/p&gt;  
图形边框效果
 Download Now

&lt;a id="download" href="https://git-scm.com/download/win"&gt;&lt;i class="fa fa-download"&gt;&lt;/i&gt;&lt;span&gt; Download Now&lt;/span&gt;
&lt;/a&gt;
更多 tips 可参考 blog
在文档中增加图标

支持 Markdown
Hexo 支持 GitHub Flavored Markdown 的所有功能，甚至可以整合 Octopress 的大多数插件. 
一件部署
只需一条指令即可部署到 Github Pages, 或其他网站
丰富的插件
Hexo 拥有强大的插件系统，安装插件可以让 Hexo 支持 Jade, CoffeeScript. 

- &lt;i class="fa fa-pencil"&gt;&lt;/i&gt;支持Markdown
&lt;i&gt;Hexo 支持 GitHub Flavored Markdown 的所有功能, 甚至可以整合 Octopress 的大多数插件. &lt;/i&gt;
- &lt;i class="fa fa-cloud-upload"&gt;&lt;/i&gt;一件部署
&lt;i&gt;只需一条指令即可部署到Github Pages, 或其他网站&lt;/i&gt;
- &lt;i class="fa fa-cog"&gt;&lt;/i&gt;丰富的插件
&lt;i&gt;Hexo 拥有强大的插件系统, 安装插件可以让 Hexo 支持 Jade, CoffeeScript. &lt;/i&gt;



`&lt;i class="fa fa-github"&gt;&lt;/i&gt;`
`&lt;i class="fa fa-github fa-lg"&gt;&lt;/i&gt;`
`&lt;i class="fa fa-github fa-2x"&gt;&lt;/i&gt;`
图表绘制


hexo-tag-mermaid


hexo-tag-plantuml

hexo-tag-plantuml is a tag plugin for Hexo. It can work with plantuml to draw uml.

在 Hexo 中绘制 uml 图。


hexo-filter-flowchart

Generate flowchart diagrams for Hexo.



Mermaid

Markdown mermaid 教程

mermaid
hexo-tag-mermaidhexo-tag-plantuml

需要用下面块包裹

{% mermaid %}
[内容]
{% endmermaid %}
先来几个演示

  graph LR 
	source (*.java) --javac--&gt; bytecode (*.class) 
	bytecode --java--&gt; result (程序输出)



  graph LR 
	type(type) -.-&gt; type 
	type -.-&gt; object(object) 
	type -.-&gt; A(A) 
	type -.-&gt; int(int) 
	A -.-&gt; a((a)) 
	int -.-&gt; i((i)) 
	object --&gt; type 
	object --&gt; A


flowchart
[docs - live editor]
{% mermaid %}
graph TD
    A[Christmas] --&gt;|Get money| B(Go shopping)
    B --&gt; C{Let me think}
    C --&gt;|One| D[Laptop]
    C --&gt;|Two| E[iPhone]
    C --&gt;|Three| F[Car]
{% endmermaid %}

  graph TD
    A[Christmas] --&gt;|Get money| B(Go shopping)
    B --&gt; C{Let me think}
    C --&gt;|One| D[Laptop]
    C --&gt;|Two| E[iPhone]
    C --&gt;|Three| F[Car]


Sequence diagram
[docs - live editor]
{% mermaid %}
sequenceDiagram
    loop every day
        Alice-&gt;&gt;John: Hello John, how are you?
        John--&gt;&gt;Alice: Great!
    end
{% endmermaid %}

  sequenceDiagram
    loop every day
        Alice-&gt;&gt;John: Hello John, how are you?
        John--&gt;&gt;Alice: Great!
    end


Gantt diagram
[docs - live editor]
{% mermaid %}
gantt
    dateFormat  YYYY-MM-DD
    title Adding GANTT diagram functionality to mermaid

    section A section
    Completed task            :done,    des1, 2014-01-06,2014-01-08
    Active task               :active,  des2, 2014-01-09, 3d
    Future task               :         des3, after des2, 5d
    Future task2               :         des4, after des3, 5d

    section Critical tasks
    Completed task in the critical line :crit, done, 2014-01-06,24h
    Implement parser and jison          :crit, done, after des1, 2d
    Create tests for parser             :crit, active, 3d
    Future task in critical line        :crit, 5d
    Create tests for renderer           :2d
    Add to mermaid                      :1d

    section Documentation
    Describe gantt syntax               :active, a1, after des1, 3d
    Add gantt diagram to demo page      :after a1  , 20h
    Add another diagram to demo page    :doc1, after a1  , 48h

    section Last section
    Describe gantt syntax               :after doc1, 3d
    Add gantt diagram to demo page      : 20h
    Add another diagram to demo page    : 48h
{% endmermaid %}

  gantt
    dateFormat  YYYY-MM-DD
    title Adding GANTT diagram functionality to mermaid

    section A section
    Completed task            :done,    des1, 2014-01-06,2014-01-08
    Active task               :active,  des2, 2014-01-09, 3d
    Future task               :         des3, after des2, 5d
    Future task2               :         des4, after des3, 5d
    
    section Critical tasks
    Completed task in the critical line :crit, done, 2014-01-06,24h
    Implement parser and jison          :crit, done, after des1, 2d
    Create tests for parser             :crit, active, 3d
    Future task in critical line        :crit, 5d
    Create tests for renderer           :2d
    Add to mermaid                      :1d
    
    section Documentation
    Describe gantt syntax               :active, a1, after des1, 3d
    Add gantt diagram to demo page      :after a1  , 20h
    Add another diagram to demo page    :doc1, after a1  , 48h
    
    section Last section
    Describe gantt syntax               :after doc1, 3d
    Add gantt diagram to demo page      : 20h
    Add another diagram to demo page    : 48h


ER 图

  erDiagram
    CUSTOMER ||--o{ ORDER : places
    CUSTOMER {
        string name
        string custNumber
        string sector
    }
    ORDER ||--|{ LINE-ITEM : contains
    ORDER {
        int orderNumber
        string deliveryAddress
    }
    LINE-ITEM {
        string productCode
        int quantity
        float pricePerUnit
    }


erDiagram
    CUSTOMER ||--o{ ORDER : places
    CUSTOMER {
        string name
        string custNumber
        string sector
    }
    ORDER ||--|{ LINE-ITEM : contains
    ORDER {
        int orderNumber
        string deliveryAddress
    }
    LINE-ITEM {
        string productCode
        int quantity
        float pricePerUnit
    }
class
[docs - live editor]
classDiagram
class Shape{
    &lt;&lt;interface&gt;&gt;
    noOfVertices
    draw()
}
class Color{
    &lt;&lt;enumeration&gt;&gt;
    RED
    BLUE
    GREEN
    WHITE
    BLACK
}

  classDiagram
class Shape{
    &lt;&gt;
    noOfVertices
    draw()
}
class Color{
    &lt;&gt;
    RED
    BLUE
    GREEN
    WHITE
    BLACK
}


State
[docs - live editor]
{% mermaid %}
stateDiagram-v2
    [*] --&gt; Still
    Still --&gt; [*]
    Still --&gt; Moving
    Moving --&gt; Still
    Moving --&gt; Crash
    Crash --&gt; [*]
{% endmermaid %}

  stateDiagram-v2
    [*] --&gt; Still
    Still --&gt; [*]
    Still --&gt; Moving
    Moving --&gt; Still
    Moving --&gt; Crash
    Crash --&gt; [*]


Pie
[docs - live editor]
{% mermaid %}
pie
"Dogs" : 386
"Cats" : 85
"Rats" : 15
{% endmermaid %}

  pie
"Dogs" : 386
"Cats" : 85
"Rats" : 15


User Journey
[docs - live editor]
{% mermaid %}
	  journey
    title My working day
    section Go to work
      Make tea: 5: Me
      Go upstairs: 3: Me
      Do work: 1: Me, Cat
    section Go home
      Go downstairs: 5: Me
      Sit down: 3: Me
{% endmermaid %}

  journey
 title My working day
 section Go to work
   Make tea: 5: Me
   Go upstairs: 3: Me
   Do work: 1: Me, Cat
 section Go home
   Go downstairs: 5: Me
   Sit down: 3: Me


plant uml
PlantUML  是一个允许你快速编写一下图表的组件 :

Sequence diagram（时序图）
Usecase diagram
Class diagram（类图）
Activity diagram (here is the legacy syntax)
Component diagram
State diagram
Object diagram
Deployment diagram(BETA)
Timing diagram(BETA)

Hexo 安装 hexo-tag-plantuml 插件，便能使其绘制的图表在博客上展示，其原理其实使用的是 PlantUML 提供的在线服务，只是简单地将标签包裹的代码传给服务器，获取生成的链接，生成 img 标签替换原来的代码区域.

plantUML 在线编辑网站

可使用 HTML 标签将其嵌套
{% plantuml %}
title Relationships - Class Diagram

class Dwelling {
  +Int Windows
  +void LockTheDoor()
}

class Apartment
class House
class Commune
class Window
class Door

Dwelling &lt;|-down- Apartment: Inheritance
Dwelling &lt;|-down- Commune: Inheritance
Dwelling &lt;|-down- House: Inheritance
Dwelling "1" *-up- "many" Window: Composition
Dwelling "1" *-up- "many" Door: Composition
{% endplantuml %}

{% plantuml %}
[内容]
{% endplantuml %}
时序图
 {% plantuml %}
    Bob-&gt;Alice : hello
{% endplantuml %}

Alice -&gt; Bob: Authentication Request
Bob --&gt; Alice: Authentication Response

Alice -&gt; Bob: Another authentication Request
Alice &lt;-- Bob: Another authentication Response

用例图
 {% plantuml %}
User -&gt; (Start)
User --&gt; (Use the application) : A small label

:Main Admin: ---&gt; (Use the application) : This is\nyet another\nlabel
{% endplantuml %}
类图
 {% plantuml %}
class Object &lt;&lt; general &gt;&gt;
Object &lt;|--- ArrayList

note top of Object : In java, every class\nextends this one.

note "This is a floating note" as N1
note "This note is connected\nto several objects." as N2
Object .. N2
N2 .. ArrayList

class Foo
note left: On last defined class
{% endplantuml %}
活动图
 {% plantuml %}
@startuml
start

if (Graphviz 已安装?) then (yes)
  :处理所有\n绘制任务;
else (no)
  :仅处理
  __时序图__ 和 __活动__ 图;
endif

stop
@enduml
{% endplantuml %}

组件图
 {% plantuml %}
@startuml

[First component]
[Another component] as Comp2
component Comp3
component [Last\ncomponent] as Comp4

@enduml
{% endplantuml %}

状态图
 {% plantuml %}
@startuml

[*] --&gt; State1
State1 --&gt; [*]
State1 : this is a string
State1 : this is another string

State1 -&gt; State2
State2 --&gt; [*]

@enduml
{% endplantuml %}

对象图
 {% plantuml %}
@startuml PERT
left to right direction
' Horizontal lines: --&gt;, &lt;--, &lt;--&gt;
' Vertical lines: -&gt;, &lt;-, &lt;-&gt;
title PERT: Project Name

map Kick.Off {
}
map task.1 {
    Start =&gt; End
}
map task.2 {
    Start =&gt; End
}
map task.3 {
    Start =&gt; End
}
map task.4 {
    Start =&gt; End
}
map task.5 {
    Start =&gt; End
}
Kick.Off --&gt; task.1 : Label 1
Kick.Off --&gt; task.2 : Label 2
Kick.Off --&gt; task.3 : Label 3
task.1 --&gt; task.4
task.2 --&gt; task.4
task.3 --&gt; task.4
task.4 --&gt; task.5 : Label 4
@enduml
{% endplantuml %}

部署图
 {% plantuml %}
@startuml
actor actor
agent agent
artifact artifact
boundary boundary
card card
cloud cloud
component component
control control
database database
entity entity
file file
folder folder
frame frame
interface  interface
node node
package package
queue queue
stack stack
rectangle rectangle
storage storage
usecase usecase
@enduml
{% endplantuml %}

URL 卡片


.vkr-url-wrapper {
    padding: 10px;
    border-radius: 5px;
    border: 1px solid;
    border-color: #eee #ddd #bbb;
    box-shadow: rgba(0,0,0,.14) 0 1px 3px;
    margin-bottom: 10px;
    display: flex;
}
.vkr-url-wrapper .desc-wrapper > hr {
    margin: 10px 0;
    height: 1px;
}
.vkr-url-wrapper .avatar {
    width: 100px;
    height: 100px;
    border: solid 1px #eee;
    box-shadow: none!important;
    margin: 0;
    margin-right: 10px;
}
.vkr-url-wrapper h2 {
    border: none;
    margin: 0;
    padding: 0;
}
.vkr-url-wrapper .desc-wrapper {
    flex: 1;
}
.vkr-url-wrapper .desc-wrapper a {
    font-size: 22px;
    font-weight: 700;
}

    
        
    
    
        valkyr ssh manager
        
        valkyr-ssh, a simple commandline tool to help you store ssh login address
    

{% valkyrurl
[url=https://github.com/toastsgithub/valkyr-ssh]
[title="valkyr ssh manager"]
[avatar=http://images2.dzmtoast.top/post-cover/github-logo_hub2899c31b6ca7aed8d6a218f0e752fe4_46649_1200x1200_fill_box_center_2.png]
[desc="valkyr-ssh, a simple commandline tool to help you store ssh login address"]
%}
{% valkyrurl [url=http://example.com] [otherOpt=value] %}

avatar image that describe your link (optional)
title title
desc description
url destination when you click image url or title
 空格要用引号包裹起来！

BILIBILI 卡片

    
        
            
                
                
                    
                
                 52:09:00
            
            
                【PKU】高等数学（全 60 讲)
                
                    
                        
                        26.6 万
                    
                        
                         148
                
                    视频
                    
                    沉迷学习的 PickleFermi
                
                
            
        
    

{% bilicard your_video_id %}
hexo-github-card
{% githubCard user:your_user [repo:your_repo] [width:400] [height:200] [theme:default] [client_id:your_client_id] [client_secret:your_client_secret] [align:text-align_position] %}
{% githubCard user:appotry %}
{% githubCard user:appotry repo:hexo-github-card %}

  




  




  



hexo-douban-card

    
        
        
            
            灯影绰约
        
        
            电影名: 绣春刀 (2014)
            导演: 路阳
            主演: 张震 / 刘诗诗
            上映时间: 2014-08-07 (中国大陆)
            评分: 7.6
        
    


    .douban-card-block {
    display: flex;
    justify-content: center;
    align-items: center;
    width: 100%;
    max-height: 400px;
}

.douban-card {
    display: flex;
    margin: 30px 10px;
    padding: 15px;
    border-radius: 15px;
    position: relative;
    justify-content: center;
    align-items: center;
    overflow: hidden;
    color: antiquewhite;
    text-decoration: none;
}

.douban-card:hover {
    text-decoration: none;
}

.douban-card-bgimg {
    position: absolute;
    width: 115%;
    height: 115%;
    filter: blur(15px) brightness(0.6);
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-img {
    position: relative;
    height: 130px;
    width: 80px;
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-left:hover .douban-card-img {
    filter: blur(5px) brightness(0.6);
    transform: perspective(800px) rotateX(180deg);
}

.douban-card-left .douban-card-img {
    transition: all 500ms ease;
}

.douban-card-left {
    position: relative;
    display: flex;
    flex-direction: column;
    align-items: center;
}

.douban-card-left .douban-card-status {
    height: 130px;
    width: 80px;
    text-align: center;
    font-weight: bold;
    position: absolute;
    left: 0;
    top: 30%;
    transform: rotateX(180deg);
    backface-visibility: hidden;
    transition: all 500ms ease;
}

.douban-card-left:hover .douban-card-status {
    transform: perspective(800px) rotateX(0deg);
}

.douban-card-right {
    position: relative;
    display: flex;
    flex-direction: column;
    margin-left: 12px;
    font-size: 16px;
    font-family: "Courier New", Courier, monospace;
    line-height: 1.3;
    color: antiquewhite;
}

.douban-card-item {
    margin-top: 4px;
}



    
        
        
        
            
            
            见字如晤
        
        
            书名: 一个人生活
            作者: [日] 谷川俊太郎
            出版年份: 2019-3
            评分: 7.1
        
    


    .douban-card-block {
    display: flex;
    justify-content: center;
    align-items: center;
    width: 100%;
    max-height: 400px;
}

.douban-card {
    display: flex;
    margin: 30px 10px;
    padding: 15px;
    border-radius: 15px;
    position: relative;
    justify-content: center;
    align-items: center;
    overflow: hidden;
    color: antiquewhite;
    text-decoration: none;
}

.douban-card:hover {
    text-decoration: none;
}

.douban-card-bgimg {
    position: absolute;
    width: 115%;
    height: 115%;
    filter: blur(15px) brightness(0.6);
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-img {
    position: relative;
    height: 130px;
    width: 80px;
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-left:hover .douban-card-img {
    filter: blur(5px) brightness(0.6);
    transform: perspective(800px) rotateX(180deg);
}

.douban-card-left .douban-card-img {
    transition: all 500ms ease;
}

.douban-card-left {
    position: relative;
    display: flex;
    flex-direction: column;
    align-items: center;
}

.douban-card-left .douban-card-status {
    height: 130px;
    width: 80px;
    text-align: center;
    font-weight: bold;
    position: absolute;
    left: 0;
    top: 30%;
    transform: rotateX(180deg);
    backface-visibility: hidden;
    transition: all 500ms ease;
}

.douban-card-left:hover .douban-card-status {
    transform: perspective(800px) rotateX(0deg);
}

.douban-card-right {
    position: relative;
    display: flex;
    flex-direction: column;
    margin-left: 12px;
    font-size: 16px;
    font-family: "Courier New", Courier, monospace;
    line-height: 1.3;
    color: antiquewhite;
}

.douban-card-item {
    margin-top: 4px;
}



	
		
		
			
            余音绕梁
        
		
			音乐名: María
			表演者: 화사/ 华莎
			发行时间: 2020-06-30
			评分: 8.3
		
	


    .douban-card-block {
    display: flex;
    justify-content: center;
    align-items: center;
    width: 100%;
    max-height: 400px;
}

.douban-card {
    display: flex;
    margin: 30px 10px;
    padding: 15px;
    border-radius: 15px;
    position: relative;
    justify-content: center;
    align-items: center;
    overflow: hidden;
    color: antiquewhite;
    text-decoration: none;
}

.douban-card:hover {
    text-decoration: none;
}

.douban-card-bgimg {
    position: absolute;
    width: 115%;
    height: 115%;
    filter: blur(15px) brightness(0.6);
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-img {
    position: relative;
    height: 130px;
    width: 80px;
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-left:hover .douban-card-img {
    filter: blur(5px) brightness(0.6);
    transform: perspective(800px) rotateX(180deg);
}

.douban-card-left .douban-card-img {
    transition: all 500ms ease;
}

.douban-card-left {
    position: relative;
    display: flex;
    flex-direction: column;
    align-items: center;
}

.douban-card-left .douban-card-status {
    height: 130px;
    width: 80px;
    text-align: center;
    font-weight: bold;
    position: absolute;
    left: 0;
    top: 30%;
    transform: rotateX(180deg);
    backface-visibility: hidden;
    transition: all 500ms ease;
}

.douban-card-left:hover .douban-card-status {
    transform: perspective(800px) rotateX(0deg);
}

.douban-card-right {
    position: relative;
    display: flex;
    flex-direction: column;
    margin-left: 12px;
    font-size: 16px;
    font-family: "Courier New", Courier, monospace;
    line-height: 1.3;
    color: antiquewhite;
}

.douban-card-item {
    margin-top: 4px;
}



{% douban movie 24745500 %}

{% douban book 30376420 %}

{% douban music 35099703 %}
插入音乐和视频


hexo-tag-aplayer
hexo-tag-dplayer
hexo-tag-mmedia 推荐使用


插入音乐

官方教程

 {% aplayer title author url [picture_url, narrow, autoplay, width:xxx, lrc:xxx] %}

title : 曲目标题
author: 曲目作者
url: 音乐文件 URL 地址
picture_url: (可选) 音乐对应的图片地址
narrow: （可选）播放器袖珍风格
autoplay: (可选) 自动播放，移动端浏览器暂时不支持此能
width:xxx: (可选) 播放器宽度 (默认: 100%)
lrc:xxx: （可选）歌词文件 URL #### 单曲附带歌词显示


        
            
        
        
          var ap = new APlayer({
            element: document.getElementById("aplayer-hupTEsyl"),
            narrow: false,
            autoplay: false,
            showlrc: 3,
            music: {
              title: "Hotel California",
              author: "Camille and Kennerly",
              url: "https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.mp3",
              pic: "https://cdn.17lai.site/media/music/Hotel%20California/Hotel%20California.webp",
              lrc: "https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.lrc"
            }
          });
          window.aplayers || (window.aplayers = []);
          window.aplayers.push(ap);
        

#### **音乐播放列表**


{% aplayerlist %}
{
    "narrow": false,                          // （可选）播放器袖珍风格
    "autoplay": true,                         // （可选) 自动播放，移动端浏览器暂时不支持此功能
    "mode": "random",                         // （可选）曲目循环类型，有 'random'（随机播放）, 'single' (单曲播放), 'circulation' (循环播放), 'order' (列表播放)， 默认：'circulation' 
    "showlrc": 3,                             // （可选）歌词显示配置项，可选项有：1,2,3
    "mutex": true,                            // （可选）该选项开启时，如果同页面有其他 aplayer 播放，该播放器会暂停
    "theme": "#e6d0b2",	                      // （可选）播放器风格色彩设置，默认：#b7daff
    "preload": "metadata",                    // （可选）音乐文件预载入模式，可选项： 'none' 'metadata' 'auto', 默认: 'auto'
    "listmaxheight": "513px",                 // (可选) 该播放列表的最大长度
    "music": [
        {
            "title": "CoCo",
            "author": "Jeff Williams",
            "url": "caffeine.mp3",
            "pic": "caffeine.jpeg",
            "lrc": "caffeine.txt"
        },
        {
            "title": "アイロニ",
            "author": "鹿乃",
            "url": "irony.mp3",
            "pic": "irony.jpg"
        }
    ]
}
{% endaplayerlist %}


        
			  
				  var options = {"narrow":false,"autoplay":true,"showlrc":3,"mode":"random","mutex":true,"theme":"#e6d0b2","preload":"metadata","listmaxheight":"513px","music":[{"title":"Hotel California","author":"Camille and Kennerly","url":"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.mp3","pic":"https://cdn.17lai.site/media/music/Hotel%20California/Hotel%20California.webp","lrc":"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.lrc"},{"title":"Sold Out","author":"Diamonds","url":"https://cdn.17lai.site/media/music/Diamonds/05%20Sold%20Out.flac","pic":"https://cdn.17lai.site/media/music/Diamonds/Diamonds.jpg"}]};
				  options.element = document.getElementById("aplayer-ZQWKcKWf");
				  var ap = new APlayer(options);
			    window.aplayers || (window.aplayers = []);
				  window.aplayers.push(ap);
			  
插入视频

官方教程

 {% dplayer key=value ... %}
例：
{% dplayer "url=http://www.nenu.edu.cn/_upload/article/videos/03/5f/7c999eed42e3aadc413d7f851f0e/0f50b3eb-9285-41d2-ac4d-6cc363651aad_B.mp4"  "autoplay=true" "preload=metadata" "hotkey=true" %} 
有关的选项列表如下:



选项
默认值
描述




 url
 必须值
视频地址


 loop
false
视频循环播放


 volume
0.7
播放器音量


 hotkey
true
开启热键


 autoplay
true
自动播放，移动端浏览器暂时不支持此功能


 logo
-
在左上角展示一个 logo，你可以通过 CSS 调整它的大小和位置


 mutex
true
该选项开启时，如果同页面有其他播放，该播放器会暂停


 highlight
[]
自定义进度条提示点


 preload
auto
视频文件预载入模式，可选项： none, metadata, auto


theme
#ad7a86
播放器风格色彩设置



注：如果使用腾讯视频、优酷视频等在线视频网站的资源，需要先进行视频地址解析，如点量视频解析，获取到实际的视频地址。
在使用优酷或者腾讯视频时可以直接复制分享代码到文章中，如：
&lt;iframe height=498 width=510 src='https://player.youku.com/embed/XMjk4ODAyMzIyOA==' frameborder=0 'allowfullscreen'&gt;&lt;/iframe&gt;

dplayer

{% dplayer "url=http://www.nenu.edu.cn/_upload/article/videos/03/5f/7c999eed42e3aadc413d7f851f0e/0f50b3eb-9285-41d2-ac4d-6cc363651aad_B.mp4"  "autoplay=false" "preload=metadata" "hotkey=true" %} 

iframe

&lt;iframe height=498 width=510 src='https://player.youku.com/embed/XMjk4ODAyMzIyOA==' frameborder=0 'allowfullscreen'&gt;&lt;/iframe&gt;
hexo-tag-mmedia 使用

官方教程

audio

此部分请熟读 Audio 相关介绍
目前主题中不可用


使用 : 或 = 分割。
所有 &lt;audio&gt; 标签的原生参数均可添加，只要能写进去就可以。
具体能否实现相关标准，取决于客户端浏览器。

{% mmedia "audio" "src:a.mp3" %}
{% mmedia "audio" "src:https://baidu.com/a.mp3" "autoplay:true" %}
video

此部分请熟读 Video 相关介绍
目前主题中不可用


使用 : 或 = 分割。
所有 &lt;video&gt; 标签的原生参数均可添加，只要能写进去就可以。
具体能否实现相关标准，取决于客户端浏览器。

{% mmedia "video" "src:a.mp4" %}
{% mmedia "video" "src:https://baidu.com/a.mp4" "autoplay:true" %}
MetingJS

此部分请熟读 MetingJS 文档




 option
default
description




id
require
song id / playlist id / album id / search keyword


server
require
music platform: netease, tencent, kugou, xiami, baidu


type
require
song, playlist, album, search, artist


auto
options
music link, support: netease, tencent, xiami


fixed
false
enable fixed mode


mini
false
enable mini mode


autoplay
false
audio autoplay


theme
#2980b9
main color


loop
all
player loop play, values: ‘all’, ‘one’, ‘none’


order
list
player play order, values: ‘list’, ‘random’


preload
auto
values: ‘none’, ‘metadata’, ‘auto’


volume
0.7
default volume, notice that player will remember user setting, default volume will not work after user set volume themselves


mutex
true
prevent to play multiple player at the same time, pause other players when this player start play


lrc-type
0
lyric type


list-folded
false
indicate whether list should folded at first


list-max-height
340px
list max height


storage-name
metingjs
localStorage key that store player setting



Documentation for APlayer can be found at https://aplayer.js.org/#/home?id=options
单曲
{% mmedia "meting" "auto=https://y.qq.com/n/ryqq/songDetail/0005RQAO3FqG5K" %}


{% mmedia "meting" "auto=https://y.qq.com/n/yqq/song/001RGrEX3ija5X.html" %}

{% mmedia "meting" "server=netease"	"type=playlist"	"id=60198" %}

#### **Aplayer**

详细参数表：

| 参数           | 默认   | 解释                                           |
| :------------- | :----- | :--------------------------------------------- |
| name           | -      | audio name                                     |
| artist         | -      | audio artist                                   |
| url            | -      | audio url                                      |
| cover          | -      | audio cover                                    |
| lrc            | -      | audio lrc                                      |
| theme          | -      | audio theme                                    |
| type           | auto   | audio type 可选 ‘auto’, ‘hls’, ‘normal’        |
| autoplay       | false  | autoplay                                       |
| loop           | ‘all’  | player loop play, values: ‘all’, ‘one’, ‘none’ |
| order          | ‘list’ | player play order, values: ‘list’, ‘random’    |
| volume         | 0.7    | default volume,                                |
| tlistMaxHeight | -      | list max height                                |

不在表格内的参数请使用下面 JSON 类型的参数。

mmedia 插件允许在 contents 部分使用 JSON 编写配置，由于允许使用 JSON5，此项配置几乎与 APlayer 完全一致。

- **单曲**

{% mmedia "aplayer" "name:Hotel California" "artist:Camille and Kennerly" "url:https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.mp3" "lrc:https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.lrc" "cover:https://cdn.17lai.site/media/music/Hotel%20California/Hotel%20California.webp" "volume:0.66" %}



 var pmkEwnuKBKdJkPZV_options = JSON.parse('{\"lrcType\":3,\"volume\":0.66,\"autoplay\":false,\"audio\":[{\"name\":\"Hotel California\",\"artist\":\"Camille and Kennerly\",\"url\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.mp3\",\"lrc\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.lrc\",\"cover\":\"https://cdn.17lai.site/media/music/Hotel%20California/Hotel%20California.webp\"}]}'); pmkEwnuKBKdJkPZV_options.container = document.getElementById("mmedia-pmkEwnuKBKdJkPZV"); const ap_pmkEwnuKBKdJkPZV = new APlayer(pmkEwnuKBKdJkPZV_options); 

- **列表**

 var nCSfYCovgunkebTx_options = JSON.parse('{\"lrcType\":3,\"volume\":0.8,\"autoplay\":false,\"audio\":[{\"name\":\"Hotel California\",\"artist\":\"Camille and Kennerly\",\"url\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.mp3\",\"cover\":\"https://cdn.17lai.site/media/music/Hotel%20California/Hotel%20California.webp\",\"lrc\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.lrc\",\"theme\":\"#ebd0c2\"},{\"name\":\"Sold Out\",\"artist\":\"Diamonds\",\"url\":\"https://cdn.17lai.site/media/music/Diamonds/05%20Sold%20Out.flac\",\"cover\":\"https://cdn.17lai.site/media/music/Diamonds/Diamonds.jpg\",\"theme\":\"#ebd0c2\"},{\"name\":\"The Final Bell\",\"artist\":\"Rocky_Original Motion Picture Score\",\"url\":\"https://cdn.17lai.site/media/music/Rocky_%20Original%20Motion%20Picture%20Score/12%20Bill%20Conti%20-%20The%20Final%20Bell.mp3\",\"cover\":\"https://cdn.17lai.site/media/music/Rocky_%20Original%20Motion%20Picture%20Score/Rocky_%20Original%20Motion%20Picture%20Score.jpg\",\"theme\":\"#ebd0c2\"},{\"name\":\" Croatian Rhapsody\",\"artist\":\"The Piano Player\",\"url\":\"https://cdn.17lai.site/media/music/The%20Piano%20Player/11%20Croatian%20Rhapsody.mp3\",\"cover\":\"https://cdn.17lai.site/media/music/The%20Piano%20Player/The%20Piano%20Player.jpg\",\"theme\":\"#ebd0c2\"}]}'); nCSfYCovgunkebTx_options.container = document.getElementById("mmedia-nCSfYCovgunkebTx"); const ap_nCSfYCovgunkebTx = new APlayer(nCSfYCovgunkebTx_options); 
例子
{% mmedias "aplayer" "autoplay:false" %}
{
  "volume": 0.8,
  "audio":
  [
    {
      "name": "name1",
      "artist": "artist1",
      "url": "url1.mp3",
      "cover": "cover1.jpg",
      "lrc": "lrc1.lrc",
      "theme": "#ebd0c2"
    },
    {
      "name": "name2",
      "artist": "artist2",
      "url": "url2.mp3",
      "cover": "cover2.jpg",
      "lrc": "lrc2.lrc",
      "theme": "#46718b"
    }
  ]
}
{% endmmedias %}
Dplayer

此部分请熟读 DPlayer 文档

 {% mmedia "dplayer" "url:a.mp4" %}
{% mmedias "dplayer" "flv:" "url:https://dandoc.u2sb.com/video/%E5%AE%89%E8%A3%85/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85.mp4" %}
{
  "contextmenu":
  [
    {
      text: "custom1",
      link: "https://github.com/DIYgod/DPlayer"
    }
  ]
}
{% endmmedias %}
{% mmedia "dplayer" "url:https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4" %}
 var izNLFKoMKZnsnkFi_options = JSON.parse('{\"video\":{\"url\":\"https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4\"}}'); izNLFKoMKZnsnkFi_options.container = document.getElementById("mmedia-izNLFKoMKZnsnkFi"); const dp_izNLFKoMKZnsnkFi = new DPlayer(izNLFKoMKZnsnkFi_options); 

{% mmedias "dplayer" %}
{
  video: 
  {
    url: "https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4"
  }
}
{% endmmedias %}

#### 哔哩哔哩

详细参数表：

| 参数            | 默认                                               | 解释                                                    |
| :-------------- | :------------------------------------------------- | :------------------------------------------------------ |
| aid             | -                                                  | aid                                                     |
| bvid            | -                                                  | bvid，与 aid 同时出现时以 bvid 为准                     |
| page            | 1                                                  | page                                                    |
| danmaku         | true                                               | 是否有弹幕 ture or false                                |
| allowfullscreen | allowfullscreen                                    | 允许全屏， allowfullscreen 或 true 允许，其他选项不允许 |
| sandbox         | 见 [配置](https://www.u2sb.com/pages/19d343/#配置) | iframe sandbox                                          |
| width           | 100%                                               | css 属性                                                |
| max_width       | 850px                                              | css 属性                                                |
| margin          | auto                                               | css 属性                                                |

mmedia 插件允许在 contents 部分使用 JSON 编写配置，使用 JSON5 标准。

.bbplayer{width: 100%; max-width: 850px; margin: auto} document.getElementById("mmedia-PnwtkuzWhJkBrivq").style.height=document.getElementById("mmedia-PnwtkuzWhJkBrivq").scrollWidth*0.76+"px";
    window.onresize = function(){
      document.getElementById("mmedia-PnwtkuzWhJkBrivq").style.height=document.getElementById("mmedia-PnwtkuzWhJkBrivq").scrollWidth*0.76+"px";
    }; 

{% mmedia "bilibili" "bvid:BV1fs411S7u7" %}

#### 西瓜视频

{% mmedia "xigua" "xid=6925997698269053453" %}

{% mmedia "xigua" "xid:6925997698269053453" "autoplay:true" %}

详细参数表：

| 参数            | 默认                                               | 解释                                                    |
| :-------------- | :------------------------------------------------- | :------------------------------------------------------ |
| xid             | -                                                  | 西瓜视频的 ID，就是那一串数字                           |
| id              | -                                                  | 一般情况下不需要填写                                    |
| autoplay        | false                                              | autoplay                                                |
| startTime       | 0                                                  | 开始时间，秒                                            |
| allowfullscreen | allowfullscreen                                    | 允许全屏， allowfullscreen 或 true 允许，其他选项不允许 |
| sandbox         | 见 [配置](https://www.u2sb.com/pages/a0c4a7/#配置) | iframe sandbox                                          |
| width           | 100%                                               | css 属性                                                |
| max_width       | 850px                                              | css 属性                                                |
| margin          | auto                                               | css 属性                                                |

.xgplayer{width: 100%; max-width: 850px; margin: auto} document.getElementById("mmedia-XIqMUMYsCGERhngD").style.height=document.getElementById("mmedia-XIqMUMYsCGERhngD").scrollWidth*0.7+"px";
    window.onresize = function(){
      document.getElementById("mmedia-XIqMUMYsCGERhngD").style.height=document.getElementById("mmedia-XIqMUMYsCGERhngD").scrollWidth*0.7+"px";
    }; 

{% mmedia "xigua" "xid=6925997698269053453" %}

#### ArtPlayer

&gt; 此部分请熟读 [ArtPlayer 文档](https://artplayer.org/document/#/options)

- 使用 `:` 或 `=` 分割。

详细参数表：

| 参数     | 默认  | 解释           |
| :------- | :---- | :------------- |
| url      | -     | url            |
| title    | -     | title          |
| poster   | -     | poster         |
| type     | -     | type           |
| autoplay | false | video autoplay |
| loop     | false | video loop     |
| volume   | 0.7   | default volume |
| style    | -     | style          |

上面有一个比较特殊的参数 flv，这里单独解释一下，这个参数是用于引入其他 js 文件的，目前支持的有： `hls` `dash` `shaka_dash` `flv` `webtorrent` ，上述参数可多个一起使用，如果后面带有 js 地址，将直接使用，否则将使用 `_config.yml` 配置或插件默认配置，如：

{% mmedia "artplayer" "flv:" "url:a.flv" %}

{% mmedias "artplayer" "flv:" "hls:https://cdn.jsdelivr.net/npm/hls.js/dist/hls.min.js" %}
{
  ...
}
{% endmmedias %}

{% mmedia "artplayer" "url:https://dandoc.u2sb.com/video/%E5%AE%89%E8%A3%85/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85.mp4" %}

{% mmedias "artplayer" "flv:"  %}
{
  url: "https://dandoc.u2sb.com/video/%E5%AE%89%E8%A3%85/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85.mp4"
}
{% endmmedias %}

{% mmedia "artplayer" "url:https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_2mb.mp4" %}

 var UPSjHUyhFogCiWHF_options = JSON.parse('{\"style\":\"width:100%;height:650px;max-width:1200px;center\",\"autoSize\":true,\"autoMini\":true,\"fullscreen\":true,\"fullscreenWeb\":true,\"url\":\"https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_2mb.mp4\"}'); UPSjHUyhFogCiWHF_options.container = "#mmedia-UPSjHUyhFogCiWHF"; const art_UPSjHUyhFogCiWHF = new Artplayer(UPSjHUyhFogCiWHF_options); 
{% mmedias "artplayer" %}
{
  url: "https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_2mb.mp4"
}
{% endmmedias %}
脑图

原作者记录


    
      
    
  
 {% markmap 250px %}
# 思维导图？
## 使用现有的插件或组件？
### Mermaid：更偏向流程图
### Kityminder
#### 现成hexo插件有些小问题。
#### 二次开发，失败
## 找寻相关项目？
### Markmap大法！
#### 直接弄，失败
#### 使用jsdom，失败
#### 寻找现成库，成功
## 咕咕咕咕咕咕咕咕咕咕咕咕
## 凑一下行数让版面好看点
{% endmarkmap %}
系列教程
hexo 系列

hexo 独立博客搭建 [三万字教程] 基于 Hexo 的 matery 主题搭建博客并深度优化



 docker 环境
 hexo 使用入门
 hexo 基础配置
自定义修改
 hexo 部署
个性定义
性能优化
常见问题 



Hexo Markdown 以及各种插件功能测试



 markdown 各种其它语法插件
 latex 公式支持
 mermaid 图表
 plant uml 图表
 URL 卡片
 bilibili 卡片
 github 卡片
豆瓣卡片
插入音乐和视频
插入脑图


笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin





Here is the footnote. ↩︎

Here's one with multiple blocks.
Subsequent paragraphs are indented to show that they ↩︎




    .markmap-container{display:flex;justify-content:center;margin:0 auto;width:90%;height:500px}.markmap-container svg{width:100%;height:100%}@media(max-width:768px){.markmap-container{height:400px}}
    
    
     document.querySelectorAll('.markmap-container>svg').forEach(mindmap => markmap.Markmap.create(mindmap, null, JSON.parse(mindmap.getAttribute('data'))))
  ]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>mermaid</tag>
        <tag>plantuml</tag>
        <tag>mathjax</tag>
      </tags>
  </entry>
  <entry>
    <title>CI/CD 与 Git Flow 与 GitLab</title>
    <url>/posts/1879721e/</url>
    <content><![CDATA[
CI/CD + Git Flow + GitLab 的整体工作流程记录。主要介绍一下 GitLab CI 相关功能，并通过 GitLab CI 实现自动化构建项目。项目中所用的示例项目已经上传到了 GitHub

一、Git Flow 简介
Git Flow 定义了一个围绕项目开发发布的严格 git 分支模型，用于管理多人协作的大型项目中实现高效的协作开发；Git Flow 分支模型最早起源于 Vincent Driessen 的 A successful Git branching model 文章；随着时间发展，Git Flow 大致分为三种:

Git Flow: 最原始的 Git Flow 分支模型
 Github Flow: Git Flow 的简化版，专门配合持续发布
 GitLab Flow: Git Flow 与 Github Flow 的结合版

关于三种 Git Flow 区别详情可参考 Git 工作流程
二、 Git Flow 流程
Github Flow 和 GitLab Flow 对于持续发布支持比较好，但是原始版本的 Git Flow 对于传统的按照版本发布更加友好一些，所以以下主要说明以下 Git Flow 的工作流程；Git Flow 主要分支模型如下

在整个分支模型中 存在两个长期分支: develop 和 master，其中 develop 分支为开发分支，master 为生产分支；master 代码始终保持随时可以部署到线上的状态；develop 分支用于合并最新提交的功能性代码；具体的分支定义如下

master: 生产代码，始终保持可以直接部署生产的状态
 develop: 开发分支，每次合并最新功能代码到此分支
 feature: 新功能分支，所有新开发的功能将采用 feature/xxxx 形式命名分支
 hotfixes: 紧急修复补丁分支，当新功能部署到了线上出现了严重 bug 需要紧急修复时，则创建 hotfixes/xxxx 形式命名的分支
 release: 稳定版分支，当完成大版本变动后，应该创建 release/xxxx 分支

在整个分支模型中，develop 分支为最上游分支，会不断有新的 feature 合并入 develop 分支，当功能开发达到完成所有版本需求时，则从 develop 分支创建 release 分支，release 后如没有发现其他问题，最终 release 会被合并到 master 分支以完成线上部署
三、Git Flow 工具
针对于 Git Flow，其手动操作 git 命令可能过于繁琐，所以后来有了 git-flow 工具；git-flow 是一个 git 扩展集，按 Vincent Driessen 的分支模型提供高层次的库操作；使用 git-flow 工具可以以更加简单的命令完成对 Vincent Driessen 分支模型的实践；
git-flow 安装以及使用具体请参考 git-flow 备忘清单，该文章详细描述了 git-flow 工具的使用方式
还有另一个工具是 git-extras，该工具没有 git-flow 那么简单化，不过其提供更加强大的命令支持
四、Git Commit Message
在整个 Git Flow 中，commit message 也是必不可少的一部分；一个良好且统一的 commit message 有助于代码审计以及 review 等；目前使用最广泛的写法是 Angular 社区规范，该规范大中 commit message 格式大致如下:
&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;
&lt;BLANK LINE&gt;
&lt;body&gt;
&lt;BLANK LINE&gt;
&lt;footer&gt;Copy
总体格式大致分为 3 部分，首行主要 3 个组成部分:

type: 本次提交类型
 scope: 本次提交影响范围，一般标明影响版本号或者具体的范围如 $browser, $compile, $rootScope, ngHref, ngClick, ngView, etc...
subject: 本次提交简短说明

关于 type 提交类型，有如下几种值:

feat：新功能 (feature)
fix：修补 bug
docs：文档 (documentation)
style： 格式 (不影响代码运行的变动)
refactor：重构 (即不是新增功能，也不是修改 bug 的代码变动)
test：增加测试
 chore：构建过程或辅助工具的变动

中间的 body 部分是对本次提交的详细描述信息，底部的 footer 部分一般分为两种情况:

不兼容变动：如果出现不兼容变动，则以 BREAKING CHANGE: 开头，后面跟上不兼容变动的具体描述和解决办法
关闭 issue: 如果该 commit 针对某个 issue，并且可以将其关闭，则可以在其中指定关闭的 issue，如 Close #9527,#9528

不过 footer 部分也有特殊情况，如回滚某次提交，则以 revert: 开头，后面紧跟 commit 信息和具体描述；还有时某些 commit 只是解决了 某个 issue 的一部分问题，这是可以使用 refs ISSUE 的方式来引用该 issue
五、Git Commit Message 工具
针对 Git 的 commit message 目前已经有了成熟的生成工具，比较有名的为 commitizen-cli 工具，其采用 node.js 编写，执行 git cz 命令能够自动生成符合 Angular 社区规范的 commit message；不过由于其使用 node.js 编写，所以安装前需要安装 node.js，因此可能不适合其他非 node.js 的项目使用；这里推荐一个基于 shell 编写的 Git-toolkit，安装此工具后执行 git ci 命令进行提交将会产生交互式生成 Angular git commit message 格式的提交说明，截图如下:

六、GitLab 整合
以上 Git Flow 所有操作介绍的都是在本地操作，而正常我们在工作中都是基于 GitLab 搭建私有 Git 仓库来进行协同开发的，以下简述以下 Git Flow 配合 GitLab 的流程
6.1、开发 features
当开发一个新功能时流程如下:

本地 git flow feature start xxxx 开启一个 feature 新分支
git flow feature publish xxxx 将此分支推送到远端以便他人获取
完成开发后 GitLab 上向 develop 分支发起合并请求
 CI sonar 等质量检测工具扫描，其他用户 review 代码
确认无误后 master 权限用户合并其到 develop 分支
部署到测试环境以便测试组测试
如果测试不通过，则继续基于此分支开发，直到该功能开发完成

6.2、创建 release
当一定量的 feature 开发完成并合并到 develop 后，如所有 feature 都测试通过并满足版本需求，则可以创建 release 版本分支；release 分支流程如下

本地 git flow release start xxxx 开启 release 分支
git flow release publish xxxx 将其推送到远端以便他人获取
继续进行完整性测试，出现问题继续修复，直到 release 完全稳定
从 release 分支向 master、develop 分支分别发起合并请求
 master 合并后创建对应的 release 标签，并部署生产环境
 develop 合并 release 的后期修改

6.3、紧急修复
当 master 某个 tag 部署到生产环境后，也可能出现不符合预期的问题出现；此时应该基于 master 创建 hotfix 分支进行修复，流程如下

本地 git flow hotfix start xxxx 创建紧急修复分支
修改代码后将其推送到远端，并像 master、develop 分支发起合并
 develop 合并紧急修复补丁，如果必要最好再做一下测试
 master 合并紧急修复补丁，创建紧急修复 tag，并部署生产环境

七、环境准备
首先需要有一台 GitLab 服务器，然后需要有个项目；这里示例项目以 Spring Boot 项目为例，然后最好有一台专门用来 Build 的机器，实际生产中如果 Build 任务不频繁可适当用一些业务机器进行 Build；本文示例所有组件将采用 Docker 启动， GitLab HA 等不在本文阐述范围内

Docker Version : 1.13.1
GitLab Version : 10.1.4-ce.0
GitLab Runner Version : 10.1.0
GitLab IP : 172.16.0.37
GitLab Runner IP : 172.16.0.36

八、GitLab CI 简介
GitLab CI 是 GitLab 默认集成的 CI 功能，GitLab CI 通过在项目内 .gitlab-ci.yaml 配置文件读取 CI 任务并进行相应处理；GitLab CI 通过其称为 GitLab Runner 的 Agent 端进行 build 操作；Runner 本身可以使用多种方式安装，比如使用 Docker 镜像启动等；Runner 在进行 build 操作时也可以选择多种 build 环境提供者；比如直接在 Runner 所在宿主机 build、通过新创建虚拟机 (vmware、virtualbox) 进行 build 等；同时 Runner 支持 Docker 作为 build 提供者，即每次 build 新启动容器进行 build；GitLab CI 其大致架构如下

九、搭建 GitLab 服务器
9.1、GitLab 搭建
GitLab 搭建这里直接使用 docker compose 启动，compose 配置如下
version: '2'
services:
  gitlab:
    image: 'gitlab/gitlab-ce:10.1.4-ce.0'
    restart: always
    container_name: gitlab
    hostname: 'git.mritd.me'
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://git.mritd.me'
        # Add any other gitlab.rb configuration here, each on its own line
    ports:
      - '80:80'
      - '443:443'
      - '8022:22'
    volumes:
      - './data/gitlab/config:/etc/gitlab'
      - './data/gitlab/logs:/var/log/gitlab'
      - './data/gitlab/data:/var/opt/gitlab'Copy
直接启动后，首次登陆需要设置初始密码如下，默认用户为 root

登陆成功后创建一个用户 (该用户最好给予 Admin 权限，以后操作以该用户为例)，并且创建一个测试 Group 和 Project，如下所示


9.2、增加示例项目
这里示例项目采用 Java 的 SpringBoot 项目，并采用 Gradle 构建，其他语言原理一样；如果不熟悉 Java 的没必要死磕此步配置，任意语言 (最好 Java) 整一个能用的 Web 项目就行，并不强求一定 Java 并且使用 Gradle 构建，以下只是一个样例项目；SpringBoot 可以采用 Spring Initializr 直接生成 (依赖要加入 WEB)，如下所示

将项目导入 IDEA，然后创建一个 index 示例页面，主要修改如下

build.gradle

buildscript {
    ext {
        springBootVersion = '1.5.8.RELEASE'
    }
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath("org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}")
    }
}

apply plugin: 'java'
apply plugin: 'eclipse'
apply plugin: 'idea'
apply plugin: 'org.springframework.boot'

group = 'me.mritd'
version = '0.0.1-SNAPSHOT'
sourceCompatibility = 1.8

repositories {
    mavenCentral()
}


dependencies {
    compile('org.springframework.boot:spring-boot-starter')
    compile('org.springframework.boot:spring-boot-starter-web')
    compile('org.springframework.boot:spring-boot-starter-thymeleaf')
    testCompile('org.springframework.boot:spring-boot-starter-test')
}Copy

新建一个 HomeController

package me.mritd.TestProject;

import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.RequestMapping;

/*******************************************************************************
 * Copyright (c) 2005-2017 Mritd, Inc.
 * TestProject
 * me.mritd.TestProject
 * Created by mritd on 2017/11/24 下午12:23.
 * Description: 
 *******************************************************************************/
@Controller
public class HomeController {

    @RequestMapping("/")
    public String home(){
        return "index";
    }
}Copy

templates 下新建 index.html

&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"/&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Test...&lt;/h1&gt;
&lt;/body&gt;
&lt;/html&gt;Copy
最后项目整体结构如下

执行 assemble Task 打包出可执行 jar 包，并运行 java -jar TestProject-0.0.1-SNAPSHOT.jar 测试下能启动访问页面即可

最后将项目提交到 GitLab 后如下

十、GitLab CI 配置

针对这一章节创建基础镜像以及项目镜像，这里仅以 Java 项目为例；其他语言原理相通，按照其他语言对应的运行环境修改即可

10.1、增加 Runner
GitLab CI 在进行构建时会将任务下发给 Runner，让 Runner 去执行；所以先要添加一个 Runner，Runner 这里采用 Docker Compose 启动，build 方式也使用 Docker 方式 Build；compose 文件如下
version: '2'
services:
  gitlab-runner:
    container_name: gitlab-runner
    image: gitlab/gitlab-runner:alpine-v10.1.0
    restart: always
    network_mode: "host"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./config.toml:/etc/gitlab-runner/config.toml
    extra_hosts:
      - "git.mritd.me:172.16.0.37"Copy
在启动前，我们需要先 touch 一下这个 config.toml 配置文件；该文件是 Runner 的运行配置，此后 Runner 所有配置都会写入这个文件 (不 touch 出来 docker-compose 发现不存在会挂载一个目录进去，导致 Runner 启动失败)；启动 docker-compose 后，需要进入容器执行注册，让 Runner 主动去连接 GitLab 服务器
# 生成 Runner 配置文件
touch config.toml
# 启动 Runner
docker-compose up -d
# 激活 Runner
docker exec -it gitlab-runner gitlab-runner registerCopy
在执行上一条激活命令后，会按照提示让你输入一些信息；首先输入 GitLab 地址，然后是 Runner Token，Runner Token 可以从 GitLab 设置中查看，如下所示

整体注册流程如下

注册完成后，在 GitLab Runner 设置中就可以看到刚刚注册的 Runner，如下所示

Runner 注册成功后会将配置写入到 config.toml 配置文件；由于两个测试宿主机都没有配置内网 DNS，所以为了保证 runner 在使用 docker build 时能正确的找到 GitLab 仓库地址，还需要增加一个 docker 的 host 映射 ( extra_hosts )；同时为了能调用 宿主机 Docker 和持久化 build 的一些缓存还挂载了一些文件和目录；完整的 配置如下 (配置文件可以做一些更高级的配置，具体参考 官方文档 )

config.toml

concurrent = 1
check_interval = 0

[[runners]]
  name = "Test Runner"
  url = "http://git.mritd.me"
  token = "c279ec1ac08aec98c7141c7cf2d474"
  executor = "docker"
  builds_dir = "/gitlab/runner-builds"
  cache_dir = "/gitlab/runner-cache"
  [runners.docker]
    tls_verify = false
    image = "debian"
    privileged = false
    disable_cache = false
    shm_size = 0
    volumes = ["/data/gitlab-runner:/gitlab","/var/run/docker.sock:/var/run/docker.sock","/data/maven_repo:/data/repo","/data/maven_repo:/data/maven","/data/gradle:/data/gradle","/data/sonar_cache:/root/.sonar","/data/androidsdk:/usr/local/android","/data/node_modules:/data/node_modules"]
    extra_hosts = ["git.mritd.me:172.16.0.37"]
  [runners.cache]Copy
注意，这里声明的 Volumes 会在每个运行的容器中都生效；也就是说 build 时新开启的每个容器都会被挂载这些目录；修改完成后重启 runner 容器即可，由于 runner 中没啥可保存的东西，所以可以直接 docker-compose down &amp;&amp; docker-compose up -d 重启
10.2、创建基础镜像
由于示例项目是一个 Java 项目，而且是采用 Spring Boot 的，所以该项目想要运行起来只需要一个 java 环境即可，中间件已经被打包到了 jar 包中；以下是一个作为基础运行环境的 openjdk 镜像的 Dockerfile
FROM alpine:edge 

LABEL maintainer="mritd &lt;mritd1234@gmail.com&gt;"

ENV JAVA_HOME /usr/lib/jvm/java-1.8-openjdk
ENV PATH $PATH:/usr/lib/jvm/java-1.8-openjdk/jre/bin:/usr/lib/jvm/java-1.8-openjdk/bin

RUN apk add --update bash curl tar wget ca-certificates unzip \
        openjdk8 font-adobe-100dpi ttf-dejavu fontconfig \
    &amp;&amp; rm -rf /var/cache/apk/* \

CMD ["bash"]Copy
这个 openjdk Dockerfile 升级到了 8.151 版本，并且集成了一些字体相关的软件，以解决在 Java 中某些验证码库无法运行问题，详见 Alpine 3.6 OpenJDK 8 Bug；使用这个 Dockerfile，在当前目录执行 docker build -t mritd/openjdk:8 . build 一个 openjdk8 的基础镜像，然后将其推送到私服，或者 Docker Hub 即可
10.3、创建项目镜像
有了基本的 openjdk 的 docker 镜像后，针对于项目每次 build 都应该生成一个包含发布物的 docker 镜像，所以对于项目来说还需要一个项目本身的 Dockerfile；项目的 Dockerfile 有两种使用方式；一种是动态生成 Dockerfile，然后每次使用新生成的 Dockerfile 去 build；还有一种是写一个通用的 Dockerfile，build 时利用 ARG 参数传入变量；这里采用第二种方式，以下为一个可以反复使用的 Dockerfile
FROM mritd/openjdk:8-144-01

MAINTAINER mritd &lt;mritd1234@gmail.com&gt;

ARG PROJECT_BUILD_FINALNAME

ENV TZ 'Asia/Shanghai'
ENV PROJECT_BUILD_FINALNAME ${PROJECT_BUILD_FINALNAME}


COPY build/libs/${PROJECT_BUILD_FINALNAME}.jar /${PROJECT_BUILD_FINALNAME}.jar

CMD ["bash","-c","java -jar /${PROJECT_BUILD_FINALNAME}.jar"]Copy
该 Dockerfile 通过声明一个 PROJECT_BUILD_FINALNAME 变量来表示项目的发布物名称；然后将其复制到根目录下，最终利用 java 执行这个 jar 包；所以每次 build 之前只要能拿到项目发布物的名称即可
10.4、Gradle 修改
上面已经创建了一个标准的通用型 Dockerfile，每次 build 镜像只要传入 PROJECT_BUILD_FINALNAME 这个最终发布物名称即可；对于发布物名称来说，最好不要固定死；当然不论是 Java 还是其他语言的项目我们都能将最终发布物变成一个固定名字，最不济可以写脚本重命名一下；但是不建议那么干，最好保留版本号信息，以便于异常情况下进入容器能够分辨；对于当前 Java 项目来说，想要拿到 PROJECT_BUILD_FINALNAME 很简单，我们只需要略微修改一下 Gradle 的 build 脚本，让其每次打包 jar 包时将项目的名称及版本号导出到文件中即可；同时这里也加入了镜像版本号的处理，Gradle 脚本修改如下

build.gradle 最后面增加如下 

bootRepackage {

    mainClass = 'me.mritd.TestProject.TestProjectApplication'
    executable = true

    doLast {
        File envFile = new File("build/tmp/PROJECT_ENV")

        println("Create ${archivesBaseName} ENV File ===&gt; " + envFile.createNewFile())
        println("Export ${archivesBaseName} Build Version ===&gt; ${version}")
        envFile.write("export PROJECT_BUILD_FINALNAME=${archivesBaseName}-${version}\n")

        println("Generate Docker image tag...")
        envFile.append("export BUILD_DATE=`date +%Y%m%d%H%M%S`\n")
        envFile.append("export IMAGE_NAME=mritd/test:`echo \${CI_BUILD_REF_NAME} | tr '/' '-'`-`echo \${CI_COMMIT_SHA} | cut -c1-8`-\${BUILD_DATE}\n")
        envFile.append("export LATEST_IMAGE_NAME=mritd/test:latest\n")
    }
}Copy
这一步操作实际上是修改了 bootRepackage 这个 Task (不了解 Gradle 或者不是 Java 项目的请忽略)，在其结束后创建了一个叫 PROJECT_ENV 的文件，里面实际上就是写入了一些 bash 环境变量声明，以方便后面 source 一下这个文件拿到一些变量，然后用户 build 镜像使用，PROJECT_ENV 最终生成如下
export PROJECT_BUILD_FINALNAME=TestProject-0.0.1-SNAPSHOT
export BUILD_DATE=`date +%Y%m%d%H%M%S`
export IMAGE_NAME=mritd/test:`echo ${CI_BUILD_REF_NAME} | tr '/' '-'`-`echo ${CI_COMMIT_SHA} | cut -c1-8`-${BUILD_DATE}
export LATEST_IMAGE_NAME=mritd/test:latestCopy

10.5、创建 CI 配置文件
一切准备就绪以后，就可以编写 CI 脚本了；GitLab 依靠读取项目根目录下的 .gitlab-ci.yml 文件来执行相应的 CI 操作；以下为测试项目的 .gitlab-ci.yml 配置
# 调试开启
#before_script:
#  - pwd
#  - env

cache:
  key: $CI_PROJECT_NAME/$CI_COMMIT_REF_NAME-$CI_COMMIT_SHA
  paths:
    - build

stages:
  - build
  - deploy

auto-build:
  image: mritd/build:2.1.1
  stage: build
  script:
    - gradle --no-daemon clean assemble
  tags:
    - test

deploy:
  image: mritd/docker-kubectl:v1.7.4
  stage: deploy
  script:
    - source build/tmp/PROJECT_ENV
    - echo "Build Docker Image ==&gt; ${IMAGE_NAME}"
    - docker build -t ${IMAGE_NAME} --build-arg PROJECT_BUILD_FINALNAME=${PROJECT_BUILD_FINALNAME} .
#    - docker push ${IMAGE_NAME}
    - docker tag ${IMAGE_NAME} ${LATEST_IMAGE_NAME}
#    - docker push ${LATEST_IMAGE_NAME}
#    - docker rmi ${IMAGE_NAME} ${LATEST_IMAGE_NAME}
#    - kubectl --kubeconfig ${KUBE_CONFIG} set image deployment/test test=$IMAGE_NAME
  tags:
    - test
  only:
    - master
    - develop
    - /^chore.*$/Copy

关于 CI 配置的一些简要说明如下

stages
stages 字段定义了整个 CI 一共有哪些阶段流程，以上的 CI 配置中，定义了该项目的 CI 总共分为 build、deploy 两个阶段；GitLab CI 会根据其顺序执行对应阶段下的所有任务；在正常生产环境流程可以定义很多个，比如可以有 test、publish，甚至可能有代码扫描的 sonar 阶段等；这些阶段没有任何限制，完全是自定义的，上面的阶段定义好后在 CI 中表现如下图

task
task 隶属于 stages 之下；也就是说一个阶段可以有多个任务，任务执行顺序默认不指定会并发执行；对于上面的 CI 配置来说 auto-build 和 deploy 都是 task，他们通过 stage: xxxx 这个标签来指定他们隶属于哪个 stage；当 Runner 使用 Docker 作为 build 提供者时，我们可以在 task 的 image 标签下声明该 task 要使用哪个镜像运行，不指定则默认为 Runner 注册时的镜像 (这里是 debian)；同时 task 还有一个 tags 的标签，该标签指明了这个任务将可以在哪些 Runner 上运行；这个标签可以从 Runner 页面看到，实际上就是 Runner 注册时输入的哪个 tag；对于某些特殊的项目，比如 IOS 项目，则必须在特定机器上执行，所以此时指定 tags 标签很有用，当 task 运行后如下图所示

除此之外 task 还能指定 only 标签用于限定那些分支才能触发这个 task，如果分支名字不满足则不会触发；默认情况下，这些 task 都是自动执行的，如果感觉某些任务太过危险，则可以通过增加 when: manual 改为手动执行；注意：手动执行被 GitLab 认为是高权限的写操作，所以只有项目管理员才能手动运行一个 task，直白的说就是管理员才能点击；手动执行如下图所示

cache
cache 这个参数用于定义全局那些文件将被 cache；在 GitLab CI 中，跨 stage 是不能保存东西的；也就是说在第一步 build 的操作生成的 jar 包，到第二部打包 docker image 时就会被删除；GitLab 会保证每个 stage 中任务在执行时都将工作目录 (Docker 容器 中) 还原到跟 GitLab 代码仓库中一模一样，多余文件及变更都会被删除；正常情况下，第一步 build 生成 jar 包应当立即推送到 nexus 私服；但是这里测试没有搭建，所以只能放到本地；但是放到本地下一个 task 就会删除它，所以利用 cache 这个参数将 build 目录 cache 住，保证其跨 stage 也能存在
关于 .gitlab-ci.yml 具体配置更完整的请参考 官方文档
十一、其他相关
11.1、GitLab 内置环境变量
上面已经基本搞定了一个项目的 CI，但是有些变量可能并未说清楚；比如在创建的 PROJECT_ENV 文件中引用了 ${CI_COMMIT_SHA} 变量；这种变量其实是 GitLab CI 的内置隐藏变量，这些变量在每次 CI 调用 Runner 运行某个任务时都会传递到对应的 Runner 的执行环境中；也就是说这些变量在每次的任务容器 SHELL 环境中都会存在，可以直接引用，具体的完整环境变量列表可以从 官方文档 中获取；如果想知道环境变量具体的值，实际上可以通过在任务执行前用 env 指令打印出来，如下所示


11.2、GitLab 自定义环境变量
在某些情况下，我们希望 CI 能自动的发布或者修改一些东西；比如将 jar 包上传到 nexus、将 docker 镜像 push 到私服；这些动作往往需要一个高权限或者说有可写入对应仓库权限的账户来支持，但是这些账户又不想写到项目的 CI 配置里；因为这样很不安全，谁都能看到；此时我们可以将这些敏感变量写入到 GitLab 自定义环境变量中，GitLab 会像对待内置变量一样将其传送到 Runner 端，以供我们使用；GitLab 中自定义的环境变量可以有两种，一种是项目级别的，只能够在当前项目使用，如下

另一种是组级别的，可以在整个组内的所有项目中使用，如下

这两种变量添加后都可以在 CI 的脚本中直接引用
11.3、Kubernetes 集成
对于 Kubernetes 集成实际上有两种方案，一种是对接 Kubernetes 的 api，纯代码实现；另一种取巧的方案是调用 kubectl 工具，用 kubectl 工具来实现滚动升级；这里采用后一种取巧的方式，将 kubectl 二进制文件封装到镜像中，然后在 deploy 阶段使用这个镜像直接部署就可以

其中 mritd/docker-kubectl:v1.7.4 这个镜像的 Dockerfile 如下
FROM docker:dind 

LABEL maintainer="mritd &lt;mritd1234@gmail.com&gt;"

ARG TZ="Asia/Shanghai"

ENV TZ ${TZ}

ENV KUBE_VERSION v1.8.0

RUN apk upgrade --update \
    &amp;&amp; apk add bash tzdata wget ca-certificates \
    &amp;&amp; wget https://storage.googleapis.com/kubernetes-release/release/${KUBE_VERSION}/bin/linux/amd64/kubectl -O /usr/local/bin/kubectl \
    &amp;&amp; chmod +x /usr/local/bin/kubectl \
    &amp;&amp; ln -sf /usr/share/zoneinfo/${TZ} /etc/localtime \
    &amp;&amp; echo ${TZ} &gt; /etc/timezone \
    &amp;&amp; rm -rf /var/cache/apk/*

CMD ["/bin/bash"]Copy
这里面的 ${KUBE_CONFIG} 是一个自定义的环境变量，对于测试环境我将配置文件直接挂载入了容器中，然后 ${KUBE_CONFIG} 只是指定了一个配置文件位置，实际生产环境中可以选择将配置文件变成自定义环境变量使用
11.4、GitLab CI 总结
关于 GitLab CI 上面已经讲了很多，但是并不全面，也不算太细致；因为这东西说起来实际太多了，现在目测已经 1W 多字了；以下总结一下 GitLab CI 的总体思想，当思路清晰了以后，我想后面的只是查查文档自己试一试就行了

CS 架构

GitLab 作为 Server 端，控制 Runner 端执行一系列的 CI 任务；代码 clone 等无需关心，GitLab 会自动处理好一切；Runner 每次都会启动新的容器执行 CI 任务

容器即环境

在 Runner 使用 Docker build 的前提下；所有依赖切换、环境切换应当由切换不同镜像实现，即 build 那就使用 build 的镜像，deploy 就用带有 deploy 功能的镜像；通过不同镜像容器实现完整的环境隔离

CI 即脚本

不同的 CI 任务实际上就是在使用不同镜像的容器中执行 SHELL 命令，自动化 CI 就是执行预先写好的一些小脚本

敏感信息走环境变量

一切重要的敏感信息，如账户密码等，不要写到 CI 配置中，直接放到 GitLab 的环境变量中；GitLab 会保证将其推送到远端 Runner 的 SHELL 变量中
转载整理 From：

git-flow-note
ci-cd-gitlab-ci

系列教程
Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

]]></content>
      <categories>
        <category>Gitlab</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
        <tag>Git</tag>
        <tag>CI/CD</tag>
      </tags>
  </entry>
  <entry>
    <title>Earthly 一个更加强大的镜像构建工具</title>
    <url>/posts/593cc323/</url>
    <content><![CDATA[一、Earthly 介绍

开局一张图，功能全靠吹。


Earthly 是一个更加高级的 Docker 镜像构建工具，Earthly 通过自己定义的 Earthfile 来代替传统的 Dockerfile 完成镜像构建；Earthfile 就如同 Earthly 官方所描述:
**Makefile + Dockerfile = Earthfile**
在使用 Earthly 进行构建镜像时目前强依赖于 buildkit，Earthly 通过 buildkit 支持了一些 Dockerfile 的扩展语法，同时将 Dockerfile 与 Makefile 整合，使得多平台构建和代码化 Dockerfile 变得更加简单；使用 Earthly 可以更加方便的完成 Dockerfile 的代码复用以及更加友好的 CI 自动集成。
二、快速开始
2.1、安装依赖
Earthly 目前依赖于 Docker 和 Git，所以安装 Earthly 前请确保机器已经安装了 Docker 和 Git。
2.2、安装 Earthly
Earthly 采用 Go 编写，所以主要就一个二进制文件，Linux 下安装可以直接参考官方的安装脚本:
sudo /bin/sh -c 'wget https://github.com/earthly/earthly/releases/latest/download/earthly-linux-amd64 -O /usr/local/bin/earthly &amp;&amp; chmod +x /usr/local/bin/earthly &amp;&amp; /usr/local/bin/earthly bootstrap --with-autocomplete'Copy
安装完成后 Earthly 将会启动一个 buildkitd 容器: earthly-buildkitd。
2.3、语法高亮
目前 Earthly 官方支持 VS Code、VIM 以及 Sublime Text 三种编辑器的语法高亮，具体如何安装请参考 官方文档。
2.4、基本使用
本示例源于官方 Basic 教程，以下示例以编译 Go 项目为样例:
首先创建一个任意名称的目录，目录中存在项目源码文件以及一个 Earthfile 文件；
main.go
package main

import "fmt"

func main() {
    fmt.Println("hello world")
}Copy
Earthfile
FROM golang:1.17-alpine
WORKDIR /go-example

build:
    COPY main.go .
    RUN go build -o build/go-example main.go
    SAVE ARTIFACT build/go-example /go-example AS LOCAL build/go-example

docker:
    COPY +build/go-example .
    ENTRYPOINT ["/go-example/go-example"]
    SAVE IMAGE go-example:latestCopy
有了 Earthfile 以后我们就可以使用 Earthly 将其打包为镜像；
# 目录结构
~/t/earthlytest ❯❯❯ tree
.
├── Earthfile
└── main.go

0 directories, 2 files

# 通过 earthly 进行构建
~/t/earthlytest ❯❯❯ earthly +dockerCopy

构建完成后我们就可以直接从 docker 的 images 列表中查看刚刚构建的镜像，并运行:

三、进阶使用
3.1、多阶段构建
Earthfile 中包含类似 Makefile 一样的 target，不同的 target 之间还可以通过特定语法进行引用，每个 target 都可以被单独执行，执行过程中 earthly 会自动解析这些依赖关系。
这种多阶段构建时语法很弹性，我们可以在每个阶段运行独立的命令以及使用不同的基础镜像；从快速开始中可以看到，我们始终使用了一个基础镜像 (golang:1.17-alpine)，对于 Go 这种编译后自带运行时不依赖其语言 SDK 的应用，我们事实上可以将 “发布物” 仅放在简单的运行时系统镜像内，从而减少最终镜像体积:

由于使用了多个 target，所以我们可以单独的运行 build 这个 target 来验证我们的编译流程，这种多 target 的设计方便我们构建应用时对编译、打包步骤的细化拆分，同时也方便我们进行单独的验证。 例如我们单独执行 build 这个 target 来验证我们的编译流程是否正确:

在其他阶段验证完成后，我们可以直接运行最终的 target，earthly 会自动识别到这种依赖关系从而自动运行其依赖的 target:

3.2、扩展指令
3.2.1、SAVE
SAVE 指令是 Earthly 自己的一个扩展指令，实际上分为 SAVE ARTIFACT 和 SAVE IMAGE；其中 SAVE ARTIFACT 指令格式如下:
SAVE ARTIFACT [--keep-ts] [--keep-own] [--if-exists] [--force] &lt;src&gt; [&lt;artifact-dest-path&gt;] [AS LOCAL &lt;local-path&gt;]Copy
SAVE ARTIFACT 指令用于将文件或目录从 build 运行时环境保存到 target 的 artifact 环境；当保存到 artifact 环境后，可以通过 COPY 等命令在其他位置进行引用，类似于 Dockerfile 的 COPY --from... 语法；不同的是 SAVE ARTIFACT 支持 AS LOCAL &lt;local-path&gt; 附加参数，一但指定此参数后，earthly 会同时将文件或目录在宿主机复制一份，一般用于调试等目的。SAVE ARTIFACT 命令在上面的样例中已经展示了，在运行完 earthly +build 命令后实际上会在本地看到被 SAVE 出来的 ARTIFACT:

而另一个 SAVE IMAGE 指令则主要用于将当前的 build 环境 SAVE 为一个 IMAGE，如果指定了 --push 选项，同时在执行 earthly +target 命令时也加入 --push 选项，该镜像将会自动被推送到目标 Registry 上。SAVE IMAGE 指令格式如下:
SAVE IMAGE [--cache-from=&lt;cache-image&gt;] [--push] &lt;image-name&gt;...Copy

3.2.2、GIT CLONE
GIT CLONE 指令用于将指定 git 仓库 clone 到 build 环境中；与 RUN git clone... 命令不同的是，GIT CLONE 通过宿主机的 git 命令运行，它不依赖于容器内的 git 命令，同时还可以直接为 earthly 配置 git 认证，从而避免将这些安全信息泄漏到 build 环境中； 关于如何配置 earthly 的 git 认证请参考 官方文档；下面是 GIT CLONE 指令的样例

3.2.3、COPY
COPY 指令与标准的 Dockerfile COPY 指令类似，除了支持 Dockerfile 标准的 COPY 功能以外，earthly 中的 COPY 指令可以引用其他 target 环节产生的 artifact，在引用时会自动声明依赖关系；即当在 B target 中存在 COPY +A/xxxxx /path/to/copy 类似的指令时，如果只单纯的执行 earthly +B，那么 earthly 根据依赖分析会得出在 COPY 之前需要执行 target A。COPY 指令的语法格式如下:
# 与 Dockerfile 相同的使用方式，从上下文复制
COPY [options...] &lt;src&gt;... &lt;dest&gt;

# 扩展支持的从 target 复制方式
COPY [options...] &lt;src-artifact&gt;... &lt;dest&gt;Copy
3.2.4、RUN
RUN 指令在标准使用上与 Dockerfile 里保持一致，除此之外增加了更多的扩展选项，其指令格式如下:
# shell 方式运行(/bin/sh -c)
RUN [--push] [--entrypoint] [--privileged] [--secret &lt;env-var&gt;=&lt;secret-ref&gt;] [--ssh] [--mount &lt;mount-spec&gt;] [--] &lt;command&gt;

# exec 方式运行
RUN [[&lt;flags&gt;...], "&lt;executable&gt;", "&lt;arg1&gt;", "&lt;arg2&gt;", ...]Copy
其中 --privileged 选项允许运行的命令使用 privileged capabilities，但是需要 earthly 在运行 target 时增加 --allow-privileged 选项；--interactive / --interactive-keep 选项用于交互式执行一些命令，在完成交互后 build 继续进行，在交互过程中进行的操作都会被持久化到 镜像中:

限于篇幅原因，其他的具体指令请查阅官方文档 Earthfile reference。
3.3、UDCS
UDCs 全称 “User-defined commands”，即用户定义指令；通过 UDCs 我们可以将 Earthfile 中特定的命令剥离出来，从而实现更加通用和统一的代码复用；下面是一个定义 UDCs 指令的样例:
# 定义一个 Command
# ⚠️ 注意: 语法必须满足以下规则
# 1、名称全大写
# 2、名称下划线分割
# 3、首个命令必须为 COMMAND(后面没有冒号)
MY_COPY:
    COMMAND
    ARG src
    ARG dest=./
    ARG recursive=false
    RUN cp $(if $recursive =  "true"; then printf -- -r; fi) "$src" "$dest"

# target 中引用
build:
    FROM alpine:3.13
    WORKDIR /udc-example
    RUN echo "hello" &gt;./foo
    # 通过 DO 关键字引用 UDCs
    DO +MY_COPY --src=./foo --dest=./bar
    RUN cat ./bar # prints "hello"Copy
UDCs 不光可以定义在一个 Earthfile 中，UDCs 可以跨文件、跨目录引用:

有了 UDCs 以后，我们可以通过这种方式将对基础镜像的版本统一控制、对特殊镜像的通用处理等操作全部抽象出来，然后每个 Earthfile 根据需要进行引用；关于 UDCs 的使用样例可以参考我的 autobuild 项目，其中的 udcs 目录定义了大量的通用 UDCs，这些 UDCs 被其他目标镜的 Earthfile 批量引用。
3.4、多平台构建
在以前使用 Dockerfile 的时候，我们需要自己配置然后开启 buildkit 来实现多平台构建；在配置过程中可能会很繁琐，现在使用 earthly 可以默认帮我们实现多平台的交叉编译，我们需要做的仅仅是在 Earthfile 中声明需要支持哪些平台而已:

以上 Earthfile 在执行 earthly --push +all 构建时，将会自动构建四个平台的镜像，并保持单个 tag，同时由于使用了 --push 选项还会自动推送到 Docker Hub 上:

四、总结
Earthly 弥补了 Dockerfile 的很多不足，解决了很多痛点问题；但同样可能需要一些学习成本，但是如果已经熟悉了 Dockerfile 其实学习成本不高；所以目前还是比较推荐将 Dockerfile 切换为 Earthfile 进行统一和版本化管理的。本文由于篇幅所限 (懒) 很多地方没有讲，比如共享缓存等，所以关于 Earthly 更多的详细使用等最好还是仔细阅读一下官方文档。

整理转载：the-best-image-build-tool-earthly

]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Earthly</tag>
      </tags>
  </entry>
  <entry>
    <title>自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）</title>
    <url>/posts/d6bad1e5/</url>
    <content><![CDATA[前言
对于经常阅读的人来说，制作本地电子书，算是刚需了。网上的很多教程都不太好用，所以我特地整理出一个详细的教程。亲测有效，一劳永逸。
当你意外发现某个宝藏公众号时，想要集中阅读上面的每一篇文章，恨不得一口气看完，你会怎么做呢？你可能会把它添加到 “微信读书” App 的书架上：

但上面这种曲线救国的方式并非最佳，仍然不尽人意，存在不少问题。
我知道，现在有很多的第三方服务，可以将任意公众号的文章制作成电子书，我试过很多次，但都是付费的。一听说要钱，你又不干了：

再列举一种场景：当你在 GitHub 上发现一个很全面很丰富的项目文档时，仿佛发现了新大陆。可 GitHub 网站的服务器在国外，国内的访问速度实在感人，你想要把它下载到本地查看，会怎么做呢？你估计会选择 git clone 或者直接选择 “Download ZIP”，然后用 Typora 或者 VS Code 软件打开这个项目文档，在本地查看：

总之，你能想到的方式，我都想到了，而且都尝试过。
现在的需求就是，如果你经常阅读网上的资料，肯定会有这样一个需求：怎么把这些几百页、甚至几千页的内容整理成 PDF、ePub、mobi 等格式的电子书呢？
要么花钱请别人做，要么自己做。
今天这篇文章，就是来告诉你” 自己动手制作 PDF、ePub、mobi 等格式电子书 “的最佳方式。如果你是码农出身，下面讲的这些步骤，根本难不倒你。如果你不是码农出身，也没关系，只要你有一台电脑，跟着我讲的教程研究下去，肯定能搞定。
问题的关键不在于难不难、会不会，而是在于你是不是爱折腾。
工具篇
bloodstar/gitbook-builder

Gitbook Docker 集成开发环境。支持 CJK，附带常用工具。使用它，下面一些列环境配置都可以省略了。开箱即用。

Usage
Read the official GitBook Toolchain Documentation documentation GitbookIO/gitbook first.
# init
docker run --rm -v "$PWD:/gitbook" -p 4000:4000 bloodstar/gitbook-builder gitbook init
# serve
docker run --rm -v "$PWD:/gitbook" -p 4000:4000 bloodstar/gitbook-builder gitbook serve
# build
docker run --rm -v "$PWD:/gitbook" -p 4000:4000 bloodstar/gitbook-builder gitbook build
For short, you can use alias for the long command line text. Place the alias statement in your .bashrc or .zshrc.
alias gitbook='docker run --rm -v "$PWD":/gitbook -p 4000:4000 bloodstar/gitbook-builder gitbook'
# init
gitbook init
# serve
gitbook serve
# build
gitbook build
# pdf output
gitbook pdf .
Integrate with Gitlab CI
This docker image is originally designed for generating ebook with Gitlab CI. You could configure your Gitlab CI as following:
before_script:
  - env
  - export LC_ALL=zh_TW.UTF-8

stages:
  - build

ebook:
  stage: build
  script:
    - gitbook pdf
  artifacts:
    paths:
      - book.pdf
  only:
    - master
  tags:
    - gitbook
  image: bloodstar/gitbook-builder:latest
  allow_failure: true
制作电子书的具体步骤
整体流程
先说一下整体步骤：
（1）安装 gitbook 工具。
（2）安装 calibre 软件，配置 ebook-convert 工具。
（3）将 md 格式的多个文件素材导出为电子书（支持 PDF、ePub、mobi 等格式）。
（4）高级进阶：配置电子书的目录、封面、页眉页脚等。
整理流程如下：

接下来我们看看详细的完整步骤。
步骤 1：通过 npm 安装 gitbook-cli
安装命令如下：
npm install -g gitbook-cli
安装成功之后，再执行 gitbook -V 命令确认是否安装成功：
gitbook -V
CLI version: 2.3.2
GitBook version: 3.2.3
备注：如果你不知道 npm 是什么，可以自行查阅如何安装 Node.js 和 npm 环境。
步骤 2：安装 ebook-convert（针对 Windows 用户）
ebook-convert 是能够自由转化格式的一个命令行工具，已经包含在 calibre 软件里面了。
（1）安装 calibre 软件。calibre 的官网如下：（我们可以去官网下载安装）

https://calibre-ebook.com/

（2）在终端输入如下命令，验证 ebook-convert 是否能正常使用：
如果输入上面的命令后提示错误，说明你还需要将 calibre 的安装目录添加到系统的环境变量中。
步骤 2：安装 ebook-convert（针对 Mac 用户）
ebook-convert 是能够自由转化格式的一个命令行工具，已经包含在 calibre 软件里面了。
（1）安装 calibre 软件。calibre 的官网如下：（我们可以去官网下载安装）

https://calibre-ebook.com/

（2）配置 ebook-convert。针对 Mac 系统，需要执行如下命令，把 ebook-convert 软链接到 bin 目录：
sudo ln -s /Applications/calibre.app/Contents/MacOS/ebook-convert /usr/bin
执行上面的命令后，如果出现 Operation not permitted 异常，说明系统权限限制，此时需要配置环境变量。
（3）环境变量配置：
vim ~/.bash_profile

# 将下面这两行配置，添加到 .bash_profile 文件中
export EBOOK_PATH=/Applications/calibre.app/Contents/MacOS
export PATH=$PATH:$EBOOK_PATH
备注：可以自行研究下，在命令行环境，如何通过 vim 编辑文件。
然后刷新一下刚刚的配置：
验证 ebook-convert 是否能正常使用：
步骤 3：配置电子书的目录
本地新建一个空的文件夹，作为我们的电子书项目。文件夹的名字随便起，但建议用英文命名。
（1）项目初始化。
在当前项目下，执行如下命令，进行初始化：
gitbook init
此时，项目下会自动生成如下两个文件：（非常重要，必不可少）

README.md：书籍的简介放在这个文件里。
SUMMARY.md：书籍的目录结构在这里配置。

这两个文件创建后，内容为空白，可使用 Markdown 语言自定义内容。
（2）配置电子书的目录。
我们先把本地的 markdown 文件（也就是我们的电子书素材）放到项目中，然后在 SUMMARY.md 文件中配置电子书的目录。
比如说， 我的项目中有下面这些文件：

那么，我在 SUMMARY.md 文件中就要这样配置：
# 目录

* [README](./README.md)
* [00-前端工具](00-前端工具/0-README.md)
  * [01-VS Code的使用](00-前端工具/01-VS Code的使用.md)
  * [02-Git的使用](00-前端工具/02-Git的使用.md)
* [01-HTML](01-HTML/0-README.md)
  * [01-认识Web和Web标准](01-HTML/01-认识Web和Web标准.md)
  * [02-浏览器的介绍](01-HTML/02-浏览器的介绍.md)
  * [03-初识HTML](01-HTML/03-初识HTML.md)
* [02-CSS基础](02-CSS基础/0-README.md)
  * [01-CSS属性：字体属性和文本属性](02-CSS基础/01-CSS属性：字体属性和文本属性.md)
  * [02-CSS属性：背景属性](02-CSS基础/02-CSS属性：背景属性.md)
  * [03-CSS样式表和选择器](02-CSS基础/03-CSS样式表和选择器.md)
* [03-JavaScript基础](03-JavaScript基础/0-README.md)
  * [00-编程语言](03-JavaScript基础/00-编程语言.md)
  * [01-JS简介](03-JavaScript基础/01-JS简介.md)
  * [02-变量](03-JavaScript基础/02-变量.md)
  * [03-变量的数据类型：基本数据类型和引用数据类型](03-JavaScript基础/03-变量的数据类型：基本数据类型和引用数据类型.md)
制作成的目录，将会是下面这种效果：

步骤 4：导出电子书
（1）本地预览电子书：
执行上方命令后，工具会对项目里的 Markdown 格式的文件进行转换，默认转换为 html 格式，最后提示 Serving book on http://localhost:4000。
我们打开浏览器输入 http://localhost:4000，预览一下电子书的效果：

（2）制作并导出电子书。接下来就是见证奇迹的时刻。
生成 PDF 格式的电子书：（PDF 是最常见的文档格式）
gitbook pdf ./ ./mybook.pdf
生成 epub 格式的电子书：（epub 是最常见、最通用的电子书格式）
gitbook epub ./ ./mybook.epub
生成 mobi 格式的电子书：（mobi 格式可以在 kindle 中打开）
gitbook mobi ./ ./mybook.mobi
上面这三种格式的电子书生成之后，项目里会看到这三个新增的文件：

我们把电子书打开，验收一下成果。
打开 pdf 电子书看看效果：

打开 epub 电子书看看效果：

怎么样，自制电子书就这样做好了，是不是很有成就感？

更详细参考教程： GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇

制作电子书的高级配置
电子书做好之后，我猜你肯定想进一步做个性化配置，比如：怎么加封面？怎么修改页眉页脚？还有其他的一些配置。
我们来看看亲手制作的电子书，有哪些常见的高级配置。
制作书籍封面
为了让书籍显示得更加优雅，我们可以指定一个自定义的封面。操作如下：
在项目的根目录下准备好 cover.jpg （大封面）和 cover_small.jpg （小封面）这两种封面图片。注意，图片的文件名和后缀名必须严格按照这句话来。
GitBook 的官方文档建议： cover.jpg （大封面）的尺寸为 1800x2360 像素，cover_small.jpg（小封面）的尺寸为 200x262 像素。图片的制作，建议遵循如下规范：

没有边框
清晰可见的书本标题
任何重要的文字在小封面中应该清晰可见

book.json ：电子书的各种配置
我们可以在项目的根目录下新建一个文件 book.json（注意，文件名是 book，后缀名是 json），这个 book.json 就是电子书的配置文件，可以在里面填一些常见的配置。
关于 book.json 的配置项有很多，我们可以在网上搜索 “GitBook book.json” 找到。这里大致列举一些。
1、常规配置如下：

配置 book.json 的示例如下：
{
    "title": "前端入门和进阶图文教程",
    "description": "前端入门到进阶图文教程，超详细的Web前端学习笔记。从零开始学前端，做一名精致优雅的前端工程师。公众号「千古壹号」作者。",
    "author": "千古壹号",
    "language": "zh-hans",
    "gitbook": "3.2.3",
    "root": "."
}
备注：上面的 root 根目录为当前目录，使用默认的就好，此项可以删掉，这里仅做演示。
2、pdf 的配置如下：（使用 book.json 中的一组选项来定制 PDF 输出）
| 配置项 | 描述 | | ----------------- | ------------------------------------------------------------ | | pdf.pageNumbers | 将页码添加到每个页面的底部（默认为 true） | | pdf.fontSize | 基本字体大小（默认是 12） | | pdf.fontFamily | 基本字体样式（默认是 Arial） | | pdf.paperSize | 页面尺寸，选项有： a0、a1、 a2、 a3、a4、a5、a6、b0、b1、b2、b3、b4、b5、b6、legal、letter （默认值是 a4） | | pdf.margin.top | 上边距（默认值是 56） | | pdf.margin.bottom | 下边距（默认值是 56） | | pdf.margin.left | 左边距（默认值是 62） | | pdf.margin.right | 右边距（默认值是 62） |
定制 PDF 文档输出格式的示例代码如下：
{
    "pdf": {
        "pageNumbers": false,
        "fontSize": 12,
        "paperSize": "a4",
        "margin": {
            "top": 36,
            "bottom": 36,
            "left": 62,
            "right": 62
        }
    }
}
备注：如果你不需要对输出的 pdf 做任何特定的配置，则不需要添加上面的内容，让 pdf 的输出格式保持默认就好。
3、plugins 插件：
插件及其配置在 book.json 中指定，让电子书的配置能力更加强大。
通过插件，我们可以做很多事情，比如：修改页眉页脚、自动生成并显示图片的标题等。
另外，针对在线版的 GitBook 电子书，也有很多插件，这里列举几个：

自带的 search 插件不支持中文搜索，使用起来非常不方便，还好 search-pro 插件横空出世，让搜索功能焕发出新的生机。插件地址：https://github.com/gitbook-plugins/gitbook-plugin-search-pro
 默认侧边栏宽度是不能够调节的，如果想通过拖拽的方式自由调节侧边栏宽度，可以使用插件 splitter。插件地址：https://github.com/yoshidax/gitbook-plugin-splitter
donate 插件支持定义和显示支付宝和微信打赏。插件地址：http://github.com/willin/gitbook-plugin-donate

关于插件的具体配置，感兴趣的同学可以自行研究下。
自动生成目录（重要）
如果你的电子书素材里有很多 markdown 文件，那么，如何将多个 markdown 文件的文件名，在 SUMMARY.md 里快速生成对应的目录？
难道要一个一个地手动 copy 吗？这不可能。
说白了，这个需求就是：如何自动生成电子书的目录？改变世界的程序员用「脚本」就能搞定，一键执行。
网上有很多好用的脚本，我给你推荐一个亲测好用的脚本：

GitBook 自动生成目录的脚本：https://github.com/fushenghua/gitbook-plugin-summary

操作方法很简单，把上面这个链接中的项目下载下来，进入到这个项目的目录，执行 $ python gitbook-plugin-summary.py dirPath 即可自动生成电子书的目录，亲测有效。备注：这里的 dirPath 指的是你的电子书目录的绝对路径。
对了，在执行上面这个脚本之前，记得先安装 Python 环境。
电子书用什么软件打开
用什么软件打开 PDF
Windows 平台：可以用「福昕阅读器」或者「Acrobat Reader DC」。「福昕阅读器」既有 Windows 平台，也有 Mac 平台。
Mac 平台：可以用自带的「预览」打开。
其实，不管你用的是 Windows 电脑还是 Mac 电脑，你都可以用 Chrome 浏览器打开 PDF。
iPhone 或 iPad 平台：可以用自带的「iBooks」打开，或者用「WPS Office」打开。也可以用第三方软件「GoodReader」，不过需要 40 人民币。
Android 手机：可以用「WPS Office」等第三方办公软件打开。
用什么软件阅读 ePub 电子书
Windows 平台：可以用「calibre」软件阅读 epub 电子书。
Mac &amp; iPhone &amp; iPad 平台：用自带的「iBooks」阅读即可。iBooks 可以非常方便地对电子书进行标注和搜索，无疑是体验最好的 ePub 电子书阅读软件。
Android 手机：可以用「多看阅读」App 来阅读 epub 格式电子书。
用什么方式阅读 mobi 电子书
kindle 电子书有两种常见的电子书格式：「mobi」格式和「azw3」格式。

针对 mobi 格式的电子书，你既可以通过邮件的形式将其发送到 kindle 阅读器（可以自行网上查一下相关教程），也可以将其拷贝到 kindle 阅读器（是连接 usb 进行拷贝）。
针对 azw3 格式的电子书，就只能通过拷贝的形式（是连接 usb 拷贝）传输到 kindle 阅读器。

小结
我在 2017 年 1 月写过一篇电子书科普的文章，快三年过去了，如今回过头来看，那篇文章一点也不过时，不妨看看：《电子书有哪些常见格式？以及该怎样阅读它》
最后一段
如果你一时半会儿找不到可用的素材来制作电子书，可以拿我的项目练练手。项目地址：

https://github.com/qianguyihao/web

不瞒你说，这篇文章，我在一年多以前就写好了初稿并放在了 GitHub 上，当时专门折腾过一次。
最近几天，我突然又有了制作电子书的需求。一年多过去了，我还以为有啥新的方法可以试试，然而我在网上找了一圈，好用的方法还是没变。所以，我今天整理一下发出来，希望让更多人看到。
其他的各种自制电子书的方法我都试过了，都不太好使，唯独 GitBook + calibre 是最佳选择，信我没错！
参考链接

GITBOOK 使用：https://kuang.netlify.app/blog/gitbook.htmlbook.html
GitBook 制作 Kindle 电子书详细教程：https://github.com/fushenghua/gitbook-plugin-summary/blob/master/gitbook-guide.md
gitbook-plugin-summary 工具（自动生成目录）：https://github.com/fushenghua/gitbook-plugin-summary
gitbook-plugin-atoc（自动生成目录的插件）：https://github.com/willin/gitbook-plugin-atoc
 自动生成目录：https://github.com/mofhu/GitBook-auto-summary
 使用 Gitbook 打造你的电子书：https://juejin.im/post/6844903793033740302
 书籍《了不起的 Markdown》的第 8 章：自由地写作 ——GitBook
gitbook 的 book.json 配置示例：https://blog.ujwd.cn/archives/349
 关于更加详细的 book.json 文件配置：https://zhousiwei.gitee.io/mybook/notes/gitbook_config.html
GitBook 简明使用教程：https://www.phpjieshuo.com/archives/153/
gitbook 入门教程之导出电子书：https://juejin.im/post/5caa0fb46fb9a05e5a2e53b3
GitBook 插件整理 - book.json 配置：https://www.cnblogs.com/mingyue5826/p/10307051.html
 如何把 Markdown 文件批量转换为 PDF（不好用）：https://sspai.com/post/47110 
自己动手制作电子书的最佳方式

系列教程
Gitbook 使用系列


GitBook+GitLab 撰写发布技术文档 - Part1:GitBook 篇


GitBook+GitLab 撰写发布技术文档 - Part2:GitLab 篇


自己动手制作电子书的最佳方式（支持 PDF、ePub、mobi 等格式）


笔记系列

完美笔记进化论


经历了很长时间，使用了各种各样的方案，最终选择了一种相对完美的方式。docker 私有部署运行的 joplin，使用 markdown 语法，github 作为图床，picgo 作为图像自动上传后端，pypora 作为 MD 编辑器，Snipaste 作为截图工具。后备 gitlab ee selfhost 备份，自建图床 VPS 多线负载均衡。cloudflare partner cdn 加速，jsdelivr 加速。

pigo 图床搭建与配置
 Joplin 教程
 Snipaste 截图工具
 Typora 作为 Markdown 编辑器最强 



Joplin 入门指南 &amp; 实践方案



 Joplin 和使用
 Joplin 同步与备份
 Joplin 导入与导出 



Joplin 插件以及其 Markdown 语法。All in One!



Joplin 简明教程
 markdown 语法简明教程 



Joplin 插件使用推荐



教你用各种插件打造一个强大的笔记工具。



为知笔记私有化 Docker 部署



如何部署自己私有的为知笔记。
其实博主更推荐私有部署 joplin


Gitlab 使用系列

Gitlab 的安装及使用教程完全版
破解 Gitlab EE
Gitlab 的安装及使用
CI/CD 与 Git Flow 与 GitLab

]]></content>
      <categories>
        <category>gitbook</category>
      </categories>
      <tags>
        <tag>GitBook</tag>
        <tag>docker</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>私人在线音乐服务器搭建与使用介绍</title>
    <url>/posts/2b9325d0/</url>
    <content><![CDATA[
多种音乐播放实现方式

页面内插入音乐列表。Aplayer 实现
单独页面音乐列表。Aplayer 实现
音乐 Docker。在线云音乐



原作者 DMCA 原因不再维护，如果你想自己部署，需要修改原作者 docker 内部代码。



音乐 Docker Mstream docker。
音乐 Docker Logitech Media Server。Github



 多用户音乐分享、播放，在线，分类等功能。




Aplayer 在线音乐

博文页面内插入音乐列表

 var BkooOeRfUQJwUTPS_options = JSON.parse('{\"lrcType\":3,\"volume\":0.66,\"audio\":[{\"name\":\"Hotel California\",\"artist\":\"Camille and Kennerly\",\"url\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.mp3\",\"lrc\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.lrc\",\"cover\":\"https://cdn.17lai.site/media/music/Hotel%20California/Hotel%20California.webp\"}]}'); BkooOeRfUQJwUTPS_options.container = document.getElementById("mmedia-BkooOeRfUQJwUTPS"); const ap_BkooOeRfUQJwUTPS = new APlayer(BkooOeRfUQJwUTPS_options); 



 var EIjOEJhIYQqfDvjp_options = JSON.parse('{\"lrcType\":3,\"volume\":0.8,\"autoplay\":false,\"audio\":[{\"name\":\"Hotel California\",\"artist\":\"Camille and Kennerly\",\"url\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.mp3\",\"cover\":\"https://cdn.17lai.site/media/music/Hotel%20California/Hotel%20California.webp\",\"lrc\":\"https://cdn.17lai.site/media/music/Hotel%20California/01%20Hotel%20California.lrc\",\"theme\":\"#ebd0c2\"},{\"name\":\"Sold Out\",\"artist\":\"Diamonds\",\"url\":\"https://cdn.17lai.site/media/music/Diamonds/05%20Sold%20Out.flac\",\"cover\":\"https://cdn.17lai.site/media/music/Diamonds/Diamonds.jpg\",\"theme\":\"#ebd0c2\"},{\"name\":\"The Final Bell\",\"artist\":\"Rocky_ Original Motion Picture Score\",\"url\":\"https://cdn.17lai.site/media/music/Rocky_%20Original%20Motion%20Picture%20Score/12%20Bill%20Conti%20-%20The%20Final%20Bell.mp3\",\"cover\":\"https://cdn.17lai.site/media/music/Rocky_%20Original%20Motion%20Picture%20Score/Rocky_%20Original%20Motion%20Picture%20Score.jpg\",\"theme\":\"#ebd0c2\"},{\"name\":\" Croatian Rhapsody\",\"artist\":\"The Piano Player\",\"url\":\"https://cdn.17lai.site/media/music/The%20Piano%20Player/11%20Croatian%20Rhapsody.mp3\",\"cover\":\"https://cdn.17lai.site/media/music/The%20Piano%20Player/The%20Piano%20Player.jpg\",\"theme\":\"#ebd0c2\"}]}'); EIjOEJhIYQqfDvjp_options.container = document.getElementById("mmedia-EIjOEJhIYQqfDvjp"); const ap_EIjOEJhIYQqfDvjp = new APlayer(EIjOEJhIYQqfDvjp_options); 
单独 Aplayer 音乐页面

直接戳这里 -&gt; Musics


在线云音乐
私人云音乐
研究学习使用
不对外公开发布，研究学习用。

用户名密码 base64 编码
55So5oi35ZCN5a+G56CB6YO95pivMTdsYWk=
base64 解密: 在线加密解密
入口


公开在线云音乐服务网页版。
可以与网易云音乐 UID 同步！
DockerHub




与网易云同步

网易云 UID 在登陆 https://music.163.com/ 后 点击右上角图标的我的主页 https://music.163.com/#/user/home?id=617xxxxx0
home?id= 后面的数字就是你的 UID。登录后，可以同步个人列表！
私人音乐服务器
入口


所有音乐作者，专辑，演唱者元数据刮削。
rclone 挂载 webdav 网盘存储音乐文件。
cloudflare parterner 加速。
私人使用，不对外公开。


在线音乐播放


SelfHost 支持。Docker 部署！
Github: Mstream docker。
浏览器界面支持。



支持 DJ 模式


在音乐库中随机选择音乐播放。
选择症患者救星。



Android 支持

其它特性


转码支持
遥控器支持
播放列表
等等


]]></content>
      <categories>
        <category>music</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>music</tag>
        <tag>mstream</tag>
        <tag>selfhost</tag>
      </tags>
  </entry>
  <entry>
    <title>音乐推荐 - 曾经我也想过一了百了</title>
    <url>/posts/8b7d3a9a/</url>
    <content><![CDATA[现场 MV
.bbplayer{width: 100%; max-width: 850px; margin: auto} document.getElementById("mmedia-VCfkcNWXsOZdZUEH").style.height=document.getElementById("mmedia-VCfkcNWXsOZdZUEH").scrollWidth*0.76+"px";
    window.onresize = function(){
      document.getElementById("mmedia-VCfkcNWXsOZdZUEH").style.height=document.getElementById("mmedia-VCfkcNWXsOZdZUEH").scrollWidth*0.76+"px";
    }; 
背景介绍
《曾经我也想过一了百了》是日本歌手中岛美嘉演唱的歌曲，由秋田弘填词和谱曲、出羽良彰编曲，于 2013 年 8 月 28 日发行，收录在中岛美嘉个人专辑《TOUGH 为爱勇敢》中。该歌曲勾勒出向死而生、努力活着的人，让人感到温暖和希望，让因为压力迷茫无助而有轻生想法的人，开始积极拥抱生活。 《曾经我也想过一了百了》由日本摇滚乐队 amazarashi 的主唱秋田弘创作，创作理念为 “为了描写浓烈的希望，必须先描写深层的黑暗”。2010 年，迎来出道十周年的中岛美嘉宣布自己因耳咽管开放症暂停一切音乐活动。在疾病的影响下，歌唱对她而言变得无比艰难。2011 年，她携单曲《Dear》复出，但复出后始终经历着状态的起伏和媒体的质疑。 中岛美嘉起先向 amazarashi 提出合作请求，希望乐队能为自己创作一首节奏明快的歌曲，但随后秋田弘向她播放了乐队一首未发行的样本歌曲，并认为该曲很适合由她来演唱。收到该曲时，中岛美嘉起先感到十分惊讶，但听到最后泪流不止，感到自己的心变得柔和，便立即要求演唱该曲。录制过程中，中岛美嘉将自己的心声融入到了该曲中，希望能将力量传达给低迷苦闷的听众。
[00:00.10]僕が死のうと思ったのは (曾经我也想过一了百了) - 中島美嘉 (なかしま みか)
[00:00.20]词：秋田ひろむ
[00:00.30]曲：秋田ひろむ
[00:00.40]编曲：出羽良彰
[00:27.95]僕が死のうと思ったのは
[00:33.83]ウミネコが桟橋で鳴いたから
[00:39.20]波の随意に浮かんで消える
[00:45.33]過去も啄ばんで飛んでいけ
[00:50.70]僕が死のうと思ったのは
[00:56.52]誕生日に杏の花が咲いたから
[01:02.22]その木漏れ日でうたた寝したら
[01:08.09]虫の死骸と土になれるかな
[01:14.09]薄荷飴 漁港の灯台
[01:17.05]錆びたアーチ橋 捨てた自転車
[01:19.74]木造の駅のストーブの前で
[01:22.74]どこにも旅立てない心
[01:25.61]今日はまるで昨日みたいだ
[01:28.30]明日を変えるなら今日を変えなきゃ
[01:31.56]分かってる 分かってる けれど
[01:39.71]僕が死のうと思ったのは
[01:44.89]心が空っぽになったから
[01:50.71]満たされないと泣いているのは
[01:56.39]きっと満たされたいと願うから
[02:25.49]僕が死のうと思ったのは
[02:30.69]靴紐が解けたから
[02:36.57]結びなおすのは苦手なんだよ
[02:42.25]人との繋がりもまた然り
[02:47.90]僕が死のうと思ったのは
[02:53.65]少年が僕を見つめていたから
[02:59.30]ベッドの上で土下座してるよ
[03:05.12]あの日の僕にごめんなさいと
[03:11.43]パソコンの薄明かり
[03:14.05]上階の部屋の生活音
[03:16.80]インターフォンのチャイムの音
[03:19.80]耳を塞ぐ鳥かごの少年
[03:22.87]見えない敵と戦ってる
[03:25.43]六畳一間のドンキホーテ
[03:28.30]ゴールはどうせ醜いものさ
[03:36.74]僕が死のうと思ったのは
[03:42.05]冷たい人と言われたから
[03:47.94]愛されたいと泣いているのは
[03:53.63]人の温もりを知ってしまったから
[04:22.79]僕が死のうと思ったのは
[04:27.91]あなたが綺麗に笑うから
[04:33.49]死ぬことばかり考えてしまうのは
[04:39.62]きっと生きる事に真面目すぎるから
[04:45.43]僕が死のうと思ったのは
[04:50.70]まだあなたに出会ってなかったから
[04:56.51]あなたのような人が生まれた
[05:02.09]世界を少し好きになったよ
[05:07.96]あなたのような人が生きてる
[05:13.65]世界に少し期待するよ
中文翻唱

        
			  
				  var options = {"narrow":false,"autoplay":false,"showlrc":3,"mode":"random","mutex":true,"theme":"#e6d0b2","preload":"metadata","listmaxheight":"513px","music":[{"title":"曾经我也想过一了百了","author":"一么","url":"https://cdn.17lai.site/media/music/僕が死のうと思ったのは/曾经我也想过一了百了-一么.mp3","pic":"https://cdn.17lai.site/media/music/僕が死のうと思ったのは/僕が死のうと思ったのは.jpg","lrc":"https://cdn.17lai.site/media/music/僕が死のうと思ったのは/曾经我也想过一了百了-一么.lrc"},{"title":"僕が死のうと思ったのは","author":"中岛美嘉","url":"https://cdn.17lai.site/media/music/僕が死のうと思ったのは/01%20僕が死のうと思ったのは.mp3","pic":"https://cdn.17lai.site/media/music/僕が死のうと思ったのは/僕が死のうと思ったのは.jpg","lrc":"https://cdn.17lai.site/media/music/僕が死のうと思ったのは/01%20僕が死のうと思ったのは.lrc"}]};
				  options.element = document.getElementById("aplayer-xSCHxjUX");
				  var ap = new APlayer(options);
			    window.aplayers || (window.aplayers = []);
				  window.aplayers.push(ap);
			  
[00:02.09]作曲 : 秋田 ひろむ
[00:02.64]曾经我也想过一了百了
[00:03.21]原唱：中岛美嘉
[00:04.46] 
[00:29.85]曾经我 也想过 一了百了
[00:34.79]因为看见蜷缩的猫
[00:37.40]在码头望着远方
[00:40.40]海浪拍打在岸上
[00:43.44]一阵又一阵侵踏
[00:46.22]希望那些过往都消失
[00:49.38]不再回望
[00:52.43]曾经我 也想过
[00:54.82]一了百了
[00:57.46]是因为生日的那天
[01:00.10]杏花 又开放
[01:03.75]阳光灿烂树荫下
[01:06.41]落花已沉睡安详
[01:09.84]是否我也 能化作尘土
[01:12.16]不再流浪
[01:15.76]仍放抽屉里过期的糖
[01:18.28]迷路的单车被留在回家路上
[01:21.27]还有海边抛弃的避风港
[01:23.88]全都提醒 我和他们一样
[01:26.75]昨天和今天的画面不断浮现
[01:29.74]明天 渴望能不能有
[01:31.54]新的改变
[01:32.90]不能沮丧 我知道啊
[01:35.55]可是啊
[01:40.88]曾经我 也想过 一了百了
[01:46.24]身边一切都像在问我
[01:49.19]过得好不好
[01:52.28]泪不能停止的流
[01:55.05]流进心底的荒漠
[01:58.28]这颗心中的模样
[02:00.17]早空如一具躯壳
[02:26.84]曾经我 也想过 一了百了
[02:32.71]因为我的存在
[02:34.23]总让别人失望
[02:37.98]不曾拥有就不怕
[02:40.80]关于人与人的伤
[02:44.18]这么简单的道理
[02:45.96]我也只会搞砸
[02:49.80]曾经我 也想过 一了百了
[02:55.49]是因为墙上
[02:56.52]那张骄傲的自画像
[03:00.96]无力反驳地跪下
[03:03.66]只说的出一句话
[03:06.99]生而为人的我
[03:08.61]真的对不起呀
[03:12.75]房间里闪烁着荧幕微光
[03:15.56]伴随着屋外夜色的声音嘈杂
[03:18.43]电话那头传来窒息的话
[03:21.28]刺痛在笼中
[03:22.44]备受折磨的时间啊
[03:24.25]黑暗中我装备
[03:25.58]唐吉轲德的毅力
[03:26.89]对抗看不见的敌人
[03:28.38]摧毁我的决心
[03:29.85]不要害怕我知道啊可是啊
[03:38.04]曾经我也想过一了百了
[03:44.29]为何人们都说我无可救药
[03:49.69]不强求能明白我
[03:52.60]不奢望时间倒流
[03:55.70]因为很久很久以前我曾爱过
[04:00.86]曾经我 也想过 一了百了
[04:06.89]是因为我该那样
[04:08.43]灿烂那样美好
[04:12.49]一味消极着过去
[04:14.95]离去的念头缠绕
[04:17.29]闭上眼能感受到
[04:20.04]更好的明天来到
[04:24.35]茫茫人海中的你
[04:27.01]泪光中微笑的你
[04:30.26]在我耳边温柔唱起这首歌曲
PS: 数据丢失了一回，折腾了很长时间才重新补回来。
]]></content>
      <categories>
        <category>music</category>
      </categories>
      <tags>
        <tag>music</tag>
        <tag>中岛美嘉</tag>
      </tags>
  </entry>
  <entry>
    <title>node 项目从构建到使用 jenkins + docker + nginx + mysql + redis 自动化部署</title>
    <url>/posts/68d3867d/</url>
    <content><![CDATA[概述
这都 2019 年末了，你还不会 docker 吗？ 你 low 爆了，我们作为一枚前端，不能说是要精通使用 docker 完成各种事情，但我觉得必须要学会使用 docker 干下面几件事：

部署前端应用
部署 nginx
 使用 docker-compose 部署
在容器之间建立联系

Docker 可理解为跑在宿主机上的非常精简、小巧、高度浓缩的虚拟机。 它可以将容器里的进程安稳的在宿主机上运行，之前我也有写过一些关于 docker 的文章，在这我就不做过多的介绍了，如有需要请自行查看我之前的文章即可，接下来我们通过项目来了解并使用 docker
Egg.js ？
在这里我使用 egg.js 来为大家实操一下项目的部署流程。有人会问 egg.js 是什么？ 我只能回答这是一款专业级的 node 框架。作为一个有梦想的前端，我们有必要去学习一种后端语言，而作为前端 node 的学习成本相对来说比较低的。 egg.js 这个框架在 node 现有框架中也是比较优秀的，如有需要，大家可以自行学习，我们今天的学习主要还是项目的部署流程，在这我就不给大家做过多的介绍。如有需要，请查阅 官方文档
开始前的准备

docker 与 docker-compose 的安装我就不给大家介绍了。在之前的文章中是有的，也比较详细，作为一位开发人员，我认为这点事情难不倒大家

初始化项目
$ mkdir egg-example &amp;&amp; cd egg-example
$ npm init egg --type=simple
$ npm i
复制代码
创建需要的文件
我们需要在项目根目录创建我们所需要的文件
$ touch Dockerfile
$ touch docker-compose.yml
$ setup.sh
复制代码
目录结构
egg-project
├── package.json
├── setup.sh (新建)
├── Dockerfile (新建)
├── docker-compose.yml (新建)
├── app
|   ├── router.js
│   ├── controller
│   |   └── home.js
│   ├── service (可选)
│   |   └── user.js
│   ├── middleware (可选)
│   |   └── response_time.js
│   ├── schedule (可选)
│   |   └── my_task.js

...

复制代码
常用指令
在开始之前我们要学习下常用的一些指令，看下方：

了解流程

安装 jenkins
在安装 jenkins 我选择了使用 docker-compose
docker-compose 是一个用来把 docker 自动化的东西
有了 docker-compose 你可以把所有繁复的 docker 操作全都一条命令，自动化的完成。
首先我们需要在服务器上创建一个目录机构 (具体结构个人自行创建)
/home/jenkins
     - docker-compose.yml
     - jenkins-home
复制代码
接下来我们来编写 docker-compose.yml 安装 jenkins
version: '3'                                    # 指定 docker-compose.yml 文件的写法格式
services:                                       # 多个容器集合
  docker_jenkins: 
    user: root                                  # 为了避免一些权限问题 在这我使用了root
    restart: always                             # 重启方式
    image: jenkins/jenkins:lts                  # 指定服务所使用的镜像 在这里我选择了 LTS (长期支持)
    container_name: jenkins                     # 容器名称
    ports:                                      # 对外暴露的端口定义
      - '8080:8080'
      - '50000:50000'
    volumes:                                    # 卷挂载路径
      - /home/jenkins/jenkins_home/:/var/jenkins_home   # 这是我们一开始创建的目录挂载到容器内的jenkins_home目录
      - /var/run/docker.sock:/var/run/docker.sock
      - /usr/bin/docker:/usr/bin/docker                 # 这是为了我们可以在容器内使用docker命令
      - /usr/local/bin/docker-compose:/usr/local/bin/docker-compose     # 同样的这是为了使用docker-compose命令
复制代码
我们需要进入到 jenkins 目录下执行：
$ docker-compose up -d
复制代码
配置
不出意外你现在可以打开你的服务器地址 http://xxxxxxx: 端口号 就能看到这个界面：

打开你所创建的 jenkins 目录进入到 jenkins-home
/home/jenkins/jenkins-home

进入 secrets 目录
$ cat initialAdminPassword
复制代码

然后把里面的文本复制出来填到管理员密码中


接下来需要安装两个插件
NodeJS Plugin
Publish Over SSH
复制代码


然后我们滑到最下方




开始我们的操作
Dockerfile
我们在开始阶段的时候学过一些常用指令，大家应该一眼就可以看得懂这些命令。 加油！！
FROM node:10.0-alpine             # 镜像版本

# 设置时区
RUN apk --update add tzdata \
    &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; echo "Asia/Shanghai" &gt; /etc/timezone \
    &amp;&amp; apk del tzdata

# 创建app目录
RUN mkdir -p /usr/src/node-app/egg-santak

# 设置工作目录
WORKDIR /usr/src/node-app/egg-santak

# 拷贝package.json文件到工作目录
# !!重要：package.json需要单独添加。
# Docker在构建镜像的时候，是一层一层构建的，仅当这一层有变化时，重新构建对应的层。
# 如果package.json和源代码一起添加到镜像，则每次修改源码都需要重新安装npm模块，这样木有必要。
# 所以，正确的顺序是: 添加package.json；安装npm模块；添加源代码。
COPY package.json /usr/src/node-app/egg-santak/package.json

# 安装npm依赖(使用淘宝的镜像源)
# 如果使用的境外服务器，无需使用淘宝的镜像源，即改为`RUN npm i`。
RUN npm i --registry=https://registry.npm.taobao.org

# 拷贝所有源代码到工作目录
COPY . /usr/src/node-app/egg-santak

# 暴露容器端口
EXPOSE 7001

# 启动node应用
CMD npm start
复制代码
在服务器中创建我们所需要挂载的数据卷

# nginx
$ mkdir -p nginx/conf.d nginx/logs

# mysql
$ mkdir mysql

# redis
$ mkdir redis
复制代码
然后进入 nginx/conf.d 文件夹中 创建一个后缀为 conf 的文件
$ cd nginx/conf.d
$ touch default.conf
$ vim default.conf
复制代码
写入以下内容：
server {
  listen 80;
  listen [::]:80;
  server_tokens off;

  root /var/www/html;
  index index.html index.htm;

  # 修改为自己的域名
  server_name api.lovelp.xin;

  # 访问 / 路径时执行反向代理
  location / {
    # 这里 nodejs 是 node 容器名
    proxy_pass http://nodejs:7001;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $host;
    # 后端的Web服务器可以通过 X-Forwarded-For 获取用户真实 IP
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    # 允许客户端请求的最大单文件字节数
    client_max_body_size 15M;
    # 缓冲区代理缓冲用户端请求的最大字节数
    client_body_buffer_size 128k;
  }
}
复制代码
docker-compose.yml
version: '3'

services:
  santak_redis:
    image: redis:3                  # 指定服务镜像
    container_name: santak_redis    # 容器名称
    restart: always                 # 重启方式
    hostname: redis
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass 123456  --appendonly yes
    volumes:                        # 挂载数据卷
      - /root/redis/redis.conf:/usr/local/etc/redis/redis.conf
    ports:                          # 映射端口
      - "6379:6379"     
    networks:                       # 加入指定网络
      - app-network

  santak_nginx:
    image: nginx:stable-alpine      # 指定服务镜像
    container_name: santak_nginx    # 容器名称
    restart: always                 # 重启方式
    ports:                          # 映射端口
      - "80:80"
    volumes:                        # 挂载数据卷
      - /etc/localtime:/etc/localtime
      - /root/nginx/conf.d:/etc/nginx/conf.d
      - /root/nginx/logs:/var/log/nginx
    depends_on:                     # 启动顺序
      - nodejs
    networks:                       # 加入指定网络
      - app-network

  santak_mysql:
    image: mysql:5.7
    container_name: santak_mysql
    restart: always
    ports:                          # 映射端口
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_USER=lovelp           # 创建lovelp用户
      - MYSQL_PASSWORD=mm123321     # 设置lovelp用户的密码
      - MYSQL_DATABASE=santak       # 创建初始数据库
      - TZ=Asia/Shanghai            # 设置时区
    volumes:                        # 挂载数据卷
      - /root/mysql:/var/lib/mysql  # 为了数据持久化
    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
    networks:                       # 加入指定网络
      - app-network 

  nodejs:
    build:                          # 这里指的是我们刚刚撸的 Dockerfile 文件
      context: .                    
      dockerfile: Dockerfile
    image: nodejs                   # 镜像名称
    container_name: nodejs          # 容器名称
    restart: always                 # 重启方式
    depends_on:                     # 启动顺序
      - santak_redis
      - santak_mysql
    links:                          # 容器连接
      - santak_redis:santak_redis
      - santak_mysql:santak_mysql
    networks:                       # 加入指定网络
      - app-network

volumes:
  certbot-etc:
  certbot-var:

networks:  # 实现通信
  app-network:
    driver: bridge
复制代码
在项目中的使用

setup.sh
#!/usr/bin/env bash
#image_version=`date +%Y%m%d%H%M`;

# 关闭容器
docker-compose stop || true;
# 删除容器
docker-compose down || true;
# 构建镜像
docker-compose build;
# 启动并后台运行
docker-compose up -d;
# 查看日志
docker logs nodejs;
# 对空间进行自动清理
docker system prune -a -f

复制代码
jenkins 创建项目




最后我们就可以愉快的 Build Now 了

在这里我选择的是手动构建。其实 jenkins 有很多可配置项，比如自动化构建啥的，兴趣使然，大家自行摸索，谢谢大家
整理转载:

掘金

]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>docker</tag>
        <tag>CI/CD</tag>
        <tag>node</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Shell 脚本实现一个简单 Docker</title>
    <url>/posts/90e60aac/</url>
    <content><![CDATA[
《使用 Shell 脚本实现 Docker》旨在通过一系列的实验使用户对 docker 的底层技术，如 Namespace、CGroups、rootfs、联合加载等有一个感性的认识。在此过程中，我们还将通过 Shell 脚本一步一步地实现一个简易的 docker，以期使读者在使用 docker 的过程中知其然知其所以然。

我们的实验环境为 Ubuntu 18.04 64bit，简易 docker 工程的名字为 docker.sh，该工程仓库地址如下：
https://github.com/pandengyang/docker.sh.git
https://github.com/appotry/docker.sh
《使用 Shell 脚本实现 Docker》目录如下：
1. Namespace
1.1. Namespace简介
1.2. uts namespace
1.2.1. uts namespace简介
1.2.2. docker.sh
1.3. mount namespace
1.3.1. /etc/mtab、/proc/self/mounts
1.3.2. /proc/self/mountinfo
1.3.3. bind mount
1.3.4. mount namespace简介
1.3.5. docker.sh
1.4. pid namespace
1.4.1. unshare的--fork选项
1.4.2. pid namespace简介
1.4.3. pid嵌套
1.4.4. docker.sh
2. CGroups
2.1. CGroups简介
2.2. 限制内存
2.2.1. 用CGroups限制内存
2.2.2. docker.sh
3. 切换根文件系统
3.1. 根文件系统
3.2. pivot_root
3.3. docker.sh
4. 联合加载
4.1. 联合加载简介
4.2. AUFS
4.3. docker.sh
5. 卷
5.1. 卷简介
5.2. docker.sh
6. 后记
1.Namespace
1.1.Namespace 简介
传统上，在 Linux 中，许多资源是全局管理的。例如，系统中的所有进程按照惯例是通过 PID 标识的，这意味着内核必须管理一个全局的 PID 列表。而且，所有调用者通过 uname 系统调用返回的系统相关信息都是相同的。用户 id 的管理方式类似，即各个用户是通过一个全局唯一的 UID 标识。
Namespace 是 Linux 用来隔离上述全局资源的一种方式。把一个或多个进程加入到同一个 namespace 中后，这些进程只会看到该 namespace 中的资源。namespace 是后来加入到 Linux 中的，为了兼容之前的全局资源管理方式，Linux 为每一种资源准备了一个全局的 namespace。Linux 中的每一个进程都默认加入了这些全局 namespace。
Linux 中的每个进程都有一个 /proc/[pid]/ns/ 目录，里面包含了该进程所属的 namespace 信息。我们查看一下当前 Shell 的 /proc/[pid]/ns 目录，命令及结果如下：
phl@kernelnewbies:~$ sudo ls -l /proc/$$/ns
total 0
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 cgroup -&gt; cgroup:[4026531835]
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 ipc -&gt; ipc:[4026531839]
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 mnt -&gt; mnt:[4026531840]
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 net -&gt; net:[4026531993]
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 pid -&gt; pid:[4026531836]
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 pid_for_children -&gt; pid:[4026531836]
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 user -&gt; user:[4026531837]
lrwxrwxrwx 1 phl phl 0 Jan 22 08:43 uts -&gt; uts:[4026531838]
该目录下有很多符号链接，每个符号链接代表一个该进程所属的 namespace。用 readlink 读取这些符号链接可以查看进程所属的 namespace id。我们读一下当前 Shell 所属的 uts namespace id，命令及结果如下：
phl@kernelnewbies:~$ sudo readlink /proc/$$/ns/uts
uts:[4026531838]
后文中我们将介绍 uts namespace、mount namespace、pid namespace 的用法。
1.2.uts namespace
1.2.1.uts namespace 简介
uts namespace 用于隔离系统的主机名等信息，我们将通过实验学习其用法。在实验过程中，我们采用如下的步骤：

查看全局 uts namespace 信息
新建一个 uts namespace，查看其信息并作出修改
查看全局 uts namespace，查看其是否被新建的 uts namespace 影响到

对于其他 namespace，我们也采取类似的步骤进行实验学习。
首先，我们查看一下全局的 hostname 及 uts namespace id。命令及结果如下：
phl@kernelnewbies:~$ hostname
kernelnewbies

phl@kernelnewbies:~$ sudo readlink /proc/$$/ns/uts
uts:[4026531838]
然后，我们创建一个新的 uts namespace，并查看其 namespce id。
在继续之前，需要介绍一个 namespace 工具 unshare。利用 unshare 我们可以新建一个的 namespace，并在新 namespace 中执行一条命令。unshare 执行时需要 root 权限。unshare 的使用方法如下：
unshare [options] [program [arguments]]
执行 unshare 时，我们可以指定要新建的 namespace 的类型以及要执行的命令。unshare 提供了一系列选项，当指定某个选项时可新建指定的 namespace。namespace 类型选项如下：

--uts 创建新的 uts namespace
--mount 创建新的 mount namespace
--pid 创建新的 pid namespace
--user 创建新的 user namespace

介绍完 unshare 之后，我们继续之前的实验。我们用 unshare 创建一个新的 uts namespace，并在新的 uts namespace 中执行 /bin/bash 命令，命令及结果如下：
phl@kernelnewbies:~$ sudo unshare --uts /bin/bash
root@kernelnewbies:~#
我们用 unshare 创建了一个新的 uts namespace。在新的 uts namespace 中查看其 hostname 和 namespace id，命令及结果如下：
root@kernelnewbies:~$ hostname
kernelnewbies

root@kernelnewbies:~# readlink /proc/$$/ns/uts
uts:[4026532177]
从结果我们可以看到，新 uts namespace 的 id 与全局 uts namespace 的 id 不一致。这说明 /bin/bash 已运行在一个新的 uts namespace 中了。
我们将新 uts namespace 的 hostname 改为 dreamland，并强制更新 Shell 提示符。命令及结果如下：
root@kernelnewbies:~# hostname dreamland
root@kernelnewbies:~# hostname
dreamland

root@kernelnewbies:~# exec /bin/bash
root@dreamland:~#
从结果我们可以看到，新 uts namespace 的 hostname 的确是被修改了，exec /bin/bash 用于强制更新 Shell 的提示符。
我们重新打开一个 Shell 窗口，该 Shell 位于全局 uts namespace 中。在新的 Shell 窗口中查看全局 uts namespace id 及 hostname，命令及结果如下：
phl@kernelnewbies:~$ hostname
kernelnewbies

phl@kernelnewbies:~$ sudo readlink /proc/$$/ns/uts
uts:[4026531838]
从结果我们可以看到，我们在新 uts namespace 中所作的修改并未影响到全局的 uts namespace。
父进程创建子进程时只有提供创建新 namespace 的标志，才可创建新的 namespace，并使子进程处于新的 namespace 中。默认情况下，子进程与父进程处于相同的 namespace 中。我们在新的 uts namespace 中创建一个子进程，然后查看该子进程的 uts namespace id，命令及结果如下：
phl@kernelnewbies:~$ sudo unshare --uts /bin/bash
root@kernelnewbies:~# readlink /proc/$$/ns/uts
uts:[4026532305]

root@kernelnewbies:~# bash
root@kernelnewbies:~# readlink /proc/$$/ns/uts
uts:[4026532305]
从结果我们可以看到，子进程所属 uts namespace 的 id 与其父进程相同。其他 namespae 与 uts namespace 类似，子进程与父进程同属一个 namespace。
1.2.2.docker.sh
有了以上关于 uts namespace 的介绍，我们就可以将 uts namespace 加入到 docker.sh 中了。docker.sh 工程分为两个脚本：docker.sh 和 container.sh。
docker.sh 用于收集用户输入、调用 unshare 创建 namespace 并执行 container.sh 脚本，docker.sh 脚本如下：
#!/bin/bash

usage () {
        echo -e "\033[31mIMPORTANT: Run As Root\033[0m"
        echo ""
        echo "Usage:    docker.sh [OPTIONS]"
        echo ""
        echo "A docker written by shell"
        echo ""
        echo "Options:"
        echo "          -c string       docker command"
        echo "                          (\"run\")"
        echo "          -m              memory"
        echo "                          (\"100M, 200M, 300M...\")"
        echo "          -C string       container name"
        echo "          -I string       image name"
        echo "          -V string       volume"
        echo "          -P string       program to run in container"

        return 0
}

if test "$(whoami)" != root
then
        usage
        exit -1
fi

while getopts c:m:C:I:V:P: option
do
        case "$option"
        in
                c) cmd=$OPTARG;;
                m) memory=$OPTARG;;
                C) container=$OPTARG;;
                I) image=$OPTARG;;
                V) volume=$OPTARG;;
                P) program=$OPTARG;;
                \?) usage
                    exit -2;;
        esac
done

export cmd=$cmd
export memory=$memory
export container=$container
export image=$image
export volume=$volume
export program=$program

unshare --uts ./container.sh
脚本最开始为 usage 函数，该函数为 docker.sh 的使用说明。当用户以非预期的方式使用 docker.sh 时，该函数会被调用。该函数输出如下信息：
IMPORTANT: Run As Root

Usage:  docker.sh [OPTIONS]

A docker written by shell

Options:
                -c string       docker command
                                ("run")
                -m              memory
                                ("100M, 200M, 300M...")
                -C string       container name
                -I string       image name
                -V string       volume
                -P string       program to run in container
从 usage 函数的输出我们可以看到，执行 docker.sh 时需要 root 权限且需要正确地传递参数。
docker.sh 首先对当前用户进行检测，如果用户不为 root，则打印使用说明并退出脚本；如果用户为 root，则继续执行。检测用户的脚本如下：
if test "$(whoami)" != root
then
        usage
        exit -1
fi
然后，docker.sh 使用 getopts 从命令行提取参数，然后赋值给合适的变量。从命令行提取参数的脚本如下：
while getopts c:m:C:I:V:P: option
do
        case "$option"
        in
                c) cmd=$OPTARG;;
                m) memory=$OPTARG;;
                C) container=$OPTARG;;
                I) image=$OPTARG;;
                V) volume=$OPTARG;;
                P) program=$OPTARG;;
                \?) usage
                    exit -2;;
        esac
done
如果用户的输入不正确，则打印使用说明并退出脚本；如果用户输入正确，则解析命令行参数并赋值给合适的变量。
为了简化，用户在运行 docker.sh 时需提供完整的参数列表，示例如下：
sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
当然，如果当前用户就是 root，就不需要 sudo 了。下表列出了各个参数的含义及示例：

docker.sh 将命令行参数赋值给变量后，需要将这些变量导出，以传递给 container.sh。导出变量的脚本如下：
export cmd=$cmd
export memory=$memory
export container=$container
export image=$image
export volume=$volume
export program=$program
这里说明一下为什么要将 docker.sh 工程拆分为 docker.sh 和 container.sh 两个脚本。因为调用 unshare 创建新的 namespace 时，会执行一个命令，该命令在新的 namespace 中运行。该命令一旦结束，unshare 也就结束了，unshare 创建的新 namespace 也就不存在了。
docker.sh 不会并发地执行 unshare 命令与 unshare 之后的脚本，因此，只有 unshare 结束了，后续脚本才可继续运行。但是当 unshare 结束了，准备执行后续脚本时，新的 namespae 已经不存在了。因此一些加入 cgroups、切换根文件系统等工作必须在 unshare 执行的命令中进行，所以我们采用在 unshare 中执行 container.sh 脚本的方式完成后续的工作。
最后，docker.sh 调用 unshare 创建新的 uts namespace，并执行 container.sh 脚本。调用 unshare 的脚本如下：
unshare --uts ./container.sh
container.sh 将容器的 hostname 修改为通过 - C 传递的容器的名字，然后执行通过 - P 传递的程序。container.sh 脚本如下：
#!/bin/bash

hostname $container
exec $program
现在，我们运行 docker.sh，并查看其 hostname。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
root@dreamland:~/docker.sh# hostname
dreamland
从结果我们可以看到，容器的 hostname 已经改变为我们传递的容器名字 dreamland 了。
1.3.mount namespace
1.3.1./etc/mtab、/proc/self/mounts
早期的 Linux 使用 /etc/mtab 文件来记录当前的挂载点信息。每次 mount/umount 文件系统时会更新 /etc/mtab 文件中的信息。
后来，linux 引入了 mount namespace，每个进程都有一份自己的挂载点信息。当然，处于同一个 mount namespace 里面的进程，其挂载点信息是相同的。进程的挂载点信息通过 /proc/[pid]/mounts 文件导出给用户。
为了兼容以前的 /etc/mtab，/etc/mtab 变成了指向 /proc/self/mounts 的符号链接。通过 readlink 查看 /etc/mtab 指向的文件，命令及结果如下：
phl@kernelnewbies:~$ readlink /etc/mtab
../proc/self/mounts
通过读取 /proc/self/mounts 文件，可以查看当前的挂载点信息，命令及结果如下：
phl@kernelnewbies:~$ cat /proc/self/mounts
sysfs /sys sysfs rw,nosuid,nodev,noexec,relatime 0 0
proc /proc proc rw,nosuid,nodev,noexec,relatime 0 0
/dev/sda1 / ext4 rw,relatime,errors=remount-ro 0 0
securityfs /sys/kernel/security securityfs rw,nosuid,nodev,noexec,relatime 0 0
...
由于该文件中内容太多，我们省略了一部分，只保留了一些比较重要的挂载点信息。每行的信息分为六个字段，各字段的含义及示例如下：

由于该文件有点过时，被后文介绍的 /proc/self/mountinfo 替换掉，所以不做过多介绍。
1.3.2./proc/self/mountinfo
/proc/self/mountinfo 包含了进程 mount namespace 中的挂载点信息。 它提供了旧的 /proc/[pid]/mounts 文件中缺少的各种信息（传播状态，挂载点 id，父挂载点 id 等），并解决了 /proc/[pid]/mounts 文件的一些其他缺陷。我们查看进程挂载点信息时应优先使用该文件。
该文件中每一行代表一个挂载点信息，每个挂载点信息分为 11 个字段。挂载点信息的示例如下：

各字段的含义及示例如下：

我们主要关注可选字段中的传播状态选项。首先，我们看一下关于 mount namespace 的问题。问题如下：
当创建 mount namespace 时，新 mount namespace 会拷贝一份老 mount namespace 里面的挂载点信息。例如，全局 mount namespace 中有一个 /a 挂载点，新建的 mount namespace 中也会有一个 /a 挂载点。那么我们在新 mount namespace 中的 /a 下创建或删除一个挂载点，全局 mount namespace 中的 /a 会同步创建或删除该挂载点吗？或者在全局 mount namespace 中的 /a 下创建或删除一个挂载点，新 mount namespace 中的 /a 会同步创建或删除该挂载点吗？
mountinfo 文件中可选字段的传播状态就是控制在一个挂载点下进行创建 / 删除挂载点操作时是否会传播到其他挂载点的选项。传播状态有四种可取值，常见的有如下两种：

shared 表示创建 / 删除挂载点的操作会传播到其他挂载点
 private 表示创建 / 删除挂载点的操作不会传播到其他挂载点

由于在容器技术中要保证主机与容器的挂载点信息互不影响，因此要求容器中的挂载点的传播状态为 private。
1.3.3.bind mount
bind mount 可以将一个目录（源目录）挂载到另一个目录（目的目录），在目的目录里面的读写操作将直接作用于源目录。
下面我们通过实验了解一下 bind mount 的功能，首先，我们准备一下实验所需要的的目录及文件。命令及结果如下：
phl@kernelnewbies:~$ mkdir bind
phl@kernelnewbies:~$ cd bind/
phl@kernelnewbies:~/bind$ mkdir a
phl@kernelnewbies:~/bind$ mkdir b
phl@kernelnewbies:~/bind$ echo hello, a &gt; a/a.txt
phl@kernelnewbies:~/bind$ echo hello, b &gt; b/b.txt
然后，我们将 a 目录 bind mount 到 b 目录并查看 b 目录下的内容。命令及结果如下：
phl@kernelnewbies:~/bind$ sudo mount --bind a b
phl@kernelnewbies:~/bind$ tree b
b
└── a.txt
0 directories, 1 file
从结果我们可以看到，b 目录下原先的内容被隐藏，取而代之的是 a 目录下的内容。
然后，我们修改 b 目录下的内容，修改完毕后，从 b 目录上卸载掉 a 目录。命令及结果如下：
phl@kernelnewbies:~/bind$ echo hello, a from b &gt; b/a.txt
phl@kernelnewbies:~/bind$ sudo umount b
我们读取一下 a 目录中 a.txt，看看其内容是否被改变。命令及结果如下：
phl@kernelnewbies:~/bind$ cat a/a.txt
hello, a from b
从结果我们可以看到，a 目录中的内容确实被当 a 被 bind mount 到 b 时对 b 目录的操作所修改了。
bind mount 在容器技术中有很重要的用途，后文会有涉及。
1.3.4.mount namespace 简介
mount namespace 用来隔离文件系统的挂载点信息，使得不同的 mount namespace 拥有自己独立的挂载点信息。不同的 namespace 之间不会相互影响，其在 unshare 中的选项为 --mount。
当用 unshare 创建新的 mount namespace 时，新创建的 namespace 将拷贝一份老 namespace 里的挂载点信息，但从这之后，他们就没有关系了。这是 unshare 将新 namespace 里面的所有挂载点的传播状态设置为 private 实现的。通过 mount 和 umount 增加和删除各自 mount namespace 里面的挂载点都不会相互影响。
下面我们将演示 mount namespace 的用法。首先，我们准备需要的目录和文件，命令及结果如下：
phl@kernelnewbies:~$ mkdir -p hds/hd1 hds/hd2 &amp;&amp; cd hds

phl@kernelnewbies:~/hds$ dd if=/dev/zero bs=1M count=1 of=hd1.img &amp;&amp; mkfs.ext2 hd1.img
phl@kernelnewbies:~/hds$ dd if=/dev/zero bs=1M count=1 of=hd2.img &amp;&amp; mkfs.ext2 hd2.img

phl@kernelnewbies:~$ tree .
.
├── hd1
├── hd1.img
├── hd2
└── hd2.img
2 directories, 2 files
然后，我们在全局的 mount namespace 中挂载 hd1.img 到 hd1 目录，然后查看该 mount namespace 中的挂载点信息与 mount namespace id。命令及结果如下：
phl@kernelnewbies:~/hds$ sudo mount hd1.img hd1
phl@kernelnewbies:~/hds$ cat /proc/self/mountinfo | grep hd
556 27 7:18 / /home/phl/hds/hd1 rw,relatime shared:372 - ext2 /dev/loop18 rw

phl@kernelnewbies:~/hds$ sudo readlink /proc/$$/ns/mnt
mnt:[4026531840]
然后，执行 unshare 命令创建一个新的 mount namespace 并查看该 mount namespace id 和挂载点信息。命令及结果如下：
phl@kernelnewbies:~/hds$ sudo unshare --uts --mount /bin/bash
root@kernelnewbies:~/hds# cat /proc/self/mountinfo | grep hd
739 570 7:18 / /home/phl/hds/hd1 rw,relatime - ext2 /dev/loop18 rw

root@kernelnewbies:~/hds# readlink /proc/$$/ns/mnt
mnt:[4026532180]
从结果我们可以看到，新 mount namespace 中的挂载点信息与全局 mountnamespace 中的挂载点信息基本一致，一些挂载选项（如传播状态）变化了。新的 mount namespace id 与全局 mount namespace id 是不一样的。
然后，我们在新的 mount namespace 中挂载 hd2.img 到 hd2 目录，并查看挂载点信息。命令及结果如下：
root@kernelnewbies:~/hds# mount hd2.img hd2
root@kernelnewbies:~/hds# cat /proc/self/mountinfo | grep hd
739 570 7:18 / /home/phl/hds/hd1 rw,relatime - ext2 /dev/loop18 rw
740 570 7:19 / /home/phl/hds/hd2 rw,relatime - ext2 /dev/loop19 rw
从结果我们可以看到，新 mount namespace 中有 hd1 和 hd2 这两个挂载点。现在启动一个新的 Shell 窗口，查看全局 mount namespace 中的挂载点信息。命令及结果如下：
phl@kernelnewbies:~/hds$ cat /proc/self/mountinfo | grep hd
556 27 7:18 / /home/phl/hds/hd1 rw,relatime shared:372 - ext2 /dev/loop18 rw
从结果我们可以看到，全局 mount namespace 中的挂载点信息只有 hd1，而没有 hd2。这说明在新 mount namespace 中进行挂载 / 卸载操作不会影响其他 mount namespace 中的挂载点信息。
mount namespace 只隔离挂载点信息，并不隔离挂载点下面的文件信息。对于多个 mount namespace 都能看到的挂载点，如果在一个 namespace 中修改了挂载点下面的文件，其他 namespace 也能感知到。下面，我们在新建的 mount namespace 中创建一个文件，命令如下：
root@kernelnewbies:~/hds# echo hello from new mount namespace &gt; hd1/hello.txt
在新启动的 Shell 中，查看 hd1 目录并读取 hd1/hello.txt 文件。命令及结果如下：
phl@kernelnewbies:~/hds$ tree hd1
hd1
├── hello.txt
└── lost+found [error opening dir]
1 directory, 1 file

phl@kernelnewbies:~/hds$ cat hd1/hello.txt
hello from new mount namespace
从结果我们可以看到，在全局 mount namespace 中，我们可以读取到在新建的 mount namespace 中创建的文件。
1.3.5.docker.sh
有了以上关于 mount namespace 的知识，我们就可以将 mount namespace 加入到 docker.sh 中了。mount namespace 将放在 docker.sh 中，带下划线的行是我们为实现 mount namespace 而修改的代码。修改后的 docker.sh 脚本如下：
...
unshare --uts --mount ./container.sh
从上述代码我们可以看到，我们仅仅是在调用 unshare 时加入 --mount 选项，就可为 docker.sh 引入了 mount namespace 功能。
1.4.pid namespace
1.4.1.unshare 的 --fork 选项
unshare 有一个选项 --fork，当执行 unshare 时，如果没有这个选项，unshare 会直接 exec 新命令，也就是说 unshare 变成了新命令。如果带有 --fork 选项，unshare 会 fork 一个子进程，该子进程 exec 新命令，unshare 是该子进程的父进程。我们分别不带 --fork 和带 --fork 来执行 unshare，然后查看进程之间的关系。
首先，我们不带 --fork 选项执行 unshare，并查看当前 Shell 的进程 id。命令及结果如下：
phl@kernelnewbies:~$ sudo unshare --uts /bin/bash
root@kernelnewbies:~/hds# echo $$
11699
此时 unshare 会创建一个新的 uts namespace，然后 exec /bin/bash。我们启动一个新 Shell，然后使用 pstree 查看进程间关系，命令及结果如下：
phl@kernelnewbies:~/hds$ pstree -p | grep 11699
sudo(11698)---bash(11699)
从结果我们可以看到，sudo fork 出一个子进程，该子进程执行 unshare。unshare 创建了新 uts namespace 后，exec 了 /bin/bash，也就是说 unshare 变成了 /bin/bash。
然后，我们带 --fork 选项执行 unshare，并查看当前 Shell 的进程 id。命令及结果如下：
phl@kernelnewbies:~/hds$ sudo unshare --uts --fork /bin/bash
root@kernelnewbies:~/hds# echo $$
11866
此时 unshare 会创建一个新的 uts namespace，然后 fork 出一个子进程，该子进程 exec /bin/bash。我们启动一个新 Shell，然后使用 pstree 查看进程间关系，命令及结果如下：
phl@kernelnewbies:~/hds$ pstree -p | grep 11866
sudo(11864)---unshare(11865)---bash(11866)
从结果我们可以看到，sudo fork 出一个子进程，该子进程执行命令 unshare。unshare 创建了新 uts namespace 后，fork 出一个子进程，该子进程 exec /bin/bash，也就是说 unshare 变成了新的 /bin/bash 进程的父进程。
1.4.2.pid namespace 简介
pid namespace 用来隔离进程 pid 空间，使得不同 pid namespace 里的进程 pid 可以重复且相互之间不影响。进程所属的 pid namespace 在创建的时候就确定了，无法更改，因此需要 --fork 选项来创建一个新进程，然后将该新进程加入新建的 pid namespace 中。pid namespace 在 unshare 中的选项为 --pid。
unshare 在创建 pid namespace 时需同时提供 --pid 与 --fork 选项。unshare 本身会加入全局的 pid namespace，其 fork 出的子进程会加入新建的 pid namespace。
首先，我们查看全局 pid namespace id，命令及结果如下：
phl@kernelnewbies:~$ sudo readlink /proc/$$/ns/pid
pid:[4026531836]
然后，执行 unshare 命令创建一个新的 pid namespace 并查看该 pid namespace id。命令及结果如下：
phl@kernelnewbies:~$ sudo unshare --mount --pid --fork /bin/bash
root@kernelnewbies:~# readlink /proc/$$/ns/pid
pid:[4026531836]
从结果我们可以看到，新创建的进程也处于全局 pid namespace 中，而不是新的 pid namespace。
出现这种情形是因为当前的 /proc 文件系统是老的。我们查看一下 $$ 的值，命令及结果如下：
root@kernelnewbies:~# echo $$
1
从结果我们可以看到，$$ 的值为 1，但是 /proc 文件系统却是老的，因此我们查看的实际是 init 进程所属的 pid namespace，当然是全局 pid namespace 了。
重新挂载 /proc 文件系统，这也是 unshare 执行时带 --mount 选项的原因，只有这样，重新挂载 /proc 文件系统时，不会搞乱整个系统。再次查看新进程所属的 pid namespace，命令及结果如下：
root@kernelnewbies:~# mount -t proc proc /proc
root@kernelnewbies:~# readlink /proc/$$/ns/pid
pid:[4026532182]
从结果我们可以看到，新进程的 pid namespace 与全局 pid namespace 的 id 不同。
接下来，我们再来查看一下新 pid namespace 中的进程信息。命令及结果如下：
root@kernelnewbies:~# ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 19:03 pts/1    00:00:00 /bin/bash
root        10     1  0 19:03 pts/1    00:00:00 ps -e
从结果我们可以看到，当前 pid namespace 中只有 2 个进程，看不到全局 pid namespace 里面的其他进程。我们通过 unshare 执行的进程 pid 为 1，也就是说该进程成了新 pid namespace 中的 init 进程。
1.4.3.pid 嵌套
pid namespace 可以嵌套，也就是说有父子关系，在当前 pid namespace 里面创建的所有新的 pid namespace 都是当前 pid namespace 的子 pid namespace。
首先，我们创建 3 个嵌套的 pid namespace，并查看每个 pid namespace id。--mount-proc 选项用于自动挂载 /proc 文件系统，省去了手动挂载 /proc 文件系统的操作。命令及结果如下：
phl@kernelnewbies:~$ sudo readlink /proc/$$/ns/pid
pid:[4026531836]

phl@kernelnewbies:~$ sudo unshare --uts --mount --pid --mount-proc --fork /bin/bash
root@kernelnewbies:~# readlink /proc/$$/ns/pid
pid:[4026532182]

root@kernelnewbies:~# unshare --uts --mount --pid --mount-proc --fork /bin/bash
root@kernelnewbies:~# readlink /proc/$$/ns/pid
pid:[4026532185]

root@kernelnewbies:~# unshare --uts --mount --pid --mount-proc --fork /bin/bash
root@kernelnewbies:~# readlink /proc/$$/ns/pid
pid:[4026532188]
然后，我们启动一个新 Shell，然后使用 pstree 查看进程间关系。命令及结果如下：
phl@kernelnewbies:~$ pstree -lp | grep unshare
sudo(12547)---unshare(12548)---bash(12549)---unshare(12579)---bash(12580)---unshare(12593)---bash(12594)
使用 cat /proc/[pid]/status | grep NSpid 可查看某进程在当前 pid namespace 及子孙 pid namespace 中的 pid。我们在全局 pid namespace 中查看上述各进程在各 pid namespace 中的 pid，命令及结果如下：
phl@kernelnewbies:~$ cat /proc/12594/status | grep NSpid
NSpid: 12594 21 11 1

phl@kernelnewbies:~$ cat /proc/12593/status | grep NSpid
NSpid: 12593 20 10

phl@kernelnewbies:~$ cat /proc/12580/status | grep NSpid
NSpid: 12580 11 1

phl@kernelnewbies:~$ cat /proc/12579/status | grep NSpid
NSpid: 12579 10

phl@kernelnewbies:~$ cat /proc/12549/status | grep NSpid
NSpid: 12549 1
下面我们将以上进程在各 pid namespace 中的 pid，整理成表格。表格信息如下：

我们以最后一行为例进行介绍，最后一行有 4 个 pid，这 4 个 pid 其实是同一个进程。这个进程在 4 个 pid namespace 中都可以被看到，且其在 4 个 pid namespace 中的 pid 各不相同。
1.4.4.docker.sh
有了以上关于 pid namespace 的知识，我们就可以将 pid namespae 加入到 docker.sh 中了。pid namespace 将放在 docker.sh 中，带下划线的行是我们为实现 pid namespace 而修改的代码。修改后的 docker.sh 脚本如下：
...
unshare --uts --mount --pid --fork ./container.sh
从上述代码我们可以看到，我们仅仅是在调用 unshare 时加入 --pid 和 --fork 选项，就可为 docker.sh 引入了 pid namespace 功能。
然后，我们需要重新挂载 /proc 文件系统。重新挂载 /proc 文件系统的功能将放在 container.sh 中，带下划线的行是我们为重新挂载 /proc 文件系统而新添的代码。修改后的 container.sh 脚本如下如下所示：
hostname $container
mount -t proc proc /proc
exec $program
现在，我们运行 docker.sh，并查看当前的进程信息。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
root@dreamland:~/docker.sh# ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 17:31 pts/1    00:00:00 /bin/bash
root        16     1  0 17:31 pts/1    00:00:00 ps -ef
从结果我们可看出，当前进程只有两个，不再有主机上的其他进程。
2.CGroups
2.1.CGroups 简介
CGroups 是一种将进程分组，并以组为单位对进程实施资源限制的技术。每个组都包含以下几类信息：

进程列表
资源 A 限制
资源 B 限制
资源 C 限制
...

我们将以常见的 CPU 资源及内存资源为例进行介绍。以下的信息将使进程号为 1001、1002、2008、3306 的四个进程总共只能使用一个 CPU 核心；总共最多使用 25% 的 CPU 资源；总共最多使用 100M 内存，这样的一个分组被称为 cgroup。

上面的介绍只是说明了要将何种资源限制施加于哪些进程，并未说明资源限制是如何施加到进程上。具体施加资源限制的过程需要 subsystem 来帮忙。subsystem 读取 cgroup 中的资源限制和进程列表，然后将这些资源限制施加到这些进程上。常见的 subsystem 包括如下几种：

cpu
memory
pids
devices
blkio
net_cls

每个 subsystem 只读取与其相关的资源限制，然后施加到进程上。例如：memory 子系统只读取内存限制，而 cpu 子系统只读取 cpu 限制。
cgroup 被组织成树，如下图所示：

采用树状结构可以方便地实现资源限制继承，一个 cgroup 中的资源限制将作用于该 cgroup 及其子孙 cgroup 中的进程。例如：图中 13001、10339、2999 受到 A、B、C、D 四个 cgroup 中的资源限制。这样的一个树状结构被称为 hierarchy。
hierarchy 中包含了系统中所有的进程，它们分布于各个 cgroup 中。在 hierarchy 中，一个进程必须属于且只属于一个 cgroup，这样才能保证对进程施加的资源限制不会遗漏也不会冲突。
要想让一个 subsystem 读取 hierarchy 中各 cgroup 的资源限制，并施加于其中的进程需要将 subsystem 和 hierarchy 关联起来。subsystem 与 hierarchy 的关系如下：

系统中可以有多个 hierarchy
 一个 hierarchy 可以关联 0 个或多个 subsystem，当关联 0 个 subsystem 时，该 hierarchy 只是对进程进行分类
一个 subsystem 最多关联到一个 hierarchy，因为每个 hierarchy 都包含系统中所有的进程，若一个 subsystem 关联到了多个 hierarchy，对同一进程将有多种资源限制，这是不对的

系统使用 CGroups 通常有两种形式：一种是创建一个 hierarchy，将所有的 subsystem 关联到其上，在这个 hierarchy 上配置各种资源限制；另一种是为每一个 subsystem 创建一个 hierarchy，并将该 subsystem 关联到其上，每个 hierarchy 只对一种资源进行限制。后一种比较清晰，得到了更普遍的采用。
CGroups 不像大多数的技术那样提供 API 或命令之类的用户接口，而是提供给用户一个虚拟文件系统，该虚拟文件系统类型为 cgroup。一个挂载后的 cgroup 文件系统就是一个 hierarchy，文件系统中的一个目录就是一个 cgroup，目录中的文件代表了进程列表或者资源限制信息。文件系统是树状结构，其各个目录之间的父子关系就代表了 cgroup 之间的继承关系。挂载 cgroup 虚拟文件系统后，通过在该文件系统上创建目录、写进程列表文件、写资源限制文件就可以操作 CGroups。
下面，我们通过实验学习一下 CGroups 的用法。首先，我们挂载一个 cgroup 虚拟文件系统，该文件系统不与任何 subsystem 关联，仅仅是将进程进行分类。命令及结果如下：
phl@kernelnewbies:~$ mkdir -p cg/test
# -o none,name=test 表示该cgroup文件系统不与任何子系统关联
# 该文件系统用name=test来标识
phl@kernelnewbies:~$ sudo mount -t cgroup -o none,name=test test cg/test
phl@kernelnewbies:~$ tree cg/test
cg/test
├── cgroup.clone_children
├── cgroup.procs
├── cgroup.sane_behavior
├── notify_on_release
├── release_agent
└── tasks
0 directories, 6 files
挂载 cgroup 文件系统后，该 cgroup 文件系统的根目录下会生成许多文件，该根目录被称为 root cgroup。cgroup.procs 里面存放的是当前 cgroup 中的所有进程 id，由于该 hierarchy 中只有一个 cgroup，所以这个文件包含了系统中所有的进程 id。其他的文件与 cgroups 基本功能关系不大，暂时可以忽略。
在 cgroup 文件系统中，创建一个目录就会创建一个 cgroup。下面我们将会演示如何创建下面这样的 hierarchy：

命令及结果如下：
phl@kernelnewbies:~$ sudo mkdir -p cg/test/test1/test11
phl@kernelnewbies:~$ sudo mkdir -p cg/test/test2/test22
phl@kernelnewbies:~$ tree cg/test
cg/test
├── cgroup.clone_children
├── cgroup.procs
├── cgroup.sane_behavior
├── notify_on_release
├── release_agent
├── tasks
├── test1
│   ├── cgroup.clone_children
│   ├── cgroup.procs
│   ├── notify_on_release
│   ├── tasks
│   └── test11
│       ├── cgroup.clone_children
│       ├── cgroup.procs
│       ├── notify_on_release
│       └── tasks
└── test2
    ├── cgroup.clone_children
    ├── cgroup.procs
    ├── notify_on_release
    ├── tasks
    └── test22
        ├── cgroup.clone_children
        ├── cgroup.procs
        ├── notify_on_release
        └── tasks

4 directories, 22 files
从结果我们可以看到，我们创建了相应的目录后，这些目录下自动出现了包含 cgroup 信息的目录及文件。
删除 cgroup 时只需删除该 cgroup 所在的目录即可。下面我们将删除 test11 cgroup，命令及结果如下：
phl@kernelnewbies:~$ sudo rmdir cg/test/test1/test11
phl@kernelnewbies:~$ tree cg/test
cg/test
├── cgroup.clone_children
├── cgroup.procs
├── cgroup.sane_behavior
├── notify_on_release
├── release_agent
├── tasks
├── test1
│   ├── cgroup.clone_children
│   ├── cgroup.procs
│   ├── notify_on_release
│   └── tasks
└── test2
    ├── cgroup.clone_children
    ├── cgroup.procs
    ├── notify_on_release
    ├── tasks
    └── test22
        ├── cgroup.clone_children
        ├── cgroup.procs
        ├── notify_on_release
        └── tasks

3 directories, 18 files
每个 cgroup 下面都有一个 cgroup.procs 文件，该文件里面包含当前 cgroup 里面的所有进程 id。只要将某个进程的 id 写入该文件，即可将该进程加入到该 cgroup 中。下面，我们将当前的 bash 加入到 test22 cgroup 中，命令及结果如下：
phl@kernelnewbies:~$ echo $$
3894
phl@kernelnewbies:~$ sudo sh -c "echo 3894 &gt; cg/test/test2/test22/cgroup.procs"
/proc/[pid]/cgroup 包含了某个进程所在的 cgroup 信息。下面，我们查看一下当前 bash 进程所在的 cgroup 信息，命令及结果如下：
phl@kernelnewbies:~$ cat /proc/3894/cgroup
13:name=test:/test2/test22
12:freezer:/
11:perf_event:/
10:blkio:/user.slice
9:devices:/user.slice
8:hugetlb:/
7:cpu,cpuacct:/user.slice
6:net_cls,net_prio:/
5:memory:/user.slice
4:rdma:/
3:pids:/user.slice/user-1001.slice/session-4.scope
2:cpuset:/
1:name=systemd:/user.slice/user-1001.slice/session-4.scope
0::/user.slice/user-1001.slice/session-4.scope
从结果我们可以看到，当前 bash 进程加入了多个 cgroup，其中带下划线的行为我们刚刚加入的 cgroup。
要想将 hierarchy 与子系统关联起来，需要在 - o 选项中指定子系统名称。下面演示了如何将 memory 子系统与新挂载的 cgroup 文件系统关联起来。代码如下：
phl@kernelnewbies:~$ sudo mkdir cg/memory
phl@kernelnewbies:~$ sudo mount -t cgroup -o memory memcg cg/memory
由于很多发行版的操作系统已经为我们配置好了这些 cgroup 文件系统，我们应当直接使用这些已经挂在好的文件系统，不需要自己去挂载。
另外，当创建子进程时，子进程会自动加入父进程所在的 cgroup。
2.2. 限制内存
2.2.1. 用 CGroups 限制内存
下面我们将介绍演示 CGroups 如何限制进程使用的内存资源，我们以内存为例进行讲解。
Ubuntu18.04 已经为我们挂载了一个关联 memory 子系统的 cgroup 虚拟文件系统。我们用 mount 命令查看一下该系统挂载到了何处，命令及结果如下：
phl@kernelnewbies:~$ mount | grep cgroup
tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755)
cgroup on /sys/fs/cgroup/unified type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate)
cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd)
cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)
cgroup on /sys/fs/cgroup/rdma type cgroup (rw,nosuid,nodev,noexec,relatime,rdma)
cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)
cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)
cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)
cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)
cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)
cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)
该系统挂载到了 /sys/fs/cgroup/memory 目录下。我们在该 hierarchy 中创建一个 test cgroup 并查看该 cgroup 的目录结构，命令及结果如下：
phl@kernelnewbies:~$ sudo mkdir /sys/fs/cgroup/memory/test
phl@kernelnewbies:~$ tree /sys/fs/cgroup/memory/test
/sys/fs/cgroup/memory/test
├── cgroup.clone_children
├── cgroup.event_control
├── cgroup.procs
├── memory.failcnt
├── memory.force_empty
├── memory.kmem.failcnt
├── memory.kmem.limit_in_bytes
├── memory.kmem.max_usage_in_bytes
├── memory.kmem.slabinfo
├── memory.kmem.tcp.failcnt
├── memory.kmem.tcp.limit_in_bytes
├── memory.kmem.tcp.max_usage_in_bytes
├── memory.kmem.tcp.usage_in_bytes
├── memory.kmem.usage_in_bytes
├── memory.limit_in_bytes
├── memory.max_usage_in_bytes
├── memory.move_charge_at_immigrate
├── memory.numa_stat
├── memory.oom_control
├── memory.pressure_level
├── memory.soft_limit_in_bytes
├── memory.stat
├── memory.swappiness
├── memory.usage_in_bytes
├── memory.use_hierarchy
├── notify_on_release
└── tasks
0 directories, 27 files
从结果我们可以看到，新建的 test cgroup 中有许多文件，这些文件中存放着资源限制信息。其中 memory.limit_in_bytes 里面存放的是该 cgroup 中的进程能够使用的内存额度。
下面，我们将当前 bash 加入到 test cgroup 中并查看当前 bash 所属的 cgroup 信息。命令及结果如下：
phl@kernelnewbies:~$ echo $$
2984
phl@kernelnewbies:~$ sudo sh -c "echo 2984 &gt; /sys/fs/cgroup/memory/test/cgroup.procs"
phl@kernelnewbies:~$ cat /proc/2984/cgroup
12:devices:/user.slice
11:hugetlb:/
10:memory:/test
9:rdma:/
8:perf_event:/
7:blkio:/user.slice
6:cpu,cpuacct:/user.slice
5:pids:/user.slice/user-1001.slice/session-4.scope
4:freezer:/
3:cpuset:/
2:net_cls,net_prio:/
1:name=systemd:/user.slice/user-1001.slice/session-4.scope
0::/user.slice/user-1001.slice/session-4.scope
从结果我们可以看到，当前 bash 所属的 memory cgroup 变为了 /test，该目录为一个相对于 root cgroup 的相对路径。
然后，将 100M 写入 test cgroup 中的 memory.limit_in_bytes 文件中，命令如下：
phl@kernelnewbies:~$ sudo sh -c "echo 100M &gt; /sys/fs/cgroup/memory/test/memory.limit_in_bytes"
我们在当前 bash 中启动一个占用 300M 进程的 stress 进程，该 stress 进程是 bash 的子进程，其与 bash 进程都在 test cgroup 中。命令如下：
phl@kernelnewbies:~$ stress --vm 1 --vm-bytes 300M --vm-keep
启动一个新的 Shell 窗口，执行 top 命令查看 stress 进程占用的内存。命令及结果如下：
PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
14216 root      20   0  315440 101224    264 D 27.7  2.5   0:02.66 stress
从结果我们可以看到，stress 进程占用了 2.5% 的内存。我的电脑的内存为 4G，4G * 2.5% = 100M，stress 进程确实受到了 cgroup 中设置的内存额度的限制。
2.2.2.docker.sh
下有了以上关于 CGroups 的知识，我们就可以将限制内存的功能加入到 docker.sh 中了。限制内存的功能将放在 container.sh 中，带下划线的行是我们为实现限制内存而新添的代码。修改后的 container.sh 脚本如下：
hostname $container
mkdir -p /sys/fs/cgroup/memory/$container
echo $$ &gt; /sys/fs/cgroup/memory/$container/cgroup.procs
echo $memory &gt; /sys/fs/cgroup/memory/$container/memory.limit_in_bytes
mount -t proc proc /proc
exec $program
首先，我们根据容器的名字创建 cgroup，命令如下：
mkdir -p /sys/fs/cgroup/memory/$container
然后，我们将当前 bash 加入到我们创建的 cgroup 中，命令如下：
echo $$ &gt; /sys/fs/cgroup/memory/$container/cgroup.procs
最后，我们将内存限制写入新 cgroup 的 memory.limit_in_bytes 文件中，命令如下：
echo $memory &gt; /sys/fs/cgroup/memory/$container/memory.limit_in_bytes
现在，我们运行 docker.sh，并启动一个占用 300M 进程的 stress 进程。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
root@dreamland:~/docker.sh# stress --vm 1 --vm-bytes 300M --vm-keep
stress: info: [12] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
启动一个新的 Shell 窗口，执行 top 命令查看 stress 进程占用的内存。命令及结果如下：
PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
14216 root      20   0  315440 101224    264 D 27.7  2.5   0:02.66 stress
从结果我们可以看到，容器内的 stress 进程只使用了 100M 的内存。
3. 切换根文件系统
3.1. 根文件系统
在容器技术中，根文件系统可为容器进程提供一个与主机不一致的文件系统环境。举个例子，主机为 Ubuntu 18.04，创建的容器采用 Ubuntu 16.04 的根文件系统，那么容器运行时所用的软件及其依赖库、配置文件等都是 Ubuntu 16.04 的。尽管该容器使用的内核是仍旧是 Ubuntu 18.04 的，但应用软件的表现却与 Ubuntu 16.04 一致，从虚拟化的角度来说该容器就是一个 Ubuntu 16.04 系统。
debootstrap 是 Ubuntu 下的一个工具，用来构建根文件系统。生成的目录符合 Linux 文件系统标准，即包含了 /boot、/etc、/bin、/usr 等目录。debootstrap 的安装命令如下：
sudo apt install debootstrap
下面我们通过 debootstrap 构建 Ubuntu 16.04 的根文件系统。为了清晰，我们在 images 目录下生成根文件系统。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ mkdir images
phl@kernelnewbies:~/docker.sh$ cd images
phl@kernelnewbies:~/docker.sh/images$ sudo debootstrap --arch amd64 xenial ./ubuntu1604
制作根文件系统需要从服务器下载很多文件，很耗时，请耐心等待。当文件系统制作好后，可以使用 tree 命令查看生成的根文件系统。命令及结果如下：
phl@kernelnewbies:~/docker.sh/images$ tree -L 1 ubuntu1604/
ubuntu1604/
├── bin
├── boot
├── dev
├── etc
├── home
├── lib
├── lib64
├── media
├── mnt
├── old_root
├── opt
├── proc
├── root
├── run
├── sbin
├── srv
├── sys
├── tmp
├── usr
└── var
20 directories, 0 files
这个根文件系统与 Linux 系统目录很相近，我们后续的实验将使用该根文件系统。
3.2.pivot_root
pivot_root 命令用于切换根文件系统，其使用方式如下：
pivot_root new_root put_old
pivot_root 将当前进程的根文件系统移至 put_old 目录并使 new_root 目录成为新的根文件系统。
下面我们将通过实验学习 pivot_root 的使用方法。为了简单，我们在一个新的 mount namespace 下进行实验。首先，我们创建一个新的 mount namespace，命令及结果如下：
phl@kernelnewbies:~/docker.sh/images$ sudo unshare --mount /bin/bash
root@kernelnewbies:~/docker.sh/images#
在我们的实验中，我们的根文件系统将挂载在 ubuntu1604 目录，而老的根文件系统将被移动到 ubuntu1604/old_root 目录下。我们先创建 old_root 目录，命令如下：
root@kernelnewbies:~/docker.sh/images# mkdir -p ubuntu1604/old_root/
由于 pivot_root 命令要求老的根目录和新的根目录不能在同一个挂载点下，因此我们通过 bind mount 将 ubuntu1604 目录变成一个挂载点。命令及结果如下：
root@kernelnewbies:~/docker.sh/images# mount --bind ubuntu1604 ubuntu1604
root@kernelnewbies:~/docker.sh/images# cat /proc/self/mountinfo | grep ubuntu1604
624 382 8:1 /home/phl/docker.sh/images/ubuntu1604 /home/phl/docker.sh/images/ubuntu1604 rw,relatime - ext4 /dev/sda1 rw,errors=remount-ro
准备好切换根文件系统所需要的条件后，我们调用 pivot_root 切换根文件系统。命令及结果如下：
root@kernelnewbies:~/docker.sh/images# cd ubuntu1604/
root@kernelnewbies:~/docker.sh/images/ubuntu1604# pivot_root . old_root/
此时，已完成根文件系统的切换，/proc 文件系统也被挪到了
/home/phl/docker.sh/images/ubuntu1604/old_root/proc，也就是说当前没有 /proc 文件系统，因此，我们无法查看挂载点信息，自然也无法执行一些依赖于 /proc 文件系统的操作。我们需要重新挂载 /proc 文件系统。命令如下：
root@kernelnewbies:~/docker.sh/images/ubuntu1604# mount -t proc proc /proc
重新挂载 /proc 文件系统后，我们就可以查看当前的挂载点信息了。通过读取 /proc/self/mountinfo 文件来查看系统的挂载点信息。命令及结果如下：
root@kernelnewbies:~/docker.sh/images/ubuntu1604# cat /proc/self/mountinfo
382 624 8:1 / /old_root rw,relatime - ext4 /dev/sda1 rw,errors=remount-ro
...
624 381 8:1 /home/phl/docker.sh/images/ubuntu1604 / rw,relatime - ext4 /dev/sda1 rw,errors=remount-ro
625 624 0:5 / /proc rw,relatime - proc proc rw
此时的挂载点很多，为了方便查看，此处只保留了一些主要的挂载点信息。这些挂载点信息包括 /、/proc、/old_root。/old_root 为老的根文件系统，我们需要将其卸载。命令及结果如下：
root@kernelnewbies:~/docker.sh/images/ubuntu1604# umount -l /old_root/
卸载掉老的根文件系统后，我们再查看系统的挂载点信息。命令及结果如下：
root@kernelnewbies:~/docker.sh/images/ubuntu1604# cat /proc/self/mountinfo
624 381 8:1 /home/phl/docker.sh/images/ubuntu1604 / rw,relatime - ext4 /dev/sda1 rw,errors=remount-ro
625 624 0:5 / /proc rw,relatime - proc proc rw
此时，挂载点信息中只有 /、/proc，不再有主机的挂载点信息。
3.3.docker.sh
有了以上关于切换根文件系统的知识，我们就可以将切换根文件系统的功能加入到 docker.sh 中了。切换根文件系统的功能将放在 container.sh 中，带下划线的行是我们为实现切换根文件系统而新添的代码。修改后的 container.sh 脚本如下：
#!/bin/bash

hostname $container

mkdir -p /sys/fs/cgroup/memory/$container
echo $$ &gt; /sys/fs/cgroup/memory/$container/cgroup.procs
echo $memory &gt; /sys/fs/cgroup/memory/$container/memory.limit_in_bytes

mkdir -p images/$image/old_root
mount --bind images/$image images/$image

cd images/$image
pivot_root . ./old_root

mount -t proc proc /proc
umount -l /old_root

exec $program
首先，我们在新的根文件系统目录中创建挂载老的根文件系统的目录。命令如下：
mkdir -p images/$image/old_root
然后，我们将新根文件系统目录 bind mount 成一个挂载点。命令如下：
mount --bind images/$image images/$image
然后，我们切换根文件系统。命令如下：
cd images/$image
pivot_root . ./old_root
最后，我们重新挂载 /proc 文件系统，然后卸载掉老的根文件系统。命令如下：
mount -t proc proc /proc
umount -l /old_root
现在，我们运行 docker.sh，并查看当前的发行版信息。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
root@dreamland:/# cat /etc/issue
Ubuntu 16.04 LTS \n \l
从结果我们可以看出，读出的发行版信息是 Ubuntu 16.04 LTS \n \l，而非主机的 Ubuntu 18.04.3 LTS \n \l。这说明当前使用的根文件系统确实是 ubuntu16.04 目录下的根文件系统，而非主机的根文件系统。
我们再查看一下当前的挂载点信息，看看是否只有 / 与 /proc。命令及结果如下：
root@dreamland:/# cat /proc/self/mountinfo
625 381 8:1 /home/phl/docker.sh/images/ubuntu1604 / rw,relatime - ext4 /dev/sda1 rw,errors=remount-ro
626 625 0:52 / /proc rw,relatime - proc proc rw
从结果我们可看出，当前挂载点信息中只有 /、/proc，不再有主机的挂载点信息。
通过根文件系统，我们实现了在容器中虚拟出与主机不一样的操作系统的功能。
4. 联合加载
4.1. 联合加载简介
联合加载指的是一次同时加载多个文件系统，但是在外面看起来只能看到 一个文件系统。联合加载会将各层文件系统叠加到一起，这样最终的文件系统会 包含所有底层的文件和目录。
联合加载的多个文件系统中有一个是可读写文件系统，称为读写层，其他文件系统是只读的，称为只读层。当联合加载的文件系统发生变化时，这些变化都应用到这个读写层。比如，如果想修改一个文件，这个文件首先会从只读层复制到读写层。原只读层中的文件依然存在，但是被读写层中的该文件副本所隐藏。我们以后读写该文件时，都是读写的该文件在读写层中的副本。这种机制被称为 写时复制。
我们之前实现的 docker.sh，有一个很大的缺陷。那就是，如果使用相同的根文件系统同时启动多个容器的实例，那么，这些容器实例使用的根文件系统位于同一个目录。我们在不同的容器实例对根文件系统所作的修改，这些容器彼此之间都可以看到，甚至一个容器可以覆覆盖另一个容器所作的修改。同时，容器实例退出时，对根文件系统所作的修改也直接作用于其所使用的根文件系统。当我们使用该根文件系统再次启动容器实例时，新启动的容器实例也可以看到以前的这些修改。例如，我们用 ubuntu1604 根文件系统启动两个容器实例，命令如下：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland2 -I ubuntu1604 -V data1 -P /bin/bash
这两个容器实例对根文件系统做的修改彼此都可以看到。容器实例退出时，这些修改也被保存了下来，当用 ubuntu1604 根文件系统启动新的容器实例时，新实例也可看到以前实例所做的修改。
如果容器使用的根文件系统是一个联合加载的文件系统，原先的根文件系统作为一个只读层，再添加一个读写层，那么，在容器内所作的修改都将只作用于读写层。为了区分，我们以后称 ubuntu1604 目录下的根文件系统为镜像。而我们可以为每一个容器实例指定一个唯一的读写层目录，这样的话，多个容器实例就可以使用同一个镜像，容器内所作的修改不会影响彼此，也不会影响到以后启动的容器实例。例如：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland2 -I ubuntu1604 -V data1 -P /bin/bash
我们使用 ubuntu1604 镜像启动了两个容器示例，并在容器实例里进行读写操作。这两个容器实例的读写层目录是不一样的，在容器实例中所作的修改只作用于各自的读写层，彼此之间不会影响，当然更不会影响到后续启动的容器实例。
4.2. AUFS
AUFS 是一个实现了联合加载功能的文件系统。我们将采用 AUFS 实现 docker.sh 中的联合加载功能。
下面，我们将通过实验演示一下 AUFS 文件系统的用法。首先，我们准备需要用到的目录及文件。命令及结果如下：
phl@kernelnewbies:~$ mkdir aufs
phl@kernelnewbies:~$ cd aufs/
phl@kernelnewbies:~/aufs$ mkdir rw r1 r2 union
phl@kernelnewbies:~/aufs$ echo hello r1 &gt; r1/hellor1.txt
phl@kernelnewbies:~/aufs$ echo hello r2 &gt; r2/hellor2.txt
phl@kernelnewbies:~/aufs$ echo hello rw &gt; rw/hellorw.txt
下表列出了各个目录的作用。列表如下：

rw 为 aufs 文件系统的读写层目录
 r1 为 aufs 文件系统的只读层目录
 r2 为 aufs 文件系统的只读层目录
 union 为挂载点，联合加载的 aufs 文件系统挂载于此目录

下面我们将 rw、r1、r2 联合加载到 union 目录。命令如下：
phl@kernelnewbies:~/aufs$ sudo mount -t aufs -o dirs=rw:r1:r2 none union

-t aufs 表示要挂载的文件系统类型为 AUFS
-o dirs=rw:r1:r2 表示要将哪些目录加载到 afus 文件系统中，多个目录之间以：分隔。目录列表中的第一个目录表示读写层目录
 union 表示 aufs 文件系统要挂载的目录

挂载好 AUFS 文件系统后，我们进入该文件系统，查看其内容。命令及结果如下：
phl@kernelnewbies:~/aufs$ cd union/
phl@kernelnewbies:~/aufs/union$ ls
hellor1.txt hellor2.txt hellorw.txt
从输出结果来看，rw、r1、r2 目录下的内容全部出现在了 AUFS 文件系统中，该文件系统由 rw、r1、r2 目录叠加而成。
然后，我们修改这些文件，看看原始的 rw、r1、r2 目录下的文件是否更改。命令及结果如下：
phl@kernelnewbies:~/aufs/union$ echo hello to r1 from union &gt; hellor1.txt
phl@kernelnewbies:~/aufs/union$ echo hello to r2 from union &gt; hellor2.txt
phl@kernelnewbies:~/aufs/union$ echo hello to rw from union &gt; hellorw.txt
我们返回到 aufs 目录，直接查看 aufs 目录下的内容。命令及结果如下：
phl@kernelnewbies:~/aufs$ tree .
.
├── r1
│   └── hellor1.txt
├── r2
│   └── hellor2.txt
├── rw
│   ├── hellor1.txt
│   ├── hellor2.txt
│   └── hellorw.txt
└── union
    ├── hellor1.txt
    ├── hellor2.txt
    └── hellorw.txt

4 directories, 8 files
从输出结果我们可以看到，我们修改的 hellor1.txt 和 hellor2.txt 文件分别被拷贝了一份放在读写层目录 rw 中。我们查看一下这些文件的内容，命令及结果如下：
phl@kernelnewbies:~/aufs$ cat r1/hellor1.txt
hello r1
phl@kernelnewbies:~/aufs$ cat r2/hellor2.txt
hello r2
phl@kernelnewbies:~/aufs$ cat rw/hellor1.txt
hello to r1 from union
phl@kernelnewbies:~/aufs$ cat rw/hellor2.txt
hello to r2 from union
phl@kernelnewbies:~/aufs$ cat rw/hellorw.txt
hello to rw from union
从输出结果我们看到，用户修改只读层 r1、r2 中的文件时，这些文件被复制到了读写层，我们修改的是读写层的副本，原只读层中的文件没有变化。用户修改读写层 rw 中的文件时，修改直接作用于这些文件本身。
4.3.docker.sh
在继续之前，我们需要将上一章在 ubuntu1604 根文件系统中创建的 old_root 目录删除掉，以保证该根文件系统跟刚制作好时一样。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo rm -rf images/ubuntu1604/old_root
有了以上关于联合加载的介绍，我们就可以将联合加载功能加入到 docker.sh 中了。联合加载功能将放在 container.sh 脚本中，带下划线的行是我们为实现联合加载功能而新添的代码。修改后的 container.sh 如下：
#!/bin/bash

hostname $container

mkdir -p /sys/fs/cgroup/memory/$container
echo $$ &gt; /sys/fs/cgroup/memory/$container/cgroup.procs
echo $memory &gt; /sys/fs/cgroup/memory/$container/memory.limit_in_bytes

mkdir -p $container/rwlayer
mount -t aufs -o dirs=$container/rwlayer:./images/$image none $container

mkdir -p $container/old_root
cd $container
pivot_root . ./old_root

mount -t proc proc /proc
umount -l /old_root

exec $program
首先，我们根据容器的名字创建联合加载需要的读写层目录及文件系统挂载目录。命令如下：
mkdir -p $container/rwlayer
假如我们传递的容器的名字为 dreamland，将创建以下目录：
phl@kernelnewbies:~/docker.sh$ tree dreamland/
dreamland/
└── rwlayer
其中 dreamland/rwlayer 目录为创建的 AUFS 文件系统的读写层，dreamland 目录为 AUFS 文件系统的挂载点。
然后我们将镜像目录、读写层目录联合加载到挂载点目录。命令如下：
mount -t aufs -o dirs=$container/rwlayer:./images/$image none $container
假如容器名字为 dreamland，使用的镜像为 ubuntu1604 根文件系统，dreamland/rwlayer、images/ubuntu1604 将被联合加载的 dreamland 目录。其中，dreamland/rwlayer 为 AUFS 文件系统的读写层，images/ubuntu1604 为 AUFS 文件系统的只读层。
之前我们将老的根文件系统挪到了 rootfs/old_root，rootfs 代表一个具体的镜像目录。创建 old_root 目录时直接修改了该镜像。下面我们将老的根文件系统的挂载点目录放在 AUFS 文件系统中，并将老的根文件系统挪到此处。命令如下：
mkdir -p $container/old_root
cd $container
pivot_root . ./old_root
此时，$container 目录本身就是一个挂载点，挂载了 AUFS 文件系统。因此下面的代码就被移除了：
mount --bind images/$image images/$image
现在，我们运行 docker.sh，并在 /root 下创建一个文件。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
root@dreamland:/# cd /root
root@dreamland:/root# ls
root@dreamland:/root# cat /etc/issue &gt; hello.txt
root@dreamland:/root# cat hello.txt
Ubuntu 16.04 LTS \n \l
启动一个新的 Shell 窗口，查看一下该容器使用的 AUFS 文件系统。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo tree dreamland/
dreamland/
└── rwlayer
    ├── old_root
    └── root
        └── hello.txt

2 directories, 1 file
从结果我们可以看到，我们新建的文件及创建的老根文件系统的挂载点目录都出现在了读写层。我们再查看一下新创建的文件。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo cat dreamland/rwlayer/root/hello.txt
Ubuntu 16.04 LTS \n \l
文件内容是 Ubuntu 16.04 的发行版信息。
通过联合加载，我们实现了在容器中的读写不会影响使用的镜像。这样使用 ubuntu1604 镜像创建多个容器时，彼此之间就不会相互影响了。
5. 卷
5.1. 卷简介
卷是容器内的一个目录，这个目录可以绕过联合文件系统，提供数据共享（容器所使用的的联合文件系统不应该被主机或其他容器访问）与数据持久化的功能。
举个例子，假如容器有个目录为 /data 的卷，我们向这个卷写入的内容不会出现在联合文件系统的读写层，而是直接出现在这个目录里。主机与其他容器也可以访问该目录，从而达到数据共享与数据持久化的目的。
卷位于联合文件系统中，通常来说写入该目录的内容会被写入容器的读写层中，那么怎样才能是写入卷的目录直接出现在该目录中，而不是容器读写层呢？其实方法很简单，只要我们将该目录变成一个挂载点就行，变成挂载点后，这个目录中的内容就不属于联合文件系统了，写入该目录的内容自然会保存在挂载到该挂载点的设备中。
5.2 docker.sh
有了以上关于卷的介绍，我们就可以将卷功能加入到 docker.sh 中了。卷功能将放在 container.sh 脚本中，带下划线的行是我们为实现卷功能而新添的代码。修改后的 container.sh 脚本如下：
#!/bin/bash

hostname $container

mkdir -p /sys/fs/cgroup/memory/$container
echo $$ &gt; /sys/fs/cgroup/memory/$container/cgroup.procs
echo $memory &gt; /sys/fs/cgroup/memory/$container/memory.limit_in_bytes

mkdir -p $container/rwlayer
mount -t aufs -o dirs=$container/rwlayer:./images/$image none $container

mkdir -p $volume
mkdir -p $container/$volume
mount --bind $volume $container/$volume

mkdir -p $container/old_root
cd $container
pivot_root . ./old_root

mount -t proc proc /proc
umount -l /old_root

exec $program
首先，我们根据卷的名字创建主机卷目录，我们在容器内部对卷的修改，都将作用于此目录。命令如下：
mkdir -p $volume
然后，我们在容器内部创建同名卷目录，该目录本身会出现在容器的读写层中，因为该目录是在 AUFS 文件系统中创建的。因为volume。命令如下：
mkdir -p $container/$volume
将主机上的卷目录 bind mount 到容器内部的卷目录上，这样容器内部对卷目录的修改，都将作用于主机卷目录。命令如下：
mount --bind $volume $container/$volume
现在，我们运行 docker.sh，并在卷目录（/data1）中创建一个文件。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo ./docker.sh -c run -m 100M -C dreamland -I ubuntu1604 -V data1 -P /bin/bash
root@dreamland:/# cd /data1
root@dreamland:/data1# echo "hello to data1 volume from ubuntu16.04" &gt;&gt; hello.txt
启动一个新的 Shell 窗口，查看一下该容器使用的 AUFS 文件系统中的内容。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo tree dreamland/
dreamland/
└── rwlayer
    ├── data1
    ├── old_root
    └── root
        └── hello.txt

4 directories, 1 file
从结果我们可以看到，我们使用的卷目录被创建在了容器的读写层，但是我们在卷目录中新建的文件却没有出现在读写层中。
我们再来查看一下主机卷目录的内容。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo tree data1/
data1/
└── hello.txt

0 directories, 1 file
从结果我们可以看到，在容器内部对卷目录的修改直接作用在了主机上的卷目录。我们再来查看一下主机卷目录下 hello.txt 中的内容。命令及结果如下：
phl@kernelnewbies:~/docker.sh$ sudo cat data1/hello.txt
hello to data1 volume from ubuntu16.04
从结果我们可以看到，该文件的内容与我们在容器内部写入 hello.txt 的内容一致。
通过卷目录，我们实现了容器之间数据共享与数据持久化的功能。
6. 后记
至此，我们通过一系列的实验对 docker 的底层技术有了一个感性的认识。我们在使用 docker 时，也能够对其是如何运作的有了一个大致的了解。当然，这对于掌握 docker 技术来说还远远不够，有很多知识我们没有涉及，例如 user namespace、容器安全、其他的 CGroups、虚拟网络等。
编辑整理 ScratchLab
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>winrar 去广告和破解</title>
    <url>/posts/3b296307/</url>
    <content><![CDATA[
WinRAR 是一款不错的解压缩软件，但还是收费软件，广告不少，今天就总结了一下网上的各路教程。


crack winrar
首先通过特殊方式获取软件许可：
新建一个文本文档

在这个文本文档里输入内容：
RAR registration data``Federal Agency ``for` `Education``1000000 PC usage license``UID=b621cca9a84bc5deffbf``6412612250ffbf533df6db2dfe8ccc3aae5362c06d54762105357d``5e3b1489e751c76bf6e0640001014be50a52303fed29664b074145``7e567d04159ad8defc3fb6edf32831fd1966f72c21c0c53c02fbbb``2f91cfca671d9c482b11b8ac3281cb21378e85606494da349941fa``e9ee328f12dc73e90b6356b921fbfb8522d6562a6a4b97e8ef6c9f``fb866be1e3826b5aa126a4d2bfe9336ad63003fc0e71c307fc2c60``64416495d4c55a0cc82d402110498da970812063934815d81470829275

然后将文件名改为：rarreg.key

再将这个文件导入 WinRAR 的安装文件夹


这时点开关于 WinRAR，已经获取许可。

去除广告
接下来使用 Resource Hacker 软件打开 winrar.exe

进入字串表，找到 “80”，删除 “1267” 和 “1277” 行
点击绿色三角形按钮，编译。

然后：文件→另存为，进行保存。

然后对源文件：winrar.exe 进行替换，注意，要关闭 winrar 软件

至此，已经完成破解和去广告了。
参考来源 52pojie
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>winrar</tag>
        <tag>crack</tag>
      </tags>
  </entry>
  <entry>
    <title>emoji 表情符号</title>
    <url>/posts/80938cfe/</url>
    <content><![CDATA[
emoji 表情符号是非常流行的表情符号，几乎没有地方都会支持。这里列举出常用的 emoji 表情不好，方便大家使用与查阅。


常用符号
❤❥웃유♋☮✌☏☢☠✔☑♚▲♪✈✞÷↑↓◆◇⊙■□△▽¿─│♥❣♂♀☿Ⓐ✍✉☣☤✘☒♛▼♫⌘☪≈←→◈◎☉★☆⊿※¡━┃♡ღ ツ

☼☁❅♒✎©®™Σ✪✯☭➳ 卐 √↖↗●◐Θ◤◥︻〖〗┄┆℃℉°✿ϟ☃☂✄¢€£∞✫★½✡×↙↘○◑⊕◣◢︼【】┅┇☽☾✚〓

▂▃▄▅▆▇█▉▊▋▌▍▎▏↔↕☽☾ の•▸◂▴▾┈┊①②③④⑤⑥⑦⑧⑨⑩ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ ㍿ ▓♨♛❖♓☪✙

┉┋☹☺☻ت ヅツッシ Üϡﭢ™℠℗©®♥❤❥❣❦❧♡۵웃유ღ♋♂♀☿☼☀☁☂☄☾☽❄☃☈⊙☉℃℉❅✺ϟ☇♤♧♡♢♠♣

♥♦☜☞☝✍☚☛☟✌✽✾✿❁❃❋❀⚘☑✓✔√☐☒✗✘ ㄨ ✕✖✖⋆✢✣✤✥❋✦✧✩✰✪✫✬✭✮✯❂✡★✱✲✳✴✵✶✷✸✹✺✻✼❄❅❆❇❈❉❊†☨✞✝☥☦☓☩☯☧☬

☸✡♁✙♆。，、＇：∶；?‘’“”〝〞ˆˇ﹕︰﹔﹖﹑•¨….¸;！´？！～—ˉ ｜‖＂〃｀@﹫¡¿﹏﹋﹌︴々﹟#

﹩$﹠&amp;﹪%*﹡﹢﹦﹤‐￣ ¯―﹨ˆ˜﹍﹎+=&lt;＿*-\ˇ~﹉﹊（）〈〉‹›﹛﹜『』〖〗［］《》〔〕{}「」【】︵︷︿︹︽*﹁﹃︻︶︸﹀︺︾ˉ﹂﹄︼☩☨☦✞✛✜✝✙✠✚†‡◉○◌◍◎●◐◑◒◓◔◕◖◗❂☢⊗⊙◘◙◍⅟½⅓⅕⅙⅛⅔⅖⅚⅜¾⅗⅝⅞⅘≂≃≄≅≆≇≈≉≊≋≌

≍≎≏≐≑≒≓≔≕≖≗≘≙≚≛≜≝≞≟≠≡≢≣≤≥≦≧≨≩⊰⊱⋛⋚∫∬∭∮∯∰∱∲∳%℅‰‱㊣㊎㊍㊌㊋㊏㊐㊊㊚㊛㊤㊥

㊦㊧㊨㊒㊞㊑㊒㊓㊔㊕㊖㊗㊘㊜㊝㊟㊠㊡㊢㊩㊪㊫㊬㊭㊮㊯㊰㊙ ㉿ 囍 ♔♕♖♗♘♙♚♛♜♝♞♟ℂℍℕℙℚℝℤℬℰℯℱℊℋℎℐℒℓℳℴ℘ℛℭ℮ℌℑℜℨ♪♫♩♬♭♮♯°øⒶ☮✌☪✡☭✯ 卐 ✐✎✏

✑✒✍✉✁✂✃✄✆✉☎☏➟➡➢➣➤➥➦➧➨➚➘➙➛➜➝➞➸♐➲➳⏎➴➵➶➷➸➹➺➻➼➽←↑→↓↔↕↖↗↘↙↚↛↜↝

↞↟↠↡↢↣↤↥↦↧↨➫➬➩➪➭➮➯➱↩↪↫↬↭↮↯↰↱↲↳↴↵↶↷↸↹↺↻↼↽↾↿⇀⇁⇂⇃⇄⇅⇆⇇⇈⇉⇊⇋⇌⇍⇎⇏⇐⇑⇒⇓⇔⇕

⇖⇗⇘⇙⇚⇛⇜⇝⇞⇟⇠⇡⇢⇣⇤⇥⇦⇧⇨⇩⇪➀➁➂➃➄➅➆➇➈➉➊➋➌➍➎➏➐➑➒➓㊀㊁㊂㊃㊄㊅㊆㊇㊈㊉ⒶⒷⒸⒹⒺⒻⒼⒽⒾⒿⓀⓁⓂⓃⓄⓅⓆⓇⓈⓉⓊⓋⓌⓍⓎⓏⓐⓑⓒⓓⓔⓕⓖⓗⓘⓙⓚⓛⓜⓝⓞⓟⓠⓡ

ⓢⓣⓤⓥⓦⓧⓨⓩ⒜⒝⒞⒟⒠⒡⒢⒣⒤⒥⒦⒧⒨⒩⒪⒫⒬⒭⒮⒯⒰⒱⒲⒳⒴⒵ⅠⅡⅢⅣⅤ

ⅥⅦⅧⅨⅩⅪⅫⅬⅭⅮⅯⅰⅱⅲⅳⅴⅵⅶⅷⅸⅹⅺⅻⅼⅽⅾⅿ┌┍┎┏┐┑┒┓└┕┖┗┘┙┚┛├┝┞┟┠┡┢┣┤┥┦┧┨┩┪┫
┬┭┮┯┰┱┲┳┴┵┶┷┸┹┺┻┼┽
┾┿╀╁╂╃╄╅╆╇╈╉╊╋╌╍╎╏
═║╒╓╔╕╖╗╘╙╚╛╜╝╞╟╠╡╢╣╤╥╦╧╨╩╪╫╬◤◥◄►▶◀◣◢▲

▼◥▸◂▴▾△▽▷◁⊿▻◅▵▿▹◃❏❐❑❒▀▁▂▃▄▅▆▇▉▊▋█▌▍▎▏▐░▒▓▔▕■□▢▣▤▥▦▧

▨▩▪▫▬▭▮▯ ㋀㋁㋂㋃㋄㋅㋆㋇㋈㋉㋊㋋㏠㏡㏢㏣㏤㏥㏦㏧㏨㏩㏪㏫㏬㏭㏮㏯㏰㏱㏲

㏳㏴㏵㏶㏷㏸㏹㏺㏻㏼㏽㏾㍙㍚㍛㍜㍝㍞㍟㍠㍡㍢㍣㍤㍥㍦㍧㍨㍩㍪㍫㍬㍭㍮㍯㍰㍘

☰☲☱☴☵☶☳☷☯
特殊符号
♠♣♧♡♥❤❥❣♂♀✲☀☼☾☽◐◑☺☻☎☏✿❀№↑↓←→√×÷★℃℉°◆◇⊙■□△▽¿½☯✡ ㍿卍卐 ♂♀✚〓㎡♪♫♩♬

㊚㊛囍㊒㊖ Φ♀♂‖KaTeX parse error: Expected ‘EOF’, got ‘&amp;’ at position 3: @*&amp;̲#※卍卐 Ψ♫♬♭♩♪♯♮⌒¶∮…
编号序号
①②③④⑤⑥⑦⑧⑨⑩⑪⑫⑬⑭⑮⑯⑰⑱⑲⑳⓪

❶❷❸❹❺❻❼❽❾❿⓫⓬⓭⓮⓯⓰⓱⓲⓳⓴

㊀㊁㊂㊃㊄㊅㊆㊇㊈㊉㈠㈡㈢㈣㈤㈥㈦㈧㈨㈩⑴⑵⑶⑷⑸⑹⑺⑻⑼⑽⑾⑿⒀⒁⒂⒃⒄⒅⒆⒇

⒈⒉⒊⒋⒌⒍⒎⒏⒐⒑⒒⒓⒔⒕⒖⒗⒘⒙⒚⒛

ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩⅪⅫⅰⅱⅲⅳⅴⅵⅶⅷⅸⅹ

ⒶⒷⒸⒹⒺⒻⒼⒽⒾⒿⓀⓁⓂⓃⓄⓅⓆⓇⓈⓉⓊⓋⓌⓍⓎⓏⓐⓑⓒⓓⓔⓕⓖⓗⓘⓙⓚⓛⓜⓝⓞⓟⓠⓡⓢⓣⓤⓥⓦⓧⓨⓩ

⒜⒝⒞⒟⒠⒡⒢⒣⒤⒥⒦⒧⒨⒩⒪⒫⒬⒭⒮⒯⒰⒱⒲⒳⒴⒵
数学符号
﹢﹣×÷±/=≌∽≦≧≒ ﹤﹥ ≈≡≠=≤≥&lt;&gt;≮≯∷∶∫∮∝∞∧∨∑∏∪∩∈∵∴⊥∥∠⌒⊙√∟⊿㏒㏑%

‰⅟½⅓⅕⅙⅛⅔⅖⅚⅜¾⅗⅝⅞⅘≂≃≄≅≆≇≈≉≊≋≌≍≎≏≐≑≒≓≔≕≖≗≘≙≚≛≜≝≞≟

≠≡≢≣≤≥≦≧≨≩⊰⊱⋛⋚∫∬∭∮∯∰∱∲∳%℅‰‱øØπ
爱心符号
♥❣ღ♠♡♤❤❥
标点符号
。，、＇：∶；?‘’“”〝〞ˆˇ﹕︰﹔﹖﹑•¨….¸;！´？！～—ˉ ｜‖＂〃｀@﹫¡¿﹏﹋﹌︴

々﹟#﹩$﹠&amp;﹪%*﹡﹢﹦﹤‐￣ ¯―﹨ˆ˜﹍﹎+=&lt;＿*-\ˇ~﹉﹊

（）〈〉‹›﹛﹜『』〖〗［］《》〔〕{}「」【】

︵︷︿︹︽*﹁﹃︻︶︸﹀︺︾ˉ﹂﹄︼❝❞
单位符号
°′″＄￥〒￠￡％＠℃℉ ﹩﹪‰﹫㎡㏕㎜㎝㎞㏎m³㎎㎏㏄º○¤%$º¹²³
货币符号
€£Ұ₴$₰¢₤¥₳₲₪₵ 元 ₣₱฿¤₡₮₭₩ރ 円 ₢₥₫₦zł﷼₠₧₯₨Kčर₹ƒ₸ ￠
箭头符号（含推导 &amp; 转换符号）
↑↓←→↖↗↘↙↔↕➻➼➽➸➳➺➻➴➵➶➷➹▶►▷◁◀◄«

»➩➪➫➬➭➮➯➱⏎➲➾➔➘➙➚➛➜➝➞➟➠➡➢➣➤➥➦➧➨

↚↛↜↝↞↟↠↠↡↢↣↤↤↥↦↧↨⇄⇅⇆⇇⇈⇉⇊⇋⇌⇍⇎⇏⇐⇑⇒⇓⇔⇖⇗⇘⇙

⇜↩↪↫↬↭↮↯↰↱↲↳↴↵↶↷↸↹☇☈↼↽↾↿⇀⇁⇂⇃⇞⇟⇠⇡⇢⇣⇤⇥⇦⇧⇨⇩⇪↺↻⇚⇛♐
符号图案
✐✎✏✑✒✍✉✁✂✃✄✆✉☎☏☑✓✔√☐☒✗✘ ㄨ ✕✖✖☢☠☣✈★☆✡ 囍㍿ ☯☰☲☱☴☵☶☳☷

☜☞☝✍☚☛☟✌♤♧♡♢♠♣♥♦☀☁☂❄☃♨웃유❖☽☾☪✿♂♀✪✯☭➳ 卍卐 √×■◆●○◐◑✙☺☻

❀⚘♔♕♖♗♘♙♚♛♜♝♞♟♧♡♂♀♠♣♥❤☜☞☎☏⊙◎☺☻☼▧▨♨◐◑↔↕▪▒◊◦▣▤▥▦▩◘◈◇

♬♪♩♭♪ の ★☆→ あぃ￡ Ю〓§♤♥▶¤✲❈✿✲❈➹☀☂☁【】┱┲❣✚✪✣✤✥✦❉❥❦❧❃❂❁❀✄☪☣☢☠☭ღ▶▷◀◁

☀☁☂☃☄★☆☇☈⊙☊☋☌☍ⓛⓞⓥⓔ╬『』∴☀♫♬♩♭♪☆∷﹌の ★◎▶☺☻►◄▧▨♨◐◑↔↕↘▀▄█▌

◦☼♪ の ☆→♧ ぃ￡ ❤▒▬♦◊◦♠♣▣۰•❤•۰►◄▧▨♨◐◑↔↕▪▫☼♦⊙●○①⊕◎Θ⊙¤ ㊣ ★☆♀◆◇◣◢◥▲▼△▽⊿◤◥

✐✌✍✡✓✔✕✖♂♀♥♡☜☞☎☏⊙◎☺☻►◄▧▨♨◐◑↔↕♥♡▪▫☼♦▀▄█▌▐░▒▬♦◊◘◙◦☼♠♣▣▤▥▦▩◘◙◈

♫♬♪♩♭♪✄☪☣☢☠♯♩♪♫♬♭♮☎☏☪♈ºº₪¤큐«»™♂✿♥ 　 ◕‿-｡　｡◕‿◕｡
希腊字母
ΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩ

αβγδεζνξοπρσηθικλμτυφχψω
俄语字母
АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвг

деёжзийклмнопрстуфхцчшщъыьэюя
汉语拼音
āáǎàōóǒòēéěèīíǐìūúǔùǖǘǚǜüêɑńňɡ ㄅㄆㄇㄈㄉ

ㄊㄋㄌㄍㄎㄏㄐㄑㄒㄓㄔㄕㄖㄗㄘㄙㄚㄛㄜㄝㄞ

ㄟㄠㄡㄢㄣㄤㄥㄦㄧㄨㄩ
中文字符
零壹贰叁肆伍陆柒捌玖拾佰仟万亿吉太拍艾分厘毫微

卍卐卄巜弍弎弐朤氺曱甴囍兀々〆のぁ〡〢〣〤〥〦〧〨〩

㊎㊍㊌㊋㊏㊚㊛㊐㊊㊣㊤㊥㊦㊧㊨㊒㊫㊑㊓㊔㊕㊖㊗㊘㊜㊝㊞㊟㊠㊡㊢㊩㊪㊬㊭㊮㊯㊰

㊀㊁㊂㊃㊄㊅㊆㊇㊈㊉
日文符号
ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてで

とどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎ

わゐゑをんゔゕゖァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタ

ダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユ

ョヨラリルレロヮワヰヱヲンヴヵヶヷヸヹヺ・ーヽヾヿ゠ㇰㇱㇲㇳㇴㇵㇶㇷㇸㇹㇺㇻㇼㇽㇾㇿ
制表符号
─ ━│┃╌╍╎╏┄ ┅┆┇┈ ┉┊┋┌┍┎┏┐┑┒┓└ ┕┖┗ ┘┙┚┛├┝┞┟┠┡┢┣ ┤┥┦┧┨┩┪┫┬ ┭ ┮ ┯ ┰ ┱ ┲ ┳

┴ ┵ ┶ ┷ ┸ ┹ ┺ ┻┼ ┽ ┾ ┿ ╀ ╁ ╂ ╃ ╄ ╅ ╆ ╇ ╈ ╉ ╊ ╋ ╪ ╫ ╬═║╒╓╔ ╕╖╗╘╙╚ ╛╜╝╞╟╠ ╡╢╣

╤ ╥ ╦ ╧ ╨ ╩ ╳╔ ╗╝╚ ╬ ═ ╓ ╩ ┠ ┨┯ ┷┏ ┓┗ ┛┳ ⊥ ﹃ ﹄┌ ╮ ╭ ╯╰
皇冠符号
♚ 　 ♛ 　 ♝ 　 ♞ 　 ♜ 　 ♟ 　 ♔ 　 ♕ 　 ♗ 　 ♘ 　 ♖ 　 ♟
彩色表情符号
🌹🍀🍎💰📱🌙🍁🍂🍃🌷💎🔪🔫🏀⚽⚡👄👍🔥
常用 emoji 符号
😀😁😂😃😄😅😆😉😊😋😎😍😘😗😙😚☺😇😐😑😶😏😣😥😮😯😪😫😴😌😛😜😝😒😓😔😕😲😷😖😞😟😤😢😭😦😧😨😬😰😱😳😵😡😠😈👿👹👺💀👻👽👦👧👨👩👴👵👶👱👮👲👳👷👸💂🎅👰👼💆💇🙍🙎🙅🙆💁🙋🙇🙌🙏👤👥🚶🏃👯💃👫👬👭💏💑👪💪👈👉☝👆👇✌✋👌👍👎✊👊👋👏👐✍👣👀👂👃👅👄💋👓👔👕👖👗👘👙👚👛👜👝🎒💼👞👟👠👡👢👑👒🎩🎓💄💅💍🌂🙈🙉🙊🐵🐒🐶🐕🐩🐺🐱😺😸😹😻😼😽🙀😿😾🐈🐯🐅🐆🐴🐎🐮🐂🐃🐄🐷🐖🐗🐽🐏🐑🐐🐪🐫🐘🐭🐁🐀🐹🐰🐇🐻🐨🐼🐾🐔🐓🐣🐤🐥🐦🐧🐸🐊🐢🐍🐲🐉🐳🐋🐬🐟🐠🐡🐙🐚🐌🐛🐜🐝🐞🦋💐🌸💮🌹🌺🌻🌼🌷🌱🌲🌳🌴🌵🌾🌿🍀🍁🍂🍃🌍🌎🌏🌐🌑🌒🌓🌔🌕🌖🌗🌘🌙🌚🌛🌜☀🌝🌞⭐🌟🌠☁⛅☔⚡❄🔥💧🌊💩🍇🍈🍉🍊🍋🍌🍍🍎🍏🍐🍑🍒🍓🍅🍆🌽🍄🌰🍞🍖🍗🍔🍟🍕🍳🍲🍱🍘🍙🍚🍛🍜🍝🍠🍢🍣🍤🍥🍡🍦🍧🍨🍩🍪🎂🍰🍫🍬🍭🍮🍯🍼☕🍵🍶🍷🍸🍹🍺🍻🍴🎪🎭🎨🎰🚣🛀🎫🏆⚽⚾🏀🏈🏉🎾🎱🎳⛳🎣🎽🎿🏂🏄🏇🏊🚴🚵🎯🎮🎲🎷🎸🎺🎻🎬👾🌋🗻🏠🏡🏢🏣🏤🏥🏦🏨🏩🏪🏫🏬🏭🏯🏰💒🗼🗽⛪⛲🌁🌃🌆🌇🌉🌌🎠🎡🎢🚂🚃🚄🚅🚆🚇🚈🚉🚊🚝🚞🚋🚌🚍🚎🚏🚐🚑🚒🚓🚔🚕🚖🚗🚘🚚🚛🚜🚲⛽🚨🚥🚦🚧⚓⛵🚤🚢✈💺🚁🚟🚠🚡🚀🎑🗿🛂🛃🛄🛅💌💎🔪💈🚪🚽🚿🛁⌛⏳⌚⏰🎈🎉🎊🎎🎏🎐🎀🎁📯📻📱📲☎📞📟📠🔋🔌💻💽💾💿📀🎥📺📷📹📼🔍🔎🔬🔭📡💡🔦🏮📔📕📖📗📘📙📚📓📃📜📄📰📑🔖💰💴💵💶💷💸💳✉📧📨📩📤📥📦📫📪📬📭📮✏✒📝📁📂📅📆📇📈📉📊📋📌📍📎📏📐✂🔒🔓🔏🔐🔑🔨🔫🔧🔩🔗💉💊🚬🔮🚩🎌💦💨💣☠♠♥♦♣🀄🎴🔇🔈🔉🔊📢📣💤💢💬💭♨🌀🔔🔕✡✝🔯📛🔰🔱⭕✅☑✔✖❌❎➕➖➗➰➿〽✳✴❇‼⁉❓❔❕❗©®™🎦🔅🔆💯🔠🔡🔢🔣🔤🅰🆎🅱🆑🆒🆓ℹ🆔Ⓜ🆕🆖🅾🆗🅿🆘🆙🆚🈁🈂🈷🈶🈯 🉐 🈹🈚🈲 🉑 🈸🈴🈳 ㊗㊙ 🈺🈵▪▫◻◼◽◾⬛⬜🔶🔷🔸🔹🔺🔻💠🔲🔳⚪⚫🔴🔵♈♉♊♋♌♍♎♏♐♑♒♓⛎💘❤💓💔💕💖💗💙💚💛💜💝💞💟❣🌿🚧💒☎📟💽⬆↗➡↘⬇↙⬅↖↕↔↩↪⤴⤵🔃🔄🔙🔚🔛🔜🔝🔀🔁🔂▶⏩◀⏪🔼⏫🔽⏬📱📶📳📴♻🏧🚮🚰♿🚹🚺🚻🚼🚾⚠🚸⛔🚫🚳🚭🚯🚱🚷🔞
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>emoji</tag>
      </tags>
  </entry>
  <entry>
    <title>ISP 数字图像处理 算法概述、工作原理、架构、处理流程</title>
    <url>/posts/798e6e62/</url>
    <content><![CDATA[
  9e6b07150603c85d3bb35cb0d64d79617e68d964baae8aadccd5ce24944ece16751226c0ae8a15932a2477b9b09b6049d435ed170c206f013270e66dfc478fc0effe73af1a6bebd4395b6b542fb87d18b3f5665babb73c45ed2071cf204d0204f6617b3607a70b43fc1258e562d0907c6ea9741b7e71c5f088a552f13a33033facd7b6f8e0dadd9f2546615901372164eebeb16428879ea0ae68e3afd8096d4668fc38ab582d3611fbe641ddd8b8a9f79c61d7e3ef101472af842ada00b88722147155ef7e6db37f92dcf03447555e540fd85487e9cc16df1cb778faf55b6caea8030dd0ef6197e2a727b528225e26913c8013ff491665f9c90b278fbcd5f1b8f8eade03d1c2a592195c71ef8de1b5422389be05d065ac8f1f991044858b67e759cce87938276b311bd3faf2f9e46f71e48fcab76676d0bd90302de30a729e6b409b2cdc93b29f9af5c4d3451240b080f0b69756f7260e247043f57f95fa31f2f78de50066e80790a87e2268df21599d8bb1471c0e97929e3c4528753055ad4cef5350069f211d520cbbe07e0223ca589d6cd0bc3ac115004a2d55725c277afec9892bdd6030b3686434c1aa6af7e6451fb7e6723d8c58e1a099c7038ef32787054d127925d605601fa6f980e1fd1042713d1ffeb97b35e098a076de6db2c5a0dde9406c23939d880344b72b4c4d1126846153800e37207011b6e17b2bf3c06021a5feb9d7c8c208401747fbdb25cdabae7191ed019903a62c4b76fd203d153293fd355ce4f0d2f6981b64253d92e91c1cd18266074bd3eadc6127b4a50f590677ed1ee689d57366dbd4741c5735f912186729b3583ff93aa2c4382047e4a9424a62fa0a2ccbadc26dd4e7cee35feaf66530bf9b2a8ed010ef680f0be670c9d6d5c7c8c60621fb15d8bafb9be6b691db2ffc05c73bf84652df197e044e9920eee47e4a116486a31f906e6331d809fe24f19c8a426c0b141eb5e1e2c575c2da83c5b429f33eb0966991a66aadacaf2b4edda8d079e59a66cd3173d0f7b1de0de2728e5b3dd6af9e2266d63b465b86e387b034f465885ab78deba8aeab19089fe7aed539321f983044fcb2a265b613f3343835437c66d339a369452002e9bb1401654d72d85b41f2dc0f227291d40d4dc4bb3c7386d6634acf3513ae02fb125438d6bbce0951b2397e3e877a28c6ee5d9284b7206bc40d391dd36505b9fcde995ddaf3dc999cca2930d7f6bf5b6f15875386bcb9a9ec9562206a0db9a1c6857c270e79d0300d0f66965af01a6ccf56656c91ad297a187bbf2ede8acf3a6df5d97ea9faf928849ea08426f576b7a1c48b6ef57dff074084dddf2a2329f27b470cdcd4f0ff3d97f383b23e46f46e31ca3b38b760eb4f60ecef4f55fc2ffd919c465c50014160cfc8eae31983ae3aec2f7d6f2a90b106882faf95b5949540bdf098a57cedeb9e30de5099b676720610ee148c72a69648936881b1230a2454bf7330cea7446a264e6ddad59392ca3e55955e423526b978e01f519794f760a924ae7f79288c565113257f442946bfd29b3b0534a0a6f920f07e81fda57680046444217b1d17279f1c8afbaf410aaa4a5965176901e93076aeaab142cd613aba526b0211e5c120002f5a5cee0bcd3d05361c3ce17c9424a7b8885e06743b5e95f30422cc0fe8ba52897480c7de1cc12a8bce2959bd43b40b17c76f060ae84ce8cad3f1c25c026dd7fb9579cdf0827f2113eb0d654f185a59f7aba1dcce30b283b2dc1a96a448ac062048eed5b70bd0669c20140e6f4fad8980978d666c83747384eb712a07f554514652041fce813fca836720aab6c8cb09a1906a5e41334f1b06b62233ad552250fd3b593b369e184167b88911ffbddd0beadee8eaeeb088f5318d2a67f0f221f84b46375231211862969c4ece058e3c008023f791528d0e0ccfcd508656f763f2e4eca074f51a5d06813a78d57e4c76d1ba14b50a5131f4c44fd53923c1483780af94c71e7660b443aa40b74ac34e2adaa887a4294d053bf7eadd6cdaf14a8457b8cb1b49834cdbdaaf9d33fb1c9a764b3f0f0a617a11e6f2e033bbcb9011c62ff73fe35ef16e365fa5241ccc04958f12f49486f0cff09bd9651ecf0a51e73075f10b2001a55371e4d6fe6559ea71732c3cd6e64127511c5725f83e3c4fbb01d646faeffadbe537415e01f44443c98040659ece759f94f9052fe3120e5a9fc7448bf70834bc91168fa6584299f3d88e88a58233e62f2cbd307efb126da4278a382503099dfd59f5ced70f8c3f4a36b1e2fc6cd03d5910468bb5eb0692251139cf6b871068e18e92ea0de714da905df27611dd723bd7f29bd35cfa26596f546e09596b381df79d6ef9978f73ab43d3a3ce122729caf8dd0e20a07f1e295c93929c7d38281389daea84cf02ea33bf51d9c59f5f5ddd82604a2363e55cd27355081f29a175e43db32812974b4ae18cdc020f9dc3aa50981a7729beb88803a04c9b9b5233ca2f79494bcf690a033accd0ae4cd43556ae67348b1b18dd5462917c6307e801664deb88f516f7b371bdd760816cf9003953c4b94abf4c091908b9815c7226195cc20330b714ff509b9496216e8e589a99d72153a06f07ac8d8e3697a47761dae2e5999dbae813f6ff205814bbccc028f5ecffc959389d24e780da8f91e28f31165c670eb029b7a9bbb6cf36cb04c362e97d75b75f90d7e8d7228dc3300b58fdf2b8bfea966146c895197b7b2dc0133369e8850e7bcd496c6adba9105e3206ebf8404214e7a51d715f9a623c7328a6cd2ac1763f019670934756c65751e00b925d0809ee49c347f7e150cfea050b3d0bbeb5808562f7a86908275a9d3df53074f9fe83a4d307e836056cdfed4bf5720c27d75df8aa820fc746c2ef4ec6e1f497780837339b90ce27756193f200b506a35372b997ea5daa0158f0ad4b0daaa56de7015c9175c2e1782dd1e58a17f65ccc6af60e0654067cad5b2522fe76a95641eb365fc864de3de1d50c3dab0c59d8c22c28ee9f472d73e22dda7c8cc22c49ea846387e47d67bc2f93b115bfe2c639e98329b3bb74c74981be63022930cae81526f16d51ec708532abf1cd6d7fd22c4debdf0c7ef0a6a4cac30ef60660755a7388359f936392592a9216adf7e75733322590eccee6085626f0bc7b0efa12df49ab914875687c5627f75f28632dd7c1912baeb41f7480b6069ef20f1bc9343ab03fe278e0da8078fddf4e1939df2714e84e312e0e5c3107b2097cd0609f628734b88fa2579f291b78091b27b00027c273567fa409bd29e86dc0317c11a586705795c053a1495b3ab94b34649ef12b307c8ab97e0601739987d9875e19c16f76021a544242d2273c633b4358b8d84d149cce249799d4278c8b6838fff38cba1e0359711681aa113acc60899adea910740b607f20cf118169930e98359276d106dbbc07f4bc5e78b268e981c3eb660b5d1117c6ce62a7ac0cad58246b4d2cf6d1b4060e73e82920483fc46ef56641d2931391df2e79f658b80ec6544c685508b1c753f21750530c32769e416714a9cb11c18018a5467d13408101db06b2df097590e74fe128176dde68535d5acf840597316e06e85842b17d250c9aae97e8b508f18ac7ededa9c6a33027e2509605ae2a58631cf1488b9ad4797e8e57686c97db7efb57e840f23b47d5efaa498c53d51d9e6ee4bdc0d165e000994370f1174a0ef79c60ab81861f5f5ece6c9f290318f4beb8ec37a3343e9c8b1997420516c19d54b77af8f18a50522549169607289895b8957191789c239965761de10cf6d4f3ca4fc2ce112aa3449c19136311b31d8fe3f71875508992cca60993b3f572af0a5565876ac3bdb3722834eab8b3ac9edc8e949fa1eccf218966be5e0fc42da1b436c6e27b10db064d98439e791865391ae55a6ef0e7b1a69e07e479712728222eaf47b99ca8c7baf81a60a4a92b0c2fbd04258e28552d1b35b237a9ce9376a6fe0d8769300a648303e6c3bd2ab1832c11d1f8341ec3bd27b234aa3e1d940acbc8fa6fecd4100deb8428ec0583f7f59d33ae6f8bf0106293e60950761a375e4a3e64822279fcca30c639dd815719b0b00f3b5df606e47c9ea7a470044f04871c1dab78b08b0b5b412f3fa894a3040e1e9c8d519b62fe955ffebf28c8eccfce32dc35a1beb735bd62dae5fb5ac46e5c611cd15d34c6248a3586383647ad37d2bffaf639acfd6dc1a65fc877b8101d56cb60eb567235bd344786f5e61d3dcd8b712d486ef2db73a5533a23538781d2dcde0f9b886232171f92fc208db87daa15ee498d7b6673cc3bc3d23f1ffbdabf27ddff8026e01267a2412c5b382638f984b6ad586d11b830f868196e6e43513d14da63bc50ee06f0e7f8f42586747daef5fe12b571638ce90a021f864743f77153e97b3bbbcf69b5d0a4afd3bc6c6ada2d0ee5b25945a0d71f805987982f28c3f44e3236526e8d6f44d9e3062db67962c5bdb92cd9272310194b25800afb398e4003ea3f2765c428f391cf0217134779c60f19e5951444898080abfab671df998d9bd2356a0076b5cb9de3b5b48ca69780737a1ba1e8a946ed7f067764b3875e0eabdfc5da6cdcdca1772b54508d2755f0f5c9a1151426631ce77fde261f87a6059dc86f9642adf0b4bb3f48993ecac423fe6fe7d7920af802ba0ba2960d080b300a2c598a32783f47d5efd7ec2dbf6576a09b013b55cfd8731d68d2008f5e647d56f5ec51ab6b2eee0b4c548b353bf4846fc4997d1d87f79a54f572ced6cd472400edda6ec08be9a0c0a134590dd75253f1be9a448efd8901f97fdab41b6fb8d7baf35be7cc4855e5e20dd70cffbcc0de7ab71e9198fa1f5d3076ccb58f279f29fd7524c826f61d9b47af17ac94e8b1cfe26e5dac356d8796248cd4c88bc0b25573394a7af65c16934776d4725562c498cc9388af95e4e28e07dd7ae467fd845b1eaf926c12d20f7c38a55f269ec87005113d524a94360fa1021f7485a70f87b0106c8c82f554f911dafd168058c84ab2e6e26c765823f99a348c1a9320a2ef658579b37209165b3cf330fe3321ab3080ec0f4ded48cff32c1715b70c7e293a0bf13a6148f743b67f18ef4559d3ca3a59706080132f5a38367b43e8f143271abfb1342553cacb62a4a7141fdb54171e1611a42af2cfe9039fb63ff366010a85304040f3ed901d12443ec50542a46ea490a0c3d3657b978be4375b09d72fc34d9c85eb2b12ac158159351b1db24c809114ddec1d768b9a91e46c79a48342a67c7cd80cddd286bae449f6443bc969c404e7e97d1dea0bf7f1d759674e99b498c243b761eb1937a68e0b1dd31245c795bc6f1ba4ed57324f022c230239f5fae8b6c29276926a2bd19d37c90b26d85519582b2e4f6f8f6a025808181d5483f941085436a401aa0696e6d97de5f056fb910971a852a0f6eb28b10847e20909d8d2b6a1a2661f7ca4d0994a497855b52084299019748f9a6b2a1a37aaa042d7018af18482e6d6fcf436a647b2f7509eb6dcbf8c00079c4b694bb5f12394eddd50e5fee7e43561b2a0e3d615589177ee89c10bfa1873c83bdf5b2eac80365eb5fb779fa78e44fa659403dcc13d8dc418c33b83c6fdee44c4aeddd3fa246ca3549b20412a6826156e855ff55da66efcd157d12be7329f0126403b103c32339cd45e6c45006ed40726f14956f90c3f75a58471575c054d81019a7c25c16cf56378daa554dcc51fee040b420a4512e9f679dfe47dfd6a5c12fb61677f0da6c2ce0607edd754e04b5bcc7b5058e8837d156e8a9afb42c44dc47d16e70553d5f40923db9114920ce2bb3ed389858fdb6bda5e6463fb0e3189a372c7b91ff979ddc510f773d655505225b0c469044ad41e25da080d1a110dfe48816faf9208d20808b1543b1ef1881e5267323adfae6ab821ffdd3414247f62f64e6c0935afc3d5229bd1a4e1bef9ff6ed313fc5e6a10759faf1649b040212da688eaf3947574b16602ed9df9df2a1ab7a0291ae3c2719dc541c8183aa7bf5faf852b8e00d29875c91462162045d5ebd4baa5981f31a187bd2ee0061a7553e9cde20acd3c9db81eaa8019532b45a2b600060689dda22edfb179db49fcb7a5db8ff6ec2423068b88b4c7ae7a3c85e8d3e9b6e5148624fee6e433ba67a4d628f3bf4b2f6cd75654301e088f78e81561c2da716db1c04fce7dd6d6ed413d49a4f510336cfb3403ff425215ade58f9a16d84544d883d2e7757853e0fcd1d8f465f8e77e7fb040fab64657529f35397c66163d7cc26ebbb204f2697177e5bc8f910e8e542e8d70642d4ede018a8f4552b3a0707e3395c2ef34a425c06673ef65f093012837514b464bdad9cea72582f63969c888957fbf4954285bea753ac65fd99f8ea26a83078095e326719bf8213165c765990a98fbbce70c111eb616658b91d2992b623e369e32edc5a13a7336283313bbce240d8f448c4fef389b315c451be86278ccf1bef9d518e05d3a679cef99cdd29f9f53d0730f488dd1030b7946c1ade32967ca8f0f5ea9ac9b005d28121028288c753cc32cf9932cd29732661b5c20a3394d36f99418579cb11fc88d55b1f7289b16d579d56df656dbd93707cb6062311f405ad31e46e940cc768eadf7c45247d160597137741fe4e5a83067796474ac5b6f2ab620c569c705093d62d67e47fdb2f39ad3ed766a6a78f2a51b2e0b96a9dd2eb5cdebdf5157dd8b6442cb6dda10d9251fbee4bf88dde2fb150d6a99363d4a4d1265a68012b9b591cbd1cbe3d3a066e4bb33962794bbadeadebab0946db0946687a65515de494fe4e6ce68cb8179f2b199bf5c7724397be561b029891b2b741a13017964daed846d9a9709e4f39832a56eddf7d19d999f6a4b4e2ee8eae8f173f2097c5fc8650ecabd5806ef344bbf0d56db913030619bf3a21402aa4fde77b842a15ffdddb00f29c905f31ffbf4137ba245c8b2427d1b51026443edc01c7e8eacc29b751f9aa7cd4a6be087b6d9186ab1d83831c87328e30a5c7020792e025100295a6d16f328978d45fc48583ec8e8b59edf6845950ec41bf69f903f0f8b82c88cc87a2b4203d23f553a47d8b417a68b3081c8fe3ce2795bf59392204b769972b675514cbbcad5abb2fc7bbfdce119113bf43e16071c464f20bc24056e173de341df0b63b3ff47013ad3d07315c61c4109eb378dcc68f0ee69f74d114036da10a14eeb0cd245ea19e25fc23429456944b01cb5e5e5572e2d3535f7792671f343656bfa23dafbd222eeccd646eaa6495b53f6c98a49b774a5c1e7af3401097d0068cc47da99d04a2dd78231264f70cd46c113ede75b8e07bbdbdfa3f0ad5978028d68328cdad6139c654149290ae3978062952531b00c2e3f78fccfec3d5edb9d7eb8e6e96657b4bee991ec3ebf24d5302142a01d9b984bdc45a92ff0541fcd187c0539c63930c94b36562dd62ec217d2331e60976764f113409f91c18b483c3dced2212fcf2623e9db383bfc519e6d49fc64bda62dedf047bd4dd147f154540db2c4fb519997ed86c6b2a201e8a1c425338bcf25db63c608ba667d27c973a711260c369cbfde9edf08be4a07a0b099e079471c0699d5ec8957d6c3896944e4294c934d059b6f419a6c7f636345fccb3d97e9027eabf6bf9eb29d24144baa16328becb8bdf271d7392259296f13c10ba4ea5227772bf256731cbc0f77e958ae9d9e43ab83e2a834fc4ccda7350c37624342475adf8398fcec2b20ba027ec334081a8f7bd920332c1c3b38628e4ab266f1fa6864b9c40fa26d08c8af8c0937d86a46b0037040dd364158007eff78991f2f22b2772efafd5b6bac9b490f7298fadef64c243f58885769c3f1e997abee6f2c40ab97c7c22fa339eac3dbf302a0f151762e8b6f3684c8514387d5b1555723e82755205c267a910e1fc062f20b43da6e4bec0e219c71fb2259a93a8696c407dd3de84863f8a459406f7d59000ff21816e96c8df7a0cde1e48357f4a0ade5b14985222defa3ba35f6166a4cc92e9c75f14cb1ca2e75a7a845d5990a1f695c108f5b18f37d322941d7c719f3bb1dfb4ca625263df859dd2a970c239b3b556faf5f96e8ce9a0a25b1965286e7229d5ece4490cea312c544642d335e9d5e52e5eb506f6586ab43a557f0b8d2ef021c95b733e3ead0c9d59b0e79349d683f83681667b2a737dd4018e0d8078c5bc1b133030bb449e730ce78d4f5ef73efa712a4ab53157cea631ffbfef752c4e17a411c1c12bb0e81403dbe03de57d7f1d2e6845fcd18925f54d9b7aabf22f09e84569ad1fc02b076bf0b25a6499c6ccbc0d249de77795329e97bd6b02bbea2eab3b34256ffe272de7f1ba1969a9bc12c8d5e07c142e1072082ec48a3d79acac2379ebdc9046f5333a5f127a0f9eec601fe46fb5e8e7705f5ba798406b8d535f25f4f6db3c6c6d85de022a8eccd66055764b5a8a81c73987bd5cad26966ce1fec42bf413c9b6c42e1692d2bf9a65d5f083abe25b8aa124d868e96dbb9307d88207092947690f015a4a94de5c5703dddf452c7e0111a4df9a05bebfb2821cd19976d23334f952f6f2bfdeb05d5188d020d2cd3e3002c85f885c4b0172bbcbe5285626e0b22cbfbfa65b31b78a6b57cff09eb05a8a6687453a61ec0bf0f9959d90cc73ba345b4fcfd2c5318bc4a33c6c58538d4fd4af239451a5519818868b461ca0923bff32834b4a024db0f308093aa35e9f732e92f518ca32353abc68554876625d9d2c12e68fa2e1ee7a80e278ca53cf0e69e512799e0366743498c567a7052eb0b0a1e760ac3e916c429f50e9fe9607a4401ab75ca912c5320cf2d290e9faa7d4a76f45719c963801fc38088681ec652166b97d9a7ed9f83833e4a1be9bc19a0c0c1b188ace495e7982f0a5850fb063f42b2b03e992b269ce70dd90a2bf6d38d422470c762cdd7990cbd0212945c31fdfdd5b77eea294ae7678d0ca988f87fdf8239c8da089a8dbb2e591d57e97c768804588a0360ceff932a4a0e011424ae2dfd260f4271b3d5a4765213ab08351b399b04f8242e2af5e9a3b3586ea87ab16f5dba4a393a329ed5ca1be7f1f8039daaa2c8c27ddacad590c218b0b424acdc5c02e69c3b70704b7972275a5a204de2a07d3bb5445183a75620a30ce4cdfce812ac5eaebc8f579371d5406fd7c9b22be052e5a4ac25bc230de9b777611d38d2134ddc7cb37d965a6af990d95a5aa681624d26ee755da9d79e87f90359723fe667af48fb6f73fe33ef70cba5df295f864bde143d87289f8d42cf832e56efb95ae828a69ed23459ff79682c29cf014bc8f17a767b65c3ac0ebfb71b103b1f4c2a3a4dd86bce6b5b2d7eef03e2b4232ff4091d5d5d683e70f49ab46100271e39413f5e4dffcd439e089a191086b32b8fd128e70cf4fe3da25f1c0be2284b69e00dec523a47f6cb9ecfe64c5739272ce9c9b84591e22c9b158dc5e23b258f5798344295b5283f4fc90584b22ecc6b4d7641fac9e72e184be15fbd99164da307c63cc25a36e59a477bc2f04e2c1a254002ce5ecad4433743739ea4d89569637adf69e7a8fe7fc724eeb5c91c2a0c6c56a28e54b7b7572739884844fc6238cb1c78647b313faab42a9be2584bf9c746e87a219c3a0927652202b1a905fec0b02cfa78c62ee237a2405d35ca4272da2f7496f1aa034c04b5c7d39bb0decb50a412c73344bc117285c39743f1de17cd9b0162ad2b9435536b1a36538b5c41379090fa12c3d62156db3503b590f20338db1fbbeab07fec96a3ecf86ec4cb5d6794bbed32891d3000a85f03e1c756f6b85cb1f8e9350e04d504fe8ec669b1ce08175843d15edf0ebb3cd24a0cc0e47a88d2c2f52214911bad7021ae837ad29b0e910640731f31bcdba51aecf4727c7447f3155bb5e4675a3b54dfcd24cee20c02cb0abf785c3fb0489a893e6c21c5621c0f19b97155c936c3230be77ef1f161b78e2dcdce49a8a69bb52e26dc969b302a190b92b6a7c336d48b0ac146b56d8eb73a33c25baeb214c1cad9c6aff2e9f72397deab8c2bd5b6a58ff5492fb28a16eefd5ffb55ddb8c23446a569113d3fa28170db1f6f39f3ebd950db843c84d6556b7607dd15faac377dc25e57d55e40001db27d24d3e25661dd1fe83f0f946977645f8344eadff5370486ff8d640e93e26491fb29d0034dfee54ca92566353baf9492c974b3fa04a46af1daccc2dbf2baf00866d46265c4db5258434941e36462257374e10a294bdb1be56cf122599804785df9324eb3c605e7d03095c573c23cb530996c1783c0ff4c1b221019af9e86aa9c4b827df448d28d20353e852c92b3c63f4abf440c0a09c2ae5293f4d295d15df04f42e31951f5a124b2db60455d304dc0b960dee18ccc28e5d35800da73f84bef6428913bbe836954cb9f7065ab45591bb892fcb86fa95260b38f187c6d81bd79917eed80fb17406bd166a44c49e6cc99dfb64919359cd42f7fbdfd5886fc8fff7ff6628c7a8d577ab47f157024d9b651442fa68a39928261e2622d9e8d6650e5f76d56a780fac2fb1d8b4f231017f379789caf4525aaa87172c182b6e5253c61e0f4e8709f883e1b1ed0112fc8bfb33098ce8adcf2a91530f5233d1cb025f1168bd692cb4edb4ad73f8e4e075f00dae7f1e2bdf5d4ae4ff5d2e0f3b57cfd640216ac3503a43be5c5b125920d9a906f810a17a95bad93693d71b8fcbec62b680e30d1d771635275a14c9f07a19cee78dc72bc32d7f5d7cd46319c0e91940d136625b468acb68002d1ddfefafa8460e66fd35d3e7705d9b2dd9c48e5ae54c0b0444c8298a07ef5eebc663c442f5646ccc69c48a86c873ad927a77d5696babb810857339619530c020400eb57fff93ebd745c6ad52d5ec8357f00060a8cf66dc6de2d11f9a26c285d53170bc4c57b3c441629abb6e5f656bc234c19ab82494fbbdaced60b7cee7a7ab37aff005df03eff20b7ac49923acf6e217e471a197463c7ce5796429c32cbb9ca49f584f983ad714f3051eb713c5888df6f7dd4122ff8c36abb3aaae77e5c7cc1213d8286ab4092ff740a3402460e03c41c98df52b4dd8899a6257166215367ea0319ddeb1c4a5461cab27fc67400dfe0429691ddd1ef4485552a01dc7009a7648939d0a43c7ff509e5a782bac8d55967311fdc1a367617a78379de47f791dc44f3a7730481c75754d13ea7704115569848518509098c4f1e1dd4b8bd9c81b07ca159a8528956751a163ce6d10fcd265159941c03946bb3f6a10d74916e6ebdc387f06ee315bf26c62773dd02c6d10797b0d14fd9335acfb2efa74153e7d7374f98f7e1cbb6aa18ed0eeb0a1ddf233bf64a76cb1dbcfaaba2a5b37d994caaa344cc595a34e424a9bca0a7917459a83171a02bfba05939cf4ae98756c06e99f7981c2c9210aa2f72d5912c3b68063de9ec6a89dec21b0c90d8081af4ab5e3bfa7b15f074381bf2b866c3cd97660117b4b365cc1b387448ae884ab39f6c51c697226e2891f2d4f143024f0f0b51084338c9aa4675852a1b76b1c6e5cccafa87ff90240a4e2a3f27c178af7b198d085953e5232d4a28d0dcb5517ad4f3b56d4219f7c5f3ba7fabea5ceac238b0e43a097b2faf624b4ce3370214b3a66a6027b5eac902d2282b771ab51c71ff601b398066bfc81bbafbf467970c62c7ebf8b83ce27bfa923744e73565f0ae5792dd7b5b3ebece433e6cbfc8a9d6b44cd468765fedbc2dc93104f3b73b4e1de5fc763a0df9422eb1d0a7f3abb59e70e43ae589c897517e7209aa136cd86aedddd3111e19b4bce829bc8991f846782e32077d48b9ed54ae384a2205a92ab0bd5b68ae8a73170d55004c7ef23f8680274c0c539990c6068624274c278c1f1264c910635b3d952a9455e58f02142cf3981b08a27f7b96a43b7455c8e8870c4bf15012bf4dffc004d893e36a160c7ac1cc324d4386bb98a5f5072c27620e58db5358b407206188cfa27058a098ce8ed8581faa45e295eddb019d9e69a7debd37eb8a720e1f9db3c369b29d61e65001cf7a44d38810d7901f128ebfbd634958b6194b131f9259876fdd0b8b3a7f5008184f87f4f5b02fae18ca98e00db6b789e3f97bb7534489a110b5f46106dadc9e3e9bf72b9e7e1877c80ff8487323332fa12c29d72a29be2e23d21501c6414785f38f56cbc1eaaec71942536f8e69c3d1891524a067f2fbacc5f3a3f19e8fffd27f38c28ba50d62312e9761a471d8c6ee6d03522e1f46ed0f7b42ca956cf2d909ddced23e2c31fa0fd77638dbabea4c7f981b3762afe0923284558c0e31a56406115da3dcffe162b7b6f3f09fa3a1917e1d89926a24198463903a04377886312f2b0f00da5c657fe675bd0bfabbe39e4639c7e6901f5967681d89d157984004a36e5878968338ce52bf3d014ac9946d5160ea261b77158da514f7309ae15207bf677d81cb43d1534d2d531d273ee0cf96c62015230b51166f58917553368c1121b67ce70945fa02b8ba80519c86a31ab731dee32671ed68054d3c2f7ace77a3b8f7cde9833cb7db5133efb2ab91b385e88996675a7e6ea494f04b092650be619ea642db8c3c6c6eae96771555bf1234adbd6c611bbb9afa2d8013a532921258b9397252d67bef4d39aa8d47a3bfc1a5f4420a0a3e708c7e8e6e0747dcfc3921d4b7efc86937d1ae127b0b0a59a111a435cb9ef74b4b374664c9678f0e10eb5a62624ac6e44b75e3dbc1d46bcb74282ce158937d47d9a5c7584c66f25b7b7f48bab8bb3b98f9dff614bd8289a7202e6d46854270dcba48d8cd66e5af3b5f9ea054f441b03dc2a8a9924a4596796aa06f20f499cf4feda88f2d0094177af818a327d64f1ebe43c199e6554dad10147fef5b0bc39b3f35f30eed86ba76a28cd4303f3373274db43b19a2423bac523678f7aa5808c603ae3fa52bd60604887e7ce48f585dd235c6d0e123b6d95e3e265106fb06ef3a8cddb710e68dcb2c14bd36289d1739a3070c2d28db6819b088082a2531210cde42d63a6c7b28dda99f5a46d16c1312fbec9d3559813584969482d15ad2a0081b932e57c19fc08d5631ee8435501cbc31f7d4030daab561ea0c1bd585c397c205eb36e423eac9cb373390ea33590888bdaa7835f08cc3fc33a80fceb06969c84ed34558484097f4d26a0286bd12e131748eda0b95b21a04d2d81541f04ebd10849923604495bba517b188d2f534af6b5bad32470a8e6b055ec0d216ca9a2dc4fdc5eb4c5ddb33af60c7a8e8bec5935ab298e2008f4f752df6b1eff15bc5b4148640e5cf5d7b4cf7e18feba640222274a80051f1748d0df17c0ee326ffcf402c1b2b1510244a82a515eca3b6d7e5f3c26c7ae7615ad607cd46a8c8a281ce163b725d8f2e519e6b4b13ede98c6ca3e749098955638039cd847136335cbd1c0992efc6f27b424a91672901e2e7ab1750bd6ea631503234a40bcd52265ccf6924e54dd0b9cdd9a1e786fdd19b1cf755ddc609a468604cea5e0a38ab00fd8a6892ca496b3310de0ee1d5d59d3f7b6a4245d0e8a55f0cf30e454d8bbb657e802bd1ad593bd464552917004f3a8dac195fd6560b3a5bc7e679a9d3b1e40600f919162802562b13d08e37864f2d9ef3ebb6dad4013ec3e3244a4693a7c431e497cdc5499478dfe9e8af9d415608e004b6e44502983cde3c2a6af9ec991b51597550d614242c9ece3a6c985e0ba4e9875ef798b0c8dee47d2b14f4088de2446029f208d2906c7050bb160d465673f4aa67b32e8d83ab277bb4312a2b46d95f1e9ea07543e7538cc74a4f800380cb69b4cee970142afa3384c59ac01f7bbb2d739dc1c5311118d0619f926bb2c09a089331f8de0aad786cdd8560d96986449485bb199e968d34224719ac550423d524973dd8a81a885d9b9367cc4cece33e0b2772813dadbb9287ca784e506c0be0c7096c772757ceb1601c3afc381979b6d7fa2420637d90675143dc11e556949a1144dfcfbdc3dba51244f821af76d7d07bd2b922edcfab8909b57de602fe57aa9a9cb61a7a9015904d760c2a1f9767e306893d37404c1e7540f3c1649edafca6c4c024c063d3e4f851ca598dddd1402806dbd101e183c5a237c9444887554a36e2364e154788df91e44aa8ed02bc7fb21825bc7b2032654035fa1ae30ae5352d23ab693ba9e5e01aacad8220e9127da6d7291c36cec37df7a99bd0c034d9d73817a327d227b858ba54229a6e4aede1f17eb2a713f8ea11bb4bdaf1697960a2ec6841480509bffce44c33aafa1ee563e3b301d951bab24afcce404a207558e367139466a51c469763579175b090a1b490d3e0971d7910cc08de64456867e29d1ff9ac39262a388c2615a35d32138cb271be55e60c34773c4a78905b9e5068a040bfdd97496ad9b2c9066c5b7f2dc1ad39a59afb67a4c4e75d1a50f474d239d10620ba0e63154b91b33e4793e7d4fddeb241bcf84cffd62a8888bc9371554b99bb8150db63b078b2eec4239325da692a5c3e335f457b1aeb4ed9d7446021aae4eb189caa4a36fd894953208fda2e6b2de3a955dca5dd3399023fa22f2082185075f263b22f44d819bf408859ae75f9d5a7a2e49fa88cdbe4a4df1da1495bb522a332a89f4e3d6aeb6bae753e9121a819e7951faa5584e144798e3985eb0f63058dfbb993c4c05d191e2df2d71f39c8a4765aea4a06fb0c5286bad742ec45743b4362dc6c7f5a2b888382288e48511062486f50b432d04856a0048a8e554aa0104d9a77aec3549a97fb1f099f0299cfa499d8c848ff47690dbea10275e4448d43bbcd2dcf7ba12ee9b0ba016e0b19661b336569b8e031e1438b4d43db33a311d7cb7cc1c131ed3e31f7885f978d97c81ad32e1da9f63e4c2994350c49e04f91ce468481b5bf4770eb92abc282aa25146301f50469ea3506fe6f391e2a5b9ea33b11e286e9771170be2853be764c942208fd4355b635b9890b3e652b4bf6371330d2a31e96025c720783782a84e5b65cb5812184273e66b25128b6fddc1ee73e76617ded20cf50c3e771860d6cdc5c791f9f90194283972a1c96bc1146fbbfcfce93f5508f12a3c706a88f15fbb7c8b6f2975c597a0ccb9d937427577d4a6f63ed6bef8ab95cb5fcfe629a564c56f666f366c0701f7ae5b6c52e991ad5d78fee504e45bc8212d161d220d61e5b1148dd0a990294ef37d91f0d47c304acfaae11186b6007543ee14ed1e665d0bb757154f814a1fa739de62a64b4c8701cd5f8fd448c3c861dded05d9d2b8aa0e451794f89039275cbe710c1d40ad671d92bc5bae4f8645a11761a25d7246110a0c83e0a9ee6d99b191ed3b17c700ec7be020fa76bf307b024e2eee10c6f0dc5b6b0748d664cd40981c5dc84864b92991e486e907e12914715e32a9d11b760e8a7df83a38b343ec320e57531841d974e1f55c15046548456ced764ef4daf6b6e31fd1c20642a066979218ecf41f1dc0d4dc699c30b938bfec56e441c0983fff7165752f7d4986b582fe9405b4778faf0efbadc151ace2d8e211a8b01e4fb6cb11af2a912f9f298419563bf5baca953624d19f62890c46f0adffe217e709ee8c078269a7be3f70a5722da081d86c561e8a4880d23810683bdb00e5b2761e7cb56447ab196112b8b87d632302c397bce988675b8577053742e5d64eee1f9e1e492c32e2e571ce0993f381c37d671dc92893989584f17e3596a70537efae494285c8233d3ecdf1c35d9e34270d8fdc9c1b280b44b2ea0f518bf26fece1910bd052c58e3c0894f1f99ecb03d411713e97b2ea17dcd9bd2bda8e4d2940708e598debc30f63ca737efbc19c94f7036e09dc2dc2df31591c99510f4a7362eacf150e188c3246be589820648380eadefce95fd9ef813b24a2a2fb64c22ebde731924763c292ead456ec66281db75dbb178a0ab3ce432fa381a35986bd0ed5fb97c949d3331824878ecbd4d1bbb7bc9c00f340c8d6e0b3dc85bd1d5e4d0ef49d95c6a525ffc46d1af4dc1b12731638863fc854922a5c765e2ee7cbef846a51e914c4d526ccf7d52665026478b7fcdc19866af6de69c0df034dc1f751b8d40b69e3e9e175f3e076c7b8ce569c53a135d5f24e74ded3839a8e42d169a417c26291afb501c37a55510eb0baacce2a286138b53854403957f9c49263c0d631ddbe3a1c2b31f398711bed68686a489f59bf00b1140937e27a260086c0d7077e504fd934a400e3fc36be0acd7b1eeb0fae0ff94d069be18c32a4b59e35381da4f7a289d9b101638e95ca8a9252f25e4308a79942eb985a09a5467c1d9e5a6307a307b00df84e08404a0a12626ebdb72812868904baae5380e624b5f73e6a2275f0a702b96b036a0843da9fbc09012718bb87c00151e92565da36bcc9caa8fd7f867c96ea954b092d6a9983eff852aebdcf1253a9af118172d4f41efaec6b679f956a55e26354c62b6258aa709645f1b95bc80a0eb76f9f481898ce47cd4a81b94b0fa76ffef91416c8eea8c9b0e3820a6b2bcefc406f27bda9553fdc70b33db0acf5ab664ff3cc89a5e4ba11760f3ecd64843d08c794808ae29ccf3a1cfec44b4841123db54b50d1cd126b7a8c94a48b447d72928e7c3908396afff11c3b3ed23702a13a89102f2366d95ce51ce0cc8157b5a421bbcdb6731bbb77e727a3a06d7e845652dc08dbec39576a241bf750f6dee528afc3928cada78cf3f9f62631d268b39a9f211124cb56c0badb0192e721481babbf33cbaa57a5309127c97a4040012084349600e6c8b07a702415f066352e7049c2a9879c3cc75d9086328c45eac84af1cd05f36baff8bb0f77f518e06d0a4e813dd5e6f7f33e3e82e4cacc7a9b082460c3ece200829edbba100bfd5e6b4c8bb1dbbeaf3b484bf22715bd92111a8b442c317709f6bc053e83e4876cc44c920a9afcc1658c038f19e1c5b0cd133f3f2c3d5ba2fbc48f742b39e77a8076360af9b5688010d82600b12361875d5693a8b08fbfd46372a44ad57de1987804bc3d15d8bc2673e89c1134ed402b42fb0a7637a81acd2b423a4bc68d9c90b835341d4a00073a83b05fd937d426aa8e539264a22f96de018b13158088a70b31d6e22c6ca0aca51147e1fb5277cf48bd4cb2f7a3a2a229460d597632d78eb459f2f262b142cd62125f88ba624007d4a93f1332a081919e7a11ede381edbb963a327001bd32785191fa9dfee2dc46dd28b5af6a6d05e3359c6a9ec3522d9e0c9dd3998e5dfaae2ea2817dff80cdfc41e300d3e1312aa6731ab7fa20db163897b39dfe890ec58648c1cb9ac0bb34631d73eb69ca5b56ee59bc63b4282a0d763a5f3f8f1274bda1d2d6329a7921476fa1d5487a2b46489c8993febdcba950106e76a1969e2e658e25dbca277f6b5eb4dff5185cf703b1c2d946270bfd3699541b1c6b5df8d03fa35988c385d1302be60937ead3af788c5e92fedd9a9ed9c5369d947396dbe4b57ab1be8d6838a7fda4023e53c6994efd920b40d6a8d83cc952113564d47b8be7821d8979e603fef5f3fb764af8dc226b0c14dba79d9e7624ad446b3add23fe7e0ea027efe25c8c1d85f97835e1a33088f52bf48e4273def6f3c84b55fd56726451b17ccd95a29bad1abd15133b4e7a8f77956bf611b9fb60880faa76e2b6675a905e28c2d872a0cf41841338568a39394fa7aefb063d9cbf1ad59dc601386773ff5aa124f29191152b0d523afbac1aa78008d3bbf3ec53a8971dfc2d278ebfbf4f3d125c85a3d369384b79fdc09079ff2b099f8ec5a8cb984719d796c1be777ff96234dcac7bf2ed6a46376e32a9cabf5aae6de3d53f243cc3102fa8564bcf83763c0c668d2951497212d22f189b5fa03e9316bf6bb4f812f27eefe138e519657a4acee4bb8d4e0c689baf19437071dc271e4436e0dd066663144b2f69eb6daffb3153aa03ba9e888d74953025b1c22f2d7f1375d744bbe8b1327024d09d41f8caf5d71c6cee7718fb270da80a370b5dbddbdae865f544d5236cb14690320af2b09057ba103b5fd1930fbd44bad8afcf55054e84020bbd8e546af578dc9a60a44324560de8a27617ccb037a59c831bccbd4038887f2fa455150ddf7b3d6c7c9661a2355474aafe2758ca1fc5e0b235106fe9014267a75f27de9630ca5c7e503ee3c3ffc9d76aed67d4f4462101539f458f33d4aa6f126ba9df8d6ea7389c947ab33ac36a83c7a195fa6d57c5f55c3bc8c0f2d3b617000b4b55016881d2805e30feae0f2c9efc4c046e38fd88a2261ab7f5b308fd80921adb21b82352505220b913478c710fba85bcea6405c26827099d6f334156c8139bed6fa7054806a1c8bd82b9b517421db0752df666df0a7192c409141a62f2ecf3e20f75adbcfc5fbac9961749b72689fa979c246913a904cfe9a4d93818a9558370d7c6c2c66c37803814c166e0102c097ab44876225aa729d63316ff126de6ab8116bde7041250b68daea15d60f46b71ae50128c7fd8c95741038bf0e94b6e717d50615cf871272389cf9030b87b3a8c9325d87dc5430a4eee32ed4ad025f622292991ab1df871a6674fad18d2956c46665c4d7a2506b64e05e78f189f5620d2e86567c6be24e8768c6583ee2effa99e7a0c81540490a1e7a23fdfd55f343c909d223e0f51efefc9c55c3096bfad0d929c5794e499625c4424b06c4a0a1e6856aa0dc53e438e2a236d87a56f2211134217f890c8d7bcf016b23b60a36d6c09d5a5ed9360d9192a107ff1fa11e60a272dc36c22351e41d10032cd82db894781ec4ae99e99f2dfa8dd802e2b6554b53576894e9e92ec39b15a3d85a4bdd90cb66cdb6a8abf18501ab404cf9960cbfcd0c4beaa5efd35e7ff0d984ebb5fe8cf4e8078a8a06869a27df217320823dda6e31600be1a73ab35832a4a41097dc9a513a44c6e8ac5665ea5869fce328644388eb4ca1d698c9ac30901008def99b4c84a2a7c5e9792b4538743312bee0395aeb7399536fe966c42393caa5bc1fc3d4f3c7721bdeed7e0198e78391e3133c4d60b579e2f90074846400b33e4555233e9bad8049562098d89c62552f7bbdd4f9fc0a1965620b3db275976cf39c5e09f515cf40eb23a3480ec310569f6e0e7ac60339b96d58855a7a2e0541695a48340877f86999f84acfc3e73f71254c2d6d76387aa412a32c2f7dae406232baa3400f3e73c2e42f2dc86c93db0ab0323679fa2aa56d3465dcd6f8f55c09e85bf327e791c3c8dd3dcedb4de916d86d796cdac6b4c188f74d154b768b8e4d7196b523a909b53900961a5188a53fa22f46b4fc9b26d635487f2a71308159c2e3da4875691cb7ce5dcda8e268c3c19f1b83ab0c8a074dea1a0ddae9eee8307fae6b511b8292fa995d5b8b1fb6e7c3370a386ff6256d1bebae2da191d8c71af64aed87e66a9dc5faa096b718ce806595a084c01b3909fdc29f7d467498ab0966991139c38ac081b91589e58d22bf8ab79a161b40af6ea9fdf7e15c64899835873770663cff449bb5f204cc0dd6fcc86d752ce89959b2329d7eb31c1b48e93db67300c63abe8c2ee0f5f74890eb0fbb827501ce8c2e6e93a5f2737145a18eb4ed0cd1b8aa5fcadfc54c080a2da28297489cd4054859040cbc0c73880ea36bf98926c938093dd7bbe55440e498da7759253ea7f89c29228beb199f6c83f8d4126e0772ec15148fd115f7ba7e40962ba07ba66f486d3e71ee47d71994e71f594d76b4b5b79266372939c72f1cc6262358ba8dc190fde887b77b17c0eda8bb977c1bd0ddfd1e5f0f5ee815201c7f2249421ab159bbf9e85b83557afbedffa1b3b813b48e1cf2f3fc692cd1f682a1799a2135bdf7bf6d744b813dc480f1639a87c457ffe352fee8eeba557e6b223175e31661d4dcb960d82003f9d3dd8733cce31e7104469512307ffed29f21d08c99d51196f614eaa1be34dc14a67fcfc6d6d8241767e83895a24acd30cefcaf26e9b7b5ea88ade717ce20b4e983f54c3d8b0c68ff9b921a9b2c99ad1dd583206e64a7e86d43e13df88f950a9e2e460afad9170d59fc9e2e7643e0ea53d8110f3545bb12c63320de208b34f1361c1e9d5cd908846a52b97ab50c480abd78d3bcaab818c4ef1c3caf11dad1175b13205727553c5b59cbe443a4d4436f6dd9e18872f1bd05e85831cf45e4dcb5bc2473757ff4be2fc29457f4218782e85b0d116ce6e9cef3d849c2b6b35685a7b825e2577473749fe37e56ecda34d3c60fce26aa3ceaeee199dd1d745c228cc4b14397aed5e63bd551a8a86280a7e5512ed1a339f60cc7c25d4061cc2ec22d87b9a6056162ea8ab9b030973c3ae62269ab07f284e875aaf3aa71282d8847103e8eff8ae29f5279765679684b8db1714cb31af14f9845f245a0069d96bf3483edae74e54884eddb208ad7b771eeffbc893ab02d6ed19f14861697afe41e17da04947d8547019f06fe7a3ca72c4d6547457c8d518f94d68d4551e90ff1c24ae2815bf0b1d99a4e962489818414dc2433725d80886589cca623e889ee578035bd338b412b46ed9ffb63dca22f983a116935d4929ecc825b3b4dbd682cb672faa1ebf7571b7aa966b39461e0850a15dcde6daa9a494347856479dc695501cca3083f4759054f788dcf9b360b61be23054b5deaf492942f3c9a7a77e5dd711f9050fd4ab557c127b07ffcf5764547a88481bce106311cddf3f9c45bda268854920c5b7e6b6f73d9940831a9cf9bfad5cb9e8ff765a095a6652fe2b1e0ad23769f6909beac38b684c45c79475d31beea4cfab397417ee366c1046b40819ee98963acbc8a79a18d430f2203dee095103dfd7cab4441a88cf7d3845829f401bd39fe2d067d44c369750c9a8c8d544fd3d29663a5451dc14c64bc8c113693d516916e1a7e7a1f2b64fd6392d38c586b996293b6cb11a06c0ec1662c344269269827f37563a03d7c83af627a38b0815669ae6a9c00eeb2bfca32df6b157181399473b163caa21b25e1662cbff1569e361aadad21c52ec5f4b8be2ce29c20357e19cca4a129d0c1c9c699fbd52a6b0b66ce04c5f2fc57ca83bb5cfc6407d9c85198b77871fcb904588e4183c5b61621cb9a3b63f278983861bf571e4309ad61bef3ed0d8a4b562d36a851392f473c5345bcb44bd43ab5e3a446d85817abca06d1509a913479f9cae1677575491238feca7bab455d9e12043d4a6ecdc1877501837db1de76698e64250b042e663c60e7c46122fed9c7a97533b63b9878613214a38aee77f6bbf8c8d9ca582dd6fd3027ee0dd1693b0b190d3714464537ab8521b5711b271030e76338c4f1208fbb74f1068b9813a21f238c18116a0979a9b34074c7d4b53407f84ecd549825a379e212071e270a2301a3d5f547ed8cad417453f4ddaad2a6873d3091d257cdf47f8e72af07209f11645377be2cd599a25f0a8db4872b833fbc3820e8655e284604f76de18879bfa406a9d1cfc84e7dbdabbeeafcadf47581910ac89c3ae201df8bdce71ac035d36d1cbbfbe6fdd01538ae3f1459d2aabaa1c98ec53ed6db7196416e74a1a6554fa8ab26c0fcf2afdce8bec36598a3ac63eb3497e6acddc9ae26c0812be762090ecbcbf7c6f2bc089c6c107af8be93a1bd762f913a9fa1c36735b724bbc606723d945cb1348a272c42c942afebd5bee42b731620fa373094715d3d4cd5dc1dad6f8af8035b521bff1d11d06adb1faf6482e0faba39d6fc3e84f8c5ac04ee4346f980bb11e79ba4027e8a88c191f6d47147873fdabd5a586aa25d81d271a8ad5c7334d861a8e33f3c43856f30935d19a4a57c8129808dfdcb12e3c76d0b98ea7036fd9f8eec75ab5d037f8bf2f6d712e5f35e28e07190adfd7b6d0a7d8e0ee7ce5b1e961f5adb04f70572c746346038e459c384c868e3f4989b4564b98d3f03a6eec26439d7bef0fcddd7be63969060b324ccae0be7794443b9515c3067625645a69d27b82584a3e782a2a0b6462c6c44ef17beca656b47dbfae1cbf7fdf521ec375968c0d0b809befcdbf0630b378b32c6ef9172d0b30dfad785425675cc5ee5d8b768a4ddc8a57a1f7c09035c5f908890e50b8734b7ea80cc76c210fec04bbefe81ca8a1fd16cc12677d5bdd46dd305bfe6e528793b56cc69d99c2872ce124f3313a730def3248acae9fcccbc1fc879471252d2e043f4addf4bdb849582ab42e152313afcefa3bdec0487754b005ce14f8abfeee77a38c62795cce0da098c505c1fb697480471811ff029e604a34cb03b6c386773488eb9f59feef9878262016c92fd0e81f4466eca91389024226ed66881f9936f1ced18de225cfaf38dea66eb7ca0c1a4abe2a54bc62d41706a6daf75e44d663ec8d46ca1f0a314799402b1789113ac96e794b013a7e0d8b839a6feb1524cd2a71418c8bc19ec79330753c83ea1c16caeb99f0c5c648f43fb31f382c330f3ed79bf48f9124bc98c60f94b9988eb480b06aa0bf7d5b8e6bb4f730a3ed77ec05d59d056306222616141b2726f6374739555f4559b9f25ad32a02dc9f0ffe4c5f5f5bafadd76bb6846a6bf9b327362d1f7985bb958083a12f8e17e15862938bd86207b8eb5f113d1a1fd8536f07608c76d00baf7eae45066769c8703f21cb6e9bcab27bab7e456c25bb9ed4d05ed56aca067cf919046677eceb8542896ce7185b524f0c871fb656105c77821abfbd9ce7e5c5c6266db5993eb8d3c5a156954430104755ff78903321e81f3853030b4a9b9ce4d40af9646774a04b0ebafe26bf0fa24f4b28afd7fe78ffcda09d0437bd139bd83181bf74d404f003cdf0b3724ab01c91760d9435ff8b4c07516184ffa04bed01e4ea562fc0493c351c32fe3598869a24fcbf74ecc5f2e4149ae7a37294dd813f1e944bcc664e0701e477d40d5318af4438a4ebef2476b3af5d786a4f502ddd1b5ccdbe18352b12dd9550e0a26fc44abb8dbebd30ab9357414def5352fab10ac8467479fb02a81d4a9a04b699c47df3515ba96d6d74718ffe040a21f860b6ef2e3b99eb57c8bd84f08bb6c820db8d7d517a03063dc93befbdae7072fe084a287ef68b8b48346485651385478c5a387ea79af5389301d0e025e14fd8e496b9722ed5fa1d11ec4b868f857e8f3859e667a1219aee31a1214d937788e47cb9f2fe5c34d1ee3d873177ce839962f02219fbbd05ac02b0d48e9b841000d2c727a89c9f08eb8c417e31c12e5b54f1f0cf066e02c63491f52363b0cad9d265ec3ce217fb8c1b44f0718f1586e9bd5133cd88718ec02904eecb1f9bf36f0a44583075ffdf4f910db53bb7bad941c1c0729ed1877b9e819879d07342ff281e15131b166d65333546539f469f25ad3429c2fbc381d5e223cfdd8b580e7da0748f5d7064d6a250d604243f90e12d46c307a35257fd4d87e12f2df63cbe346b6becdb039d384d6888b5a7dfc9e1fd73733a10f1067b40e41210b78ffac05a6713eb605746117b2d892cc30cb448dc4b29d456c9556648dc7fc62c26918dfd41bd597e1b6824e0bd7931946d67dc64a162058980ab26de973d6780f89e2491bba31a88ddd207aff712b10a260a851efe27a5427e35542bf32b1d5d5d9285aa40928cbf18957fe8bd9d59b0546237d490a7ca820b401bd0762112c87348e69add231cf93b90e254cf109c9a40fc8f83c3e9721f294d209fedc974f8fc408188ab219f25382b01fcc32abc23d2404aec6e40c250c11ee1daaeea5edb429e2e80ca4b396f99c9cd14a40acc042849305ee51ce3a32bed8ea16de439f2911886130e41f6d3806413160bda70f0b56bd889c0c0c8067222bef30a8ef99572ab364a981041a293655bbddf184d49d00e61f9bfa52082288b9a3acf12d858e608ef60138aab7bf71c7655bfd650228c679a0fc012526ec403e71f551cbdd7c129acead679dd5a7930168fdca930b07fda5f6a0051e84385102bebf03caf3c251d982ff2502ce4763e3e4d892191553f40c9c1da8f19ab4b0b884e0d2edf1101eb7b55110d08d9e54f505d450bf5b0e4ba32d857ce9b8e0e7117737c4df6fa03957f7d56d97aa87cf68de474f50ecb751d96b6e21c35a7e2b49d47b21037048605e9de1849bda22426d62411e9092fafe935aac72b7cdeb41b4dafdf6c3de70dc22ca6a98631987c47b6d4c6c6843e5e67e6a0eaaf8be92f9e7e6aff7980e3b69b7f47d48dd4530932e90ecc3a162c0af4d31d454c4028bc58c7ffd0873d6188e5b0b2af822d1e8bd42b76d7b4eb213fbaee76a1a29ede06bb7885b5e8ddb59ee9a0c2aef2214ac0038ece43dde03641e9fc171aaeec3b203f2d5fcf4860c13e7dc5fdb3bd84d757f3b9ba031c9abb9392c143586022de4350a325c2c1d72f51092941f9abd6d54c659624d22265854d39a1662a884ab4f5cbf81cbb6d328474842a28daab8c0246e972a9fb834f379e15c922590b7e7d6fe949ceab83932a7d0844cf09a32d7d92c855623b46f3db6835deca9e0626848c1b64a95201927b69f04848441d7ccae65fdea16634db82562d471214c11f7b3e1da7f88dbae78340566b6e457102a6864d49db02b653276c675a513a163490284d6d3b72152370078a9a4c4e2ee4ab03cdf3b7698e6fc48b6e653d267a43ea67dc59d142518a5eba429acfb990a98814523742e390c675db30a5e525a0c77c65d459135729c3f336153e79eb210b1a512dbb8f3ad9d0b64a788d0e38a2b282989497274e8c1e12b2f25f9a66f8369e4a8ada41c9427d52e6f8116870a75439b5199d29861b3b8934e296ea6b580d96f3d1e0d3e1ccf94e37c616a453c974e4e4d9f05068c46961a8d6d90f539983acc7109d1f128cc1a5a6a119d234dc0714752b7f2f94bc93dbcc87bfbfeacc55e15f4df1492da1e2afb2bbf894d620cddf06d76642e10de2f9d5f4c0d6304e720ffee4598ebd1e35f344b46a435e594f1657ac31777d595de4ce0571ee74b1d70374bfd012d6a4c475cdde31b0cda628758496e5847c6972559d584d50e86585dc191f9aa3ccad5c6dadf8ae580ba39445a263102594bb46a740e21ec7cfe4e026b28beb8fcdce987db0857d0ba37309e15e71395e58ef588d6bf07a5af92c4c78a334905a8d96f83a6f8e27248975af931e26e1a4ba346a0990ee11812da895d2130dc589027393c56b703c049a04db73931e6b30882387495355a805af9e8a46c2029dae671b2d6fb1e2fa0c0097925d1c7ba752791b7b85698af981ec16c200cc4f952b90ccdbd8a715d9faffa5d6b986dd72f7463876a686fbde3d0a1ea6138304f653bde48eb2905ff893fa018889c06f4ce703cb7dd2f3d2f180265ef8faddbe84f1e8269815527466eaf67c9d922c5e28d31c3218d898d1d5494c449a7fe679dc3b7ee2997f6ec7c7b711c527d1032e7e04c8ffcbd12a0ec561e582ea54d33fb5e0cd4a46374dd18fab4f5fc51810c4d1c3b8915a5243cc22ffeaa8d296fedd3e518e2dbbe3522f75e63fcab74d2f939e8fb79616c49b76ab64f38a6802c71eaa69e5c378d469e66ac2b89e45cac360d2f6208a4cf0b4e95348a5758a5c1c160099bdb62b43f9b6c62d69e39aeb28d28ee1e37524f5d7f17c49756b3bb144a72a9331cddc881aee2e7ac58ef9fc3c3df9c97a7c7929ee39a26db93d9d17c4ef9bea6ce5d07a8c87807ca298a3712484e508be95f60e70644a3efd4c046bc5bf4d73c094436056d89b3c703fd4fdfc5ee42e31bf5c0860f26170c37693a3f780350d8ad829ea867af8bf9f56b8e73471319f6ce43fa44bb863f12f3a3e08ed21a6afde35ca511f5fef575195b5936d447197ac2d311652ef6d9482b73b4bb86d8b429ee17c04db93c06d6b7ac27d361ba3362bf4d3e36916958e2d71e3af7d44b7854f42311fa7e0856acbcfeaa506aed4f294ac95f66c383ac2ae2b5aa8ff4f8ad112cff962285e783c29266d1684db8dd8dc3f3fe79ab4bd4505cc58bdfdb0ab26c531ea825174a23d878d71850b23981b3da3900eb668691f0ecd35a24356cf6c7a1664c2d64add18e46bc62e3464dd630f9cbee5af9ce74b74e70ab318447ea159ffd91aeab78764c791acb9f8c4ec884e228516fa9f4798ca279c4aec1ddd78b4283254954b2bc634fc4a38c8bb7a72430194c9e99cbf659e4261e53f3c5810cbe68426483293d6212ef776e233150efa8c5113a1ba002cbcec7063db2476f4ac04231a6d3674190d221094008758516b692b786667470f44a1a94aaa705c3abac2f47c2e6527514f95e056ef6a0880739d8683f2ec66b33c6b2c643817c6a2c6955fb4a2c4a7d978dbaabfc71dcec3b0612c6bc37b499b12f082bdb1f1b2f4ebcb7ed0f9ffdebd2cb74fd6956a45a0b7fe050e03fb509f7ad1ceb4f50035ac33668ee47c37e63b22232cd8c82ae02dabdd79fa08bba9ceab67c90cc8edab4905641be6818bd60fb2ed99f79edfd5f234ce89db263fc2d544b9f9d952aeeeb033f97d1175617be27e694506dbdb551aff55be07eea991eae634b9f27be3b1f84c3112fedaaac775eaad308d6aae6694df5645bb3a141161e8cfb6dd69b2637284ba8d0095d7c52fb66f469ae650dcb898443169863100f26ff8839fca5c4563e509a1ec2de7b3093782c6f7183fd7f56e8ea43435abf90936799ac1699081d8c58511fc985002f2c434dc1e793f72ff80250eaa34d2980d75fdb2b7a6cec1db4b9275e50495efd07eb4a3c4ab2a7ccec8b014d7cc078a7b63bd83928f8319a3b1a80b067319505cc50b63b6835c37556af27aa21d6c8a5ccf6c25b0859859b5883d4d05d03ea239ae2c33a9fcd23f7261e3b2ae7e5bd39ffa31b2e59b9b5ab1b68aaf9693f896ea5844c90ec2c69c7f602b510ecc93f7c5eee6bf42b9524e01791f18952b0639f869e94c4353dc18ba9782291aa1875269e98ece8323dec09841dc6156cb8df13b5c8e1654ec0f64f453203ad87a7a6df7ca57df4d62ee6f63e99a7b1afde63dbe19d14de7c12a60ad0701f388816aad80a63d2daf9333d9546f79caaf8ad6cfc78cdb6235f8205a76fe9632352c216b739eb6889917323003940ca1fa3a6f7bbc31e3333f7bf0ae25715d3c33b5186012df8002d29fe40f4ba5e97ce137f3da5a72752ab2dd8f879f5d2bfe13f92aba138d2855abcc403dc26734603db49fb6775cabccde96b56fe74a38136b97027084884aa71eade3004027a39b709b1320ac1eeb7a301c04e7ed59551282c1c3f78d6a18bbce452e67ebc3a968d581538bb67118dc6ed4607ac15aba18aa20f95af9585edb4737df96e8f50e6f6bf213e27a01b9c061381657968ec2c169a2d6e0eab58b925c3bf3b334cf885cae1d8cf993a6bab45d49d0dcc624ede10af194aa8286d7c4f28841629743bbe0073ec711dbe8d0088e70eb6fb1d13662c1a2b721e2c37441618d91f752571faa8d9e829a2132446406504be85fbbc7759bdc83cf5ee20a73932a8281cbbbb90f7b0b4967ed1ccdc1f15d82d8946c433f5bdfee9bcf8987ccdbc2a03d22460000d15ff3ccf13a6c18b5518559f0f00b4dc4f83f2391f4f5a06955be7e74796bf06e3e9b09d9109be59c051b34318d090dc3fa061a6a92b519c8f030110f6aa5e3431f069a2eee841a8d435efba7c363ab6808bd1f36230ce717ec1130a563557c476d1ab77d2235b3462d677439aed8ff494bc96af3e9f30e486f1878f38e29c046d669d218d4d9b171b0c67ae6dd5641fe4ca3b94ff2ac54d46405c8454392c9031c0ea335a7846f4039b5227454f055e63341f6b1721fc48d72a25ce75892625cbae8260ff21715e39a896d733542ea833626afc5813802d5dbcea8d3e0f03ea9da4439380c8196b64c8ef3ee2562b44f2cb0745b0a2dd67005a93b879b2d305b328fc74af691bf7a9469c0bfb3bbb4a0df679b7811921fe63052a6a4062921f19f016a63c3c54e50874364e7425606f658eb4d0e070c5ea211fdf882f413155412b8230d6aacf34472727d09998723e696e0fa752f65b8bec49959f7b1ac02562ac951c0f2f57e693476712c5397424ce12e82f7903463a356792d393fa94a23f0a1614c814d8c86b0fb675590c9cc7d8d6b9c5d34ff2d03b8e1ebfba358265f7d5dc8c34c9663db8ed6469c8d9b146f146bacd58ed44172321ed6a65c84a51b5d174c6c07d59998b5ed8a223d60cfa3fd0877d446aa828241de9296c5c5c79ad70f43df7d6b89b90827d1deef22b8f8a33ee9619089e2b13db5911188305c409ec410ae49b7b41e99cce9d3cf2017d5bd190f9a10dc21028667521f8d2e1b4c5bd2ec25d67f38bcababec2eae4b4e0e5c7af0c8c87c91c52b9b999ec8605bfcd1481b3951eff7a9ef86574533760c4772cfb3297d7f853f462dc6bcc8566120a41bfada6990f09630cdf4f0c39d8516af6c422bf6922fa8f0426a30d17c3dadb6706fd4526047912216f509f953f5da8e15190664ea827e0b2277188286ebacf083c40a872739f19fd2302a8f5baa5102b4d905115c04f8f6f35b0e435b7ce1c07ee4c30bc3f996cb2a04bc784e54f61fe25bd5da6e073554285094162faca989d710c981b0f9c03151bb38ab5004e244a87bcf488d6c7693d6c8167b4204d0411f074c0b3f56bc4747f7247188036887d569cc66d2fc95e11d8d780c4e28ed11d0506cc3c23fea58049c82af3b1b0c3f7325430ea00b969eed9763aa2f3cc0629888afc2a71ff61520011a889cae8d2747c4996c2ca1ec0d48d7c5919d2151846f33f4a2551ae40790a2c33e4eff982e906ca6c51de8b6e1d1c0edc6439d68f0cda151650fb0671850bbf48d241c385c6eefc6b764614c3bd53dce5c3091723251171832c3523510f13433dcc59d8ab9734b7a2917185adba8fbe7c76a04d4030ccd916ec2f924a0a6e71c44bc871c04058708627de6b8a52464fb53fe1c6c95d350742f49f0c3e1b2e995d421829326b670faa28dbee613d1ab0e62c33f2f7f007c110e0e8e662719afeed49663d97026f6feae1e69da9a47b65244030fd790cda8e99a3d36fff92ee29fa74c5ac6c5853b816090670585bd72b3d1282407b4bd6f70197f1bfbad3112ce5c8a52e41ca2cd46d3a364f66f283ed4fe0ca23d10bb6bc254423dc65cfe534fbf5e3625969de8cf62a45252a79029c5062dd55dbc1224bf9f4bb97480d45255364cf4a884a5fe621f46312931ef5e9d122c0d7f61807c04f4b3dca8570eae96ec4c09ca6681b24a3445b9b09244b088636f8796728776e69b16754a642a134058c221b407abbb500f4999ae2cab59cc5587bf0c49f31456669c5d019011b0993bbf074686a616592782019100ed2e6184fae02f67224c38da07b26292007fad6138d4185dad0e71d5fbd511b3b0baa8d4b3d2f1b9226d61a3917e4c2ce7ea36605933f4b5f9d13a49fdc9fc5b6b7414041b5f2966041f38d3b4a36e9b7a78573ef3ddea2ef1ac19d16ae2ba6bf3f0e45113f987e98697ecadeaad3c3d1f4cb2221a4a644fcab98f76bb44676ca116a4b624bb22a3163912f46eb15c0407e0f3478b89937e98dfdad590d24cd24b58ccd4b0670d0952704c6e74c9c3415b9f3de9d8ffcd04a8fe55b0c226cd687a79f32d1ed753a3d915e94a1d34bb005022e10634c8817872f0eaa6867adb301acdd414a98cb02f93c2d8c373d9bf90ade2c76b9386ade9b0dce2216aa40163dd4a1aec040740ede1393848dfaed55c42c9cc7ccbe25366d411695565d60a85229ba0a5a581e31a22e9086b9b5aa98b51574e5d115baf559615d3bd9f97ff25be79b7e9222daac1c384b47c67b086f4778baeaa89cb963d7394e4d4c682985345f0368c513d652e0b4d9179bedeb262f65d8e177f1efc7e5c64fc85d7811fec91756b5d3536841666da39cc4e8f9ea6ebbb171d0b206c9b06b48bc08b8bc37fab7f4ec7f892607fb6a0f0d0700a5394eda1a3afc78fd5761535a7853119820bf4244e56a69f1222dd37fefcceb5c271744a2d42005185e7acd291c0b29ccd07818dc07b63f2989951588c3ee5de297266d98dbaea42c91671d5031bb26709300c2d83dcdc4aa949b9438d3fcf53dfa10f81206d42d57f2eeffcfafe604ce173a73c5f1008394a2a212d7e5e0fe0042f050d374f01c103b7c76fd1a9b895bef03b55da4cb424952cdf441955b2b3a0336304de5f5633df5dd5da24901e9cb440511712a1850602e6dfcc62b5cb35ab21b6718ba847460fad11461c131a1321f73eee4cf9f0152ec7a9e7166f8bd966241a43a3d8b25c89a27e2f74f996fbbad78efda269944781b08637be851c67c6b357d683ed78ffc96a202ee55c39fb35a0d4635e7dc22986c884f36467b9ec8d74f9a04c361e98784d55b08b7bba36cf861d0dee74346fdc94b073abd63a0ad76afcb40bb04707eb45804f90ab0537322f64eaf14e32f55b828a5cfbe42645db190ba6d84453b0a8f799c97e4ca3d18f96d2d27277d99b95941639c32be288c1e36f806a21c97b269cfa7cbc394fd1ff5c89f445dbac0f0a0e55570e1e70008da475cdc135228fc47c2e99cf8e2072f0841cf1e637df098d81630e762521090e6a9df0d6ef6242b3b6dfa8172f2463984b25884a56996243c7fccab4abe02bd421995cc5769052cd6bdedf9f88599a8ddc2599b1b58aaa726dbf4f13762eb775528174c9c6f923f461a376eee7be041840a0f7f006564eb342c082f43d7a0ec5e590671de9999c98fb3f461a214393304e8663d5f88a3a9ee08a1d294e59ae70736c2eb22a4bcfe1a7f95fb16351d2e7344d8eb1f011233b8fd4bf86230689924d7a801709c22145b902ab81b9ada62a329cb6e047cdedadbbf49fc068e828e18b1092c3167a9f72904b61a82ed04ce03c3adce3a49a53540c20202cad39a2cfa6a997a74a8c4bcf2070d5a264104013b640ce728bafb058caa6a3187508f095434bf2ae2ca19f235691d6e41b7759f52f35530a344a1dc78a2314aa1e2489d4bc7f1d3718daedcfc2a159026779914a2e3f18c788a4d912ed5938b8c09e480d8b786b52f834b953114530b45a8426ca0ee34f7b86b4d632e493075c77ad97e6bcbd4d2ecea1877f3efcc5eca07fbec99d5011146639a5df40fcabc644479f7ae007a9c7e4a28ad50994e20599ea41dac135f79ab1a3bef9eb72f89ae3510153add05b586ae6ba454a3ef4c49b3fed4b721ca95a03ecd97bb8a1aa9c06c5bb1dc611fe154b9b025fbb5e38c0ca15f7a60a239da453afb98c1c26664e0e213c67478ccacddb4e9f6b937a5c6741290a43f42a5e3eb8f29452718454bd5accf930e4eb667eedd8e4d8bd97a0f9cf16b3d3b60e2ce3c2f0f727e89c86ab4132268e4d299805d9b34fb6f4e2a3f8352c651bc0e756cd5fc1624bcbf1e86488883ea3c3f2324b967a5229f06904f38dbc82666e7ca873714122e83e2119678a88251fad85c5c80fb9c28b4cbfdf3ce38d810611790f8fa464d83339ba71f6fee8779ebb614d87c241dc08917660f98858e2a2416a5a3634ab208871c3a2870410a94fa84edf22bc1fc2abe2b3150c788cb054d68a9f95a9dc070cd42afe467417536b212f51a18f235c7aa0d7ccf8b74738deddf5c70ab86c952e9eb8eaa97ab3fa6503d458f55f5d3b288fad7f7338bdafc37a8bb0dc36a91fa876e82780c4ab88ef9a84b8da43a002836a692c05658062b2f478686a8472d8ac1e3e84bccdaac73cba284bb3ac8136b941e011c87dafb45bae4456d0984999f9326163778b39aae4395ad2981de85bea13654dddbf13c438c70557f8ad740a7849fe006607a95d318962a0ec20e1f920d273fff9fb08f2cf54f1728236396a9cbd004ea8dce921a2b845a8d38a9d6c745aef0caa6541d22f526876f7a2774cf7c4f9010ec90f7c1c3f20e9d7c13f779ca6f0570d41db0581f658695bf818f6115dfca137eac1410c7b0e6dc6a70cd3b152536605277eb5a747780d9b6faa2f9d779f2e41522a591c5b6936197689151c90c026ca71fe419a78198c9706ff460ca52e8e6154e4f2b13e4a87f48fdecc39df9e48afcedebe452d0c754caf44690337026d2543933496b80a863d3bf8933c6499a84660d00795edfd2f7733ee48feee517dfdf7b0e5f7ba04dc661388d83a4bf8988e425a8026709c9e0b393c40744fd5c013779213fcd1dc75f8127aecf1bf7a737d5f4ee1200f014181b1feeb279906a5b926d94bcf0185a012c30af359735be45adf2555554ca0fdd2ec3d7903be3c977f73c9654d6f981779150ac24e0efc3f3ac5e9336581db525dc103ebe5385c119c8c04068b03dc8c6aec421e2b86b4caac0034444d7e48f00079ca80c6aa3e7b39a96aa1beef4d5bf93ece7da0f3ed50627fd67c8f2afcab54e408e930d928dccdacacb26ea83948f11f9984a0b1847765c2bd91f9da6408a15bc184b330acdb6c659c99fef47842e8d0352babb017dda31b0e4e22b8849c0e2083e85fd10cb8165ccb4dfa7a98d08b4b347596f6e9c7226ce88a690b6ca2c75432dce8e6c6db06a460445df0ad51f6f09303f0cfd8cdcffe14343125d2321bd2cf5970f350d0b2bca6ac2956761e2de5bcaaeea3e54f68ed53ff200b7432c033ab512da5c47e929b8dca0cfeab0c657122450a36e215de2163bf14acb39c4287df86db6191131994259f187b50ed38be55a56d8db093b3310733b376d341f2f19e7186ff49fa805e04c3a5cac01e77883945a1ef98837431a7bc8f3e96438df6ba9ce90914600de04904be40675571402bcb5f7892b40316319f5ce1b79759b2c9e6d1ba2626548b4dd4ccbc519f6905afa063b594582c694a4591e24ce369583eb85d77ce88f171a91f3f58c5ff8c2e8fab60b870c4c739582d1fa5e8519644d2304556ee3b5c0a8730fef47bb8a5023a3054dc50139efec8b15ba4d4a2602ac30cecf15eaace1ccaa5f36c99814a027582af141a702678854dbf60d5e559c5c20caefd8ead7be81c6fef27143e486243cb766e62b200e1ac7188d9a6fe367770e451d8d8bd02443c641665b75626bdfb1db4614acf3f09fbd6d098f10e92299d8d17839082603f7aefc15ae08b1e816c746d77d198a953c253ca1a33d3b156b4e737a84fccb9596226297a7b7ca1746ad66ee07d7d0d693bf7c38471b29efb1a637c1184ceae6e370fad7ba7e0d5a1a570f4f8c5839ab962df487262332cece513df13a5f0644728197b2b7284307e3be50388fb9a78764066d655d999f7eccdf02359985435b80d325ef88bba6ba974ea87ed0109053b0d0161ef72a39b754b47bd3144990d13caad6714c4f5406757fb0925cfa2849f3412f2e76ce447566bda3e43607fef8ea205aa6c93e854d81519f53dd32fbc207acceeeab287129f8e3b7732deb7134f8f69cb1726c50004396ac2837f1d43176c8696b84bf1d1d2876e02428dac75091ee9352720d5934f63b484402f470468df97348ccbbd6a9088c3d2f67f8838a2f1e532d43b0f5c8e0b194a4116731b77ef2b127c7b7b3fcd20b0812442cbe5a63b6e738f99c571d19fec97f03cb5c68bbe3fdd04e204d2f027c3f6acf6b3091b8a080916c1a3a460c893ef6a9561fe62e558927ed07c1b1cacf87bd7abd91471c4d89b48e45928715db4577fbf83ad55624de2556674026b79f096ebdabcf85878981646b200fc6a9c4131e5cfbe2d3b55cc69bfb51aa32872a4b94c86f2bfedabd6f302e630cdc07d4f369b0692f1d650b105013e0715895a9d2418098248837f673575b98b35749dd57ef815512576987f743fdcb39674ae6ba2c4a8b6bbaa4a11a9c1028eb59a95659057929003989a28a51188ef1d9b5d8deab3d3572b28d4928807c356629901483e99d7b7603acaca9f153dfc81447c01e710daf352cf9cc4b00d0bb53cc2b284eabe8cd9bfd28c6c259527c31ad2dc7f38ad1636cb7d453f6c53bed3760691d2d37a73ff57a28cef5c6ee5db15d95fdaa9bd5a4b89d12dfdc045e1fe83b359f2b658a75d32a6033d245a085100678782bf4182fbbcc4bfe0ff65b0f0d51658a1864dce656b22de73a1a9c859ceb6b155e050b8a0807d4d34d19a1442d10e574622349e3e19f0ef9c28f26374459b127e27d3b4cffb843ece881c85da215dec877d4968b210f31e4225ce8bb156d2dfdf14ad92d821c3a0b813a57d052b8a682041a26f0875b300700a5e457c193f92db6a8b73c8bcd364456f8bb53529c954c99c31969ac369381c5b727dd9bd9a3ab5cee352a9b5ec02987d9492ab25848edcd18c4c78f93a45cd507a14f46de1f70b729e6de70532edc0a2fda3073c06602952d881f3cad2bf2f01d1cf42e5a84b53413d157be6c9e17c3feb6e408a3fac81985b5df97a0f0942801ff55fbbf1bfb10827bdaa78bd86eaa29ae87f31950938adb252351362d13e16616bf4b4464f9c3cf31d6ef37979106a1b9b03f50bee48101b392e77d108fdadd90a706db1e0a6441e5b54df975cef4d2607e87b4a830ad43621fb0cbcc1639ff744f32902f0a481a65b62ff67e2e35807864fc723604259048698fda9298312ccd0780786b2ff14de302120d13cb90b4ffde7fd8e56a0d934396d41a2fd3d83a52dda0eb000d7e2e67feda51f4e74f25476f274d7ff15eb3addedcb3901b2c8cb43fb2bbfcc5b6ce0819bb896c7a1eef67333717291472658f895e3a8cb3c2631df319b0abedb0aa17338fde1bf591dd4c0b84fefebc1622bc2c343da5954f67afe310c1ce6fe93905eb3d19d801828630d41eab23325840b23ddb999aeb624d56324d38293784690fe45d9ddf590e022e4657dc567b62977d1486fe18971835b622b166a3095779144ee1af88e2846c7bd97f755e868d9532165e0e9d6b274f8c74a5cdb72240e532fc253be90997937f670659d27b6f8a26b88db112af48a00839a850c3c8b05c786b9b8f2ac03921819a0fa3b484768ca9ca917c4a6b8464b23289b50d828fbe75ec09c50b2b3f0414202e3225ca8e2d2845f03e795dbdbd761af1d23c163c531e702bb82041089db2689685209df9f10e36f58eb686b576902046a4a5a9f768de402aecd64cd77b5076ce44be10562512a058151c8da9efecbbfebc8f0ac5432f17283923444bf185b84ae7236465a216c0d5a092c0f6eca044608aff2a777d0e9c3f6ef4591a0d951e5e9422d2bbec5610fa268a756fa7b927065173128cb9e3ebd6e9a2cf5492316e1f2c5186d33f56ecb590604c5a324af2112c56124fdce93a1b86c9d7c85c981fdf0c56d6adce87808dcf91118325165f43e1ef6a11d9649a7fcb5ac5f796e5fa0b0d31151cce42943270f920e5ca879f98f4945b225b104485561ea984210af086abdcd767d1206819c3ffeaf4e52f4cf931853d0b8fd331a07a448b10c53610d0e7e9fbc6f1b48d2d52c616d8a8354d4fc7f8e9b62461153003dc2735269efcfe7516d3f853eae0d1af022ade5c933be6c4dddc914058f2aba45a54854c8f7fbba4f37766a448eaa09878e85f95970141ab2201e9ecb89b45565eea116d49834f7dcc290473592fcd6400098752cb074c047ee2a0486e19dc24d8911df37503966afdf98d7c2d7fb9765315dd391d49e37364cc765d71e65770f9ad9ed8b1ea6b7c217859ba472e871190ec5aa96402dbd2dc7add6378d0a9fc99d4107e2ab881c824cc8bf86b3ee196bf3e8aee9f471b43711c79faae100b1c2d5818da3c459867a3ac97e4e8c6aaeec52cb20ec3857db8d308e1d7b903d1d01360aba200a9f19a7ab075558b07e5bb9ec7def6d861dd91b71f1b7d4f6955f3ae3c8e3ab67b5ddd0d25821972c6df2031d1871188f7bb4bbcaec720343f5d8c3a487aff096cfd6154504f146ca437445307819f2b995904e7c1883de27a98cef31e6dc1f24064bb539d698a1930223e9b5771c8b3a8f271b2a5f0150944d2ea44d32e0866eeb5099b3a46651a42a082b03bf98d554e1d40d9c857988ca7dc2c902ef101cfb93dc374c25e91dc3e5765e14384e36b943a22935e53d92121dd4004649c53fd2edcc0946e360aa32267137765849d38253cb8e4dce7fdb8cbaece08dcfcc27527be8b9eb1929dbab3dd1e1c6db5f21a245690e81bc20e4b30991b30ef268c4878e433466e5d7fb617b71c1774a994ec2f87210154cd2b521d21b0656d2b4c3842d58567ea3ee39556834ddbd4cf1c828447f6041d8fa7135cb619f77d499e7367e70e94ff08ed02c700fb766f0b030a4f57a18647b9f99074a8178914c2db202e647d9441a260e463e9bb39bd50b09e4bcb9c7ab9f23072a0d35e8d40d5112adea5747856beda9c88df4ed2321ee07973e1b23b3db1cbe88e0df91953099b8dd0b90f3421c533c2b79327a423cdd9333355b7d2996ab03c5255f8c9077c64c0f132be0e9f7bef0fb1ece497310f1f9640444e1d66f31827c344ab5e5e0a7d8af760b5d2067cd939b463e5b2ad877e08057742d7789ad67c730eb0b8c46cfdbbab231c79a023ebb98864ccdf549b91c906aaf2ac06c52d828d1785e752c7219830cfa24883a60701095da3309c681a2d3d8b0c56e9034bbff0979b57c9658f1091230a2b19a76a1c9a7c3343b72737dbe7dac500abbcb601d6ff859b9bc8ba2d2c139fe6da20a8b93eba86acd261026c7218f7ca4289760bdea5c0e4ee2f09c276bdd7e349f8178cdbd1b33a2f2f033f59e143548cfb247dca6ef5038fa692824e0dd61b020c7c8851f9e8a428c9b811cb3191e29347e0006047381255d09648a4b03812e0e1a9c0d023e316ce47fd699513de9b62ef894a243dfa8a2e7ffa03bae1a0cb2bdda742a2ed37455a10eeb2793abb4c85bd38d81097fb48bbd082f00c9a040997ce18bfad0e4e464326d72992ebe2d40fadea39599729d1d29fdee7bc89cb3ba1a66a93f1d8e137004c4aad1bc3f0d32bf961eb8f63563b34a165b461b1fe92ae81061c14336d394b09437c0c238320599b9d980cb7526f7c3d0b90fd598a99174757a8ef711f13f4a5d41bde176858bd4529c65bfa94209594bedb0ba91eef30e0b4c1b9374c3549c011d98c5cc8347e65d28dd0e37d1cb6d8d114aca966ac47d49e62995c5373b8dec52da89b7ff426b1e4c8129f7af3313daab11192a534845bd60d54e446a4316a930b3442d022a2a5394fd1ce14642187a8f010fb5983c49e8905ccc461713863e737d49dfccb5798ec41464491779291405bf5d880d388873f0f6df92a92662004e351efac73223a3aeabdbee1a1ad60d21724cda9e0061d3181307f91fc1deb69cf3f5af9a31116222c388dfd885c6f8c6a7bfc33e0a592bf2ee88336a412d3173d0eeda5ae685741715dcc2406b282f85c1b48c5c4d65d9f9ef87774a0eef000974f740601cdeb10268c372c32c6d2e6de12908c73e5901d310a46e627dcc2e275fd2028396852be7a20e1f3fa50b3ea73fd80cda8f037024bf42161923c35a3c0c23f5a96f8331d38f0a2597bd0fff0c098c28b874e2565772966c65fb2cc9abfb3a1a2bf2651cd845898b7eadb656f2ee5bb9474d1192bbfe14c6cef3633e1b1668df410d144823aac054c383ad2b9300be2fd902e3eccaa52d2d3f212b1624e3c3b66b4effcb985184d24dafd49fb6ddf8d98bdef53215cc395b0645f1dea6b5807182d585f2699ffa01fabd94de38b6e20730f1a1ce83a180651abe4af136075e471f1f15781769e7b8cda3975068e0f18cc0c9349e1603015c0524806f94ee62e3ab80ff9ec5938108aaeb610dc7659f0f37a88b538391b031603fbad44626e7057dc22939e6419c1a7dcdab85f1c356cd0d3d61a7a922038184fe9d4f24d154ad8d0b9b9f5bdce98e93c35739d9a87bb215b09ad957f0298c80c60209269ed021a0108a4d35dd67a1e3f70a99245b5ccf1097c1f6075fa58655486993981804be53a82a69790b98c78bebef5f09f86bf52c7abd22363ffac999c4b6df2e71489dbaab04b46b338e99fa2f0207530923a4302e5c30152818365bf49dc16aedb85ec29cf18c3950cc9511f99e7118807b6b7d6d41f65d4fbddc40a0e713da33dbc46b7e3f9fdaebb2b95b851d04701dcbb6a3e668758fc23ecbc8cf8153b253bdc072e1fe42f64ccc6d23b1df5daba0b27c6f7e2278b81da29c1fb501882fa97058956ca56d9f464ebbb3be08ceb66da4a17b7c85f0be1630d589217ded388c32eeb5b45cd65b401eaf0582a1ec2ba856df03c8872e1c6
  
    
      
      
        您好，这里需要密码.
      
    
  

]]></content>
      <categories>
        <category>isp</category>
      </categories>
      <tags>
        <tag>isp</tag>
        <tag>awb</tag>
        <tag>mywork</tag>
      </tags>
  </entry>
</search>
