<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.17lai.site</id>
    <title>夜法之书 • Posts by &#34;ai&#34; category</title>
    <link href="https://blog.17lai.site" />
    <updated>2021-09-14T04:25:00.000Z</updated>
    <category term="Github" />
    <category term="Jekyll" />
    <category term="blog" />
    <category term="Gitlab" />
    <category term="Git" />
    <category term="Crack" />
    <category term="Linux" />
    <category term="hardlink" />
    <category term="bt" />
    <category term="pt" />
    <category term="note" />
    <category term="markdown" />
    <category term="picgo" />
    <category term="wiz" />
    <category term="Joplin" />
    <category term="Typora" />
    <category term="QNAP" />
    <category term="硬盘" />
    <category term="nas" />
    <category term="embeded" />
    <category term="3G" />
    <category term="4G" />
    <category term="3531a" />
    <category term="移植" />
    <category term="嵌入式" />
    <category term="hisilicon" />
    <category term="Driver" />
    <category term="3798M" />
    <category term="MPP" />
    <category term="UNF" />
    <category term="Kernel" />
    <category term="宝塔" />
    <category term="VPS" />
    <category term="建站" />
    <category term="Nginx" />
    <category term="Apache" />
    <category term="MySQL" />
    <category term="Docker" />
    <category term="LAMP" />
    <category term="PHP" />
    <category term="Tomcat" />
    <category term="JSP" />
    <category term="教程" />
    <category term="Rigistry" />
    <category term="email" />
    <category term="https" />
    <category term="ssl" />
    <category term="Debian" />
    <category term="Laptop" />
    <category term="ED2K" />
    <category term="ATI" />
    <category term="WIFI" />
    <category term="Hotkey" />
    <category term="SSD" />
    <category term="HDD" />
    <category term="管理" />
    <category term="PDCA" />
    <category term="5W2H" />
    <category term="SMART" />
    <category term="SWOT" />
    <category term="GROW" />
    <category term="OKR" />
    <category term="WBS" />
    <category term="PT" />
    <category term="BT" />
    <category term="qbittorrent" />
    <category term="transmission" />
    <category term="Emby" />
    <category term="Sonarr" />
    <category term="Jeckett" />
    <category term="Portainer" />
    <category term="Watchtower" />
    <category term="DNSMasq" />
    <category term="DNSCrypt" />
    <category term="启动" />
    <category term="优化" />
    <category term="SSL" />
    <category term="TLS" />
    <category term="隐私" />
    <category term="安全" />
    <category term="linux" />
    <category term="GitBook" />
    <category term="MySql" />
    <category term="Mariadb" />
    <category term="技巧" />
    <category term="MarkDown" />
    <category term="Mermaid" />
    <category term="Nas" />
    <category term="群晖" />
    <category term="web" />
    <category term="http" />
    <category term="css" />
    <category term="js" />
    <category term="3a" />
    <category term="ae" />
    <category term="image" />
    <category term="ccs" />
    <category term="vim" />
    <category term="ide" />
    <category term="docker" />
    <category term="ai" />
    <category term="face" />
    <category term="music" />
    <category term="韩红" />
    <category term="hexo" />
    <category term="matery" />
    <category term="cdn" />
    <category term="seo" />
    <category term="thinkpad" />
    <category term="sound" />
    <category term="speaker" />
    <category term="刮削" />
    <category term="MusicBrainz" />
    <category term="mp3tag" />
    <category term="tmm" />
    <category term="字幕" />
    <category term="emby" />
    <category term="plex" />
    <category term="qnap" />
    <category term="ipv6" />
    <category term="cmake" />
    <category term="develop" />
    <category term="traefik" />
    <category term="proxy" />
    <category term="swarm" />
    <category term="ubuntu" />
    <category term="vscode" />
    <category term="插件" />
    <category term="编码" />
    <category term="mermaid" />
    <category term="plantuml" />
    <category term="mathjax" />
    <category term="CI/CD" />
    <category term="Earthly" />
    <category term="git" />
    <category term="mstream" />
    <category term="selfhost" />
    <category term="中岛美嘉" />
    <category term="node" />
    <category term="jenkins" />
    <category term="tools" />
    <category term="winrar" />
    <category term="crack" />
    <category term="emoji" />
    <category term="shell" />
    <category term="isp" />
    <category term="awb" />
    <category term="mywork" />
    <entry>
        <id>https://blog.17lai.site/posts/a0f3c838/</id>
        <title>深度学习之视频人脸识别系列</title>
        <link rel="alternate" href="https://blog.17lai.site/posts/a0f3c838/"/>
        <content type="html">&lt;link rel=&#34;stylesheet&#34; class=&#34;aplayer-secondary-style-marker&#34; href=&#34;/assets/css/APlayer.min.css&#34;&gt;&lt;script src=&#34;/assets/js/APlayer.min.js&#34; class=&#34;aplayer-secondary-script-marker&#34;&gt;&lt;/script&gt;&lt;h2 id=&#34;系列1-简介&#34;&gt;系列 1 简介&lt;/h2&gt;
&lt;p&gt;出品 | 磐创 AI 技术团队&lt;/p&gt;
&lt;p&gt;【磐创 AI 导读】本文是深度学习之视频&lt;a target=&#34;_blank&#34; rel=&#34;noopener&#34; href=&#34;https://cloud.tencent.com/product/facerecognition?from=10680&#34;&gt;人脸识别&lt;/a&gt;系列的第一篇文章，介绍了人脸识别领域的一些基本概念，分析了深度学习在人脸识别的基本流程，并总结了近年来科研领域的研究进展，最后分析了静态数据与视频动态数据在人脸识别技术上的差异。欢迎大家点击上方篮子关注我们的公众号：磐创 AI。&lt;/p&gt;
&lt;h2 id=&#34;一、基本概念&#34;&gt;&lt;strong&gt;一、基本概念&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;1-人脸识别（face-identification）&#34;&gt;&lt;strong&gt;1. 人脸识别（face identification）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;人脸识别是 1 对 n 的比对，给定一张人脸图片，如何在 n 张人脸图片中找到同一张人脸图片，相对于一个分类问题，将一张人脸划分到 n 张人脸中的一张。类似于管理人员进行的人脸识别门禁系统。&lt;/p&gt;
&lt;h3 id=&#34;2-人脸验证（face-verification）&#34;&gt;&lt;strong&gt;2. 人脸验证（face verification）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;人脸验证的 1 对 1 的比对，给定两张人脸图片，判断这两张人脸是否为同一人，类似于手机的人脸解锁系统，事先在手机在录入自己的脸部信息，然后在开锁时比对摄像头捕捉到的人脸是否与手机上录入的人脸为同一个人。&lt;/p&gt;
&lt;h3 id=&#34;3-人脸检测（face-detection）&#34;&gt;&lt;strong&gt;3. 人脸检测（face detection）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;人脸检测是在一张图片中把人脸检测出来，即在图片上把人脸用矩形框出来，并得到矩形的坐标，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140027.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;4-人脸关键点检测&#34;&gt;&lt;strong&gt;4. 人脸关键点检测&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;根据输入的人脸图像，识别出面部关键特征点，如眼睛、鼻尖、嘴角点、眉毛以及人脸各部件轮廓点的坐标，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140105.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;5-人脸矫正（人脸对齐）&#34;&gt;&lt;strong&gt;5. 人脸矫正（人脸对齐）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;通过人脸关键点检测得到人脸的关键点坐标，然后根据人脸的关键点坐标调整人脸的角度，使人脸对齐，由于输入图像的尺寸是大小不一的，人脸区域大小也不相同，角度不一样，所以要通过坐标变换，对人脸图像进行归一化操作，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140120.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;二、基于深度学习的人脸识别算法基本流程&#34;&gt;&lt;strong&gt;二、基于深度学习的人脸识别算法基本流程&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;随着神经网络的迅速发展和其对图像数据的强大的特征提取，深度学习运用于人脸识别也成为热点研究方向；2014 年的开山之作 DeepFace，第一个真正将&lt;a target=&#34;_blank&#34; rel=&#34;noopener&#34; href=&#34;https://cloud.tencent.com/solution/bigdata?from=10680&#34;&gt;大数据&lt;/a&gt;和深度学习结合应用于人脸识别与验证，确立人脸识别的常规流程：图片 -&amp;gt; 人脸与关键点检测 -&amp;gt; 人脸对齐 -&amp;gt; 人脸表征（representation）-&amp;gt; 分类。首先将图片中的人脸检测处理并通过关键点进行对齐，如何输入到神经网络，得到特征向量，通过分类训练过程，该向量即为人脸的特征向量。要求出两张人脸的相似度即计算两个特征的向量度量之差，方法包括：SVM、SiameseNetwork、JointBayesian、L1 距离、L2 距离、cos 距离等。&lt;/p&gt;
&lt;h2 id=&#34;三、科研领域近期进展&#34;&gt;&lt;strong&gt;三、科研领域近期进展&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;科研领域近期进展主要集中于 loss 函数的研究，包括 DeepId2（Contrastive Loss）、FaceNet（Triplet loss）、L-Softmax、SphereFace（A-Softmax）、Center Loss、L2-Softmax、NormFace、CosFace（AM-Softmax）、ArcFace（AA-Softmax）等。&lt;/p&gt;
&lt;h2 id=&#34;四、基于视频人脸识别和图片人脸识别的区别&#34;&gt;&lt;strong&gt;四、基于视频人脸识别和图片人脸识别的区别&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;（&lt;em&gt;该小结部分参考于博客园 - 米罗西 http://www.cnblogs.com/zhehan54/p/6727631.html&lt;/em&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;相对于图片数据，目前视频人脸识别有很多挑战，包括：（1）视频数据一般为户外，视频图像质量比较差；（2）人脸图像比较小且模糊；（3）视频人脸识别对实时性要求更高。&lt;/p&gt;
&lt;p&gt;但是视频数据也有一些优越性，视频数据同时具有空间信息和时间信息，在时间和空间的联合空间中描述人脸和识别人脸会具有一定提升空间。在视频数据中人脸跟踪是一个提高识别的方法，首先检测出人脸，然后跟踪人脸特征随时间的变化。当捕捉到一帧比较好的图像时，再使用图片人脸识别算法进行识别。这类方法中跟踪和识别是单独进行的，时间信息只在跟踪阶段用到。&lt;/p&gt;
&lt;p&gt;【总结】：本期文章主要介绍了基于深度学习的人脸识别算法的一些基本入门知识，下一期我给大家介绍人脸识别中获取神经网络输入的算法，即关于人脸检测、人脸关键点检测与人脸对齐的一些重要算法和相关论文解析。&lt;/p&gt;
&lt;h2 id=&#34;系列2-人脸检测与对齐&#34;&gt;系列 2 人脸检测与对齐&lt;/h2&gt;
&lt;h2 id=&#34;一、人脸检测与关键点检测&#34;&gt;&lt;strong&gt;一、人脸检测与关键点检测&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;1-问题描述：&#34;&gt;&lt;strong&gt;1. 问题描述：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;人脸检测解决的问题为给定一张图片，输出图片中人脸的位置，即使用方框框住人脸，输出方框的左上角坐标和右下角坐标或者左上角坐标和长宽。算法难点包括：人脸大小差异、人脸遮挡、图片模糊、角度与姿态差异、表情差异等。而关键检测则是输出人脸关键点的坐标，如左眼（x1，y1）、右眼（x2，y2）、鼻子（x3，y3）、嘴巴左上角（x4，y4）、嘴巴右上角（x5，y5）等。&lt;/p&gt;
&lt;h3 id=&#34;2-深度学习相关算法：&#34;&gt;&lt;strong&gt;2. 深度学习相关算法：&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;（1）Cascade-CNN&#34;&gt;&lt;strong&gt;（1）Cascade CNN&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Cascade CNN 源于发表于 2015 年 CVPR 上的一篇论文 A Convolutional Neural Network Cascade for Face Detection【2】，作者提出了一种级连的 CNN 网络结构用于人脸检测。算法主体框架是基于 V-J 的瀑布流思想【1】，是传统技术和深度网络相结合的一个代表，Cascade CNN 包含了多个分类器，这些分类器使用级联结构进行组织，与 V-J 不同的地方在于 Cascade CNN 采用卷积网络作为每一级的分类器。整个网络的处理流程如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140330.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;整个处理流程里包含了六个网络：12-net、12-calibration-net、24-net、24-calibration-net、48-net、48-calibration-net，其中三个二分类网络用于分类其是否为人脸，另外三个 calibration 网络用于矫正人脸框边界。其中第二个网络之后、第四个网络之后、第五个网络之后使用 NMS 算法过滤掉冗余的框。&lt;/p&gt;
&lt;p&gt;12-net，24-net 和 48-net 的网络结构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140401.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;13-12-calibration-net，24-calibration-net，48-calibration-net 的结构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140426.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;该算法结合了 V-J 框架构造了级连的 CNN 网络结构并设计边界矫正网络用来专门矫正人脸框边界，在 AFW 数据集上准确率达到 97.97%。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140457.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;（2）Faceness-Net&#34;&gt;&lt;strong&gt;（2）Faceness-Net&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Faceness-Net 源于论文 A convolutional neural network cascade for face detection【3】，该算法基于 DCNN 网络【5】的人脸局部特征分类器，算法首先进行人脸局部特征的检测，使用多个基于 DCNN 网络的 facial parts 分类器对人脸进行评估，然后根据每个部件的得分进行规则分析得到 Proposal 的人脸区域，然后从局部到整体得到人脸候选区域，再对人脸候选区域进行&lt;a target=&#34;_blank&#34; rel=&#34;noopener&#34; href=&#34;https://cloud.tencent.com/product/facerecognition?from=10680&#34;&gt;人脸识别&lt;/a&gt;和矩形框坐标回归，该过程分为两个步骤。&lt;/p&gt;
&lt;p&gt;第一个步骤：每个人脸局部特征使用 attribute-aware 网络检测并生成人脸局部图，其中一共五个特征属性： 头发、眼睛、鼻子、嘴巴、胡子。然后通过人脸局部图根据评分构建人脸候选区域，具体如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140529.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第二个步骤：训练一个多任务的卷积网络来完成人脸二分类和矩形框坐标回归，进一步提升其效果，具体如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140548.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Faceness 从脸部特征的角度来解决人脸检测中的遮挡和姿态角度问题，其整体性能在当时是非常好的，在 AFW 数据集上准确率可以达到 98.05%。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140611.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;（3）MTCNN&#34;&gt;&lt;strong&gt;（3）MTCNN&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;MTCNN 源于论文 Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks【6】，是基于多任务级联卷积神经网络来解决人脸检测和对齐问题，同时输出图片的人脸矩阵框和关键点坐标（左眼、右眼、鼻子、嘴巴左上角、嘴巴右上角）。MTCNN 为三阶的级联卷积神经网络，整体框架如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140644.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;输入阶段：为应对目标多尺度问题，将原始图像 resize 到不同尺寸，构建图像金字塔，作为三阶级联架构的输入，这样处理可以更好地检测大小不一的人脸。&lt;/p&gt;
&lt;p&gt;第一阶段：通过一个全部由卷积层组成的 CNN，取名 P-Net，获取候选人脸框、关键点坐标和人脸分类（是人脸或不是），之后采用 NMS 过滤掉高重叠率的候选窗口。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140717.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第二阶段：第一阶段输出的候选人脸框作为更为复杂的 R-Net 网络的输入，R-Net 进一步筛除大量错误的候选人脸框，同样也通过 NMS 过滤掉高重叠率的候选窗口。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140741.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第三阶段：与第二阶段类似，最终网络输出人脸框坐标、关键点坐标和人脸分类（是人脸或不是）。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140801.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;MTCNN 通过三级的级联卷积神经网络对任务进行从粗到细的处理，还提出在线困难样本生成策略（online hard sample mining ）可以进一步提升性能。兼并了速度与准确率，速度在 &lt;a target=&#34;_blank&#34; rel=&#34;noopener&#34; href=&#34;https://cloud.tencent.com/product/gpu?from=10680&#34;&gt;GPU&lt;/a&gt; 上可以达到 99FPS，在 FDDB 数据集上可以达到 95.04 准确率，具体如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140818.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;二、人脸对齐（部分参考于GraceDD的博客文章）&#34;&gt;&lt;strong&gt;二、人脸对齐（部分参考于 GraceDD 的博客文章）&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;人脸对齐通过人脸关键点检测得到人脸的关键点坐标，然后根据人脸的关键点坐标调整人脸的角度，使人脸对齐，由于输入图像的尺寸是大小不一的，人脸区域大小也不相同，角度不一样，所以要通过坐标变换，对人脸图像进行归一化操作。人脸关键点检测有很多算法可以使用包括：ASM、AAM、DCNN 、TCDCN 、MTCNN 、TCNN、TCNN 等，这里就不详细介绍，主要说一下得到人脸关键点之后如何进行人脸对齐，是所有人脸达到归一化效果，该过程如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140841.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;该过程涉及到图像的仿射变换，简单来说，“仿射变换” 就是：“线性变换”+“平移”，即坐标的变换。假如我们希望人脸图片归一化为尺寸大小 600&lt;em&gt;600，左眼位置在（180，200），右眼位置在（420，200）。 这样人脸中心在图像高度的 1/3 位置，并且两个眼睛保持水平，所以我们选择左眼角位置为 ( 0.3&lt;/em&gt;width, height / 3 )，右眼角位置为（0.7*width , height / 3） 。&lt;/p&gt;
&lt;p&gt;利用这两个点计算图像的变换矩阵（similarity transform），该矩阵是一个 2*3 的矩阵，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果我们想对一个矩形进行变换，其中 x、y 方向的缩放因为分别为 sx，sy，同时旋转一个角度 ，然后再在 x 方向平移 tx, 在 y 方向平移 ty&lt;/p&gt;
&lt;p&gt;利用 opencv 的 estimateRigidTransform 方法，可以获得这样的变换矩阵，但遗憾的是，estimateRigidTransform 至少需要三个点，所以我们需要构选第三个点，构造方法是用第三个点与已有的两个点构成等边三角形，这样第三个点的坐标为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140918.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;代码如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914140938.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;经过上一步的处理之后，所有的图像都变成一样大小，并且又三个关键点的位置是保持一致的，但因为除了三个点对齐了之外，其他点并没有对齐。所以根据得到的变换矩阵对剩下所有的点进行仿射变换，opencv 代码如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914141001.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;img 为输入图像；&lt;/p&gt;
&lt;p&gt;warped 为变换后图像，类型与 src 一致；&lt;/p&gt;
&lt;p&gt;M 为变换矩阵，需要通过其它函数获得，当然也可以手动输入；&lt;/p&gt;
&lt;p&gt;Image_size 为输出图像的大小；&lt;/p&gt;
&lt;h2 id=&#34;三、-总结&#34;&gt;&lt;strong&gt;三、 总结&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;本期文章主要介绍了人脸检测与对齐的相关算法，下一期我给大家介绍一下人脸表征的相关算法，即通过深度学习提取人脸特征，通过比较人脸特征进行人脸识别与验证。&lt;/p&gt;
&lt;h3 id=&#34;参考文献：-2&#34;&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;【1】 S.Z.Li, L.Zhu, Z.Q.Zhang, A.Blake, H.J.Zhang, H.Y.Shum. Statistical learning of multi-view face detection. In: Proceedings of the 7-th European Conference on Computer Vision. Copenhagen, Denmark: Springer, 2002.67-81.&lt;/li&gt;
&lt;li&gt;【2】Li H, Lin Z, Shen X, et al. A convolutional neural network cascade for face detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 5325-5334.&lt;/li&gt;
&lt;li&gt;【3】Yang S, Luo P, Loy C C, et al. Faceness-Net: Face detection through deep facial part responses[J]. IEEE transactions on pattern analysis and machine intelligence, 2017.&lt;/li&gt;
&lt;li&gt;【4】Yang S, Luo P, Loy C C, et al. From facial parts responses to face detection: A deep learning approach[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 3676-3684.&lt;/li&gt;
&lt;li&gt;【5】Sun Y, Wang X, Tang X. Deep convolutional network cascade for facial point detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2013: 3476-3483.&lt;/li&gt;
&lt;li&gt;【6】Zhang K, Zhang Z, Li Z, et al. Joint face detection and alignment using multitask cascaded convolutional networks[J]. IEEE Signal Processing Letters, 2016, 23(10): 1499-1503.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系列3：人脸表征&#34;&gt;系列 3：人脸表征&lt;/h2&gt;
&lt;h2 id=&#34;一、人脸表征&#34;&gt;&lt;strong&gt;一、人脸表征&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;把人脸图像通过神经网络，得到一个特定维数的特征向量，该向量可以很好地表征人脸数据，使得不同人脸的两个特征向量距离尽可能大，同一张人脸的两个特征向量尽可能小，这样就可以通过特征向量来进行人脸识别。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914141235.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;二、论文综述&#34;&gt;&lt;strong&gt;二、论文综述&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;1-DeepFace：&#34;&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;DeepFace：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;2014 年论文 DeepFace: Closing the Gap toHuman-Level Performance in Face Verification 提出了 DeepFace 算法，第一个真正将&lt;a target=&#34;_blank&#34; rel=&#34;noopener&#34; href=&#34;https://cloud.tencent.com/solution/bigdata?from=10680&#34;&gt;大数据&lt;/a&gt;和深度学习神经网络结合应用于人脸识别与验证。在该人脸识别模型中分为四个阶段：人脸检测 =&amp;gt; 人脸对齐 =&amp;gt; 人脸表征 =&amp;gt; 人脸分类，在 LFW 数据集中可以达到 97.00% 的准确率。&lt;/p&gt;
&lt;p&gt;（1）人脸检测与对齐：该模型使用 3D 模型来将人脸对齐，该方法过于繁琐，在实际应用中很少使用，经过 3D 对齐以后，形成的图像都是 152×152 的图像，具体步骤如下图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;分为如下几步：&lt;/p&gt;
&lt;p&gt;a. 人脸检测，使用 6 个基点  b. 二维剪切，将人脸部分裁剪出来  c. 67 个基点，然后 Delaunay 三角化，在轮廓处添加三角形来避免不连续  d. 将三角化后的人脸转换成 3D 形状  e. 三角化后的人脸变为有深度的 3D 三角网  f. 将三角网做偏转，使人脸的正面朝前。  g. 最后放正的人脸  h. 一个新角度的人脸（在论文中没有用到）&lt;/p&gt;
&lt;p&gt;（2）人脸表征：人脸表征使用了 5 个卷积层和 1 个最大池化层、1 个全连接层，如下图所示。前三层的目的在于提取低层次的特征，为了网络保留更多图像信息只使用了一层池化层；后面三层都是使用参数不共享的卷积核，因为主要是因为人脸不同的区域的特征是不一样的，具有很大的区分性，比如鼻子和眼睛所表示的特征是不一样的，但是使用参数不共享的卷积核也增加了模型计算量以及需要更多的训练数据。最后输出的 4096 维向量进行 L2 归一化。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914141316.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;a. Conv：32 个 11×11×3 的卷积核&lt;/p&gt;
&lt;p&gt;b. max-pooling: 3×3， stride=2&lt;/p&gt;
&lt;p&gt;c. Conv: 16 个 9×9 的卷积核&lt;/p&gt;
&lt;p&gt;d. Local-Conv: 16 个 9×9 的卷积核，Local 的意思是卷积核的参数不共享&lt;/p&gt;
&lt;p&gt;e. Local-Conv: 16 个 7×7 的卷积核，参数不共享&lt;/p&gt;
&lt;p&gt;f. Local-Conv: 16 个 5×5 的卷积核，参数不共享&lt;/p&gt;
&lt;p&gt;g. Fully-connected: 4096 维&lt;/p&gt;
&lt;p&gt;h. Softmax: 4030 维&lt;/p&gt;
&lt;p&gt;（3）分类：论文介绍了两种方法进行分类，加权的卡方距离和使用 Siamese 网络结构，设 f1 和 f2 为特征向量，上一个步骤的输出，则有：&lt;/p&gt;
&lt;p&gt;①加权卡方距离：计算公式如下，加权参数由线性 SVM 计算得到：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;②Siamese 网络：网络结构是成对进行训练，得到的特征表示再使用如下公式进行计算距离：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-DeepID1：&#34;&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;DeepID1：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;DeepID1 是 2014 年 Deep LearningFace Representation from Predicting 10,000 Classes 一文提出的，是 DeepID 三部曲的第一篇。DeepID1 使用 softmax 多分类训练，主要思想第一个是数据集的增大，包括训练集使用 celebface，包含 87628 张图片，5436 个人脸，增大了训练集；使用多尺寸输入，通过 5 个 landmarks 将每张人脸划分成 10regions，每张图片提取 60patches=10regions&lt;em&gt;3scales&lt;/em&gt;2 (RGB orgray)，第二个是网络结构，DeepID 提取的人脸特征就是一个由连接第三层与第四层组成的全连接层特征，如下图所示，每个 patches 经过这个 cnn 网络，第四层的特征更加全局化（global），第三层的特征更加细节，因此 DeepID 连接了两者，以求同时包含全局，细节信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;60 个 patches 使用 60 个 CNN, 每个 CNN 提取 2*160=320 维特征（与水平翻转一起输入），总网络模型如下图所示，最后分别使用联合贝叶斯算法与神经网络进行分类，并比较结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;模型最终以 CelebFaces + 中 202,599 图像作为训练集， patch 数提升为 100（10r&lt;em&gt;10s&lt;/em&gt;2） ，特征数提升为 100&lt;em&gt;160&lt;/em&gt;2=32000 然后使用 PCA 降为 150 维 ，使用联合贝叶斯算法进行验证， 最终在 LFW 上达到 97.20% 的验证准确率。&lt;/p&gt;
&lt;h3 id=&#34;3-DeepID2：&#34;&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;DeepID2：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;DeepID2 是 Deep Learning Face Representationby Joint Identification-Verification 一文提出的，对 DeepID1 进行了进一步的改进，提出了 contrastive loss，在分类任务，我们需要的是减少类内差距（同一人脸），增加类间差距（不同人脸），softmax loss 分类的监督信号可以增大类间差距，但是却对类内差距影响不大，所以 DeepID2 加入了另一个 loss，contrastive loss，从而增加验证的监督信号，就可以减少类内差距。&lt;/p&gt;
&lt;p&gt;网络结构类似 DeepID1, 不同之处在于使用了两种不同的损失函数，网络结构如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;损失函数：&lt;/p&gt;
&lt;p&gt;①分类信号，Softmax loss。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;②验证信号，contrastiveloss，使用 l2 范数距离表示，m 为阈值不参与训练，括号内的 θve={m}，该损失函数可以让类间的距离给定一个限制 margin，即 m 大小的距离。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-8.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;两 loss 的组合方式： 首先使用 2 个输入，计算 Softmax loss 和 contrastive loss, 总损失为二者通过 λ 加权求和，通过总损失来执行梯度下降更新卷积参数，通过 Softmax loss 来更新 softmax 层的参数。&lt;/p&gt;
&lt;p&gt;整个模型使用 celebrate + 数据集训练，每张图片使用了 21 facial landmarks，分成 200patches（20regions&lt;em&gt;5scales&lt;/em&gt;2RGB&amp;amp;Gray)，水平翻转后变为 400patches，使用了 200 个卷积神经网络，提取 400（200&lt;em&gt;2）个 Deepid2 特征，使用贪婪算法降为 25 个 Deepid2 特征，使用 PCA 将 25&lt;/em&gt;160Deepid2 特征降为 180 维，最后使用联合贝叶斯算法进行验证，最终在 LFW 上得到的最终准确率是 98.97%，使用 7 组 25 个 Deepid2 特征，SVM 融合可得到准确率为 99.15% 。DeepID2 在 2014 年是人脸领域非常有影响力的工作，也掀起了在人脸领域引进 MetricLearning 的浪潮。&lt;/p&gt;
&lt;h3 id=&#34;4-DeepID2-：&#34;&gt;&lt;strong&gt;4.&lt;/strong&gt; &lt;strong&gt;DeepID2+：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;DeepID2 + 源于论文 Deeply learned facerepresentations are sparse, selective, and robust，DeepID2 + 是对 DeepID2 的改进。①卷积层在原来基础上再增加 128 维，第四层全连接层从 160 增加到 512，训练数据增加了 CelebFaces+ dataset，WDRef 等，有 12000 个人脸的大约 290,000 张图片； ②每个卷积层的后面都加了一个 512 为的全连接层，并添加 contrastive loss 监督信号，而不仅在第四层全连接层上有 。网络结构如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-10.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;最终在 LFW 数据集上准确率为 99.47%。&lt;/p&gt;
&lt;h3 id=&#34;5-DeepID3：&#34;&gt;&lt;strong&gt;5.&lt;/strong&gt; &lt;strong&gt;DeepID3：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;DeepID3 源于 2015 年的 Deepid3:Face recognition with very deep neural networks 论文，该论文探究了复杂神经网络对人脸识别的作用。论文研究 VGG 与 GoogleNet 用于人脸识别的效果，论文在 VGG 和 GooLeNet 的基础上进行构建合适的结构，使得方便人脸识别。结果发现 DeepID3 的结果和 DeepID2 + 相当，可能是由于数据集的瓶颈，需要更大的数据才能有更好的提升，两个网络结构如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-11.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;网络输出使用 PCA 降维到 300 维的向量，使用联合贝叶斯算法进行验证，最终在 LFW 上得到的最终准确率是 99.53%。&lt;/p&gt;
&lt;h3 id=&#34;6-FaceNet：&#34;&gt;&lt;strong&gt;6.&lt;/strong&gt; &lt;strong&gt;FaceNet：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;FaceNet 由论文 Facenet: A unified embedding forface recognition and clustering 提出，这篇 2015 年来自 Google 的 论文同样具有非常大的影响力，不仅仅成功应用了 TripletLoss 在 benchmark 上取得 state-of-art 的结果，更因为他们提出了一个绝大部分人脸问题的统一解决框架，即：识别、验证、搜索等问题都可以放到特征空间里做，需要专注解决的仅仅是如何将人脸更好的映射到特征空间。FaceNet 在 DeepID 的基础上，将 ContrastiveLoss 改进为 Triplet Loss，去掉 softmaxloss。FaceNet 实验了 ZFNet 类型网络和 Inception 类型网络，最终 Inception 类型网络效果更好，网络结构如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-12.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;FaceNet 没有使用 PCA 降维，而是在网络中直接训练输出 128 维的向量，用全连接层来完成降维，最后的 128 维的向量经过 Triplet Loss。&lt;/p&gt;
&lt;p&gt;Triplet Loss 输入不再是 Image Pair，而是三张图片（Triplet），分别为 Anchor Face（xa），Negative Face（xn）和 Positive Face（xp）。Anchor 与 Positive Face 为同一人，与 Negative Face 为不同人，在特征空间里 Anchor 与 Positive 的距离要小于 Anchor 与 Negative 的距离，且相差超过一个 Margin Alpha。&lt;/p&gt;
&lt;p&gt;loss 的目标为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-13.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;总 loss 公式为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-14.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Contrastive Loss 与 Triplet Loss 的比较， Contrastive Loss 目标是减少类内差距（两个蓝点），增加类间差距（蓝点与红点）；Triplet Loss 则是输入三张图片，Anchor 与 Positive 的距离要小于 Anchor 与 Negative 的距离，且相差超过一个 Margin Alpha，即 Triplet Loss 同时约束了两个距离。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-15.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;最后 FaceNet 在 LFW 数据集上达到了 99.63% 的准确率。&lt;/p&gt;
&lt;p&gt;基于 ContrastiveLoss 和 Triplet Loss 的 MetricLearning 符合人的认知规律，在实际应用中也取得了不错的效果，但同时也有很多问题，由于 ContrastiveLoss 和 Triplet Loss 的训练样本都基于 pair 或者 triplet 的，可能的样本数是 O (N2) 或者 O (N3) 的，所以模型需要很久的计算才能拟合并且训练集需要足够大。&lt;/p&gt;
&lt;h2 id=&#34;三、总结&#34;&gt;&lt;strong&gt;三、总结&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;本期文章主要介绍人脸表征相关算法和论文综述，主要是 2014 年到 2016 年的研究成果， ContrastiveLoss 和 Triplet Loss 在实际应用中也取得了很好的效果，但是也有很多问题，由于 Contrastive Loss 和 Triplet Loss 的训练样本都基于 pair 或者 triplet 的，可能的样本数是 O (N2) 或者 O (N3) 的，所以模型需要很久的计算才能拟合并且训练集要足够大，所以在之后的人脸识别研究中，大部分在于 loss 函数的研究，这部分将会在下一期给大家介绍。&lt;/p&gt;
&lt;h3 id=&#34;参考文献：-3&#34;&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;【1】 Taigman Y, Yang M, Ranzato M A, et al.Deepface: Closing the gap to human-level performance in faceverification[C]//Proceedings of the IEEE conference on computer vision andpattern recognition. 2014: 1701-1708.&lt;/li&gt;
&lt;li&gt;【2】Sun Y, Wang X, Tang X. Deep learning facerepresentation from predicting 10,000 classes[C]//Proceedings of the IEEEconference on computer vision and pattern recognition. 2014: 1891-1898.&lt;/li&gt;
&lt;li&gt;【3】Sun Y, Chen Y, Wang X, et al. Deeplearning face representation by joint identification-verification[C]//Advancesin neural information processing systems. 2014: 1988-1996.&lt;/li&gt;
&lt;li&gt;【4】Sun Y, Liang D, Wang X, et al. Deepid3:Face recognition with very deep neural networks[J]. arXiv preprintarXiv:1502.00873, 2015.&lt;/li&gt;
&lt;li&gt;【5】Simonyan K, Zisserman A. Very deepconvolutional networks for large-scale image recognition[J]. arXiv preprintarXiv:1409.1556, 2014.&lt;/li&gt;
&lt;li&gt;【6】Szegedy C, Liu W, Jia Y, et al. Goingdeeper with convolutions[C]//Proceedings of the IEEE conference on computervision and pattern recognition. 2015: 1-9.&lt;/li&gt;
&lt;li&gt;【7】Sun Y, Wang X, Tang X. Deeply learned facerepresentations are sparse, selective, and robust[C]//Proceedings of the IEEEconference on computer vision and pattern recognition. 2015: 2892-2900.&lt;/li&gt;
&lt;li&gt;【8】Schroff F, Kalenichenko D, Philbin J.Facenet: A unified embedding for face recognition andclustering[C]//Proceedings of the IEEE conference on computer vision andpattern recognition. 2015: 815-823.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系列4：人脸表征-续&#34;&gt;系列 4：人脸表征 - 续&lt;/h2&gt;
&lt;h2 id=&#34;一、人脸表征-2&#34;&gt;&lt;strong&gt;一、人脸表征&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;把人脸图像通过神经网络，得到一个特定维数的特征向量，该向量可以很好地表征人脸数据，使得不同人脸的两个特征向量距离尽可能大，同一张人脸的两个特征向量尽可能小，这样就可以通过特征向量来进行人脸识别。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-16.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;二、论文综述-2&#34;&gt;&lt;strong&gt;二、论文综述&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;1-L-Softmax：&#34;&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;L-Softmax：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Softmax Loss 函数被广泛应用于深度学习，较为简单实用，但是它并不能够明确引导神经网络学习区分性较高的特征。L-Softmax 能够有效地引导网络学习使得样本类内距离较小、类间距离较大的特征，L-Softmax 不但能够调节类间距离的间隔（margin）大小，而且能够防止过拟合。&lt;/p&gt;
&lt;p&gt;L-Softmax 是对 softmax loss 的改进，softmax loss 公式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-17.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中 fj 表示最终全连接层的类别输出向量 f 的第 j 个元素，N 为训练样本的个数，则 fyi 可以表示为 fyi=WTyi xi，其中 0≤θj≤π，最终的损失函数可得：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-18.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;softmax 的目的是使得 WT1x&amp;gt;WT2x，即 ∥W1∥∥x∥cos (θ1)&amp;gt;∥W2∥∥x∥cos (θ2)，从而得到输入 x（来自类别 1）输出正确的分类结果。L-Softmax 通过增加一个正整数变量 m，从而产生一个决策余量，能够更加严格地约束上述不等式，即：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-19.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中 0≤θ1&amp;lt;π/m。如果 W1 和 W2 能够满足∥W1∥∥x∥cos (mθ1)&amp;gt;∥W2∥∥x∥cos (θ2)，那么就必然满足∥W1∥∥x∥cos (θ1)&amp;gt;∥W2∥∥x∥cos (θ2)，这样的约束对学习 W1 和 W2 的过程提出了更高的要求，在训练学习过程中，类间要比之前多了一个 m 的间隔，从而使得 1 类和 2 类有了更宽的分类决策边界。这种 Margin Based Classification 使得学习更加的困难，从而使类间距离增加了一个 margin 距离，L-Softmax loss 的总公式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-20.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;当 m 越大时，分类的边界越大，学习难度当然就越高。&lt;/p&gt;
&lt;p&gt;论文仅使用了 WebFace 数据集作为训练集和一个简单的卷积网络，就在 LFW 上达到了 98.71% 的正确率，证明了 L-Softmax loss 取得了比 softmax loss 更好的结果。&lt;/p&gt;
&lt;h3 id=&#34;2-SphereFace&#34;&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;SphereFace :&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;SphereFace 在 MegaFace 数据集上识别率在 2017 年排名第一，提出 A-Softmax Loss 使人脸识别达到不错的效果。A-Softmax Loss 基于 softmax loss 和 L-Softmax loss，在二分类模型中，softmax loss 为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-21.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果 x 为类别一，则希望 p1&amp;gt;p2, 则二分类的划分函数为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-22.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;权重归一化 ||w|| 为 1，b 为 0，此时特征上的点映射到单位超球面上，则二分类的划分函数为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-23.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;然后使用与 L-Softmax loss 相同的原理，使&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-24.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;则 A-Softmax Loss 最终为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-25.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;因此 A-Softmax Loss 是样本类别之间产生了角度距离，让决策函数更加严格并且更加具有可区分性。当 m 增大，角度距离也会增加。&lt;/p&gt;
&lt;p&gt;A-Softmax 与 L-Softmax 的最大区别在于 A-Softmax 的权重归一化了，而 L-Softmax 则没有。A-Softmax 权重的归一化导致特征上的点映射到单位超球面上，A-Softmax 仅仅能从角度上划分类别，而 L-Softmax 是在角度与长度方向进行考量，两个方向如果划分不一就会收到干扰，导致精度下降。&lt;/p&gt;
&lt;p&gt;SphereFace 使用的模型如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-26.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;训练与测试过程如下图所示，在测试过程中使用余弦计算相似度：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-27.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;最终 SphereFace 在训练集较小的情况下，LFW 数据集上准确率为 99.42%。Sphereface 效果很好，但是它不优美。在测试阶段，Sphereface 通过特征间的余弦值来衡量相似性，即以角度为相似性的度量，在训练阶段，其实 Sphereface 的损失函数并不是在直接优化特征与类中心的角度，而是优化特征与类中心的角度在乘上一个特征的长度，这就造成了训练跟测试之间目标不一致。&lt;/p&gt;
&lt;h3 id=&#34;3-Normface&#34;&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;Normface :&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在优化人脸识别任务时，softmax 本身优化的是没有归一化的内积结果，但是最后在预测的时候使用的一般是 cosine 距离或者欧式距离，这会导致优化目标和最终的距离度量其实并不一致。 Normface 的核心思想是既然最后在特征对比的时候使用归一化的 cosine 距离，那么在训练的过程中把特征也做归一化处理，做了归一化之后，softmax 的优化就变成了直接优化 cosine 距离了，归一化过程如下，其中 e 是为了防止除 0 的较小正数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-28.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;相应的损失函数如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-29.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中 W 是归一化的权重，f_i 是归一化的特征，参数 s 的引入是因为保证梯度大小的合理性，去掉 bias 是因为 softmax 之前的 fc 有 bias 的情况下会使得有些类别在角度上没有区分性但是通过 bias 可以区分，在这种情况下如果对 feature 做 normalize，会使得中间的那个小类别的 feature 变成一个单位球形并与其他的 feature 重叠在一起，所以在 feature normalize 的时候是不能加 bias 的。&lt;/p&gt;
&lt;p&gt;Normface 使用了较小的模型使用多种 loss 训练，然后在 LFW 数据集上测试，证明了 feature normalize 的效果，结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142413.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;4-CosFace&#34;&gt;&lt;strong&gt;4.&lt;/strong&gt; &lt;strong&gt;CosFace :&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Normface 用特征归一化解决了 Sphereface 训练和测试不一致的问题。但是却没有了 margin 的惩罚，腾讯 AI Lab 的 CosFace 或者 AM-softmax 是在 Normface 的基础上引入了 margin，损失函数为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-30.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中特征与权值都做了归一化：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-31.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;分类决策为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-32.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;，比之前增加了 m 的 margin，m 是一个超参数，控制惩罚的力度，m 越大，惩罚越强。&lt;/p&gt;
&lt;p&gt;CosFace 使用 mtcnn 进行人脸检测与对齐，人脸表征训练模型使用基于 residual units 64 层卷积网络的 Sphere Face，在 5M 的训练集上训练，在 LFW 数据集上测试，精度达到 99.73%。&lt;/p&gt;
&lt;h3 id=&#34;5-ArcFace&#34;&gt;&lt;strong&gt;5.&lt;/strong&gt; &lt;strong&gt;ArcFace :&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;ArcFace 源于论文 Additive angular margin lossfor deep face recognition，也叫做 InsightFace，论文基本介绍了近期较为流行的人脸识别模型，loss 变化从 softmax 到 AM-softmax，然后提出 ArcFace，可以说起到了很好的综述作用，论文从三个方面探讨影响人脸识别模型精度的主要因素。&lt;/p&gt;
&lt;p&gt;（1）数据：数据方面，论文探讨了各个数据集的数据质量和优缺点，并对 MS-Celeb-1M，MegaFace FaceScrub 做了清洗，清洗后的数据公开。&lt;/p&gt;
&lt;p&gt;（2）网络：详细对比了不同的主流网络结构的性能，包括输入层尺寸大小、最后输出几层的不同结构、基本网络单元残差网络的不同结构、主干网络的不同模型。经过实验的证明，最后的网络结构：输入图片大小 112x112；第一层 convLayer 卷积核为 3&lt;em&gt;3 stride 1 时，网络输出 7&lt;/em&gt;7；主干网络使用 ResNet100，并使用改进后的改进的残差网络结构，如下图；最后的几层输出层为最后一个卷积层后 + BN-Dropout-FC-BN 的结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-33.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;（3）损失函数：与 AM-softmax 相比，区别在于 Arcface 引入 margin 的方式不同，损失函数为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/appotry/cloudimg@latest/data/2021/09/1420210914142652-34.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Arcface 的 m 是在余弦里面，AM-softmax 的在外面，ArcFace 更为直观并且在超球面维度上有更清晰的解释。Arcface 在 VGG2 和 MS-Celeb-1M 数据集上训练，在 LFW 数据集上精度达到 99.83%。&lt;/p&gt;
&lt;h2 id=&#34;三、总结-2&#34;&gt;&lt;strong&gt;三、总结&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;本期文章主要介绍人脸表征相关算法和论文综述，人脸检测、对齐、特征提取等这些操作都可以在静态数据中完成，下一期将给大家介绍在视频数据中进行人脸识别的另一个重要的算法，视频人脸跟踪的概念与方法。&lt;/p&gt;
&lt;h3 id=&#34;参考文献：-4&#34;&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;【1】 Liu W, Wen Y, Yu Z, et al. Large-MarginSoftmax Loss for Convolutional Neural Networks[C]//ICML. 2016: 507-516.1708.&lt;/li&gt;
&lt;li&gt;【2】Liu W, Wen Y, Yu Z, et al. Sphereface:Deep hypersphere embedding for face recognition[C]//The IEEE Conference onComputer Vision and Pattern Recognition (CVPR). 2017, 1: 1.&lt;/li&gt;
&lt;li&gt;【3】Wang F, Xiang X, Cheng J, et al. Normface:l 2 hypersphere embedding for face verification[C]//Proceedings of the 2017 ACMon Multimedia Conference. ACM, 2017: 1041-1049.&lt;/li&gt;
&lt;li&gt;【4】Wang F, Cheng J, Liu W, et al. Additivemargin softmax for face verification[J]. IEEE Signal Processing Letters, 2018,25(7): 926-930.&lt;/li&gt;
&lt;li&gt;【5】Wang H, Wang Y, Zhou Z, et al. CosFace:Large margin cosine loss for deep face recognition[J]. arXiv preprintarXiv:1801.09414, 2018.&lt;/li&gt;
&lt;li&gt;【6】Deng J, Guo J, Zafeiriou S. Arcface:Additive angular margin loss for deep face recognition[J]. arXiv preprintarXiv:1801.07698, 2018.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From： https://cloud.tencent.com/developer/article/1160037?from=article.detail.1344438&lt;/p&gt;
&lt;p&gt;出品 | 磐创 AI 技术团队&lt;/p&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/css/bilicard.css&#34; type=&#34;text/css&#34;&gt;</content>
        <category term="ai" />
        <category term="face" />
        <updated>2021-09-14T04:25:00.000Z</updated>
    </entry>
</feed>
